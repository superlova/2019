<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Superlova</title>
  
  <subtitle>Be a better man...</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://superlova.github.io/"/>
  <updated>2020-06-02T06:50:40.788Z</updated>
  <id>https://superlova.github.io/</id>
  
  <author>
    <name>Superlova</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【论文阅读笔记】Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/</id>
    <published>2020-06-02T06:16:03.000Z</published>
    <updated>2020-06-02T06:50:40.788Z</updated>
    
    <content type="html"><![CDATA[<p>文本领域的对抗样本生成技术综述。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;文本领域的对抗样本生成技术综述。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="Adversarial Attacks" scheme="https://superlova.github.io/tags/Adversarial-Attacks/"/>
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="survey" scheme="https://superlova.github.io/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】 Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/</id>
    <published>2020-06-02T06:02:29.000Z</published>
    <updated>2020-06-02T06:50:27.694Z</updated>
    
    <content type="html"><![CDATA[<p>通过模糊测试进行数据增强，数据增强新思路。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过模糊测试进行数据增强，数据增强新思路。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="Fuzz Testing" scheme="https://superlova.github.io/tags/Fuzz-Testing/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91EDA-Easy-Data-Augmentation-Techniques-for-Boosting-Performance-on-Text-Classification-Tasks/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91EDA-Easy-Data-Augmentation-Techniques-for-Boosting-Performance-on-Text-Classification-Tasks/</id>
    <published>2020-06-02T06:01:54.000Z</published>
    <updated>2020-06-02T06:50:44.567Z</updated>
    
    <content type="html"><![CDATA[<p>这篇论文介绍了一个文本领域的数据增强工具，提出了一些数据增强方法。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇论文介绍了一个文本领域的数据增强工具，提出了一些数据增强方法。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="Text Classification" scheme="https://superlova.github.io/tags/Text-Classification/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】A survey on Image Data Augmentation for Deep Learning</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91A-survey-on-Image-Data-Augmentation-for-Deep-Learning/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91A-survey-on-Image-Data-Augmentation-for-Deep-Learning/</id>
    <published>2020-06-02T06:01:16.000Z</published>
    <updated>2020-06-02T06:52:12.004Z</updated>
    
    <content type="html"><![CDATA[<p>图像领域的对抗样本生成技术综述。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;图像领域的对抗样本生成技术综述。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="survey" scheme="https://superlova.github.io/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>Datawhale——SVHN——Task05：模型集成</title>
    <link href="https://superlova.github.io/2020/06/02/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task05%EF%BC%9A%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90/"/>
    <id>https://superlova.github.io/2020/06/02/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task05%EF%BC%9A%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90/</id>
    <published>2020-06-02T02:18:31.000Z</published>
    <updated>2020-06-02T02:19:10.962Z</updated>
    
    <content type="html"><![CDATA[<p>模型的训练和验证过程，基本到了最后咯。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;模型的训练和验证过程，基本到了最后咯。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="datawhale" scheme="https://superlova.github.io/tags/datawhale/"/>
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>numpy拼合数组方法大全</title>
    <link href="https://superlova.github.io/2020/06/01/numpy%E6%8B%BC%E5%90%88%E6%95%B0%E7%BB%84/"/>
    <id>https://superlova.github.io/2020/06/01/numpy%E6%8B%BC%E5%90%88%E6%95%B0%E7%BB%84/</id>
    <published>2020-06-01T08:39:58.000Z</published>
    <updated>2020-06-02T04:23:43.383Z</updated>
    
    <content type="html"><![CDATA[<p>numpy的一大特色就是其内部的矩阵向量运算。矩阵之间的拼接方法，你掌握多少？<br><a id="more"></a></p><h2 id="1-append拼接"><a href="#1-append拼接" class="headerlink" title="1. append拼接"></a>1. append拼接</h2><p>我们都知道对于Python原生列表list来说，append是最方便的添加元素的方法，一句list.append(elem)就能在列表最后添加一个元素。</p><p>在numpy中，append也是一个直观且好用的方法，np.append(A,B)能够直接拼合两个ndarray数组。</p><p>首先我们新建两个三维数组，一个全为零，一个全为一。</p><pre><code class="lang-python">C = np.zeros((2,2,2))D = np.ones((2,2,2))print(&quot;C: &quot;, C, C.shape)print(&quot;D: &quot;, D, D.shape)C:  [[[0. 0.]  [0. 0.]] [[0. 0.]  [0. 0.]]] shape=(2, 2, 2)D:  [[[1. 1.]  [1. 1.]] [[1. 1.]  [1. 1.]]] shape=(2, 2, 2)</code></pre><p>然后我们采用不同的方法将其拼合在一起。</p><p>首先是append(C,D)这种直观的方法，可以看到C和D都被展开成了一维。</p><pre><code class="lang-python">np.append(C,D)array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])</code></pre><p>在很多时候我们希望数组拼接时能够保持原有的维度，按照行拼接/列拼接/其他维度拼接。此时只需要改动append的参数axis即可。</p><pre><code class="lang-python">np.append(C,D,axis=0)array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.append(C,D,axis=1)array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])np.append(C,D,axis=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><p>对于三维数组，axis=0为层，axis=1为行，axis=2为列。这不难理解，因为确定单位数组中元素位置的坐标就是(层，行，列)</p><h2 id="2-concatenate拼接"><a href="#2-concatenate拼接" class="headerlink" title="2. concatenate拼接"></a>2. concatenate拼接</h2><p>concatenate从字面意义上就让人明白这个函数专门负责数组拼接。不仅仅是两个，还可以负责多个数组一起拼接。理论上来说concatenate的速度和内存消耗都比append要小，但我并没有实际做实验验证。</p><pre><code class="lang-python">np.concatenate((C,D)) # default axis=0array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.concatenate((C,D), axis=1) # =np.append(C,D,axis=1)array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])</code></pre><h2 id="3-stack系列"><a href="#3-stack系列" class="headerlink" title="3. stack系列"></a>3. stack系列</h2><p>stack系列函数包括np.stack/hstack/vstack/dstack/column_stack/row_stack，顾名思义，hstack是按照横向拼接，vstack竖着拼接，dstack则是层叠数组。其实我最烦这种抽象描述了，因为二维数组和三维数组/高维数组的抽象描述根本不一致，还是axis好。不明白axis的同学可以看<a href="https://superlova.github.io/2020/05/19/numpy%E4%B8%ADaxis%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/">这篇文章</a>。</p><pre><code class="lang-python">np.hstack((C,D)) # = np.append(C,D,axis=1) = np.column_stack()array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])np.vstack((C,D)) # =np.append(C,D,axis=0) = np.row_stack()array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.dstack((C,D)) # =np.append(C,D,aixs=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><h2 id="4-np-r"><a href="#4-np-r" class="headerlink" title="4. np.r_[]"></a>4. np.r_[]</h2><p>神奇的numpy总能给出神奇的解法。np.r_是构建数组/拼合数组的最简便写法，但不一定是好理解的。这种写法和之前写的append没什么不同，但是更加简洁。你也可以使用np.r_做出更加复杂的功能。</p><p>一言以蔽之，np.r_[]表达式能够快速使得多个在中括号里面的array/array切片，按照axis=0拼接起来。</p><p>np.r_[]存在两种使用情况：</p><ol><li>如果中括号内部是由若干逗号(comma,)分隔的array，就将他们按照axis=0拼接起来。</li><li>如果中括号内部包括矩阵切片(slices)或者标量(scalars)，就将他们全部变成一维数组首尾相接。</li></ol><p><strong>注意：</strong></p><ul><li>中括号<code>[3:6:1]</code>内部代表的切片，其含义相当于<code>np.arange(3,6,1)</code>，即在<code>[3,6)</code>范围内，从3开始走一步取一个元素，也就是<code>[3,4,5]</code>。</li><li>中括号<code>[0:5:3j]</code>在最后加了字母<code>j</code>，相当于<code>np.linspace(0,5,3,endpoint=True)</code>，在<code>[0,5]</code>范围内，均匀地取三个元素。</li></ul><pre><code class="lang-python">np.r_[C,D] # =np.append(C,D,axis=0)array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.r_[0:10:3, 0:5:4j]array([0.        , 3.        , 6.        , 9.        , 0.        ,       1.66666667, 3.33333333, 5.        ])</code></pre><p>在中括号内，如果最开始是一个<strong>特定的字符串</strong>，np.r_会试图根据字符串的含义，改变其输出格式。</p><ul><li><code>np.r_[&#39;r&#39;, index_expression]</code>和<code>np.r_[&#39;c&#39;, index_expression]</code>将输出从array类型转变成matrix类型。<code>np.r_[&#39;c&#39;, index_expression]</code>会把一维index_expression组装成N*1的列向量。</li></ul><pre><code class="lang-python">np.r_[&quot;r&quot;, 0:10:3, 0:5:4j]matrix([[0.        , 3.        , 6.        , 9.        , 0.        ,         1.66666667, 3.33333333, 5.        ]])np.r_[&quot;c&quot;, 0:10:3, 0:5:4j]matrix([[0.        ],        [3.        ],        [6.        ],        [9.        ],        [0.        ],        [1.66666667],        [3.33333333],        [5.        ]])</code></pre><ul><li><code>np.r_[&quot;n&quot;, index_expression]</code>前面字符串是整数，则拼接时将会按照axis=n进行拼接。</li></ul><pre><code class="lang-python">np.r_[&quot;-1&quot;,C,D]array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><h2 id="5-np-c"><a href="#5-np-c" class="headerlink" title="5. np.c_"></a>5. np.c_</h2><p>在日常使用时，我们经常需要按照最后一个维度拼合两个数组，也就是np.r_[‘-1’,index_expression]。此时我们可以直接使用<code>np.c_[]</code></p><pre><code class="lang-python">np.c_[C,D] # =np.append(C,D,axis=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])np.c_[0:10:3, 0:5:4j]array([[0.        , 0.        ],       [3.        , 1.66666667],       [6.        , 3.33333333],       [9.        , 5.        ]])</code></pre><p>关于numpy中的<code>np.c_</code>和<code>np.r_</code>相关知识，可以参考<a href="https://numpy.org/devdocs/reference/generated/numpy.r_.html#numpy.r_" target="_blank" rel="noopener">官方文档</a>，里面有关于中括号前参数的详细解释。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;numpy的一大特色就是其内部的矩阵向量运算。矩阵之间的拼接方法，你掌握多少？&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="numpy" scheme="https://superlova.github.io/tags/numpy/"/>
    
      <category term="concatenate" scheme="https://superlova.github.io/tags/concatenate/"/>
    
      <category term="array" scheme="https://superlova.github.io/tags/array/"/>
    
  </entry>
  
  <entry>
    <title>移动硬盘文件或目录损坏且无法读取解决方法</title>
    <link href="https://superlova.github.io/2020/05/31/%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%E6%8D%9F%E5%9D%8F%E4%B8%94%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/05/31/%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%E6%8D%9F%E5%9D%8F%E4%B8%94%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</id>
    <published>2020-05-31T07:33:24.000Z</published>
    <updated>2020-05-31T09:06:18.674Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h2><p>家里的移动硬盘寿命已有4年之久，里面存储了200多G的学习资料（字面意思）。今天我将其插在系统为win10的电脑上，却出现了以下情况：</p><ul><li>硬盘通电指示灯亮；</li><li>右下角托盘区域出现usb插入提示，并可以点击“安全删除硬件”；</li><li>在“我的电脑”界面，显示“本地磁盘 D:”，但是双击之后出现错误“文件或目录损坏且无法读取”。</li></ul><p>重启电脑、重新插拔、更换另一台win7系统的电脑，都是该状况。至此基本确定是移动硬盘本身的问题。</p><h2 id="硬盘参数："><a href="#硬盘参数：" class="headerlink" title="硬盘参数："></a>硬盘参数：</h2><ul><li>黑甲虫 640G 移动机械硬盘</li><li>磁盘格式为NTFS</li><li>使用4年有余</li><li>之前出现过数据丢失的状况，转移敏感数据之后，在该盘中只留有非敏感的学习资料，约280G</li></ul><p>查阅资料可知，我这种错误大概率是由于某次未断电插拔硬盘导致的文件目录错误。好消息是，这种错误可以通过一句简单的指令解决。</p><h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><ol><li>打开cmd</li><li>输入 chkdsk D: /f 请注意，我的移动硬盘盘符为D:</li></ol><p>参考：<a href="https://cloud.tencent.com/developer/article/1487000" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1487000</a></p><p>chkdsk 参数说明：</p><p>volume 指定驱动器(后面跟一个冒号)、装入点或卷名。<br>filename 仅用于 FAT/FAT32: 指定要检查是否有碎片的文件<br>/F 修复磁盘上的错误。<br>/V　 在 FAT/FAT32 上: 显示磁盘上每个文件的完整路径和名称。在 NTFS 上: 如果有清除消息，将其显示。<br>/R 查找不正确的扇区并恢复可读信息(隐含 /F)。<br>/L:size 仅用于 NTFS:? 将日志文件大小改成指定的 KB 数。如果没有指定大小，则显示当前的大小。<br>/X 如果必要，强制卷先卸下。卷的所有打开的句柄就会无效(隐含 /F)<br>/I 仅用于 NTFS: 对索引项进行强度较小的检查<br>/C 仅用于 NTFS: 跳过文件夹结构的循环检查。<br>/I 和 /C 命令行开关跳过卷的某些检查，减少运行 Chkdsk 所需的时间</p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>这种错误一般产生于外置移动硬盘上面，或者外置U盘等等。之所以产生这些问题，一般有以下几个原因：</p><ol><li>没有点击“安全删除硬件”直接拔USB接口导致系统没有完成读写操作。这会使得文件目录不完整，损坏文件目录系统。</li><li>劣质产品，或者劣质硬盘盒。硬盘盒内部的电源、电路供电不稳定，也会产生文件系统错误的状况。</li><li>停电了</li></ol><h2 id="恢复效果质量"><a href="#恢复效果质量" class="headerlink" title="恢复效果质量"></a>恢复效果质量</h2><p>如果是大移动硬盘并且是NTFS分区格式的，恢复质量十分理想，基本都能成功恢复文件和目录结构。</p><p>如果是FAT或FAT32格式，根据损坏程度不同，恢复质量效果比NTFS格式结构的分区稍差一些，所以日常使用建议使用NTFS格式分区，其数据安全性更高一些。</p><p>一般情况下，CHKDSK可以成功修复出错的分区。但仍有可能没有反应。此时建议不要拔出设备，重启电脑，再观察是否仍然错误。 如果故障依然存在，可以尝试用EasyRecovery、R-STUDIO等软件恢复分区数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题描述：&quot;&gt;&lt;a href=&quot;#问题描述：&quot; class=&quot;headerlink&quot; title=&quot;问题描述：&quot;&gt;&lt;/a&gt;问题描述：&lt;/h2&gt;&lt;p&gt;家里的移动硬盘寿命已有4年之久，里面存储了200多G的学习资料（字面意思）。今天我将其插在系统为win10的电脑上，
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="hardware" scheme="https://superlova.github.io/tags/hardware/"/>
    
      <category term="移动硬盘" scheme="https://superlova.github.io/tags/%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98/"/>
    
  </entry>
  
  <entry>
    <title>numpy中delete的使用方法</title>
    <link href="https://superlova.github.io/2020/05/31/np-delete%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/05/31/np-delete%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2020-05-31T05:10:08.000Z</published>
    <updated>2020-05-31T09:03:47.140Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍np.delete中的参数及使用方法<br><a id="more"></a></p><h2 id="Python中列表元素删除"><a href="#Python中列表元素删除" class="headerlink" title="Python中列表元素删除"></a>Python中列表元素删除</h2><p>在列表中删除元素，我们可以：</p><pre><code class="lang-python">list_a = [1,2,3,4,5]list_a.pop(-1)print(list_a) # [1,2,3,4]del list_a[0]print(list_a) # [2,3,4]del list[1:]print(list_a) # [2]</code></pre><h2 id="在numpy的ndarray中删除元素"><a href="#在numpy的ndarray中删除元素" class="headerlink" title="在numpy的ndarray中删除元素"></a>在numpy的ndarray中删除元素</h2><p>numpy中的数组ndarray是定长数组，对ndarray的处理不像对python中列表的处理那么方便。想要删除ndarray中的元素，我们往往只能退而求其次，返回一个没有对应元素的副本。在numpy中我们一般使用delete函数。此外，numpy的delete是可以删除数组的整行和整列的。</p><p>简单介绍一下<code>np.delete</code>：</p><pre><code class="lang-python">numpy.delete(arr, obj, axis=None)</code></pre><ul><li>arr：输入数组</li><li>obj：切片，整数，表示哪个子数组要被移除</li><li>axis：删除子数组的轴</li><li>返回：一个新的子数组</li></ul><p>下面是使用举例：</p><pre><code class="lang-python">A = np.arange(15).reshape((3,5))print(A)[[ 0  1  2  3  4] [ 5  6  7  8  9] [10 11 12 13 14]]B = np.delete(A, 1) # 先把A给ravel成一维数组，再删除第1个元素。C = np.delete(A, 1, axis=0) # axis=0代表按行操作D = np.delete(A, 1, axis=1) # axis=1代表按列操作print(A) # 并没有改变，delete不会操作原数组。[[ 0  1  2  3  4] [ 5  6  7  8  9] [10 11 12 13 14]]print(B) # 先把A给ravel成一维数组，再删除第1个元素。[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]print(C) # axis=0代表按行操作[[ 0  1  2  3  4] [10 11 12 13 14]]print(D) # axis=1代表按列操作[[ 0  2  3  4] [ 5  7  8  9] [10 12 13 14]]</code></pre><p>不了解axis的读者可以看我写的<a href="https://superlova.github.io/2020/05/19/numpy%E4%B8%ADaxis%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/">这篇文章</a>。</p><h2 id="在np-delete的index参数中应用切片操作"><a href="#在np-delete的index参数中应用切片操作" class="headerlink" title="在np.delete的index参数中应用切片操作"></a>在np.delete的index参数中应用切片操作</h2><p>index参数必须是个由整数元素组成的列表，内部存放着的整数代表着目标array的下标。</p><p>当我想实现删除从第5个到第100个之间的所有元素时，不能使用slice，这就比较尴尬了。</p><pre><code class="lang-python">In [5]: np.delete(x, [3:6])  File &quot;&lt;ipython-input-215-0a5bf5cc05ba&gt;&quot;, line 1    np.delete(x, [3:6])                   ^SyntaxError: invalid syntax</code></pre><p>我们没办法在函数参数部分让其接受slice。怎么解决呢？我们可以把参数从<code>[start:end]</code>换成<code>A[start:end]</code>吗？</p><pre><code class="lang-python">A = np.arange(10)*2print(A)[ 0  2  4  6  8 10 12 14 16 18]B = np.delete(A, A[1:4]) # 搞错了吧！预期结果：0 8 10 12 14 16 18print(B)[ 0  2  6 10 14 16 18]</code></pre><p>我们这段代码能够执行，但是不是我们想要的结果。什么原因呢？是因为np.delete的index参数接受的是下标数组，而A[1:4]=[2,4,6]，那么np.delete就忠实地执行了删除第2、4、6个元素的任务。但我们的本意只是想删除下标从1到4的元素而已。</p><pre><code class="lang-python">D = np.delete(A, [1,2,3])print(D) # [ 0  8 10 12 14 16 18]</code></pre><p>要想使用slice，可以采用下列方式：1. <code>slice</code>函数或者<code>range</code>函数；2. <code>np.s_</code></p><pre><code class="lang-python">C = np.delete(A, slice(1,4))print(C) # [ 0  8 10 12 14 16 18]E = np.delete(A, np.s_[1:4])print(E) # [ 0  8 10 12 14 16 18]</code></pre><p>其实<code>np.s_[1:4]</code>只不过是很方便产生slice(1,4)的一种方式而已。</p><h2 id="其他实用的方法"><a href="#其他实用的方法" class="headerlink" title="其他实用的方法"></a>其他实用的方法</h2><p>除此之外，我们还可以采用mask的方式选择原数组中的元素组成新数组</p><pre><code class="lang-python">mask = np.ones((len(A),), dtype=bool)mask[[1,2,3]] = Falseprint(A[mask]) # [ 0  8 10 12 14 16 18]</code></pre><p>或者干脆采用数组拼合的方式</p><pre><code class="lang-python">G = np.empty(len(A)-len(A[1:4]), dtype=int)G[0:1] = A[0:1]G[1:len(G)] = A[4:]print(G) # [ 0  8 10 12 14 16 18]</code></pre><p>后两种方法不像我们想象的那么没用，反而很常见，尤其是mask方法。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍np.delete中的参数及使用方法&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="numpy" scheme="https://superlova.github.io/tags/numpy/"/>
    
      <category term="slice" scheme="https://superlova.github.io/tags/slice/"/>
    
  </entry>
  
  <entry>
    <title>Datawhale——SVHN——Task04：模型训练与验证</title>
    <link href="https://superlova.github.io/2020/05/30/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task04%EF%BC%9A%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%AA%8C%E8%AF%81/"/>
    <id>https://superlova.github.io/2020/05/30/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task04%EF%BC%9A%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%AA%8C%E8%AF%81/</id>
    <published>2020-05-30T13:13:01.000Z</published>
    <updated>2020-05-30T14:17:39.933Z</updated>
    
    <content type="html"><![CDATA[<p>模型的训练和验证过程，基本到了最后咯。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;模型的训练和验证过程，基本到了最后咯。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="datawhale" scheme="https://superlova.github.io/tags/datawhale/"/>
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Validation" scheme="https://superlova.github.io/tags/Validation/"/>
    
      <category term="Verification" scheme="https://superlova.github.io/tags/Verification/"/>
    
  </entry>
  
  <entry>
    <title>Datawhale——SVHN——Task03：字符识别</title>
    <link href="https://superlova.github.io/2020/05/27/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task03%EF%BC%9A%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB/"/>
    <id>https://superlova.github.io/2020/05/27/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task03%EF%BC%9A%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB/</id>
    <published>2020-05-27T05:30:18.000Z</published>
    <updated>2020-06-02T02:14:29.587Z</updated>
    
    <content type="html"><![CDATA[<p>介绍常见的字符识别模型<br><a id="more"></a></p><h2 id="用-tf-data-加载图片"><a href="#用-tf-data-加载图片" class="headerlink" title="用 tf.data 加载图片"></a>用 tf.data 加载图片</h2><h2 id="用CNN建立字符识别模型"><a href="#用CNN建立字符识别模型" class="headerlink" title="用CNN建立字符识别模型"></a>用CNN建立字符识别模型</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍常见的字符识别模型&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="datawhale" scheme="https://superlova.github.io/tags/datawhale/"/>
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Digit Recognition" scheme="https://superlova.github.io/tags/Digit-Recognition/"/>
    
  </entry>
  
  <entry>
    <title>Datawhale——SVHN——Task02：数据扩增</title>
    <link href="https://superlova.github.io/2020/05/23/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task02%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%89%A9%E5%A2%9E/"/>
    <id>https://superlova.github.io/2020/05/23/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task02%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%89%A9%E5%A2%9E/</id>
    <published>2020-05-23T13:15:18.000Z</published>
    <updated>2020-06-02T06:57:05.053Z</updated>
    
    <content type="html"><![CDATA[<p>训练模型第一步、数据读取和扩增！<br><a id="more"></a></p><h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><p>图像领域的数据读取方法，使用Pillow或者OpenCV内置的函数即可。</p><h2 id="数据扩增"><a href="#数据扩增" class="headerlink" title="数据扩增"></a>数据扩增</h2><p>在读取图像时，还可以对原始图像添加扰动等，这就启发我们一件事：是不是对原数据增加一些扰动，就可以使其变成新的数据呢？</p><p>下面介绍利用该思想的数据扩增环节。</p><h3 id="1-数据扩增为什么会有用"><a href="#1-数据扩增为什么会有用" class="headerlink" title="1. 数据扩增为什么会有用"></a>1. 数据扩增为什么会有用</h3><p>数据扩增的最常见作用，是增加数据集，用以缓解样本量不足导致的模型过拟合现象，从而提升模型的泛化性能。</p><p>究其本质，还是扩展数据集的多样性。</p><p>试想一下，我们如果想要试图训练一个完美模型，必然要利用完美的架构+完美的训练集，这个完美的训练集必然要覆盖到样本空间的方方面面。</p><p>我们当然不可能真的搞到无限多的样本。所以为了尽可能趋近于这个目标，就要试图以有限的数据集覆盖无限的样本空间。</p><p>每个样本在样本空间中就是一个坐标点。通过添加扰动，就能生成许多个在该样本点附近的增强样本。</p><p>上一个利用样本空间中添加扰动、从而生成与原样本很相似的应用，叫做<strong>生成对抗样本</strong>。</p><p>数据增强和对抗样本生成之间的区别在于，数据增强要保证扰动之后样本不能和原样本有区别；然而对抗样本生成则保证<strong>必须</strong>与原样本有区别。</p><p>有一些学者也通过将对抗样本添加至模型重训练的方法，使模型的泛化性能得到了提高。这说明数据增强和对抗样本的生效原理是一样的，都是通过扩大样本覆盖的样本空间的程度，通俗来讲就是模型见多识广了，再碰到新的问题也不怕了。</p><p>可以参考这篇论文：<a href="https://arxiv.org/abs/2003.08773" target="_blank" rel="noopener">Do CNNs Encode Data Augmentations?</a></p><h3 id="2-常见的数据扩增"><a href="#2-常见的数据扩增" class="headerlink" title="2. 常见的数据扩增"></a>2. 常见的数据扩增</h3><h4 id="2-1-图像数据扩增"><a href="#2-1-图像数据扩增" class="headerlink" title="2.1 图像数据扩增"></a>2.1 图像数据扩增</h4><ul><li><p>色彩抖动（Color Jittering）<br>调整图片的亮度、饱和度、对比度，针对图像的颜色进行的数据增强。<br>对比度受限自适应直方图均衡化算法（Clahe），锐化（Sharpen），凸点（Emboss）</p></li><li><p>主成分噪声（PCA  Jittering）<br>首先按照RGB三个颜色通道计算均值和标准差，对网络的输入数据进行规范化；再在整个训练集上计算协方差矩阵，进行特征分解，得到特征向量和特征值，最后做PCA Jittering；最后对RGB空间做PCA，然后对主成分做一个(0, 0.1)的高斯扰动。</p></li><li><p>弹性变换（Elastic Transform）</p></li></ul><p>算法一开始是由Patrice等人在2003年的ICDAR上发表的《Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis》提出的，最开始应用在mnist手写体数字识别数据集中。当前也有很多人把该方法应用到手写体汉字的识别问题中。</p><p>首先对于图像中的每个像素点，产生对应的随机数对$(\Delta x, \Delta y)$，大小介于-1~1之间，分别表示该像素点的x方向和y方向的移动距离；<br>然后生成一个以0为均值，以σ为标准差的高斯核$k_{nn}$，并用前面的随机数与之做卷积，并将结果作用于原图像。</p><p><img src="https://www.kaggleusercontent.com/kf/1181488/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..JOqe3f7Joxv4qWUFbLMQew.CgYzaNwIIFF7jVY1bX0NSs1-ti8NMrPcp61few_93xUuYBRF6ug3wh2awESp_gDWx1BvlZAI45TF3uJ5vNqVLNPS4sIjHMM1oX721fmldeIQAnh84dOKzvTaIK-J0HFhapl_dyBAcV7yOQY_GQYR2MJi3SrPLxvekt-t1hEL0pSdWIl3wbeghVLpgUBg1VmFUFvkti7XL0GltuXOPuQMylsbdbz4GpKX-4gIWyVr301jLLOH-woNbaJuPN0DI4346ok8sJIoG2k7ZdBLq9xRunhHHe4UvmWx2Dj0OK9g8vjKZGA2pRQcxd6_-vWj1KLYyFEWzBWK67rMSFLsQ3zi287T1NK8VJ9C0fLm6FdrQSA4v3BrgbHMwWijkcvG0MdMIdRdZxWbhmxYQ_eKLGntll-2k_1UMFID03h4qjFU-1p2HWv8VktUcpHhvUtu-N26j0vOuWXI484Ttwm2kBkiPZxD0jAfIUVIpSP6pVOTd-E6drxGbr_bqcycOJP2BSzOb5fMqCuP7f_c0B3fnVgVU7-SCb5ngcW6M4ayyy9SNfpobLc2pYj47aTlMmz0iXRrofaEcXiVzhlKz_r8EUUXAkPw5F_X5heFp2S_0hJpKpQJPsssty6FG_PwzN7b5BoSa2mxcNpqiX4ADy-J1dwXzgQesePXPj3rVyQAjxcQmQfXNKVKCo6ASCMBkJsnSQb3.npeRt-2aWHuMiEMkWLKuxA/__results___files/__results___5_1.png" srcset="/img/loading.gif" alt></p><p>参考：<br><a href="https://www.kaggle.com/jiqiujia/elastic-transform-for-data-augmentation" target="_blank" rel="noopener">https://www.kaggle.com/jiqiujia/elastic-transform-for-data-augmentation</a><br><a href="https://blog.csdn.net/lhanchao/article/details/54234490" target="_blank" rel="noopener">https://blog.csdn.net/lhanchao/article/details/54234490</a></p><p>还有诸如透视变换（Perspective Transform）、分段仿射变换（Piecewise Affine transforms）、枕形畸变（Pincushion Distortion）等不同的图像变换操作。</p><p>根据Datawhale大佬分享，对于本次题目（SVHN街道彩色数字识别），最常见的、最有效的数据扩增方法是：</p><ul><li>随机改变大小（resize）</li><li>随机切割（randomcrop），即从原始图像中，随机的crop出一些图像。</li></ul><p>鉴于本次数据集中的图片大小不一，一般一开始我们都需要resize到指定大小。但也有的文章中提到了，先对图片resize会使得图片长宽比发生变化，造成失真。所以我们要具体问题具体分析。</p><p>我在博客中也有分享过一篇讲述图像数据增强的<a href>相关论文</a>，大家可以看一下。</p><h4 id="2-2-文本数据增强"><a href="#2-2-文本数据增强" class="headerlink" title="2.2 文本数据增强"></a>2.2 文本数据增强</h4><p>此部分参考我的<a href>文本数据增强</a>，而且由于本次赛题并不必进行文本数据增强，因此就不在这里赘述了。</p><h3 id="3-数据扩增实战——使用tensorflow"><a href="#3-数据扩增实战——使用tensorflow" class="headerlink" title="3.. 数据扩增实战——使用tensorflow"></a>3.. 数据扩增实战——使用tensorflow</h3><p>大家都用的Pytorch吗？不会只有我自己用tensorflow吧。我来给大家介绍一下tensorflow是怎么做数据扩增的。</p><p>参考：<a href="https://www.tensorflow.org/tutorials/images/data_augmentation" target="_blank" rel="noopener">TensorFlow Core</a></p><h4 id="1-准备"><a href="#1-准备" class="headerlink" title="1. 准备"></a>1. 准备</h4><pre><code class="lang-python"># 首先安装一个tensorflow_docs的库!pip install git+https://github.com/tensorflow/docsimport urllib # 负责下载网上的图片import tensorflow as tffrom tensorflow.keras.datasets import mnistfrom tensorflow.keras import layersAUTOTUNE = tf.data.experimental.AUTOTUNEimport tensorflow_docs as tfdocsimport tensorflow_docs.plotsimport tensorflow_datasets as tfdsimport PIL.Image # 大名鼎鼎PILimport matplotlib.pyplot as pltimport matplotlib as mplmpl.rcParams[&#39;figure.figsize&#39;] = (12, 5)import numpy as np</code></pre><p>下载一张示例图片：</p><pre><code class="lang-python">image_path = tf.keras.utils.get_file(&quot;cat.jpg&quot;, &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg&quot;)PIL.Image.open(image_path)</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-29-50.png" srcset="/img/loading.gif" alt></p><p>将该图片解析成tensor</p><pre><code class="lang-python">image_string=tf.io.read_file(image_path)image=tf.image.decode_jpeg(image_string,channels=3)</code></pre><p>定义一个函数，用于可视化图像。</p><pre><code class="lang-python">def visualize(original, augmented):  fig = plt.figure()  plt.subplot(1,2,1)  plt.title(&#39;Original image&#39;)  plt.imshow(original)  plt.subplot(1,2,2)  plt.title(&#39;Augmented image&#39;)  plt.imshow(augmented)</code></pre><h4 id="2-执行数据扩增"><a href="#2-执行数据扩增" class="headerlink" title="2. 执行数据扩增"></a>2. 执行数据扩增</h4><p><strong>翻转图像</strong></p><pre><code class="lang-python">flipped = tf.image.flip_left_right(image)visualize(image, flipped)</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-32-30.png" srcset="/img/loading.gif" alt></p><p><strong>灰度处理</strong></p><pre><code class="lang-python">grayscaled = tf.image.rgb_to_grayscale(image)visualize(image, tf.squeeze(grayscaled))plt.colorbar()</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-33-51.png" srcset="/img/loading.gif" alt></p><p><strong>改变图像饱和度</strong></p><pre><code class="lang-python">saturated = tf.image.adjust_saturation(image, 3)visualize(image, saturated)</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-35-05.png" srcset="/img/loading.gif" alt></p><p><strong>改变图像亮度</strong></p><pre><code class="lang-python">bright = tf.image.adjust_brightness(image, 0.4)visualize(image, bright)</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-35-39.png" srcset="/img/loading.gif" alt></p><p><strong>旋转图像</strong></p><pre><code class="lang-python">rotated = tf.image.rot90(image)visualize(image, rotated)</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-36-11.png" srcset="/img/loading.gif" alt></p><p><strong>中心放大并裁剪图像</strong></p><pre><code class="lang-python">cropped = tf.image.central_crop(image, central_fraction=0.5)visualize(image,cropped)</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-36-51.png" srcset="/img/loading.gif" alt></p><p>等等此类操作，不一而足。大家感兴趣的可以查阅tensorflow的<code>tf.image</code>文档。</p><h4 id="3-使用扩增数据集训练"><a href="#3-使用扩增数据集训练" class="headerlink" title="3. 使用扩增数据集训练"></a>3. 使用扩增数据集训练</h4><p>我们构造一个模型，该模型架构为纯全连接网络，数据集为MNIST手写数字识别数据集。我们可以直接在tensorflow_datasets这个库中使用这个数据集。</p><pre><code class="lang-python">dataset, info =  tfds.load(&#39;mnist&#39;, as_supervised=True, with_info=True)train_dataset, test_dataset = dataset[&#39;train&#39;], dataset[&#39;test&#39;]num_train_examples= info.splits[&#39;train&#39;].num_examples</code></pre><p>编写函数执行对原来数据集的扩增操作。</p><pre><code class="lang-python">def convert(image, label):  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]  return image, labeldef augment(image,label):  image,label = convert(image, label)  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]  image = tf.image.resize_with_crop_or_pad(image, 34, 34) # Add 6 pixels of padding  image = tf.image.random_crop(image, size=[28, 28, 1]) # Random crop back to 28x28  image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness  return image,label</code></pre><pre><code class="lang-python">BATCH_SIZE = 64# Only use a subset of the data so it&#39;s easier to overfit, for this tutorialNUM_EXAMPLES = 2048</code></pre><p>创建扩增后的数据集</p><pre><code class="lang-python">augmented_train_batches = (    train_dataset    # Only train on a subset, so you can quickly see the effect.    .take(NUM_EXAMPLES)    .cache()    .shuffle(num_train_examples//4)    # The augmentation is added here.    .map(augment, num_parallel_calls=AUTOTUNE)    .batch(BATCH_SIZE)    .prefetch(AUTOTUNE))</code></pre><p>为了对照，我们创建没有扩增的数据集。</p><pre><code class="lang-python">non_augmented_train_batches = (    train_dataset    # Only train on a subset, so you can quickly see the effect.    .take(NUM_EXAMPLES)    .cache()    .shuffle(num_train_examples//4)    # No augmentation.    .map(convert, num_parallel_calls=AUTOTUNE)    .batch(BATCH_SIZE)    .prefetch(AUTOTUNE))</code></pre><p>设置验证集。验证集与数据增不增强无关，反正我们不使用验证机训练，只用于最后的打分。</p><pre><code class="lang-python">validation_batches = (    test_dataset    .map(convert, num_parallel_calls=AUTOTUNE)    .batch(2*BATCH_SIZE))</code></pre><p>建立模型。注意这个模型纯粹是为了体现数据扩增的效果而专门构建的，因为卷积网络CNN即便是不用数据扩增也能很好地解决MNIST手写数字识别问题，这样比较起来效果就不明显了。两层4096个神经元的全连接网络，激活函数为RELU。最后是一个softmax层分类。</p><pre><code class="lang-python">def make_model():  model = tf.keras.Sequential([      layers.Flatten(input_shape=(28, 28, 1)),      layers.Dense(4096, activation=&#39;relu&#39;),      layers.Dense(4096, activation=&#39;relu&#39;),      layers.Dense(10)  ])  model.compile(optimizer = &#39;adam&#39;,                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),                metrics=[&#39;accuracy&#39;])  return model</code></pre><p>先使用<strong>没有经过数据扩增</strong>的数据训练模型，并记录其精度变化和loss变化：</p><pre><code class="lang-python">model_without_aug = make_model()no_aug_history = model_without_aug.fit(non_augmented_train_batches, epochs=50, validation_data=validation_batches)</code></pre><p>再使用<strong>经过扩增的数据</strong>训练模型，并记录。</p><pre><code class="lang-python">model_with_aug = make_model()aug_history = model_with_aug.fit(augmented_train_batches, epochs=50, validation_data=validation_batches)</code></pre><p>最后绘制图标，看一下表现。</p><p>首先是精度随着训练轮次的变化曲线：</p><pre><code class="lang-python">plotter = tfdocs.plots.HistoryPlotter()plotter.plot({&quot;Augmented&quot;: aug_history, &quot;Non-Augmented&quot;: no_aug_history}, metric = &quot;accuracy&quot;)plt.title(&quot;Accuracy&quot;)plt.ylim([0.75,1])</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-49-01.png" srcset="/img/loading.gif" alt></p><p>从图中可以看出，橙色线（没有数据增强的模型）在训练的时候很容易过拟合，但是在验证集上的精度不及蓝色线（数据增强的模型）。</p><p>再来看loss变化。</p><pre><code class="lang-python">plotter = tfdocs.plots.HistoryPlotter()plotter.plot({&quot;Augmented&quot;: aug_history, &quot;Non-Augmented&quot;: no_aug_history}, metric = &quot;loss&quot;)plt.title(&quot;Loss&quot;)plt.ylim([0,1])</code></pre><p><img src="/2020/05/23/Datawhale——SVHN——Task02：数据扩增/2020-05-23-22-51-30.png" srcset="/img/loading.gif" alt></p><p>这里看的就更明显了，橙色线在训练时的loss很快就下降到趋近0，这说明模型已经很难从未经增强的数据中学到东西了，产生了严重的过拟合。</p><p>而蓝色线直到最后也在逐步地学习之中，我们可以得出结论，数据增强的确有助于避免过拟合、增强模型的泛化性能。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;训练模型第一步、数据读取和扩增！&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="datawhale" scheme="https://superlova.github.io/tags/datawhale/"/>
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
  </entry>
  
  <entry>
    <title>如何评价推荐系统以及其他智能系统</title>
    <link href="https://superlova.github.io/2020/05/20/%E5%A6%82%E4%BD%95%E8%AF%84%E4%BB%B7%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%A5%E5%8F%8A%E5%85%B6%E4%BB%96%E6%99%BA%E8%83%BD%E7%B3%BB%E7%BB%9F/"/>
    <id>https://superlova.github.io/2020/05/20/%E5%A6%82%E4%BD%95%E8%AF%84%E4%BB%B7%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%A5%E5%8F%8A%E5%85%B6%E4%BB%96%E6%99%BA%E8%83%BD%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-05-20T13:43:38.000Z</published>
    <updated>2020-05-21T00:51:02.937Z</updated>
    
    <content type="html"><![CDATA[<p>看到一篇介绍推荐系统的评价方法与指标的文章，刚好本课题组也有个同学在做推荐系统相关的课题，并且该文章的评价指标部分对我目前的课题有启发作用，因此转载。<br><a id="more"></a></p><h1 id="如何评价推荐系统以及其他智能系统"><a href="#如何评价推荐系统以及其他智能系统" class="headerlink" title="如何评价推荐系统以及其他智能系统"></a>如何评价推荐系统以及其他智能系统</h1><h2 id="1-评价推荐系统"><a href="#1-评价推荐系统" class="headerlink" title="1. 评价推荐系统"></a>1. <a href="https://www.jianshu.com/p/9d7c228eee59" target="_blank" rel="noopener">评价推荐系统</a></h2><p>评测一个推荐系统时，需要考虑用户、物品提供商、推荐系统提供网站的利益，一个好的推荐系统是能够令三方共赢的系统。比如弹窗广告就不是一个好的推荐系统。</p><h3 id="1-1-评测实验方法"><a href="#1-1-评测实验方法" class="headerlink" title="1.1 评测实验方法"></a>1.1 评测实验方法</h3><h4 id="1-1-1-离线实验（offline-experiment）"><a href="#1-1-1-离线实验（offline-experiment）" class="headerlink" title="1.1.1 离线实验（offline experiment）"></a>1.1.1 离线实验（offline experiment）</h4><p>离线实验的方法的步骤如下：</p><p>a）通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；<br>b）将数据集按照一定的规则分成训练集和测试集；<br>c）在训练集上训练用户兴趣模型，在测试集上进行预测；<br>d）通过事先定义的离线指标，评测算法在测试集上的预测结果。</p><p>从以上步骤看出，离线实验的都是在数据集上完成的。意味着，它不需要一个实际的系统作为支撑，只需要有一个从日志中提取的数据集即可。</p><p>离线实验的优点是：</p><ul><li>不需要有对实际系统的控制权；</li><li>不需要用户参与实践；</li><li>速度快，可以测试大量算法；</li></ul><p>缺点是：</p><ul><li>数据集的稀疏性限制了适用范围，例如一个数据集中没有包含某用户的历史行为，则无法评价对该用户的推荐结果；</li><li>评价结果的客观性，无法得到用户主观性的评价；</li><li>难以找到离线评价指标和在线真实反馈(如 点击率、转化率、点击深度、购买客单价、购买商 品类别等)之间的关联关系；</li></ul><h4 id="1-1-2-用户调查（user-study）"><a href="#1-1-2-用户调查（user-study）" class="headerlink" title="1.1.2 用户调查（user study）"></a>1.1.2 用户调查（user study）</h4><p>用户调查需要一些真实的用户，让他们在需要测试的推荐系统上完成一些任务。在他们完成任务时，需要观察和记录用户的行为，并让他们回答一些问题。</p><p>最后，我们通过分析他们的行为和答案，了解测试系统的性能。</p><p>用户调查的优点是：</p><ul><li>可以获得用户主观感受的指标，出错后容易弥补；</li></ul><p>缺点是：</p><ul><li>招募测试用户代价较大；</li><li>无法组织大规模的测试用户，统计意义不足；</li></ul><h4 id="1-1-3-在线实验（online-experiment）"><a href="#1-1-3-在线实验（online-experiment）" class="headerlink" title="1.1.3 在线实验（online experiment）"></a>1.1.3 在线实验（online experiment）</h4><p>在完成离线实验和用户调查之后，可以将系统上线做AB测试，将它和旧算法进行比较。</p><p>在线实验最常用的评测算法是【A/B测试】，它通过一定的规则将用户随机分成几组，对不同组的用户采用不同的算法，然后通过统计不同组的评测指标，比较不同算法的好坏。</p><p>它的核心思想是:</p><p>a) 多个方案并行测试;<br>b) 每个方案只有一个变量不同;<br>c) 以某种规则优胜劣汰。</p><p>其中第2点暗示了A/B 测试的应用范围：A/B测试必须是单变量。</p><p>对于推荐系统的评价中，唯一变量就是—推荐算法。</p><p>有个<a href="http://www.abtests.com" target="_blank" rel="noopener">很棒的网站</a>，里面有很多通过实际AB测试提高网站用户满意度的例子。</p><p>AB测试的优点是：</p><ul><li>可以公平获得不同算法实际在线时的性能指标，包括商业上关注的指标；</li></ul><p>缺点是：</p><ul><li>周期较长，必须进行长期的实验才能得到可靠的结果；</li></ul><h4 id="1-1-4-总结"><a href="#1-1-4-总结" class="headerlink" title="1.1.4 总结"></a>1.1.4 总结</h4><p>一般来说，一个新的推荐算法最终上线，需要完成上述的3个实验。</p><ul><li>首先，通过<strong>离线实验</strong>证明它在很多离线指标上优于现有的算法；</li><li>其次，通过<strong>用户调查</strong>确定用户满意度不低于现有的算法；</li><li>最后，通过<strong>在线AB测试</strong>确定它在我们关心的指标上优于现有的算法；</li></ul><h3 id="1-2-评测指标"><a href="#1-2-评测指标" class="headerlink" title="1.2 评测指标"></a>1.2 评测指标</h3><p>评测指标用于评测推荐系统的性能，有些可以定量计算，有些只能定性描述。</p><h4 id="1）用户满意度"><a href="#1）用户满意度" class="headerlink" title="1）用户满意度"></a>1）用户满意度</h4><p>用户满意度是评测推荐系统的重要指标，无法离线计算，只能通过用户调查或者在线实验获得。</p><p>调查问卷，需要考虑到用户各方面的感受，用户才能针对问题给出准确的回答。</p><p>在线系统中，用户满意度通过统计用户行为得到。比如用户如果购买了推荐的商品，就表示他们在一定程度上满意，可以用购买率度量用户满意度。</p><p>一般情况，我们可以用用户点击率、停留时间、转化率等指标度量用户的满意度。</p><h4 id="2）预测准确度"><a href="#2）预测准确度" class="headerlink" title="2）预测准确度"></a>2）预测准确度</h4><p>预测准确度，度量的是推荐系统预测用户行为的能力。 是推荐系统最重要的离线评测指标。</p><p>大部分的关于推荐系统评测指标的研究，都是针对预测准确度的。因为该指标可以通过离线实验计算，方便了学术界的研究人员。</p><p>由于离线的推荐算法有不同的研究方向，准确度指标也不同，根据研究方向，可分为：预测评分准确度和TopN推荐。</p><h5 id="a）预测评分准确度"><a href="#a）预测评分准确度" class="headerlink" title="a）预测评分准确度"></a>a）预测评分准确度</h5><p>预测评分的准确度，衡量的是算法预测的评分与用户的实际评分的贴近程度。</p><p>这针对于一些需要用户给物品评分的网站。</p><p>预测评分的准确度指标，一般通过以下指标计算：</p><p><strong>平均绝对误差（MAE）</strong></p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-51-32.png" srcset="/img/loading.gif" alt></p><p>MAE因其计算简单、通俗易懂得到了广泛的应用。但MAE指标也有一定的局限性，因为对MAE指标贡献比较大的往往是那种很难预测准确的低分商品。</p><p>所以即便推荐系统A的MAE值低于系统B，很可能只是由于系统A更擅长预测这部分低分商品的评分，即系统A比系统B能更好的区分用户非常讨厌和一般讨厌的商品，显然这样区分的意义不大。</p><p><strong>均方根误差（RMSE）</strong></p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-51-51.png" srcset="/img/loading.gif" alt></p><p>Netflix认为RMSE加大了对预测不准的用户物品评分的惩罚（平方项的惩罚），因而对系统的评测更加苛刻。</p><p>研究表明，如果评分系统是基于整数建立的（即用户给的评分都是整数），那么对预测结果取整数会降低MAE的误差。</p><h5 id="b）TopN推荐"><a href="#b）TopN推荐" class="headerlink" title="b）TopN推荐"></a>b）TopN推荐</h5><p>网站提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做TopN推荐。</p><p>TopN推荐的预测准确率，一般通过2个指标度量：</p><p><strong>准确率（precision）</strong></p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-52-10.png" srcset="/img/loading.gif" alt></p><p><strong>召回率（recall）</strong></p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-52-18.png" srcset="/img/loading.gif" alt></p><p>R(u)是根据用户在训练集上的行为给用户做出的推荐列表，T(u)是用户在测试集上的行为列表。</p><p>TopN推荐更符合实际的应用需求，比如预测用户是否会看一部电影，比预测用户看了电影之后会给它什么评分更重要。</p><p><strong>ROC曲线、AUC曲线、F值</strong></p><p>分类任务一般都有这三兄弟。</p><p>除此之外，还有Hit Rate (HR)等。</p><h4 id="3）覆盖率"><a href="#3）覆盖率" class="headerlink" title="3）覆盖率"></a>3）覆盖率</h4><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-52-29.png" srcset="/img/loading.gif" alt></p><p>覆盖率（coverage）是描述一个推荐系统对物品长尾的发掘能力。</p><p>最简单的定义是，推荐系统推荐出来的物品占总物品的比例。</p><p>假设系统的用户集合为U，推荐系统给每个用户推荐一个长度为N的物品列表R(u)，覆盖率公式为：</p><p>覆盖率是内容提供者关心的指标，覆盖率为100%的推荐系统可以将每个物品都推荐给至少一个用户。</p><p>除了推荐物品的占比，还可以通过研究物品在推荐列表中出现的次数分布，更好的描述推荐系统的挖掘长尾的能力。</p><p>如果分布比较平，说明推荐系统的覆盖率很高；如果分布陡峭，说明分布系统的覆盖率较低。</p><p>信息论和经济学中有两个著名指标，可以定义覆盖率：</p><p><strong>信息熵</strong></p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-52-40.png" srcset="/img/loading.gif" alt></p><p>p(i)是物品i的流行度除以所有物品流行度之和。</p><p><strong>基尼系数（Gini Index）</strong></p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-52-57.png" srcset="/img/loading.gif" alt></p><p>p(ij)是按照物品流行度p()从小到大排序的物品列表中第j个物品。</p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-53-09.png" srcset="/img/loading.gif" alt></p><p><strong>评测马太效应</strong></p><p>马太效应，是指强者越强，弱者越弱的效应。推荐系统的初衷是希望消除马太效应，使得各物品都能被展示给对它们感兴趣的人群。</p><p>但是，很多研究表明，现在的主流推荐算法（协同过滤）是具有马太效应的。评测推荐系统是否具有马太效应可以使用基尼系数。</p><p>如，G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出的物品流行度的基尼系数，那么如果G1&gt;G2，就说明推荐算法具有马太效应。</p><h4 id="4）多样性"><a href="#4）多样性" class="headerlink" title="4）多样性"></a>4）多样性</h4><p>为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同兴趣的领域，即需要具有多样性。</p><p>多样性描述了推荐列表中物品两两之间的不相似性。假设s(i,j)在[0,1]区间定义了物品i和j之间的相似度，那么用户u的推荐列表R(u)的多样性定义如下：</p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-53-44.png" srcset="/img/loading.gif" alt></p><p>推荐系统整体多样性可以定义为所有用户推荐列表多样性的平均值：</p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-53-51.png" srcset="/img/loading.gif" alt></p><h4 id="5）新颖性"><a href="#5）新颖性" class="headerlink" title="5）新颖性"></a>5）新颖性</h4><p>新颖性也是影响用户体验的重要指标之一。它指的是向用户推荐非热门非流行物品的能力。</p><p>评测新颖度最简单的方法，是利用推荐结果的平均流行度，因为越不热门的物品，越可能让用户觉得新颖。</p><p>此计算比较粗糙，需要配合用户调查准确统计新颖度。</p><h4 id="6）惊喜度"><a href="#6）惊喜度" class="headerlink" title="6）惊喜度"></a>6）惊喜度</h4><p>推荐结果和用户的历史兴趣不相似，但却让用户满意，这样就是惊喜度很高。</p><p>目前惊喜度还没有公认的指标定义方式，最近几年研究的人很多，深入研究可以参考一些论文。</p><h4 id="7）信任度"><a href="#7）信任度" class="headerlink" title="7）信任度"></a>7）信任度</h4><p>如果用户信任推荐系统，就会增加用户和推荐系统的交互。</p><p>提高信任度的方式有两种：</p><ul><li>增加系统透明度：提供推荐解释，让用户了解推荐系统的运行机制。</li><li>利用社交网络，通过好友信息给用户做推荐</li></ul><p>度量信任度的方式，只能通过问卷调查。</p><h4 id="8）实时性"><a href="#8）实时性" class="headerlink" title="8）实时性"></a>8）实时性</h4><p>推荐系统的实时性，包括两方面：</p><ul><li>实时更新推荐列表满足用户新的行为变化；</li><li>将新加入系统的物品推荐给用户；</li></ul><h4 id="9）健壮性"><a href="#9）健壮性" class="headerlink" title="9）健壮性"></a>9）健壮性</h4><p>任何能带来利益的算法系统都会被攻击，最典型的案例就是搜索引擎的作弊与反作弊斗争。</p><p>健壮性（robust，鲁棒性）衡量了推荐系统抗击作弊的能力。</p><p>2011年的推荐系统大会专门有一个推荐系统健壮性的教程，作者总结了很多作弊方法，最著名的是行为注入攻击（profile injection attack）。</p><p>就是注册很多账号，用这些账号同时购买A和自己的商品。此方法针对亚马逊的一种推荐方法，“购买商品A的用户也经常购买的其他商品”。</p><p>评测算法的健壮性，主要利用模拟攻击：</p><ul><li>a）给定一个数据集和算法，用算法给数据集中的用户生成推荐列表；</li><li>b）用常用的攻击方法向数据集中注入噪声数据；</li><li>c）利用算法在有噪声的数据集上再次生成推荐列表；</li><li>d）通过比较攻击前后推荐列表的相似度评测算法的健壮性。</li></ul><p>提高系统健壮性的方法：</p><ul><li>选择健壮性高的算法；</li><li>选择代价较高的用户行为，如购买行为比浏览行为代价高；</li><li>在使用数据前，进行攻击检测，从而对数据进行清理。</li></ul><h4 id="10）商业目标"><a href="#10）商业目标" class="headerlink" title="10）商业目标"></a>10）商业目标</h4><p>设计推荐系统时，需要考虑最终的商业目标。不同网站具有不同的商业目标，它与网站的盈利模式息息相关。</p><p>总结：</p><p><img src="/2020/05/20/如何评价推荐系统以及其他智能系统/2020-05-20-21-54-09.png" srcset="/img/loading.gif" alt></p><p>作者认为，对于可以离线优化的指标，在给定覆盖率、多样性、新颖性等限制条件下，应尽量优化预测准确度。</p><h3 id="1-3-评测维度"><a href="#1-3-评测维度" class="headerlink" title="1.3 评测维度"></a>1.3 评测维度</h3><p>如果推荐系统的评测报告中，包含了不同维度下的系统评测指标，就能帮我们全面了解系统性能。一般评测维度分3种：</p><p>用户维度，主要包括用户的人口统计学信息、活跃度以及是不是新用户等；<br>物品维度，包括物品的属性信息、流行度、平均分以及是不是新加入的物品等；<br>时间维度，包括季节，是工作日还是周末，白天还是晚上等；</p><h2 id="2-评价智能系统"><a href="#2-评价智能系统" class="headerlink" title="2. 评价智能系统"></a>2. 评价智能系统</h2><p>【未完成】</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;看到一篇介绍推荐系统的评价方法与指标的文章，刚好本课题组也有个同学在做推荐系统相关的课题，并且该文章的评价指标部分对我目前的课题有启发作用，因此转载。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
      <category term="Recommendation System" scheme="https://superlova.github.io/tags/Recommendation-System/"/>
    
      <category term="Metrics" scheme="https://superlova.github.io/tags/Metrics/"/>
    
  </entry>
  
  <entry>
    <title>Datawhale——SVHN——Task01：赛题理解</title>
    <link href="https://superlova.github.io/2020/05/20/Datawhale%E5%B0%8F%E7%BB%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1%E2%80%94%E2%80%94Task01%EF%BC%9A%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3/"/>
    <id>https://superlova.github.io/2020/05/20/Datawhale%E5%B0%8F%E7%BB%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1%E2%80%94%E2%80%94Task01%EF%BC%9A%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3/</id>
    <published>2020-05-20T08:38:22.000Z</published>
    <updated>2020-06-02T04:42:21.259Z</updated>
    
    <content type="html"><![CDATA[<p>本次新人赛是Datawhale与天池联合发起的0基础入门系列赛事第二场 —— 零基础入门CV之街景字符识别比赛。<br><a id="more"></a></p><h1 id="Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解"><a href="#Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解" class="headerlink" title="Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解"></a>Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解</h1><h2 id="1-大赛简介"><a href="#1-大赛简介" class="headerlink" title="1. 大赛简介"></a>1. 大赛简介</h2><p>本次新人赛是Datawhale与天池联合发起的0基础入门系列赛事第二场 —— 零基础入门CV之街景字符识别比赛。</p><h3 id="1-1-赛题数据介绍"><a href="#1-1-赛题数据介绍" class="headerlink" title="1.1 赛题数据介绍"></a>1.1 赛题数据介绍</h3><p>赛题来源自Google街景图像中的门牌号数据集（The Street View House Numbers Dataset, SVHN），该数据来自真实场景的门牌号。</p><p>训练集数据包括3W张照片，验证集数据包括1W张照片，每张照片包括颜色图像和对应的编码类别和具体位置</p><h3 id="1-2-参赛规则"><a href="#1-2-参赛规则" class="headerlink" title="1.2 参赛规则"></a>1.2 参赛规则</h3><ul><li>比赛允许使用CIFAR-10和ImageNet数据集的预训练模型，不允许使用其他任何预训练模型和任何外部数据；</li><li>报名成功后，选手下载数据，在本地调试算法，提交结果；</li><li>提交后将进行实时评测；每天排行榜更新时间为12:00和20:00，按照评测指标得分从高到低排序；排行榜将选择历史最优成绩进行展示。</li></ul><h3 id="1-3-数据集简介"><a href="#1-3-数据集简介" class="headerlink" title="1.3 数据集简介"></a>1.3 数据集简介</h3><p>所有的数据（训练集、验证集和测试集）的标注使用JSON格式，并使用文件名进行索引。</p><div class="table-container"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>top</td><td>左上角坐标X</td></tr><tr><td>height</td><td>字符高度</td></tr><tr><td>left</td><td>左上角最表Y</td></tr><tr><td>width</td><td>字符宽度</td></tr><tr><td>label</td><td>字符编码</td></tr></tbody></table></div><p>字符的坐标具体如下所示：<br><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/字符坐标.png" srcset="/img/loading.gif" alt="坐标">  </p><p>在比赛数据（训练集和验证集）中，同一张图片中可能包括一个或者多个字符，因此在比赛数据的JSON标注中，会有两个字符的边框信息：<br>|原始图片|图片JSON标注|<br>|——|——-|<br><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/原始图片.png" srcset="/img/loading.gif" alt="19">    | <img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/原始图片标注.png" srcset="/img/loading.gif" alt="标注">  |</p><p>在<a href="http://ufldl.stanford.edu/housenumbers/" target="_blank" rel="noopener">SVHN官网</a>上下载数据集的话，有两种格式可供选择：</p><h4 id="第一种格式"><a href="#第一种格式" class="headerlink" title="第一种格式"></a>第一种格式</h4><p>第一种格式的数据集，除了原始图像之外还包括边界框信息。每个tar.gz文件都包含png格式的原始图像，以及一个digitStruct.mat文件。边界框信息存储在digitStruct.mat文件中，而不是直接绘制在数据集中的图像上。以<code>.mat</code>结尾的文件是matlab专用文件，可以使用python的scipy库打开，内部装的是类似json的字典。</p><p>digitStruct中的每个元素都有以下字段：</p><ul><li>name是一个字符串，其中包含相应图像的文件名。</li><li>bbox是一个结构数组，包含图像中每个数字边界框的位置，大小和标签。</li></ul><p>例如：digitStruct（300）.bbox（2）.height则是第300张图片中第二个数字边界框的高度。</p><h4 id="第二种格式"><a href="#第二种格式" class="headerlink" title="第二种格式"></a>第二种格式</h4><p>为了降低难度，将上述第一种格式的图片都被剪切到只剩下有效字符，并被缩放至32*32像素的标准大小，以方便识别。图片的边界框经过适当的选择，避免出现扭曲等状况。尽管如此，这种处理还是可能导致引入一些错误信息。</p><p>train_32x32.mat和test_32x32.mat，<code>.mat</code>文件中包含两个变量,X是一个4D的矩阵，维度是(32,32,3,n),n是数据个数,y是label变量。看一下前十张图：</p><pre><code class="lang-python">import scipy.io as sioimport matplotlib.pyplot as pltprint (&#39;Loading Matlab data.&#39;)mat = sio.loadmat(&#39;train_32x32.mat&#39;)data = mat[&#39;X&#39;]label = mat[&#39;y&#39;]for i in range(10):    plt.subplot(2,5,i+1)    plt.title(label[i][0])    plt.imshow(data[...,i])    plt.axis(&#39;off&#39;)plt.show()</code></pre><p><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/2020-05-30-22-17-20.png" srcset="/img/loading.gif" alt></p><h3 id="1-4-成绩评定方式"><a href="#1-4-成绩评定方式" class="headerlink" title="1.4 成绩评定方式"></a>1.4 成绩评定方式</h3><p>评价标准为准确率。<br>选手提交结果与实际图片的编码进行对比，以编码整体识别准确率为评价指标，结果越大越好，具体计算公式如下：</p><p> Score=编码识别正确的数量/测试集图片数量   </p><h3 id="1-5-结果提交格式"><a href="#1-5-结果提交格式" class="headerlink" title="1.5 结果提交格式"></a>1.5 结果提交格式</h3><p>提交前请确保预测结果的格式与sample_submit.csv中的格式一致，以及提交文件后缀名为csv。<br>形式如下：<br>file_name, file_code<br>0010000.jpg,451<br>0010001.jpg,232<br>0010002.jpg,45<br>0010003.jpg,67<br>0010004.jpg,191<br>0010005.jpg,892 </p><h2 id="2-数据读取"><a href="#2-数据读取" class="headerlink" title="2. 数据读取"></a>2. 数据读取</h2><p>JSON中标签的读取方式：  </p><pre><code class="lang-python">import jsontrain_json = json.load(open(&#39;../input/train.json&#39;))# 数据标注处理def parse_json(d):    arr = np.array([        d[&#39;top&#39;], d[&#39;height&#39;], d[&#39;left&#39;],  d[&#39;width&#39;], d[&#39;label&#39;]    ])    arr = arr.astype(int)    return arrimg = cv2.imread(&#39;../input/train/000000.png&#39;)arr = parse_json(train_json[&#39;000000.png&#39;])plt.figure(figsize=(10, 10))plt.subplot(1, arr.shape[1]+1, 1)plt.imshow(img)plt.xticks([]); plt.yticks([])for idx in range(arr.shape[1]):    plt.subplot(1, arr.shape[1]+1, idx+2)    plt.imshow(img[arr[0, idx]:arr[0, idx]+arr[1, idx],arr[2, idx]:arr[2, idx]+arr[3, idx]])    plt.title(arr[4, idx])    plt.xticks([]); plt.yticks([])</code></pre><p><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/19.png" srcset="/img/loading.gif" alt="19"></p><h2 id="3-解题思路"><a href="#3-解题思路" class="headerlink" title="3. 解题思路"></a>3. 解题思路</h2><p>赛题思路分析：赛题本质是分类问题，需要对图片的字符进行识别。但赛题给定的数据图片中不同图片中包含的字符数量不等，如下图所示。有的图片的字符个数为2，有的图片字符个数为3，有的图片字符个数为4。 </p><div class="table-container"><table><thead><tr><th>字符属性</th><th>图片</th></tr></thead><tbody><tr><td>字符：42   字符个数：2</td><td><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/42.png" srcset="/img/loading.gif" alt="标注"></td></tr><tr><td>字符：241   字符个数：3</td><td><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/2411.png" srcset="/img/loading.gif" alt="标注"></td></tr><tr><td>字符：7358   字符个数：4</td><td><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/7358.png" srcset="/img/loading.gif" alt="标注"></td></tr></tbody></table></div><p>因此本次赛题的难点是需要对不定长的字符进行识别，与传统的图像分类任务有所不同。为了降低参赛难度，我们提供了一些解题思路供大家参考：</p><ul><li>简单入门思路：定长字符识别    </li></ul><p>可以将赛题抽象为一个定长字符识别问题，在赛题数据集中大部分图像中字符个数为2-4个，最多的字符    个数为6个。<br>因此可以对于所有的图像都抽象为6个字符的识别问题，字符23填充为23XXXX，字符231填充为231XXX。<br><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/23xxxxxx.png" srcset="/img/loading.gif" alt="标注">   </p><p>经过填充之后，原始的赛题可以简化了6个字符的分类问题。在每个字符的分类中会进行11个类别的分类，假如分类为填充字符，则表明该字符为空。    </p><ul><li>专业字符识别思路：不定长字符识别 </li></ul><p><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/不定长字符识别.png" srcset="/img/loading.gif" alt="标注"> </p><p>在字符识别研究中，有特定的方法来解决此种不定长的字符识别问题，比较典型的有CRNN字符识别模型。<br>在本次赛题中给定的图像数据都比较规整，可以视为一个单词或者一个句子。   </p><ul><li>专业分类思路：检测再识别</li></ul><p>在赛题数据中已经给出了训练集、验证集中所有图片中字符的位置，因此可以首先将字符的位置进行识别，利用物体检测的思路完成。   </p><p><img src="/2020/05/20/Datawhale小组学习之街景字符编码识别任务——Task01：赛题理解/检测.png" srcset="/img/loading.gif" alt="IMG"> </p><p>此种思路需要参赛选手构建字符检测模型，对测试集中的字符进行识别。选手可以参考物体检测模型SSD或者YOLO来完成。    </p><h2 id="4-Baseline思路：将不定长字符转换为定长字符的识别问题，并使用CNN完成训练和验证"><a href="#4-Baseline思路：将不定长字符转换为定长字符的识别问题，并使用CNN完成训练和验证" class="headerlink" title="4. Baseline思路：将不定长字符转换为定长字符的识别问题，并使用CNN完成训练和验证"></a>4. Baseline思路：将不定长字符转换为定长字符的识别问题，并使用CNN完成训练和验证</h2><h3 id="4-1-运行环境及安装示例"><a href="#4-1-运行环境及安装示例" class="headerlink" title="4.1 运行环境及安装示例"></a>4.1 运行环境及安装示例</h3><ul><li>运行环境要求：Python2/3，Pytorch1.x，内存4G，有无GPU都可以。         </li></ul><p>下面给出python3.7+ torch1.3.1gpu版本的环境安装示例：      </p><ul><li><p>首先在Anaconda中创建一个专门用于本次天池练习赛的虚拟环境。          </p><blockquote><p>$conda create -n py37_torch131 python=3.7      </p></blockquote></li><li><p>激活环境，并安装pytorch1.3.1                                     </p><blockquote><p>$source activate py37_torch131<br>$conda install pytorch=1.3.1 torchvision cudatoolkit=10.0                     </p></blockquote></li><li><p>通过下面的命令一键安装所需其它依赖库     </p><blockquote><p>$pip install jupyter tqdm opencv-python matplotlib pandas                                  </p></blockquote></li><li><p>启动notebook，即可开始baseline代码的学习                  </p><blockquote><p>$jupyter-notebook   </p></blockquote></li><li><p>假设所有的赛题输入文件放在../input/目录下，首先导入常用的包：</p></li></ul><pre><code class="lang-python">import os, sys, glob, shutil, jsonos.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &#39;0&#39;import cv2from PIL import Imageimport numpy as npfrom tqdm import tqdm, tqdm_notebookimport torchtorch.manual_seed(0)torch.backends.cudnn.deterministic = Falsetorch.backends.cudnn.benchmark = Trueimport torchvision.models as modelsimport torchvision.transforms as transformsimport torchvision.datasets as datasetsimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimfrom torch.autograd import Variablefrom torch.utils.data.dataset import Dataset</code></pre><h3 id="4-2-步骤"><a href="#4-2-步骤" class="headerlink" title="4.2 步骤"></a>4.2 步骤</h3><ul><li>赛题数据读取（封装为Pytorch的Dataset和DataLoder）</li><li>构建CNN模型（使用Pytorch搭建）</li><li>模型训练与验证</li><li>模型结果预测</li></ul><h4 id="步骤1：定义好读取图像的Dataset"><a href="#步骤1：定义好读取图像的Dataset" class="headerlink" title="步骤1：定义好读取图像的Dataset"></a>步骤1：定义好读取图像的Dataset</h4><pre><code class="lang-python">class SVHNDataset(Dataset):    def __init__(self, img_path, img_label, transform=None):        self.img_path = img_path        self.img_label = img_label         if transform is not None:            self.transform = transform        else:            self.transform = None    def __getitem__(self, index):        img = Image.open(self.img_path[index]).convert(&#39;RGB&#39;)        if self.transform is not None:            img = self.transform(img)        # 设置最长的字符长度为5个        lbl = np.array(self.img_label[index], dtype=np.int)        lbl = list(lbl)  + (5 - len(lbl)) * [10]        return img, torch.from_numpy(np.array(lbl[:5]))    def __len__(self):        return len(self.img_path)</code></pre><h4 id="步骤2：定义好训练数据和验证数据的Dataset"><a href="#步骤2：定义好训练数据和验证数据的Dataset" class="headerlink" title="步骤2：定义好训练数据和验证数据的Dataset"></a>步骤2：定义好训练数据和验证数据的Dataset</h4><pre><code class="lang-python">train_path = glob.glob(&#39;../input/train/*.png&#39;)train_path.sort()train_json = json.load(open(&#39;../input/train.json&#39;))train_label = [train_json[x][&#39;label&#39;] for x in train_json]print(len(train_path), len(train_label))train_loader = torch.utils.data.DataLoader(    SVHNDataset(train_path, train_label,                transforms.Compose([                    transforms.Resize((64, 128)),                    transforms.RandomCrop((60, 120)),                    transforms.ColorJitter(0.3, 0.3, 0.2),                    transforms.RandomRotation(5),                    transforms.ToTensor(),                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])    ])),     batch_size=40,     shuffle=True,     num_workers=10,)val_path = glob.glob(&#39;../input/val/*.png&#39;)val_path.sort()val_json = json.load(open(&#39;../input/val.json&#39;))val_label = [val_json[x][&#39;label&#39;] for x in val_json]print(len(val_path), len(val_label))val_loader = torch.utils.data.DataLoader(    SVHNDataset(val_path, val_label,                transforms.Compose([                    transforms.Resize((60, 120)),                    # transforms.ColorJitter(0.3, 0.3, 0.2),                    # transforms.RandomRotation(5),                    transforms.ToTensor(),                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])    ])),     batch_size=40,     shuffle=False,     num_workers=10,)</code></pre><h4 id="步骤3：定义好字符分类模型，使用renset18的模型作为特征提取模块"><a href="#步骤3：定义好字符分类模型，使用renset18的模型作为特征提取模块" class="headerlink" title="步骤3：定义好字符分类模型，使用renset18的模型作为特征提取模块"></a>步骤3：定义好字符分类模型，使用renset18的模型作为特征提取模块</h4><pre><code class="lang-python">class SVHN_Model1(nn.Module):    def __init__(self):        super(SVHN_Model1, self).__init__()        model_conv = models.resnet18(pretrained=True)        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)        model_conv = nn.Sequential(*list(model_conv.children())[:-1])        self.cnn = model_conv        self.fc1 = nn.Linear(512, 11)        self.fc2 = nn.Linear(512, 11)        self.fc3 = nn.Linear(512, 11)        self.fc4 = nn.Linear(512, 11)        self.fc5 = nn.Linear(512, 11)    def forward(self, img):                feat = self.cnn(img)        # print(feat.shape)        feat = feat.view(feat.shape[0], -1)        c1 = self.fc1(feat)        c2 = self.fc2(feat)        c3 = self.fc3(feat)        c4 = self.fc4(feat)        c5 = self.fc5(feat)        return c1, c2, c3, c4, c5</code></pre><h4 id="步骤4：定义好训练、验证和预测模块"><a href="#步骤4：定义好训练、验证和预测模块" class="headerlink" title="步骤4：定义好训练、验证和预测模块"></a>步骤4：定义好训练、验证和预测模块</h4><pre><code class="lang-python">def train(train_loader, model, criterion, optimizer):    # 切换模型为训练模式    model.train()    train_loss = []    for i, (input, target) in enumerate(train_loader):        if use_cuda:            input = input.cuda()            target = target.cuda()        c0, c1, c2, c3, c4 = model(input)        loss = criterion(c0, target[:, 0]) + \                criterion(c1, target[:, 1]) + \                criterion(c2, target[:, 2]) + \                criterion(c3, target[:, 3]) + \                criterion(c4, target[:, 4])        # loss /= 6        optimizer.zero_grad()        loss.backward()        optimizer.step()        if i % 100 == 0:            print(loss.item())        train_loss.append(loss.item())    return np.mean(train_loss)def validate(val_loader, model, criterion):    # 切换模型为预测模型    model.eval()    val_loss = []    # 不记录模型梯度信息    with torch.no_grad():        for i, (input, target) in enumerate(val_loader):            if use_cuda:                input = input.cuda()                target = target.cuda()            c0, c1, c2, c3, c4 = model(input)            loss = criterion(c0, target[:, 0]) + \                    criterion(c1, target[:, 1]) + \                    criterion(c2, target[:, 2]) + \                    criterion(c3, target[:, 3]) + \                    criterion(c4, target[:, 4])            # loss /= 6            val_loss.append(loss.item())    return np.mean(val_loss)def predict(test_loader, model, tta=10):    model.eval()    test_pred_tta = None    # TTA 次数    for _ in range(tta):        test_pred = []        with torch.no_grad():            for i, (input, target) in enumerate(test_loader):                if use_cuda:                    input = input.cuda()                c0, c1, c2, c3, c4 = model(input)                output = np.concatenate([                    c0.data.numpy(),                     c1.data.numpy(),                    c2.data.numpy(),                     c3.data.numpy(),                    c4.data.numpy()], axis=1)                test_pred.append(output)        test_pred = np.vstack(test_pred)        if test_pred_tta is None:            test_pred_tta = test_pred        else:            test_pred_tta += test_pred    return test_pred_tta</code></pre><h4 id="步骤5：迭代训练和验证模型"><a href="#步骤5：迭代训练和验证模型" class="headerlink" title="步骤5：迭代训练和验证模型"></a>步骤5：迭代训练和验证模型</h4><pre><code class="lang-python">model = SVHN_Model1()criterion = nn.CrossEntropyLoss()optimizer = torch.optim.Adam(model.parameters(), 0.001)best_loss = 1000.0use_cuda = Falseif use_cuda:    model = model.cuda()for epoch in range(2):    train_loss = train(train_loader, model, criterion, optimizer, epoch)    val_loss = validate(val_loader, model, criterion)    val_label = [&#39;&#39;.join(map(str, x)) for x in val_loader.dataset.img_label]    val_predict_label = predict(val_loader, model, 1)    val_predict_label = np.vstack([        val_predict_label[:, :11].argmax(1),        val_predict_label[:, 11:22].argmax(1),        val_predict_label[:, 22:33].argmax(1),        val_predict_label[:, 33:44].argmax(1),        val_predict_label[:, 44:55].argmax(1),    ]).T    val_label_pred = []    for x in val_predict_label:        val_label_pred.append(&#39;&#39;.join(map(str, x[x!=10])))    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))    print(&#39;Epoch: {0}, Train loss: {1} \t Val loss: {2}&#39;.format(epoch, train_loss, val_loss))    print(val_char_acc)    # 记录下验证集精度    if val_loss &lt; best_loss:        best_loss = val_loss        torch.save(model.state_dict(), &#39;./model.pt&#39;)</code></pre><p>训练两个2 Epoch后，输出的训练日志为：</p><p>Epoch: 0, Train loss: 3.1      Val loss: 3.4 验证集精度：0.3439<br>Epoch: 1, Train loss: 2.1      Val loss: 2.9 验证集精度：0.4346     </p><h4 id="步骤6：对测试集样本进行预测，生成提交文件"><a href="#步骤6：对测试集样本进行预测，生成提交文件" class="headerlink" title="步骤6：对测试集样本进行预测，生成提交文件"></a>步骤6：对测试集样本进行预测，生成提交文件</h4><pre><code class="lang-python">test_path = glob.glob(&#39;../input/test_a/*.png&#39;)test_path.sort()test_label = [[1]] * len(test_path)print(len(val_path), len(val_label))test_loader = torch.utils.data.DataLoader(    SVHNDataset(test_path, test_label,                transforms.Compose([                    transforms.Resize((64, 128)),                    transforms.RandomCrop((60, 120)),                    # transforms.ColorJitter(0.3, 0.3, 0.2),                    # transforms.RandomRotation(5),                    transforms.ToTensor(),                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])    ])),     batch_size=40,     shuffle=False,     num_workers=10,)test_predict_label = predict(test_loader, model, 1)test_label = [&#39;&#39;.join(map(str, x)) for x in test_loader.dataset.img_label]test_predict_label = np.vstack([    test_predict_label[:, :11].argmax(1),    test_predict_label[:, 11:22].argmax(1),    test_predict_label[:, 22:33].argmax(1),    test_predict_label[:, 33:44].argmax(1),    test_predict_label[:, 44:55].argmax(1),]).Ttest_label_pred = []for x in test_predict_label:    test_label_pred.append(&#39;&#39;.join(map(str, x[x!=10])))import pandas as pddf_submit = pd.read_csv(&#39;../input/test_A_sample_submit.csv&#39;)df_submit[&#39;file_code&#39;] = test_label_preddf_submit.to_csv(&#39;renset18.csv&#39;, index=None)</code></pre><p><strong>在训练完成2个Epoch后，模型在测试集上的成绩应该在0.33左右。</strong>    </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次新人赛是Datawhale与天池联合发起的0基础入门系列赛事第二场 —— 零基础入门CV之街景字符识别比赛。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="datawhale" scheme="https://superlova.github.io/tags/datawhale/"/>
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>numpy中的einsum使用方法</title>
    <link href="https://superlova.github.io/2020/05/19/numpy%E4%B8%AD%E7%9A%84einsum%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/05/19/numpy%E4%B8%AD%E7%9A%84einsum%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2020-05-19T06:52:52.000Z</published>
    <updated>2020-05-20T02:48:40.857Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍爱因斯坦求和约定，以及在numpy中的使用<br><a id="more"></a></p><p>numpy里面有很多奇技淫巧，爱因斯坦求和约定就是其中之一。</p><p>爱因斯坦求和约定能够很方便和简介地表示点积、外积、转置、矩阵-向量乘法、矩阵-矩阵乘法等，这在深度学习公式推导中的用处很大。</p><p>其实我不认为einsum在numpy中用处很大，我认为其顶多就是一种统一的矩阵运算写法罢了。这种技巧，是在牺牲可读性基础上，对代码的简化。而且由于numpy对其他运算也有进行优化，所以仅凭借爱因斯坦乘数法还不一定能提升代码执行效率。</p><p>可能是我还没有体会到高维张量相互计算时的痛苦吧。</p><p>先看一下einsum的api：</p><pre><code class="lang-python">np.einsum(equation, *arr)</code></pre><p>最开始需要一个字符串，用以描述想要完成的计算。后面是计算需要的操作数，也就是你的矩阵等。</p><p>来看具体的例子：</p><h3 id="对于向量"><a href="#对于向量" class="headerlink" title="对于向量"></a>对于向量</h3><pre><code class="lang-python">arr1 = np.arange(5) # 0,1,2,3,4arr2 = np.arange(5) # 0,1,2,3,4</code></pre><ol><li>计算向量所有分量的和，即<code>np.sum(arr)</code>。如何利用einsum完成？</li></ol><pre><code class="lang-python">np.einsum(&quot;i-&gt;&quot;, arr) # 10</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c = \sum_{i} a_i,\quad i = 1, 2, \dots</script><ol><li>计算两向量内积，即<code>np.dot(arr1, arr2)</code>或<code>np.inner(arr1, arr2)</code></li></ol><pre><code class="lang-python"># 0*0 + 1*1 + 2*2 + 3*3 + 4*4np.einsum(&quot;i,i-&gt;&quot;, arr1, arr2) # 30</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c = \sum_{i} a_i \times b_i,\quad i = 1, 2, \dots</script><ol><li>计算两向量逐元素乘积，即<code>arr1 * arr2</code></li></ol><pre><code class="lang-python">np.einsum(&quot;i,i-&gt;i&quot;, arr1, arr2) # 0,1,4,9,16</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_i = a_i \times b_i,\quad i = 1, 2, \dots</script><ol><li>计算两向量外积，即<code>np.outer(arr1, arr2)</code></li></ol><pre><code class="lang-python">[[ 0  0  0  0  0] [ 0  1  2  3  4] [ 0  2  4  6  8] [ 0  3  6  9 12] [ 0  4  8 12 16]]np.einsum(&quot;i,j-&gt;ij&quot;, arr1, arr2)</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_{i,j} = a_i \times b_j,\quad i,j = 1, 2, \dots</script><h3 id="对于矩阵"><a href="#对于矩阵" class="headerlink" title="对于矩阵"></a>对于矩阵</h3><pre><code class="lang-python">A = np.arange(4).reshape(2,2)B = np.arange(4,8).reshape(2,2)[[0 1] [2 3]][[4 5] [6 7]]</code></pre><ol><li>计算矩阵转置，即<code>A.T</code></li></ol><pre><code class="lang-python">[[0 2] [1 3]]print(np.einsum(&quot;ij-&gt;ji&quot;, A))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_{i,j} = a_{j,i},\quad i,j = 1, 2, \dots</script><ol><li>计算矩阵各元素求和，即<code>np.sum(A)</code></li></ol><pre><code class="lang-python">6print(np.einsum(&quot;ij-&gt;&quot;, A))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c = \sum_{i}\sum_{j}a_{i,j},\quad i,j = 1, 2, \dots</script><ol><li>计算矩阵按列求和，即<code>np.sum(A, axis=0)</code></li></ol><pre><code class="lang-python">[2 4]print(np.einsum(&quot;ij-&gt;j&quot;, A))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_{j} = \sum_{i}a_{i,j},\quad i,j = 1, 2, \dots</script><ol><li>计算矩阵按行求和，即<code>np.sum(A, axis=1)</code></li></ol><pre><code class="lang-python">[1 5]print(np.einsum(&quot;ij-&gt;i&quot;, A))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_{i} = \sum_{j}a_{i,j},\quad i,j = 1, 2, \dots</script><ol><li>求矩阵对角线元素，即<code>np.diag(A)</code></li></ol><pre><code class="lang-python">[0 3]print(np.einsum(&quot;ii-&gt;i&quot;, A))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_{i} = a_{i,i},\quad i = 1, 2, \dots</script><ol><li>计算矩阵的迹，即对角线元素和，即<code>np.trace(A)</code></li></ol><pre><code class="lang-python">3print(np.einsum(&quot;ii-&gt;&quot;, A))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c = \sum_{i}a_{i,i},\quad i = 1, 2, \dots</script><ol><li>计算两矩逐元素乘积，即<code>A*B</code></li></ol><pre><code class="lang-python">[[ 0  5] [12 21]] print(np.einsum(&quot;ij,ij-&gt;ij&quot;, A, B))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_{i,j} = a_{i,j} \times b_{i,j}, i,j = 1, 2, \dots</script><ol><li>计算<code>A*B.T</code></li></ol><pre><code class="lang-python">[[ 0  6] [10 21]]print(np.einsum(&quot;ij,ji-&gt;ij&quot;, A, B))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_{i,j} = a_{i,j} \times b_{j,i}, i,j = 1, 2, \dots</script><ol><li>计算两矩阵乘积<code>np.dot(A, B)</code></li></ol><pre><code class="lang-python">[[ 6  7] [26 31]]print(np.einsum(&quot;ij,jk-&gt;ik&quot;, A, B))</code></pre><p>在数学上相当于：</p><script type="math/tex; mode=display">c_{i,k} = a_{i,j} \times b_{j,k}, i,j = 1, 2, \dots</script><p>停一下，停一下。</p><p><img src="/2020/05/19/numpy中的einsum使用方法/2020-05-20-09-45-48.png" srcset="/img/loading.gif" alt></p><p>你们懂了吗？反正我没有。网上的文章指望着我们光看例子就能学会，这是把我们都当成模型训练了吗？</p><p>仔细看一下上面的两个例子，其实每个equation都拥有一个箭头<code>-&gt;</code>。对应数学公式不难得出，箭头左边对应数学公式右边，箭头右边对应数学公式左边。</p><p>比如这个式子：</p><pre><code class="lang-python">np.einsum(&quot;ij,ji-&gt;i&quot;, A, B)</code></pre><p><code>&quot;ij,ji-&gt;i&quot;</code>解释成自然语言：将A中第<code>{i,j}</code>个元素与B中第<code>{j,i}</code>个元素相乘（逗号理解成相乘），结果中没有j分量，只有i分量，所以所有j分量求和。</p><p>就是对应这个数学公式：</p><script type="math/tex; mode=display">c_i = \sum_{j}a_{i,j}\times b_{j,i}</script><p>实际含义代表：<code>np.sum(A*B.T, axis=1)</code></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍爱因斯坦求和约定，以及在numpy中的使用&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="numpy" scheme="https://superlova.github.io/tags/numpy/"/>
    
      <category term="einsum" scheme="https://superlova.github.io/tags/einsum/"/>
    
  </entry>
  
  <entry>
    <title>numpy中axis的简单理解</title>
    <link href="https://superlova.github.io/2020/05/19/numpy%E4%B8%ADaxis%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/"/>
    <id>https://superlova.github.io/2020/05/19/numpy%E4%B8%ADaxis%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/</id>
    <published>2020-05-19T06:52:25.000Z</published>
    <updated>2020-05-19T10:36:47.657Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍numpy中的axis<br><a id="more"></a></p><p>我对于numpy中的axis的理解，一直处于似懂非懂、似是而非的状态。看到网上大神的文章，也只能点个赞之后，该不会还是不会。每次看完博客，都会觉得自己懂了；但是每次使用的时候，又要想老半天才行。因此今天我想借此机会，彻底扫清使用numpy时，axis的障碍。</p><p>在numpy中，数据的基本类型是array。array有个基本的数据属性，是它的维度。</p><p>比如下面的这个array，在逻辑上来看这就是个2维的数据，是一个矩阵。</p><pre><code class="lang-python">A = np.random.randint(0, 19, 9).reshape(3, 3)print(A)[[12 15  0] [ 3  3  7] [ 9 18  4]]</code></pre><p>接下来我要对其中的元素进行求和。</p><pre><code class="lang-python">print(np.sum(A))print(np.sum(A, axis=0))print(np.sum(A, axis=1))71[24 36 11][27 13 31]</code></pre><p>显然，第一个sum是对所有元素累加。第二个参数为axis=0的求和，则是这样计算的：</p><p><code>A[0][X] + A[1][X] + A[2][X]</code><br><code>--|---------|---------|----</code></p><p>也就是说，axis=0意味着在求和的过程中，只有A的第0个分量会变化，将第0个分量的所有情况穷举出来，再作为被操作元素，求和之。</p><p>第0个分量的元素计算完毕、得到一个结果时，计算并没有结束，因为我们的X还有很多种可能。</p><p>同理，axis=1时，变化的只有A的第1个（从逻辑上讲是第二个）分量有变化：</p><p><code>A[X][0] + A[X][1] + A[X][2]</code><br><code>-----|---------|---------|-</code></p><p>把该结论推广到更高维度的数据也不会有问题。我们看一个4维的张量是如何指定axis求和的：</p><pre><code class="lang-python">np.random.seed(0)A = np.random.randint(0, 9, 16).reshape(2, 2, 2, 2)print(&quot;orignal A&quot;, A)orignal A [[[[5 0]   [3 3]]  [[7 3]   [5 2]]] [[[4 7]   [6 8]]  [[8 1]   [6 7]]]]</code></pre><pre><code class="lang-python">print(np.sum(A))75</code></pre><pre><code class="lang-python">print(np.sum(A, axis=0))# 相当于print(A[0,:,:,:]+A[1,:,:,:])[[[ 9  7]  [ 9 11]] [[15  4]  [11  9]]]</code></pre><pre><code class="lang-python">print(np.sum(A, axis=1))# 相当于print(A[:,0,:,:] + A[:,1,:,:])[[[12  3]  [ 8  5]] [[12  8]  [12 15]]]</code></pre><pre><code class="lang-python">print(np.sum(A, axis=2))# 相当于print(A[:,:,0,:] + A[:,:,1,:])[[[ 8  3]  [12  5]] [[10 15]  [14  8]]]</code></pre><pre><code class="lang-python">print(np.sum(A, axis=3))# 相当于print(A[:,:,:,0]+A[:,:,:,1])[[[ 5  6]  [10  7]] [[11 14]  [ 9 13]]]</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍numpy中的axis&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="numpy" scheme="https://superlova.github.io/tags/numpy/"/>
    
      <category term="axis" scheme="https://superlova.github.io/tags/axis/"/>
    
  </entry>
  
  <entry>
    <title>闭包的迷思</title>
    <link href="https://superlova.github.io/2020/05/19/%E9%97%AD%E5%8C%85%E7%9A%84%E8%BF%B7%E6%80%9D/"/>
    <id>https://superlova.github.io/2020/05/19/%E9%97%AD%E5%8C%85%E7%9A%84%E8%BF%B7%E6%80%9D/</id>
    <published>2020-05-19T06:50:52.000Z</published>
    <updated>2020-05-19T08:05:48.783Z</updated>
    
    <content type="html"><![CDATA[<p>闭包是什么？如果你与我有同样的疑问，敬请阅读。<br><a id="more"></a></p><h2 id="什么是闭包？"><a href="#什么是闭包？" class="headerlink" title="什么是闭包？"></a><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-closure/#note_1" target="_blank" rel="noopener">什么是闭包？</a></h2><p>这个问题困扰了我很长时间。</p><p>第一次接触闭包这个概念，是在“形式语言”这门课上。好像“离散数学”这门课上也教过闭包，但是这都不重要，因为我们这里讨论的闭包与数学上的闭包没什么关系。本文讨论的闭包，是程序设计语言中的闭包。</p><h3 id="专业概念："><a href="#专业概念：" class="headerlink" title="专业概念："></a>专业概念：</h3><p><img src="/2020/05/19/闭包的迷思/2020-05-19-15-20-04.png" srcset="/img/loading.gif" alt></p><p>闭包是在其词法上下文中引用了自由变量的<strong>函数</strong>，自由变量是指除局部变量以外的变量。</p><p>又有一种说法是闭包<strong>不是函数</strong>，而是由函数和与其相关的引用环境组合而成的实体。</p><p><a href="https://zh.wikipedia.org/wiki/%E9%97%AD%E5%8C%85_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6" target="_blank" rel="noopener">维基百科</a>)的解释：闭包在实现上是一个结构体，它存储了一个函数（通常是其入口地址）和一个关联的环境（相当于一个符号查找表）。</p><p>看到这里我彻底懵逼了。是是是，你们说的都对！<br><img src="/2020/05/19/闭包的迷思/2020-05-18-14-59-42.png" srcset="/img/loading.gif" alt></p><p>身为新手小白，我需要通过判断闭包是做什么的，之后再讨论为什么叫做闭包。</p><h2 id="闭包有什么用？"><a href="#闭包有什么用？" class="headerlink" title="闭包有什么用？"></a>闭包有什么用？</h2><p>如果你是从C++来的，那么阅读下面没有什么障碍。如果不是也没有关系，反正各种语言的设计原理都是类似的，只要你掌握的语言有<strong>匿名函数</strong>的功能即可。</p><p>我们都知道，C++11标准引入了lambda表达式，就是一个匿名函数。这个函数长成这样：</p><pre><code class="lang-cpp">[](const string&amp;a, const string&amp;b) {    return a.size() &lt; b.size();};</code></pre><p>上面的这个匿名函数负责比较两个字符串的大小。匿名函数的好处就是节省代码。</p><p>比如我现在想要实现自定义字符串排序函数，按照字符串长度从小到大排序，而不是按照字典排序。这个排序函数就可以用lambda表达式定义。</p><pre><code class="lang-cpp">stable_sort(words.begin(), words.end(),             [](const string&amp;a, const string&amp;b) {                return a.size() &lt; b.size();};)</code></pre><p>lambda前面的中括号是干啥的？是用来捕获外部变量的。比如我想判断字符串长度有没有大于阈值threshold，这个threshold是在函数外面定义的。按照C++的语法，一般的函数不能访问函数外部的变量。但是lambda可以把外部的变量“捕获”，就像下面这样：</p><pre><code class="lang-cpp">int threshold = 10;[threshold](const string&amp; a) {    return a.size() &gt; threshold;};</code></pre><p>可以看到，这个lambda不但使用了lambda内部的变量和参数，而且还“偷取”了不属于它的全局变量threshold。<strong>我们把lambda表达式定义的这种函数叫做闭包。</strong></p><h2 id="为什么叫做闭包？"><a href="#为什么叫做闭包？" class="headerlink" title="为什么叫做闭包？"></a>为什么叫做闭包？</h2><p>有人说这不是脑子有坑吗，闭包哪里“闭”了？这明明比普通函数更“开放”好吧？是不是名字起错了？</p><p>其实不然。闭包并不是对内部封闭，而是给当前外部环境取了个快照，相当于封闭了外部状态。下面是著名营养快线经销商vczh的回答：</p><p><img src="/2020/05/19/闭包的迷思/2020-05-19-15-40-47.png" srcset="/img/loading.gif" alt></p><h2 id="Python中的闭包"><a href="#Python中的闭包" class="headerlink" title="Python中的闭包"></a>Python中的闭包</h2><p>Python中写闭包就要方便多了，毕竟Python的设计哲学就是“一切皆对象”，函数都是对象。</p><p>我们来看这样一个问题：利用闭包和生成器返回一个计数器函数，每次调用它返回递增整数。</p><pre><code class="lang-python"># 利用闭包和生成器返回一个计数器函数，每次调用它返回递增整数。def createCounter():        [...]# 检验部分counterA = createCounter()print(counterA(), counterA(), counterA(), counterA(), counterA()) # 1 2 3 4 5counterB = createCounter()if [counterB(), counterB(), counterB(), counterB()] == [1, 2, 3, 4]:    print(&#39;测试通过!&#39;)else:    print(&#39;测试失败!&#39;)</code></pre><p>你想怎么写？我能想到的，就是在函数内部定义一个生成器，每次调用生成一个整数；然后利用next函数构造一个迭代器，每次调用让这个整数+1，最后返回这个迭代器。</p><pre><code class="lang-python">def createCounter():        def counter():        &#39;&#39;&#39;定义一个生成器        &#39;&#39;&#39;        n = 0        while 1:            n += 1            yield n    g = counter() # 取生成器    def g_fn():        &#39;&#39;&#39;定义一个迭代器，利用next迭代生成器g        &#39;&#39;&#39;        return next(g)    return g_fn # 返回这个迭代器</code></pre><p>我们看一下上面这个函数，函数内部定义的<code>g_fn</code>函数，它使用了外部变量<code>g</code>，也就是说<code>g_fn</code>是个闭包。</p><h2 id="总结一下："><a href="#总结一下：" class="headerlink" title="总结一下："></a>总结一下：</h2><p><strong>引用了自由变量的函数，就是闭包。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;闭包是什么？如果你与我有同样的疑问，敬请阅读。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="C++" scheme="https://superlova.github.io/tags/C/"/>
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="closure" scheme="https://superlova.github.io/tags/closure/"/>
    
      <category term="lambda" scheme="https://superlova.github.io/tags/lambda/"/>
    
  </entry>
  
  <entry>
    <title>Python装饰器为什么这么难以理解</title>
    <link href="https://superlova.github.io/2020/05/18/Python%E8%A3%85%E9%A5%B0%E5%99%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E9%9A%BE%E4%BB%A5%E7%90%86%E8%A7%A3/"/>
    <id>https://superlova.github.io/2020/05/18/Python%E8%A3%85%E9%A5%B0%E5%99%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E9%9A%BE%E4%BB%A5%E7%90%86%E8%A7%A3/</id>
    <published>2020-05-18T04:43:08.000Z</published>
    <updated>2020-05-19T10:06:38.373Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍Python中的装饰器，以及设计模式中的装饰模式。<br><a id="more"></a></p><p>从C/C++或Java迁移来的新Python程序员一定会对Python的装饰器功能感到陌生，尤其是在函数定义前加<code>@func</code>这一功能感到困惑。装饰器到底是什么？Python背后做了什么？在仔细研究网上的资料之后，我总结了此文，与大家分享。</p><p><a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017451662295584" target="_blank" rel="noopener">参考文章</a></p><h2 id="1-提出需求"><a href="#1-提出需求" class="headerlink" title="1. 提出需求"></a>1. 提出需求</h2><p>我们想在函数增加一点功能，比如每次函数执行之前打印一段话，但是又不想更改函数的定义。</p><p>这种想要给原来函数增加需求的同时，不修改原来代码的行为，非常有“面向对象编程思想”内味儿，因为它符合“开放封闭原则”。</p><p>现在就有请大名鼎鼎的设计模式之——装饰器模式登场！</p><blockquote><p>装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。</p></blockquote><p><img src="/2020/05/18/Python装饰器为什么这么难以理解/2020-05-19-17-27-00.png" srcset="/img/loading.gif" alt></p><h2 id="2-Python中的装饰器模式"><a href="#2-Python中的装饰器模式" class="headerlink" title="2. Python中的装饰器模式"></a>2. Python中的装饰器模式</h2><p>在Python中实现装饰器模式很方便。在Python中，有个功能模块直接就叫装饰器。在Python中的装饰器是指一个返回其他函数的函数。外部的高阶函数在执行内部的原函数的前后，再私藏一点干货，然后把修改后的函数对象赋值给原来的函数变量。这样就能在不修改原函数的基础上，增加一些功能。</p><p>总结下来，实现装饰器三步走：</p><ol><li>定义原函数</li><li>定义高阶函数，在里面除了执行原函数之外，再添加一些功能</li><li>将高阶函数对象赋值为原函数变量，以后调用原函数的时候都会执行高阶函数了</li></ol><pre><code class="lang-python">def log(func):    def wrapper(*args, **kw):        print(&#39;call %s():&#39; % func.__name__)        return func(*args, **kw)    return wrapper</code></pre><p>上面的函数，输入参数为原函数变量，在内部构造了一个高阶函数对象wrapper，wrapper里面负责执行一个print语句。最后返回构造好的wrapper。</p><p>以后我们使用<code>func</code>的时候，只要使用<code>log(func)</code>就可以在执行<code>func</code>的同时，打印一段话了。</p><p>看起来不咋地啊，毕竟我们还是修改了代码，把<code>func</code>全都替换成<code>log(func)</code>才能执行。</p><p>或者我们来这样一句：</p><pre><code class="lang-python">func = log(func)</code></pre><p>这个log函数就是一个装饰器，它现在装饰的是func函数。</p><h2 id="3-Python的语法糖"><a href="#3-Python的语法糖" class="headerlink" title="3. Python的语法糖"></a>3. Python的语法糖</h2><p>借助Python的@语法，把decorator置于函数的定义处，我们可以直接完成<code>func = log(func)</code>的操作。</p><pre><code class="lang-python">@logdef basic_fun():    print(&quot;basic_func&quot;)</code></pre><p>以后使用basic_func就会默认执行log(basic_func)了。</p><h2 id="4-改函数名"><a href="#4-改函数名" class="headerlink" title="4. 改函数名"></a>4. 改函数名</h2><p>Python的设计思想就是“一切皆对象”，就连函数也不例外。既然是对象，那么对象可以赋值给一个变量，也可以直接使用。通过变量也可以调用该函数对象。</p><pre><code class="lang-python">def f():    return 0f_obj = f # 注意，这里f为函数名，不加括号则为将函数对象赋值为变量f_res = f() # f后面跟了括号，则此时执行函数，并把返回值赋值给变量</code></pre><p>Python有个特别方便的功能，那就是函数对象可以在运行时打印自己的名字。接上面的代码：</p><pre><code class="lang-python">print(f.__name__) # fprint(f_obj.__name__) # 本质上还是调用上面的函数对象，结果仍为f</code></pre><p>前面我们做了赋值操作<code>func = log(func)</code>，但是其变量代表的函数名称发生了变化。</p><pre><code class="lang-python">print(func.__name__) # funcfunc = log(func)print(func.__name__) # wrapper</code></pre><p>我们希望装饰器完全包裹原函数，也就是说令外界环境感觉不到内部逻辑的变化。那么就需要我们把函数名字也给保持住。这个功能不难，我们使用<code>functools</code>库中自带的装饰器<code>wraps</code>就可以保持函数名称了。</p><pre><code class="lang-python">import functoolsdef log(func):    @functools.wraps(func) # 将被装饰函数名变成参数中函数名    def wrapper(*args, **kw):        print(&#39;call %s():&#39; % func.__name__)        return func(*args, **kw)    return wrapper</code></pre><h2 id="5-带参数的装饰器"><a href="#5-带参数的装饰器" class="headerlink" title="5. 带参数的装饰器"></a>5. 带参数的装饰器</h2><p>在上面我们可以看到，装饰器也是可以带参数的。这是怎么做到的呢？</p><p>其实我们不难想到，只需装饰一个装饰器即可。比如下面这个问题：</p><p><strong>实现log(str)：在函数每次执行前打印str和函数名</strong></p><pre><code class="lang-python">@log(&#39;end&#39;)def now():    print(np.datetime64(&#39;today&#39;, &#39;D&#39;))&gt;&gt;&gt; now()end now():2019-10-13</code></pre><p>解法如下：</p><pre><code class="lang-python">import functoolsdef log(text):    def decorator(func):        @functools.wraps(func)        def wrapper(*args, **kw):            print(&#39;%s %s():&#39; % (text, func.__name__))            return func(*args, **kw)        return wrapper    return decorator</code></pre><p>相当于<code>fun = log(&#39;text&#39;)(fun)</code>，实际上函数变成了<code>wrapper</code><br>但是由于<code>@functools.wraps(func)</code>，函数的<code>__name__</code>不变</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍Python中的装饰器，以及设计模式中的装饰模式。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="decorator" scheme="https://superlova.github.io/tags/decorator/"/>
    
  </entry>
  
  <entry>
    <title>深度学习工作站调研--结合政府采购网信息</title>
    <link href="https://superlova.github.io/2020/05/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E7%AB%99%E8%B0%83%E7%A0%94-%E7%BB%93%E5%90%88%E6%94%BF%E5%BA%9C%E9%87%87%E8%B4%AD%E7%BD%91%E4%BF%A1%E6%81%AF/"/>
    <id>https://superlova.github.io/2020/05/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E7%AB%99%E8%B0%83%E7%A0%94-%E7%BB%93%E5%90%88%E6%94%BF%E5%BA%9C%E9%87%87%E8%B4%AD%E7%BD%91%E4%BF%A1%E6%81%AF/</id>
    <published>2020-05-11T03:59:50.000Z</published>
    <updated>2020-05-20T02:36:25.578Z</updated>
    
    <content type="html"><![CDATA[<h1 id="服务器调研-2020年5月10日"><a href="#服务器调研-2020年5月10日" class="headerlink" title="服务器调研 2020年5月10日"></a>服务器调研 2020年5月10日</h1><p><strong>调研目标：</strong></p><ul><li>目前典型的计算机，包括商用台式机、工作站、服务器</li><li>搭配目前典型的GPU卡</li><li>GPU适配计算机，需要厂家网站公开的列表，特别是对于服务器。如果厂家没有，需要致电厂商（非销售商）的技术支持。</li></ul><h2 id="1-制约性能的典型项目"><a href="#1-制约性能的典型项目" class="headerlink" title="1. 制约性能的典型项目"></a>1. 制约性能的典型项目</h2><h3 id="1-1-主板"><a href="#1-1-主板" class="headerlink" title="1.1 主板"></a>1.1 主板</h3><p>Intel部分芯片组不支持PCIe 3.0接口，无法发挥显卡的最佳速度。</p><h4 id="名词解释："><a href="#名词解释：" class="headerlink" title="名词解释："></a>名词解释：</h4><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-21-33-30.png" srcset="/img/loading.gif" alt><br><strong>PCI Express / PCI-e</strong><br>PCI-E的全名叫PCI Express，简称PCI-E，官方简称PCIe，他是计算机内部的一种高速总线。PCI-E既是通道，也是接口，当他以接口形式存在的时候，就是我们主板上那长长的槽。PCI-E接口目前最大的作用就是插显卡<br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-21-32-30.png" srcset="/img/loading.gif" alt></p><p><strong>PCI Express 修订版 / PCIe版本</strong><br>PCIe所能承受的带宽一般以版本和长度来区分，目前最流行的PCIe版本是3.0，最新的版本是4.0，目前只有高端主板支持4.0，只有比2080ti还要高端的显卡才需要4.0。</p><p><strong>PCI Express 配置</strong><br>通俗的说就是插槽长度。X1长度是最短的，所能承受的带宽大约是986MB/S。X2长度就是2GB/S，X4长度就是4GB/S，那X16长度就是16GB/S。当前主流显卡，均采用PCIE×16插槽结构。只要具有PCIE×16插槽的主板，都是可以安装独立显卡的。<br>英特尔官网的意义没大看懂，真正有意义的是“支持的处理器 PCI Express 端口配置”这一项。</p><p><strong>支持的处理器 PCI Express 端口配置</strong><br>以Z390主板为例，该主板1x16 or 2x8 or 1x8+2x4，意思就是可以插1个长度为16X的显卡，也可以插两个长度为8X的固态硬盘之类的，但是如果同时插上显卡和固态硬盘，就会出现抢通道的现象：显卡占用16个通道，两个固态占用16个通道，然而<strong>PCI Express 通道数的最大值</strong>就只有24个，通道不够用就会导致限速，甚至无法正常运转。</p><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-13-34.png" srcset="/img/loading.gif" alt><br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-13-57.png" srcset="/img/loading.gif" alt><br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-14-07.png" srcset="/img/loading.gif" alt><br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-14-15.png" srcset="/img/loading.gif" alt></p><p>以上是当前在售处理器搭配主板（芯片组）的特性支持情况，仅供参考，并不是说某块主板用了上述某个芯片组芯片就会具备这么多的扩展接口及能力，具体还要看主板厂商针对这个版型作出什么样的“阉割”调整。</p><h3 id="1-2-电源"><a href="#1-2-电源" class="headerlink" title="1.2 电源"></a>1.2 电源</h3><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-11-24.png" srcset="/img/loading.gif" alt="顶级游戏显卡及需要的电源功率大小"></p><h2 id="2-目前典型计算机"><a href="#2-目前典型计算机" class="headerlink" title="2. 目前典型计算机"></a>2. 目前典型计算机</h2><p>服务器对显卡的支持不如工作站，台式机的性能过低，因此本调查汇聚于工作站查询。</p><h3 id="2-1-服务器"><a href="#2-1-服务器" class="headerlink" title="2.1 服务器"></a>2.1 服务器</h3><p>服务器按外形划分可以划分为：塔式服务器、机架式服务器、刀片式服务器。<br>服务器除了一些低端的塔式机能用显卡以外，其他的都不支持显度卡，当然机架式服务器很薄根本就没有显卡的空间。<br>如果购买服务器，官方售后将不会主动为你安装个人家用系列显卡，转而推销商业计算卡。<br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-15-26-49.png" srcset="/img/loading.gif" alt></p><p>截至2020年5月，服务器热销品牌Top-10（取自<a href="http://top.zol.com.cn/compositor/server.html" target="_blank" rel="noopener">ZOL网</a>）：<br>Dell、华为、浪潮、联想、惠普、H3C、ThinkServer、中科曙光、宝德、IBM。</p><h3 id="2-2-工作站"><a href="#2-2-工作站" class="headerlink" title="2.2 工作站"></a>2.2 工作站</h3><p>工作站的机箱主要以塔式为主，和一般家用主机机箱差距不大。<br>工作站对显卡的支持比服务器强很多，具体来说，工作站的主板对PCI-E的接口支持更好。</p><p>以下价格和资料全部取自于北京市政府采购网。</p><p><strong>神舟</strong><br>HFMPB2O8型号支持双路2080ti或TITAN<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=1r6e15444412038777n5&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HFMPB2O8</a>    78,016.00 自带2080ti<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=2g0v15681729710791z0&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HFMPB99K</a>  55,691.28   自带2080ti<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=6u7m15621197126648s6&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HFMPB3IR</a>  32,870.00   C422可更换更高级显卡<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=8n5x15444417182251i6&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HFMPB3J9</a>  29,980.00   自带2080</p><p><strong>联想</strong><br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=6h7y15571256822209c5&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">Think Station P520</a>   46,920.00    C422可更换更高级显卡<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=1s8z15571265520623u2&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">ThinkStation P720</a> 35,000.00   C622可更换更高级 </p><p><strong>宏碁</strong><br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=7w0g15281019011939v9&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">AP150 F4</a> 38,500.00    C622可更换更高级 </p><p><strong>浪潮</strong><br>浪潮是自研主板，不过其主板支持PCIe 16x，理论上只要供电足够即可安装包括2080Ti在内的显卡<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=3f4m15287143876139q2&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">P8000</a>    37,260.00</p><p><strong>惠普</strong><br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=4g2q15281081290990x3&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HP Z4 G4</a>  15,900.00   C622可更换更高级<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=4v9p15281082398434h6&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HP Z6 G4</a>  23,500.00   C622可更换更高级<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=0z0m15314586871347z2&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HP Z8 G4</a>  35,800.00   C622可更换更高级 </p><p><strong>苹果</strong><br>苹果的主板仅支持AMD的显卡，A卡不能用作深度学习。</p><h3 id="2-3-商用台式机"><a href="#2-3-商用台式机" class="headerlink" title="2.3 商用台式机"></a>2.3 商用台式机</h3><p>即普通台式机。普通台式机难以支撑深度学习任务。</p><h2 id="3-显卡介绍"><a href="#3-显卡介绍" class="headerlink" title="3. 显卡介绍"></a>3. 显卡介绍</h2><p>显卡分为Nvidia显卡和AMD显卡，其中Nvidia显卡可以用来深度学习训练和推理。</p><p>比较显卡性能，可以去<a href="https://versus.com/cn" target="_blank" rel="noopener">这个网站</a></p><h3 id="3-1-Nvidia显卡简介"><a href="#3-1-Nvidia显卡简介" class="headerlink" title="3.1 Nvidia显卡简介"></a>3.1 Nvidia显卡简介</h3><p><a href="https://www.bybusa.com/gpu-rank" target="_blank" rel="noopener">2020年显卡天梯图</a></p><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-23-18.png" srcset="/img/loading.gif" alt="2020年显卡天梯图"></p><p>目前最强的显卡是2080ti。预计在2020年底的3080ti发布之前，2080ti还会持续称霸显卡江湖。</p><h3 id="3-2-游戏显卡"><a href="#3-2-游戏显卡" class="headerlink" title="3.2 游戏显卡"></a>3.2 游戏显卡</h3><p>对游戏显卡的调研，参考<a href="https://post.smzdm.com/p/a6lrwk3e/" target="_blank" rel="noopener">“什么值得买”上的调研</a>以及<a href="https://www.cnblogs.com/xiaozhi_5638/p/10923351.html" target="_blank" rel="noopener">这个网址</a>。</p><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-09-38.png" srcset="/img/loading.gif" alt="游戏显卡一览"></p><p><strong>Geforce系列</strong></p><p>这个系列是销量最多、大众最为熟悉的显卡，一般用来打游戏。价格便宜，最新出来的旗舰卡RTX 2080Ti京东售价大概1w左右，根据不同的品牌，价格有所波动。低配置的便宜的一千就能买到。官方定位是消费级，但是它在深度学习上的表现也非常不错，很多人用来做推理、训练，单张卡的性能跟深度学习专业卡Tesla系列比起来其实差不太多，但是性价比却高很多。比如已经停产的GTX 1080显卡的参数基本和深度学习入门级显卡Tesla P4一样，用来做训练和推理的效果比Tesla P4还要好，可是GTX 1080一张卡才卖5000~6000左右，而Tesla P4要卖到1.4w。</p><p>究其原因，很大程度上在于英伟达官方禁止使用GTX、RTX系列显卡用于深度学习等用途，一经使用，自动过保。除了商业考虑外，还包括：Tesla多块显卡合起来的性能不会受很大影响，且Tesla系列显卡功耗优化非常明显，基本都是被动散热，不提供风扇，更适合数据中心机房工作环境等。</p><h3 id="3-3-计算显卡"><a href="#3-3-计算显卡" class="headerlink" title="3.3 计算显卡"></a>3.3 计算显卡</h3><p>专业级显卡的介绍参考<a href="https://product.pconline.com.cn/itbk/diy/graphics/1802/10846244.html" target="_blank" rel="noopener">“什么值得买”上的调研</a>以及<a href="https://www.cnblogs.com/xiaozhi_5638/p/10923351.html" target="_blank" rel="noopener">这个网址</a>。</p><p><strong>Quadro系列</strong><br>Quadro系列显卡一般用于特定行业，比如设计、建筑等，图像处理专业显卡，比如CAD、Maya等软件，一般人很少用到，价格相对来讲也稍微贵一些，最新的包括RTX 3000/4000/6000/8000型号。</p><p><strong>Tesla系列</strong><br>Tesla系列显卡定位并行计算，一般用于数据中心，具体点，比如用于深度学习，做训练、推理等。阿里云、Amazon云有非常多的GPU服务器，基本都采用Tesla系列显卡。这个系列显卡有个特别明显的特征，那就是贵。Tesla系列入门级显卡 Tesla P4，前面提到过，用来做深度学习的效果比GTX 1080还差，但是价格是后者的3倍多。像其他更高级别的Tesla V100、Tesla P100 价格高达8w、4w，这种价位的显卡虽然性能强劲，但是一般人是买不起的，只有企业数据中心才会部署这种显卡。</p><h3 id="3-4-显卡性能指标"><a href="#3-4-显卡性能指标" class="headerlink" title="3.4 显卡性能指标"></a>3.4 显卡性能指标</h3><p>本部分请参考<a href="https://www.cnblogs.com/xiaozhi_5638/p/10923351.html" target="_blank" rel="noopener">这里</a>。</p><h3 id="3-4-显卡罗列"><a href="#3-4-显卡罗列" class="headerlink" title="3.4 显卡罗列"></a>3.4 显卡罗列</h3><p>政府采购网上，值得采购的显卡如下</p><div class="table-container"><table><thead><tr><th>型号</th><th>价格</th></tr></thead><tbody><tr><td>p5000</td><td>27000</td></tr><tr><td>p6000</td><td>43500</td></tr><tr><td>2080</td><td>13500</td></tr><tr><td>k4000</td><td>42450</td></tr><tr><td>p4000</td><td>6800</td></tr><tr><td>2070s</td><td>8000</td></tr><tr><td>8000</td><td>93350</td></tr><tr><td>2080ti</td><td>16000</td></tr><tr><td>1080ti</td><td>8620</td></tr><tr><td>p4</td><td>28000</td></tr><tr><td>2080</td><td>10290</td></tr><tr><td>2060</td><td>5000</td></tr><tr><td>titan rtx</td><td>30000</td></tr><tr><td>p1000</td><td>3500</td></tr><tr><td>2070</td><td>7500</td></tr><tr><td>m2000</td><td>2982</td></tr><tr><td>titan v</td><td>37500</td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;服务器调研-2020年5月10日&quot;&gt;&lt;a href=&quot;#服务器调研-2020年5月10日&quot; class=&quot;headerlink&quot; title=&quot;服务器调研 2020年5月10日&quot;&gt;&lt;/a&gt;服务器调研 2020年5月10日&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;调研目标：&lt;
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="PCIe" scheme="https://superlova.github.io/tags/PCIe/"/>
    
      <category term="显卡" scheme="https://superlova.github.io/tags/%E6%98%BE%E5%8D%A1/"/>
    
      <category term="工作站" scheme="https://superlova.github.io/tags/%E5%B7%A5%E4%BD%9C%E7%AB%99/"/>
    
  </entry>
  
  <entry>
    <title>chrome升级版本失败解决办法</title>
    <link href="https://superlova.github.io/2020/05/11/chrome%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/05/11/chrome%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</id>
    <published>2020-05-11T03:46:55.000Z</published>
    <updated>2020-05-11T04:22:34.367Z</updated>
    
    <content type="html"><![CDATA[<h2 id="错误描述："><a href="#错误描述：" class="headerlink" title="错误描述："></a>错误描述：</h2><p>在Win7电脑上试图将Chrome从32位的72版本升级到64位的80版本时发生问题，升级进度到62%报错：<br>Chrome安装 未知错误导致安装失败  “0x80040902”</p><p>从chrome官网下载“chromesetup.exe”，打开梯子之后下载成功，在安装过程中也出现未知错误。<br>从Chrome官网下载“Chromestandalonesetup64.exe”，即离线安装包，最后也出现同样的错误。<br>重新启动、进入安全模式、试图结束所有有关google的进程的方法对我都没用。</p><h2 id="最后有效的方法："><a href="#最后有效的方法：" class="headerlink" title="最后有效的方法："></a>最后有效的方法：</h2><p>把原来的Chrome从控制面板的“添加删除程序”中卸载；</p><p>按住windows+R，在“开始”运行中输入“regedit”，打开注册表编辑器，依次进入HKEY_CURRENT_USER\Software\Google\Chrome；</p><p>把Chrome这一项删除，然后重启。再安装就不会存在问题了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;错误描述：&quot;&gt;&lt;a href=&quot;#错误描述：&quot; class=&quot;headerlink&quot; title=&quot;错误描述：&quot;&gt;&lt;/a&gt;错误描述：&lt;/h2&gt;&lt;p&gt;在Win7电脑上试图将Chrome从32位的72版本升级到64位的80版本时发生问题，升级进度到62%报错：&lt;br&gt;
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="chrome" scheme="https://superlova.github.io/tags/chrome/"/>
    
  </entry>
  
  <entry>
    <title>testRNN--Coverage-guided Testing on Recurrent Neural Networks 论文阅读笔记</title>
    <link href="https://superlova.github.io/2020/03/25/testRNN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>https://superlova.github.io/2020/03/25/testRNN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2020-03-25T02:37:35.000Z</published>
    <updated>2020-05-20T02:37:02.929Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;

      
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="RNN" scheme="https://superlova.github.io/tags/RNN/"/>
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
      <category term="testRNN" scheme="https://superlova.github.io/tags/testRNN/"/>
    
  </entry>
  
</feed>
