<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Superlova</title>
  
  <subtitle>Welcome...</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://superlova.github.io/"/>
  <updated>2020-07-27T15:11:39.605Z</updated>
  <id>https://superlova.github.io/</id>
  
  <author>
    <name>Superlova</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【竞赛打卡】新闻文本分类之深度学习FastText</title>
    <link href="https://superlova.github.io/2020/07/27/%E3%80%90%E7%AB%9E%E8%B5%9B%E6%89%93%E5%8D%A1%E3%80%91%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B9%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0FastText/"/>
    <id>https://superlova.github.io/2020/07/27/%E3%80%90%E7%AB%9E%E8%B5%9B%E6%89%93%E5%8D%A1%E3%80%91%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B9%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0FastText/</id>
    <published>2020-07-27T13:56:03.000Z</published>
    <updated>2020-07-27T15:11:39.605Z</updated>
    
    <content type="html"><![CDATA[<p>当你写东西或讲话的时候，始终要想到使每个普通工人都懂得，都相信你的号召，都决心跟着你走。要想到你究竟为什么人写东西，向什么人讲话。——《反对党八股》<br><a id="more"></a></p><p>在上一章节，我们使用传统机器学习算法来解决了文本分类问题，从本章开始我们将尝试使用深度学习方法。与传统机器学习不同，深度学习既提供特征提取功能，也可以完成分类的功能。</p><p>本次学习我们主要介绍FastText。</p><p>fastText是一个快速文本分类算法，与基于神经网络的分类算法相比有两大优点：<br>1、fastText在保持高精度的情况下加快了训练速度和测试速度<br>2、fastText不需要预训练好的词向量，fastText会自己训练词向量<br>3、fastText两个重要的优化：层级 Softmax、N-gram</p><pre><code class="lang-python">import fasttextmodel = fasttext.train_supervised(&#39;train.csv&#39;, lr=1.0, wordNgrams=2, verbose=2, minCount=1, epoch=25, loss=&quot;hs&quot;)val_pred = [model.predict(x)[0][0].split(&#39;__&#39;)[-1] for x in df_train.iloc[-5000:][&#39;text&#39;]]print(f1_score(df_train[&#39;label&#39;].values[-5000:].astype(str), val_pred, average=&#39;macro&#39;))0.8256254253081777</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当你写东西或讲话的时候，始终要想到使每个普通工人都懂得，都相信你的号召，都决心跟着你走。要想到你究竟为什么人写东西，向什么人讲话。——《反对党八股》&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Datawhale" scheme="https://superlova.github.io/tags/Datawhale/"/>
    
      <category term="Deep Learning" scheme="https://superlova.github.io/tags/Deep-Learning/"/>
    
      <category term="Classification" scheme="https://superlova.github.io/tags/Classification/"/>
    
      <category term="FastText" scheme="https://superlova.github.io/tags/FastText/"/>
    
  </entry>
  
  <entry>
    <title>【竞赛打卡】新闻文本分类之机器学习文本分类</title>
    <link href="https://superlova.github.io/2020/07/23/%E3%80%90%E7%AB%9E%E8%B5%9B%E6%89%93%E5%8D%A1%E3%80%91%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B9%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    <id>https://superlova.github.io/2020/07/23/%E3%80%90%E7%AB%9E%E8%B5%9B%E6%89%93%E5%8D%A1%E3%80%91%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B9%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</id>
    <published>2020-07-22T17:43:15.000Z</published>
    <updated>2020-07-27T14:18:20.439Z</updated>
    
    <content type="html"><![CDATA[<p>今我睹子之难穷也，吾非至于子之门则殆矣。<br><a id="more"></a></p><h1 id="文本表示方法实践"><a href="#文本表示方法实践" class="headerlink" title="文本表示方法实践"></a>文本表示方法实践</h1><p>自然语言总需要转换成数值等表示才能被线性模型等处理。下面利用task1&amp;2提到的编码方式进行实践。</p><h2 id="Label"><a href="#Label" class="headerlink" title="Label"></a>Label</h2><p>这种编码方式是把自然语言首先分词成基本语素单元，然后把不同的单元赋予唯一的整数编码。比如本次比赛提供的数据集就是该编码方式。每条数据都是整数序列，最大整数为7549，最小整数为0。</p><p>这样做的好处是相对节约内存，且实现简单；坏处是破坏了自然语言中部分语义，无法进一步进行诸如删除停用词、词根提取等操作。另外，编码的大小可能会让算法误以为词和词之间有大小关系。</p><p>因为原来的数据集就是此编码方法，故不再赘述。</p><h2 id="Bag-of-Words-CountVectorizer"><a href="#Bag-of-Words-CountVectorizer" class="headerlink" title="Bag of Words: CountVectorizer"></a>Bag of Words: CountVectorizer</h2><p>用于机器学习的文本表示有一种最简单的方法，也是最有效且最常用的方法，就是使用词袋（bag-of-words）表示。使用这种表示方式时，我们舍弃了输入文本中的大部分结构，如章节、段落、句子和格式，<strong>只计算语料库中每个单词在每个文本中的出现频次</strong>。舍弃结构并仅计算单词出现次数，这会让脑海中出现将文本表示为“袋”的画面。</p><pre><code class="lang-python">from sklearn.feature_extraction.text import CountVectorizerbagvect = CountVectorizer(max_df=.15)bagvect.fit(corpus)feature_names = bagvect.get_feature_names()print(&quot;Number of features: {}&quot;.format(len(feature_names)))print(&quot;First 20 features:\n{}&quot;.format(feature_names[:20]))Number of features: 4740First 20 features:[&#39;10&#39;, &#39;100&#39;, &#39;1000&#39;, &#39;1001&#39;, &#39;1002&#39;, &#39;1004&#39;, &#39;1005&#39;, &#39;1006&#39;, &#39;1007&#39;, &#39;1008&#39;, &#39;1009&#39;, &#39;101&#39;, &#39;1010&#39;, &#39;1012&#39;, &#39;1013&#39;, &#39;1014&#39;, &#39;102&#39;, &#39;1020&#39;, &#39;1022&#39;, &#39;1023&#39;]bag_of_words = bagvect.transform(corpus)print(&quot;bag_of_words: {}&quot;.format(repr(bag_of_words)))print(bag_of_words[0].toarray())bag_of_words: &lt;10000x4740 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;    with 813365 stored elements in Compressed Sparse Row format&gt;[[0 0 0 ... 0 0 0]]</code></pre><p>词袋表示保存在一个 SciPy 稀疏矩阵中，这种数据格式只保存非零元素</p><p>矩阵的形状为 10000x4740，每行对应于两个数据点之一，每个特征对应于词表中的一个单词。当然，我们在这里选了10000个样本，如果把所有数据集都给转化成词袋向量，那么矩阵形状将会是 200000×6859。</p><h2 id="Hash编码实践"><a href="#Hash编码实践" class="headerlink" title="Hash编码实践"></a>Hash编码实践</h2><p><a href="https://chenk.tech/posts/eb79fc5f.html" target="_blank" rel="noopener">https://chenk.tech/posts/eb79fc5f.html</a></p><pre><code class="lang-python">from sklearn.feature_extraction.text import HashingVectorizerhvec = HashingVectorizer(n_features=10000)hvec.fit(corpus)h_words = hvec.transform(corpus)print(&quot;h_words: {}&quot;.format(repr(h_words)))h_words: &lt;10000x10000 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;    with 2739957 stored elements in Compressed Sparse Row format&gt;</code></pre><p>我选取了10000个样本，将其映射到10000个特征的Hash向量中。</p><pre><code class="lang-python">print(h_words[0]) (0, 0)    -0.009886463280261834  (0, 6)    -0.04943231640130917  (0, 9)    0.03954585312104734  (0, 26)    -0.04943231640130917  (0, 42)    0.01977292656052367  (0, 70)    0.01977292656052367  (0, 74)    -0.12852402264340385  (0, 94)    0.009886463280261834  (0, 99)    0.01977292656052367  (0, 109)    -0.009886463280261834  :    :  (0, 9642)    -0.009886463280261834  (0, 9650)    0.01977292656052367  (0, 9653)    0.009886463280261834  (0, 9659)    -0.04943231640130917  (0, 9715)    -0.009886463280261834  (0, 9721)    0.009886463280261834  (0, 9729)    -0.009886463280261834  (0, 9741)    0.009886463280261834  (0, 9765)    -0.01977292656052367  (0, 9781)    0.01977292656052367  (0, 9821)    -0.009886463280261834  (0, 9862)    0.009886463280261834  (0, 9887)    -0.009886463280261834  (0, 9932)    0.009886463280261834</code></pre><p>输出的含义，前面的元组代表了该特征在词袋中的位置，后面的数值代表了对应的Hash值。</p><h2 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h2><p>TF-IDF（Term Frequency-inverse Document Frequency）是一种针对关键词的统计分析方法，用于评估一个词对一个文件集或者一个语料库的重要程度。</p><pre><code class="lang-python">from sklearn.feature_extraction.text import TfidfVectorizertvec = TfidfVectorizer()tvec.fit(corpus)feature_names = tvec.get_feature_names()print(&quot;Number of features: {}&quot;.format(len(feature_names)))print(&quot;First 20 features:\n{}&quot;.format(feature_names[:20]))Number of features: 5333First 20 features:[&#39;10&#39;, &#39;100&#39;, &#39;1000&#39;, &#39;1001&#39;, &#39;1002&#39;, &#39;1004&#39;, &#39;1005&#39;, &#39;1006&#39;, &#39;1007&#39;, &#39;1008&#39;, &#39;1009&#39;, &#39;101&#39;, &#39;1010&#39;, &#39;1012&#39;, &#39;1013&#39;, &#39;1014&#39;, &#39;1018&#39;, &#39;102&#39;, &#39;1020&#39;, &#39;1022&#39;]t_words = tvec.transform(corpus)print(&quot;t_words: {}&quot;.format(repr(t_words)))print(t_words[0].toarray())t_words: &lt;10000x5333 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;    with 2797304 stored elements in Compressed Sparse Row format&gt;[[0. 0. 0. ... 0. 0. 0.]]# 找到数据集中每个特征的最大值max_value = t_words.max(axis=0).toarray().ravel()sorted_by_tfidf = max_value.argsort()# 获取特征名称feature_names = np.array(tvec.get_feature_names())print(&quot;Features with lowest tfidf:\n{}&quot;.format(feature_names[sorted_by_tfidf[:20]]))print(&quot;Features with highest tfidf: \n{}&quot;.format(feature_names[sorted_by_tfidf[-20:]]))sorted_by_idf = np.argsort(tvec.idf_)print(&quot;Features with lowest idf:\n{}&quot;.format(feature_names[sorted_by_idf[:100]]))Features with lowest tfidf:[&#39;6844&#39; &#39;6806&#39; &#39;7201&#39; &#39;5609&#39; &#39;5585&#39; &#39;5485&#39; &#39;3453&#39; &#39;7390&#39; &#39;2322&#39; &#39;2083&#39; &#39;1222&#39; &#39;2360&#39; &#39;319&#39; &#39;2520&#39; &#39;6268&#39; &#39;3105&#39; &#39;6049&#39; &#39;4888&#39; &#39;2390&#39; &#39;2849&#39;]Features with highest tfidf: [&#39;3198&#39; &#39;2346&#39; &#39;5480&#39; &#39;4375&#39; &#39;6296&#39; &#39;1710&#39; &#39;682&#39; &#39;354&#39; &#39;4381&#39; &#39;482&#39; &#39;5990&#39; &#39;2798&#39; &#39;5907&#39; &#39;3992&#39; &#39;418&#39; &#39;513&#39; &#39;4759&#39; &#39;6250&#39; &#39;6220&#39; &#39;1633&#39;]Features with lowest idf:[&#39;3750&#39; &#39;900&#39; &#39;648&#39; &#39;6122&#39; &#39;7399&#39; &#39;2465&#39; &#39;4811&#39; &#39;4464&#39; &#39;1699&#39; &#39;299&#39; &#39;2400&#39; &#39;3659&#39; &#39;3370&#39; &#39;2109&#39; &#39;4939&#39; &#39;669&#39; &#39;5598&#39; &#39;5445&#39; &#39;4853&#39; &#39;5948&#39; &#39;2376&#39; &#39;7495&#39; &#39;4893&#39; &#39;5410&#39; &#39;340&#39; &#39;619&#39; &#39;4659&#39; &#39;1460&#39; &#39;6065&#39; &#39;1903&#39; &#39;5560&#39; &#39;6017&#39; &#39;2252&#39; &#39;4516&#39; &#39;1519&#39; &#39;2073&#39; &#39;5998&#39; &#39;5491&#39; &#39;2662&#39; &#39;5977&#39; &#39;6093&#39; &#39;1324&#39; &#39;5780&#39; &#39;3915&#39; &#39;3800&#39; &#39;5393&#39; &#39;2210&#39; &#39;5915&#39; &#39;3223&#39; &#39;4490&#39; &#39;2490&#39; &#39;1375&#39; &#39;803&#39; &#39;1635&#39; &#39;7539&#39; &#39;4411&#39; &#39;4128&#39; &#39;7543&#39; &#39;5602&#39; &#39;1866&#39; &#39;5176&#39; &#39;2799&#39; &#39;4646&#39; &#39;3700&#39; &#39;5858&#39; &#39;307&#39; &#39;913&#39; &#39;25&#39; &#39;6045&#39; &#39;1702&#39; &#39;4822&#39; &#39;3099&#39; &#39;5330&#39; &#39;1920&#39; &#39;1567&#39; &#39;2614&#39; &#39;4190&#39; &#39;1080&#39; &#39;5510&#39; &#39;4149&#39; &#39;3166&#39; &#39;3530&#39; &#39;192&#39; &#39;5659&#39; &#39;3618&#39; &#39;4525&#39; &#39;3686&#39; &#39;6038&#39; &#39;1767&#39; &#39;5589&#39; &#39;5736&#39; &#39;6831&#39; &#39;7377&#39; &#39;4969&#39; &#39;1394&#39; &#39;6104&#39; &#39;7010&#39; &#39;6407&#39; &#39;5430&#39; &#39;23&#39;]</code></pre><h2 id="多个单词的词袋：N-gram《》"><a href="#多个单词的词袋：N-gram《》" class="headerlink" title="多个单词的词袋：N-gram《》"></a>多个单词的词袋：N-gram《》</h2><p>使用词袋表示的主要缺点之一是完全舍弃了单词顺序。因此，“it’s bad, not good at all”（电影很差，一点也不好）和“it’s good, not bad at all”（电影很好，还不错）这两个字符串的词袋表示完全相同，尽管它们的含义相反。将“not”（不）放在单词前面，这只是上下文很重要的一个例子（可能是一个极端的例子）。幸运的是，使用词袋表示时有一种获取上下文的方法，就是不仅考虑单一词例的计数，而且还考虑相邻的两个或三个词例的计数。两个词例被称为二元分词（bigram），三个词例被称为三元分词（trigram），更一般的词例序列被称为 n 元分词（n-gram）。我们可以通过改变 CountVectorizer 或 TfidfVectorizer 的 ngram_range 参数来改变作为特征的词例范围。ngram_range 参数是一个元组，包含要考虑的词例序列的最小长度和最大长度。</p><p>在大多数情况下，添加二元分词会有所帮助。添加更长的序列（一直到五元分词）也可能有所帮助，但这会导致特征数量的大大增加，也可能会导致过拟合，因为其中包含许多非常具体的特征。原则上来说，二元分词的数量是一元分词数量的平方，三元分词的数量是一元分词数量的三次方，从而导致非常大的特征空间。在实践中，更高的 n 元分词在数据中的出现次数实际上更少，原因在于（英语）语言的结构，不过这个数字仍然很大。</p><pre><code class="lang-python">from sklearn.feature_extraction.text import TfidfVectorizertvec = TfidfVectorizer(ngram_range=(1,3), min_df=5)tvec.fit(corpus)# 找到数据集中每个特征的最大值max_value = t_words.max(axis=0).toarray().ravel()sorted_by_tfidf = max_value.argsort()# 获取特征名称feature_names = np.array(tvec.get_feature_names())print(&quot;Features with lowest tfidf:\n{}&quot;.format(feature_names[sorted_by_tfidf[:20]]))print(&quot;Features with highest tfidf: \n{}&quot;.format(feature_names[sorted_by_tfidf[-20:]]))sorted_by_idf = np.argsort(tvec.idf_)print(&quot;Features with lowest idf:\n{}&quot;.format(feature_names[sorted_by_idf[:100]]))Features with lowest tfidf:[&#39;1008 5612&#39; &#39;100 5560&#39; &#39;1018 4089 5491&#39; &#39;101 648 900&#39; &#39;1006 3750 826&#39; &#39;1018 1066 3231&#39; &#39;101 5560 3568&#39; &#39;100 5589&#39; &#39;1018 2119 281&#39; &#39;101 5560 3659&#39; &#39;1018 1066 3166&#39; &#39;100 5598 1465&#39; &#39;1000 5011&#39; &#39;101 2662 4939&#39; &#39;100 5602&#39; &#39;101 873 648&#39; &#39;1006 2265 648&#39; &#39;1008 5640&#39; &#39;1008 5689&#39; &#39;101 856 531&#39;]Features with highest tfidf: [&#39;101 2087&#39; &#39;1018 1066 281&#39; &#39;101 648 3440&#39; &#39;1006 5640 3641&#39; &#39;101 760 4233&#39; &#39;1006 6017&#39; &#39;1018 1066 6983&#39; &#39;1014 3750 3659&#39; &#39;100 5430 2147&#39; &#39;100 5510 2471&#39; &#39;1018 1141&#39; &#39;1006 1866 5977&#39; &#39;1018 2119 3560&#39; &#39;1018 2662 3068&#39; &#39;101 1844 4486&#39; &#39;101 2304 3659&#39; &#39;1006 3750 5330&#39; &#39;101 5589&#39; &#39;1008 900 3618&#39; &#39;100 6122 2489&#39;]Features with lowest idf:[&#39;3750&#39; &#39;900&#39; &#39;648&#39; &#39;2465&#39; &#39;6122&#39; &#39;7399&#39; &#39;4811&#39; &#39;4464&#39; &#39;1699&#39; &#39;3659&#39; &#39;2400&#39; &#39;299&#39; &#39;3370&#39; &#39;2109&#39; &#39;4939&#39; &#39;5598&#39; &#39;669&#39; &#39;5445&#39; &#39;4853&#39; &#39;2376&#39; &#39;5948&#39; &#39;7495&#39; &#39;4893&#39; &#39;5410&#39; &#39;340&#39; &#39;619&#39; &#39;4659&#39; &#39;1460&#39; &#39;6065&#39; &#39;4516&#39; &#39;1903&#39; &#39;5560&#39; &#39;6017&#39; &#39;2252&#39; &#39;2073&#39; &#39;1519&#39; &#39;5491&#39; &#39;5998&#39; &#39;2662&#39; &#39;5977&#39; &#39;1324&#39; &#39;5780&#39; &#39;6093&#39; &#39;3915&#39; &#39;5393&#39; &#39;2210&#39; &#39;3800&#39; &#39;3223&#39; &#39;5915&#39; &#39;4490&#39; &#39;2490&#39; &#39;803&#39; &#39;1635&#39; &#39;4128&#39; &#39;1375&#39; &#39;7539&#39; &#39;4411&#39; &#39;7543&#39; &#39;5602&#39; &#39;2799&#39; &#39;1866&#39; &#39;5176&#39; &#39;5858&#39; &#39;4646&#39; &#39;3700&#39; &#39;307&#39; &#39;6045&#39; &#39;1702&#39; &#39;25&#39; &#39;913&#39; &#39;5330&#39; &#39;4822&#39; &#39;2614&#39; &#39;3099&#39; &#39;1920&#39; &#39;1567&#39; &#39;4190&#39; &#39;4149&#39; &#39;5510&#39; &#39;1080&#39; &#39;3166&#39; &#39;3659 3370&#39; &#39;3530&#39; &#39;192&#39; &#39;3618&#39; &#39;4525&#39; &#39;5659&#39; &#39;3686&#39; &#39;6038&#39; &#39;1767&#39; &#39;5736&#39; &#39;7377&#39; &#39;5589&#39; &#39;6831&#39; &#39;3370 3370&#39; &#39;1394&#39; &#39;4969&#39; &#39;5430&#39; &#39;7010&#39; &#39;6104&#39;]</code></pre><h1 id="无监督探索"><a href="#无监督探索" class="headerlink" title="无监督探索"></a>无监督探索</h1><h2 id="PCA可视化"><a href="#PCA可视化" class="headerlink" title="PCA可视化"></a>PCA可视化</h2><pre><code class="lang-python">from sklearn.decomposition import PCApca = PCA(n_components=2)pca_vec = pca.fit_transform(t_words.toarray())pca_vec.shape, pca.explained_variance_ratio_((10000, 2), array([0.03817303, 0.02684457]))</code></pre><p>我们成功将tfidf转化后的词向量压缩成2维向量，这样就能够在二维平面可视化了。</p><p>后面的<code>explained_variance_ratio_</code>代表着经过PCA算法压缩后，保留的信息量。这个数值还是偏低，因此这种PCA压缩方法仅适用于实验。</p><pre><code class="lang-python">plt.figure(figsize=(12,10))plt.scatter(pca_vec[:,0], pca_vec[:,1], c=labels)</code></pre><p><img src="/2020/07/23/【竞赛打卡】新闻文本分类之机器学习文本分类/1.png" srcset="/img/loading.gif" alt></p><h2 id="主题建模"><a href="#主题建模" class="headerlink" title="主题建模"></a>主题建模</h2><p>常用于文本数据的一种特殊技术是主题建模（topic modeling），这是描述将每个文档分配给一个或多个主题的任务（通常是无监督的）的概括性术语。这方面一个很好的例子是新闻数据，它们可以被分为“政治”“体育”“金融”等主题。如果为每个文档分配一个主题，那么这是一个文档聚类任务。我们学到的每个成分对应于一个主题，文档表示中的成分系数告诉我们这个文档与该主题的相关性强弱。通常来说，人们在谈论主题建模时，他们指的是一种叫作隐含狄利克雷分布（Latent Dirichlet Allocation，LDA）的特定分解方法。</p><p>我们将 LDA 应用于新闻数据集，来看一下它在实践中的效果。对于无监督的文本文档模型，通常最好删除非常常见的单词，否则它们可能会支配分析过程。我们将删除至少在15% 的文档中出现过的单词，并在删除前 15% 之后，将词袋模型限定为最常见的 10 000 个单词：</p><pre><code class="lang-python">vect = CountVectorizer(max_features=10000, max_df=.15)X = vect.fit_transform(corpus)from sklearn.decomposition import LatentDirichletAllocationlda = LatentDirichletAllocation(n_components=14, learning_method=&quot;batch&quot;, max_iter=25, random_state=0)# 我们在一个步骤中构建模型并变换数据# 计算变换需要花点时间，二者同时进行可以节省时间document_topics = lda.fit_transform(bag_of_words)# 对于每个主题（components_的一行），将特征排序（升序）# 用[:, ::-1]将行反转，使排序变为降序sorting = np.argsort(lda.components_, axis=1)[:, ::-1]# 从向量器中获取特征名称feature_names = np.array(bagvect.get_feature_names())plt.figure()plt.bar(x=range(14), height=document_topics[0])plt.xticks(list(range(14)))</code></pre><p><img src="/2020/07/23/【竞赛打卡】新闻文本分类之机器学习文本分类/2.png" srcset="/img/loading.gif" alt></p><p>由LDA确定的主题词如下：</p><pre><code class="lang-python">topic 0       topic 1       topic 2       topic 3       topic 4       --------      --------      --------      --------      --------      6654          1970          7349          3464          4412          4173          2716          7354          7436          7363          1219          4553          1684          5562          6689          6861          7042          5744          3289          4986          5006          5822          6569          5105          2506          7400          5099          1999          5810          3056          3508          3654          1351          3134          6220          6223          3021          56            3648          5117          6227          4967          4036          6308          6319          7257          3396          4223          1706          2695          topic 5       topic 6       topic 7       topic 8       topic 9       --------      --------      --------      --------      --------      4967          1334          1934          4114          7328          7528          5166          1146          3198          5547          3644          6143          532           517           4768          1899          2695          4802          812           3231          6678          1616          419           3090          5492          5744          7532          4089          4163          4080          6047          368           3725          5305          4120          1252          2918          2851          177           2331          5814          2968          6227          7251          3019          1170          3032          6639          2835          6613          topic 10      topic 11      topic 12      topic 13      --------      --------      --------      --------      3523          4902          5178          5122          3342          1258          6014          6920          6722          343           5920          5519          6352          4089          4603          7154          3186          5226          3648          4381          5179          810           4042          4760          4369          6284          1724          4412          3501          3477          4450          4595          2334          7127          657           3377          2722          7077          5803          7006</code></pre><h2 id="t-SNE可视化"><a href="#t-SNE可视化" class="headerlink" title="t-SNE可视化"></a>t-SNE可视化</h2><p>t-SNE是当前最流行的数据可视化方法。将TF-IDF转化后的向量可视化如下：</p><pre><code class="lang-python">from sklearn.manifold import TSNEwords_emb = TSNE(n_components=2).fit_transform(t_words)plt.figure(figsize=(12,10))plt.scatter(words_emb[:,0], words_emb[:,1], c=labels)</code></pre><p><img src="/2020/07/23/【竞赛打卡】新闻文本分类之机器学习文本分类/3.png" srcset="/img/loading.gif" alt></p><p>将HashingVectorizer转化后的向量经过t-SNE算法可视化结果分享如下：</p><pre><code class="lang-python">hash_words_emb = TSNE(n_components=2).fit_transform(h_words)plt.figure(figsize=(12,10))plt.scatter(hash_words_emb[:,0], hash_words_emb[:,1], c=labels)</code></pre><p><img src="/2020/07/23/【竞赛打卡】新闻文本分类之机器学习文本分类/4.png" srcset="/img/loading.gif" alt></p><h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><p>首先导入相关库</p><pre><code class="lang-python">from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizerfrom sklearn.pipeline import make_pipelinefrom sklearn.linear_model import LogisticRegression, RidgeClassifierfrom sklearn.model_selection import GridSearchCV, train_test_split, cross_val_scorefrom sklearn.multiclass import OneVsRestClassifierfrom sklearn.svm import SVCfrom sklearn.metrics import f1_score</code></pre><p><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model" target="_blank" rel="noopener">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model</a></p><h2 id="RidgeClassifier-CountVectorizer"><a href="#RidgeClassifier-CountVectorizer" class="headerlink" title="RidgeClassifier+CountVectorizer"></a>RidgeClassifier+CountVectorizer</h2><p>首先我们使用教程中的范例</p><pre><code class="lang-python">X, y = df_train[&#39;text&#39;][:10000], df_train[&#39;label&#39;][:10000]vectorizer = CountVectorizer(max_features=3000)X = vectorizer.fit_transform(X)clf = RidgeClassifier()clf.fit(X[:5000], y[:5000]) # 使用前5000个样本进行训练val_pred = clf.predict(X[5000:]) # 使用后5000个样本进行预测print(f1_score(y[5000:], val_pred, average=&#39;macro&#39;))0.6322204326986258</code></pre><p>我们把10000个样本中，前5000个用于训练，后5000个用于测试，最终结果以F1指标展示，结果为0.63，不太令人满意。</p><h2 id="LogisticRegression-TFIDF"><a href="#LogisticRegression-TFIDF" class="headerlink" title="LogisticRegression+TFIDF"></a>LogisticRegression+TFIDF</h2><p>最常见的线性分类算法是 Logistic 回归。虽然 LogisticRegression 的名字中含有回归（regression），但它是一种分类算法，并不是回归算法，不应与 LinearRegression 混淆。<br>我们可以将 LogisticRegression 和 LinearSVC 模型应用到经过tfidf处理的新闻文本数据集上。</p><p>我们使用了sklearn中的划分数据集的方法<code>train_test_split</code>，将数据集划分成训练集和测试集两部分。但是这样一来，数据集中的测试集部分将不能被训练，未免有点可惜。</p><p>我们在训练时，采用了pipeline方式，Pipeline 类可以将多个处理步骤合并（glue）为单个 scikit-learn 估计器。Pipeline 类本身具有 fit、predict 和 score 方法，其行为与 scikit-learn 中的其 他模型相同。Pipeline 类最常见的用例是将预处理步骤（比如数据缩放）与一个监督模型 （比如分类器）链接在一起。</p><pre><code class="lang-python">%%timeX_train, X_test, y_train, y_test = train_test_split(df_train[&#39;text&#39;][:10000], df_train[&#39;label&#39;][:10000], random_state=0)pipe_logis = make_pipeline(TfidfVectorizer(min_df=5, ngram_range=(1,3)), LogisticRegression())param_grid = {&#39;logisticregression__C&#39;: [0.001, 0.01, 0.1, 1, 10]}grid = GridSearchCV(pipe_logis, param_grid, cv=5)grid.fit(X_train, y_train)print(&quot;Best params:\n{}\n&quot;.format(grid.best_params_))print(&quot;Best cross-validation score: {:.2f}&quot;.format(grid.best_score_))print(&quot;Test-set score: {:.2f}&quot;.format(grid.score(X_test, y_test)))Best params:{&#39;logisticregression__C&#39;: 10}Best cross-validation score: 0.91Test-set score: 0.92</code></pre><h2 id="SVC-tfidf"><a href="#SVC-tfidf" class="headerlink" title="SVC+tfidf"></a>SVC+tfidf</h2><p>这次我们使用非线性模型中大名鼎鼎的SVM模型，并采用交叉验证的方法划分数据集，不浪费任何一部分数据。</p><pre><code class="lang-python">X_train, y_train = df_train[&#39;text&#39;][:10000], df_train[&#39;label&#39;][:10000]pipe_svc = make_pipeline(TfidfVectorizer(min_df=5), SVC()) # decision_function_shape=&#39;ovr&#39;scores = cross_val_score(pipe_svc, X_train, y_train, cv=5, n_jobs=-1)print(scores.mean())0.8924</code></pre><h1 id="模型评价"><a href="#模型评价" class="headerlink" title="模型评价"></a>模型评价</h1><p>TR，FN，precision，recall等的进一步解释，请参考以下链接：<br><a href="https://www.zhihu.com/question/30643044" target="_blank" rel="noopener">https://www.zhihu.com/question/30643044</a></p><h1 id="进一步优化"><a href="#进一步优化" class="headerlink" title="进一步优化"></a>进一步优化</h1><p>使用机器学习模型+巧妙的特征工程，我们可以达到90%以上的精度，这在14分类问题中已经很惊人了。然而我们的工作并没有结束，还有许许多多的问题等着我们去探索。比如</p><ul><li>删除停用词、罕见词、其他常见词和不能反映特征的词</li><li>类别不平衡问题</li></ul><p>周志华《机器学习》中介绍到，分类学习方法都有一个共同的基本假设，即不同类别的训练样例数目相当。如果不同类别的训练样例数目稍有差别，对学习结果的影响通常也不大，但若样本类别数目差别很大，属于极端不均衡，则会对学习过程（模型训练）造成困扰。这些学习算法的设计背后隐含的优化目标是数据集上的分类准确度，而这会导致学习算法在不平衡数据上更偏向于含更多样本的多数类。多数不平衡学习（imbalance learning）算法就是为了解决这种“对多数类的偏好”而提出的。如果正负类样本类别不平衡比例超过4:1，那么其分类器会大大地因为数据不平衡性而无法满足分类要求</p><p>关于如何解决类别不平衡的问题，可以参考以下链接：<br><a href="https://zhuanlan.zhihu.com/p/84322912" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/84322912</a><br><a href="https://zhuanlan.zhihu.com/p/36381828" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36381828</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今我睹子之难穷也，吾非至于子之门则殆矣。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Machine Learning" scheme="https://superlova.github.io/tags/Machine-Learning/"/>
    
      <category term="Datawhale" scheme="https://superlova.github.io/tags/Datawhale/"/>
    
      <category term="Classification" scheme="https://superlova.github.io/tags/Classification/"/>
    
  </entry>
  
  <entry>
    <title>【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析</title>
    <link href="https://superlova.github.io/2020/07/22/%E3%80%90%E7%AB%9E%E8%B5%9B%E6%89%93%E5%8D%A1%E3%80%91%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8NLP%E4%B9%8B%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B9%8B%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/"/>
    <id>https://superlova.github.io/2020/07/22/%E3%80%90%E7%AB%9E%E8%B5%9B%E6%89%93%E5%8D%A1%E3%80%91%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8NLP%E4%B9%8B%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B9%8B%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E4%B8%8E%E5%88%86%E6%9E%90/</id>
    <published>2020-07-22T04:03:05.000Z</published>
    <updated>2020-07-25T05:22:02.670Z</updated>
    
    <content type="html"><![CDATA[<p>不要对我有任何期待哦！<br><a id="more"></a></p><h1 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h1><p>Colab</p><pre><code class="lang-python">import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom sklearn.model_selection import train_test_splitimport seaborn as snsimport scipyfrom collections import Counter</code></pre><h1 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h1><pre><code class="lang-python">df_train = pd.read_csv(train_path, sep=&#39;\t&#39;)df_test = pd.read_csv(test_path, sep=&#39;\t&#39;)</code></pre><h1 id="数据探索"><a href="#数据探索" class="headerlink" title="数据探索"></a>数据探索</h1><h2 id="简单查看数据"><a href="#简单查看数据" class="headerlink" title="简单查看数据"></a>简单查看数据</h2><pre><code class="lang-python">df_train.head(), len(df_train)(   label                                               text 0      2  2967 6758 339 2021 1854 3731 4109 3792 4149 15... 1     11  4464 486 6352 5619 2465 4802 1452 3137 5778 54... 2      3  7346 4068 5074 3747 5681 6093 1777 2226 7354 6... 3      2  7159 948 4866 2109 5520 2490 211 3956 5520 549... 4      3  3646 3055 3055 2490 4659 6065 3370 5814 2465 5..., 200000)</code></pre><p>发现text域的数据是字符串。我们想要得到整数序列。可以用字符串分割<code>split()</code>。</p><pre><code class="lang-python">print(len(df_train[&#39;text&#39;][0]), type(df_train[&#39;text&#39;][0]))df_train.head()</code></pre><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/1.png" srcset="/img/loading.gif" alt></p><h2 id="长度分布"><a href="#长度分布" class="headerlink" title="长度分布"></a>长度分布</h2><h3 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h3><p>这里与教程中的方法有所不同。vectorize是numpy中很方便的函数，作用和pandas中<code>apply</code>差不多。用法：</p><p><code>np.vectorize(function)(array)</code></p><p>输入待处理的array，以及逐元素处理函数function，返回经过处理后的ndarray。原来的array则不受影响。</p><p>当前我使用的函数<code>split_df</code>负责将一行数据按空格切分成整数列表，然后计算该列表的长度。</p><pre><code class="lang-python">def split_df(df_row):    return len(str(df_row).split())len_dist = np.vectorize(split_df)(df_train[&#39;text&#39;])len_test_dist = np.vectorize(split_df)(df_test[&#39;text&#39;])</code></pre><p>使用describe函数查看训练集和测试集中的数据长度分布</p><pre><code class="lang-python">print(pd.Series(len_dist).describe())print(pd.Series(len_test_dist).describe())count    200000.000000mean        907.207110std         996.029036min           2.00000025%         374.00000050%         676.00000075%        1131.000000max       57921.000000dtype: float64count    50000.000000mean       909.844960std       1032.313375min         14.00000025%        370.00000050%        676.00000075%       1133.000000max      41861.000000dtype: float64</code></pre><p>通过数据描述可以看到</p><p>训练集共200,000条新闻，每条新闻平均907个字符，最短的句子长度为2，最长的句子长度为57921，其中75%以下的数据长度在1131以下。</p><p>测试集共50,000条新闻，每条新闻平均909个字符，最短句子长度为14，最长句子41861,75%以下的数据长度在1133以下。</p><p>训练集和测试集就长度来说似乎是同一分布。</p><h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><p>绘制直方图查看训练集和测试集中的数据长度分布</p><pre><code class="lang-python">fig, ax = plt.subplots(1,1,figsize=(12,6))ax = plt.hist(x=len_dist, bins=100)ax = plt.hist(x=len_test_dist, bins=100)plt.xlim([0, max(max(len_dist), max(len_test_dist))])plt.xlabel(&quot;length of sample&quot;)plt.ylabel(&quot;number of sample&quot;)plt.legend([&#39;train_len&#39;,&#39;test_len&#39;])plt.show()</code></pre><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/2.png" srcset="/img/loading.gif" alt></p><p>使用seaborn绘制更好的图</p><p>seaborn计算的纵坐标是频率，而不是出现次数。由于训练集和测试集的数据量不一样，因此用频率更加科学、更能看出是否符合同一分布。</p><pre><code class="lang-python">plt.figure(figsize=(15,5))ax = sns.distplot(len_dist, bins=100)ax = sns.distplot(len_test_dist, bins=100)plt.xlim([0, max(max(len_dist), max(len_test_dist))])plt.xlabel(&quot;length of sample&quot;)plt.ylabel(&quot;prob of sample&quot;)plt.legend([&#39;train_len&#39;,&#39;test_len&#39;])</code></pre><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/3.png" srcset="/img/loading.gif" alt></p><p>通过直方图，我们能直观感受到训练集和测试集的长度分布都属于右偏分布。按理说分析到这份儿上就该停了。</p><h3 id="同分布验证"><a href="#同分布验证" class="headerlink" title="同分布验证"></a>同分布验证</h3><pre><code class="lang-python">import scipyscipy.stats.ks_2samp(len_dist, len_test_dist)Ks_2sampResult(statistic=0.004049999999999998, pvalue=0.5279614323123156)</code></pre><p>P值为0.52，比指定的显著水平（假设为5%）大，我们认为二者同分布。</p><h3 id="截断位置"><a href="#截断位置" class="headerlink" title="截断位置"></a>截断位置</h3><p>在输入模型进行训练之前，我们要把所有的数据长度统一化，数据肯定要截断。但是在什么位置截断合适呢？</p><p>考虑到数据长度分布是长尾分布，log一下看看是不是正态分布，如果是正态分布，使用3sigma法则作为截断的参考。如果不是，则就只能瞎猜了</p><p>测量拟合分布的均值和方差sigma原则</p><p>$1\sigma$原则：数值分布在$(\mu-\sigma,\mu+\sigma)$中的概率为0.6526；</p><p>$2\sigma$原则：数值分布在$(\mu-2\sigma,\mu+2\sigma)$中的概率为0.9544；</p><p>$3\sigma$原则：数值分布在$(\mu-3\sigma,\mu+3\sigma)$中的概率为0.9974；</p><p>由于“小概率事件”和假设检验的基本思想 “小概率事件”通常指发生的概率小于5%的事件，认为在一次试验中该事件是几乎不可能发生的。由此可见X落在$(\mu-3\sigma,\mu+3\sigma)$以外的概率小于千分之三，在实际问题中常认为相应的事件是不会发生的，基本上可以把区间$(\mu-3\sigma,\mu+3\sigma)$看作是随机变量X实际可能的取值区间，这称之为正态分布的“$3\sigma$”原则。</p><pre><code class="lang-python">log_len_dist = np.log(1+len_dist)log_len_test_dist = np.log(1+len_test_dist)plt.figure(figsize=(15,5))ax = sns.distplot(log_len_dist)ax = sns.distplot(log_len_test_dist)plt.xlabel(&quot;log length of sample&quot;)plt.ylabel(&quot;prob of log&quot;)plt.legend([&#39;train_len&#39;,&#39;test_len&#39;])</code></pre><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/4.png" srcset="/img/loading.gif" alt></p><p>从log图上也能看出二者（很像）同分布。</p><p>下面我想验证一下我的猜想：该分布为正态分布，且训练集和测试集为同分布。</p><p>先验证训练集分布为正态分布：</p><pre><code class="lang-python">_, lognormal_ks_pvalue = scipy.stats.kstest(rvs=log_len_dist, cdf=&#39;norm&#39;)print(&#39;P value is &#39;, lognormal_ks_pvalue)P value is  0.0</code></pre><p>？0？？？拟合优度检验，p值为0，意思就是说这不是一个正态分布。<br>关于分布检验，参考<a href="https://blog.csdn.net/QimaoRyan/article/details/72861387" target="_blank" rel="noopener">这篇文章</a></p><p>之前我们把数据log了一下，但是这里有更科学的变换方式。log只是box-cox变换的特殊形式。我们使用box-cox变换再次做一下验证，是否为正态分布：</p><pre><code class="lang-python">trans_data, lam = scipy.stats.boxcox(len_dist+1)scipy.stats.normaltest(trans_data)NormaltestResult(statistic=1347.793358118494, pvalue=2.1398873511704724e-293)</code></pre><p>e后面跟了那么多负数，我佛了。这说明我们的假设不成立。</p><p>但总归是要猜一个截断值的。看log图上8.5的位置比较靠谱。np.exp(8.5)=4914约等于5000，因此我初步决定把截断长度定为5000。</p><h2 id="类别信息"><a href="#类别信息" class="headerlink" title="类别信息"></a>类别信息</h2><h3 id="简单查看类别信息表"><a href="#简单查看类别信息表" class="headerlink" title="简单查看类别信息表"></a>简单查看类别信息表</h3><p>先改造一下df_train，多加几个字段，分别是</p><ul><li>text-split，将text字段分词</li><li>len，每条新闻长度</li><li>first_char，新闻第一个字符</li><li>last_char，新闻最后一个字符</li><li>most_freq，新闻最常出现的字符</li></ul><pre><code class="lang-python">df_train[&#39;text_split&#39;] = df_train[&#39;text&#39;].apply(lambda x:x.split())df_train[&#39;len&#39;] = df_train[&#39;text&#39;].apply(lambda x:len(x.split()))df_train[&#39;first_char&#39;] = df_train[&#39;text_split&#39;].apply(lambda x:x[0])df_train[&#39;last_char&#39;] = df_train[&#39;text_split&#39;].apply(lambda x:x[-1])df_train[&#39;most_freq&#39;] = df_train[&#39;text_split&#39;].apply(lambda x:np.argmax(np.bincount(x)))df_train.head()</code></pre><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/2020-07-25-12-22-01.png" srcset="/img/loading.gif" alt></p><p>构建一个类别信息表。</p><ul><li>count，该类别新闻个数</li><li>len_mean，该类别新闻平均长度</li><li>len_std，该类别新闻长度标准差</li><li>len_min，该类别新闻长度最小值</li><li>len_max，该类别新闻长度最大值</li><li>freq_fc，该类别新闻最常出现的第一个字符</li><li>freq_lc，该类别新闻最常出现的最后一个字符</li><li>freq_freq，该类别新闻最常出现的字符</li></ul><pre><code class="lang-python">df_train_info = pd.DataFrame(columns=[&#39;count&#39;,&#39;len_mean&#39;,&#39;len_std&#39;,&#39;len_min&#39;,&#39;len_max&#39;,&#39;freq_fc&#39;,&#39;freq_lc&#39;,&#39;freq_freq&#39;])for name, group in df_train.groupby(&#39;label&#39;):    count = len(group) # 该类别新闻数    len_mean = np.mean(group[&#39;len&#39;]) # 该类别长度平均值    len_std = np.std(group[&#39;len&#39;]) # 长度标准差    len_min = np.min(group[&#39;len&#39;]) # 最短的新闻长度    len_max = np.max(group[&#39;len&#39;]) # 最长的新闻长度    freq_fc = np.argmax(np.bincount(group[&#39;first_char&#39;])) # 最频繁出现的首词    freq_lc = np.argmax(np.bincount(group[&#39;last_char&#39;])) # 最频繁出现的末词    freq_freq = np.argmax(np.bincount(group[&#39;most_freq&#39;])) # 该类别最频繁出现的词    df_train_info.loc[name] = [count,len_mean,len_std,len_min,len_max,freq_fc,freq_lc,freq_freq]df_train_info</code></pre><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/2020-07-25-12-30-24.png" srcset="/img/loading.gif" alt></p><h3 id="类别分布"><a href="#类别分布" class="headerlink" title="类别分布"></a>类别分布</h3><p>之前的讨论是从数据集总体验证同分布的，我们还需要验证训练集的类别足够均匀。</p><p>在数据集中标签的对应的关系如下</p><pre><code class="lang-python">label_2_index_dict = {&#39;科技&#39;: 0, &#39;股票&#39;: 1, &#39;体育&#39;: 2, &#39;娱乐&#39;: 3, &#39;时政&#39;: 4, &#39;社会&#39;: 5, &#39;教育&#39;: 6, &#39;财经&#39;: 7, &#39;家居&#39;: 8, &#39;游戏&#39;: 9, &#39;房产&#39;: 10, &#39;时尚&#39;: 11, &#39;彩票&#39;: 12, &#39;星座&#39;: 13}index_2_label_dict = {v:k for k,v in label_2_index_dict.items()}plt.figure()plt.bar(x=range(14), height=np.bincount(df_train[&#39;label&#39;]))plt.xlabel(&quot;label&quot;)plt.ylabel(&quot;number of sample&quot;)plt.xticks(range(14), list(index_2_label_dict.values()), fontproperties=zhfont, rotation=60)plt.show()</code></pre><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/6.png" srcset="/img/loading.gif" alt></p><p>从统计结果可以看出</p><p>赛题的数据集类别分布存在较为不均匀的情况。在训练集中科技类新闻最多，其次是股票类新闻，最少的新闻是星座新闻。</p><p>科技类新闻最多，星座类新闻最少。这个国家的人大部分是唯物主义者哈，神秘学受众比较少（啊这，我在分析什么？）。</p><p>由于类别不均衡，会严重影响模型的精度。但是我们也是有办法应对的。</p><h3 id="类别长度"><a href="#类别长度" class="headerlink" title="类别长度"></a>类别长度</h3><pre><code class="lang-python">df_train[&#39;len&#39;] = df_train[&#39;text&#39;].apply(lambda x: len(x.split()))plt.figure()ax = sns.catplot(x=&#39;label&#39;, y=&#39;len&#39;, data=df_train, kind=&#39;strip&#39;)plt.xticks(range(14), list(index_2_label_dict.values()), fontproperties=zhfont, rotation=60)</code></pre><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/7.png" srcset="/img/loading.gif" alt></p><p>在散点图中，股票类新闻的长度都飘到天上去了，可以看出股票分析类文章真的很容易写得又臭又长啊（发现：不同类别的文章长度不同，可以把长度作为一个Feature，以供机器学习模型训练）！</p><h2 id="字符分布"><a href="#字符分布" class="headerlink" title="字符分布"></a>字符分布</h2><p>训练集中总共包括6869个字，最大数字为7549，最小数字为0，其中编号3750的字出现的次数最多，编号3133的字出现的次数最少，仅出现一次。</p><pre><code class="lang-python"># 内存警告！！！没有8G内存不要运行该代码all_lines = &#39; &#39;.join(list(df_train[&#39;text&#39;]))word_count = Counter(all_lines.split(&quot; &quot;))word_count = sorted(word_count.items(), key=lambda d:d[1], reverse=True)print(len(word_count))# 6869print(word_count[0])# (&#39;3750&#39;, 7482224)print(word_count[-1])# (&#39;3133&#39;, 1)</code></pre><p>下面代码统计了不同字符在多少个句子中出现过，其中字符3750、字符900和字符648在20w新闻的覆盖率接近99%，很有可能是标点符号。</p><pre><code class="lang-python">%%timedf_train[&#39;text_unique&#39;] = df_train[&#39;text&#39;].apply(lambda x: &#39; &#39;.join(list(set(x.split(&#39; &#39;)))))all_lines = &#39; &#39;.join(list(df_train[&#39;text_unique&#39;]))word_count = Counter(all_lines.split(&quot; &quot;))word_count = sorted(word_count.items(), key=lambda d:int(d[1]), reverse=True)# 打印整个训练集中覆盖率前5的词for i in range(5):    print(&quot;{} occurs {} times, {}%&quot;.format(word_count[i][0], word_count[i][1], (word_count[i][1]/200000)*100))</code></pre><p>3750 occurs 197997 times, 98.9985%<br>900 occurs 197653 times, 98.8265%<br>648 occurs 191975 times, 95.9875%<br>2465 occurs 177310 times, 88.655%<br>6122 occurs 176543 times, 88.2715%</p><h2 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h2><p><strong>假设字符3750，字符900和字符648是句子的标点符号，请分析赛题每篇新闻平均由多少个句子构成？</strong></p><p>如果这是英文文章，那么3750应该是空格吧？如果3750是逗号怎么办？先要判断哪个是句号。</p><p>思路：该新闻的句子数为该个数。每条新闻最后的字符往往是句号，先看看每条新闻最后一个字符是什么：</p><pre><code class="lang-python">last_char = np.vectorize(lambda x:int(x.split()[-1]))(df_train[&#39;text&#39;])last_char_count = Counter(last_char)last_char_count = sorted(last_char_count.items(), key=lambda d:d[1], reverse=True)# 打印出现次数最多的前十个for i in range(10):    print(&quot;{}在新闻末尾出现了{}次&quot;.format(last_char_count[i][0], last_char_count[i][1]))900在新闻末尾出现了85040次2662在新闻末尾出现了39273次885在新闻末尾出现了14473次1635在新闻末尾出现了7379次2465在新闻末尾出现了7076次57在新闻末尾出现了3284次3231在新闻末尾出现了2758次1633在新闻末尾出现了2706次3568在新闻末尾出现了1504次2265在新闻末尾出现了1389次</code></pre><p>因此我们有理由认为900是句号。至于3750应该是逗号吧？猜的，理由是3750不太容易在新闻末尾出现。</p><p>但是除了句号之外，感叹号和问号照样能划分句子，我们试着将2662当作感叹号，将885当作问号。什么理由？猜的。</p><p>下面开始计算每篇新闻所含标点符号（900、2662、885）的个数，</p><pre><code class="lang-python">def sum_of_sep(row):    counter = Counter(row.split())    return counter.get(&#39;900&#39;, 0)+counter.get(&#39;2662&#39;, 0)+counter.get(&#39;885&#39;, 0)sum_sep = np.vectorize(sum_of_sep)(df_train[&#39;text&#39;])print(&quot;平均每条新闻的句子个数约为：&quot;, np.round(np.mean(sum_sep)))pd.Series(sum_sep).describe()平均每条新闻的句子个数约为： 19.0count    200000.000000mean         19.070155std          21.463798min           0.00000025%           7.00000050%          14.00000075%          24.000000max        1392.000000dtype: float64</code></pre><p>平均长度为19，其实这是把那些股票文章也算上了，拉高了平均值。75%的新闻长度都在24个句子以下。</p><p>给df_train_info新加一列sent_num，计算分词后的句子个数；sent_len为句子长度。</p><pre><code class="lang-python">list_num_sentence = []for name, group in df_train.groupby(&#39;label&#39;):    sum_sep_label = np.vectorize(sum_of_sep)(group[&#39;text&#39;])    num_sentence = np.mean(sum_sep_label)    list_num_sentence.append(num_sentence)df_train_info[&#39;sent_num&#39;] = list_num_sentencedf_train_info[&#39;sent_len&#39;] = df_train_info[&#39;len_mean&#39;] / df_train_info[&#39;sent_num&#39;]df_train_info</code></pre><p>不同类别的新闻，其句子长度和个数也是不同的。</p><p>之前我们分析，股票类文章往往很长，而社会（label=5）和教育（label=6）类文章的句子最多。家居（label=8）和时尚（label=11）类新闻的句子最少。游戏类（label=9）句子是最长的，社会（label=5）句子是最短的（发现：句子和个数长度也可以作为特征）。</p><p><img src="/2020/07/22/【竞赛打卡】零基础入门NLP之新闻文本分类之数据读取与分析/2020-07-25-13-00-28.png" srcset="/img/loading.gif" alt></p><p><strong>每类新闻中出现次数前10</strong></p><p>在每类新闻中出现频率最高的词汇，就是df_train_info表中的freq_freq列。可以看到，清一色的3750，这个字符我们在后期处理时可以拿掉。</p><pre><code class="lang-python">word_count_dict = {}for name, df in df_train.groupby(&#39;label&#39;):    # print(name, type(df))    all_text = &#39; &#39;.join(list(df[&#39;text&#39;].apply(lambda x: &#39; &#39;.join(list(x.split(&#39; &#39;))))))    word_count_single_class = Counter(all_text.split(&quot; &quot;))    word_count_single_class = sorted(word_count_single_class.items(), key=lambda d:int(d[1]), reverse = True)    word_count_dict[name] = word_count_single_classfor label in range(14):    print(index_2_label_dict[label], [x for x,_ in word_count_dict[label][:10]])科技 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;3370&#39;, &#39;4464&#39;, &#39;2465&#39;, &#39;6122&#39;, &#39;3659&#39;, &#39;7399&#39;, &#39;4939&#39;]股票 [&#39;3750&#39;, &#39;648&#39;, &#39;3370&#39;, &#39;900&#39;, &#39;4464&#39;, &#39;3659&#39;, &#39;5036&#39;, &#39;6250&#39;, &#39;1633&#39;, &#39;6065&#39;]体育 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;7399&#39;, &#39;6122&#39;, &#39;4939&#39;, &#39;4704&#39;, &#39;1667&#39;, &#39;5598&#39;, &#39;669&#39;]娱乐 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;6122&#39;, &#39;4939&#39;, &#39;4893&#39;, &#39;7399&#39;, &#39;669&#39;, &#39;803&#39;, &#39;1635&#39;]时政 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;4411&#39;, &#39;7399&#39;, &#39;4893&#39;, &#39;6122&#39;, &#39;4464&#39;, &#39;2400&#39;, &#39;4853&#39;]社会 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;6122&#39;, &#39;5598&#39;, &#39;4893&#39;, &#39;7399&#39;, &#39;4939&#39;, &#39;3370&#39;, &#39;669&#39;]教育 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;6248&#39;, &#39;2555&#39;, &#39;5620&#39;, &#39;2465&#39;, &#39;6122&#39;, &#39;5560&#39;, &#39;3370&#39;]财经 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;3370&#39;, &#39;5296&#39;, &#39;4464&#39;, &#39;6835&#39;, &#39;3659&#39;, &#39;6122&#39;, &#39;7399&#39;]家居 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;6122&#39;, &#39;4939&#39;, &#39;913&#39;, &#39;5560&#39;, &#39;7399&#39;, &#39;3961&#39;, &#39;4811&#39;]游戏 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;7328&#39;, &#39;6122&#39;, &#39;7399&#39;, &#39;5547&#39;, &#39;4939&#39;, &#39;3370&#39;, &#39;2465&#39;]房产 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;3370&#39;, &#39;2465&#39;, &#39;5560&#39;, &#39;3686&#39;, &#39;4464&#39;, &#39;3523&#39;, &#39;6122&#39;]时尚 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;4939&#39;, &#39;6122&#39;, &#39;5560&#39;, &#39;669&#39;, &#39;4811&#39;, &#39;7539&#39;, &#39;4893&#39;]彩票 [&#39;3750&#39;, &#39;4464&#39;, &#39;3370&#39;, &#39;648&#39;, &#39;2465&#39;, &#39;900&#39;, &#39;3659&#39;, &#39;6065&#39;, &#39;1667&#39;, &#39;2614&#39;]星座 [&#39;3750&#39;, &#39;648&#39;, &#39;900&#39;, &#39;4939&#39;, &#39;669&#39;, &#39;6122&#39;, &#39;4893&#39;, &#39;3864&#39;, &#39;4811&#39;, &#39;1465&#39;]</code></pre><h1 id="分析结果"><a href="#分析结果" class="headerlink" title="分析结果"></a>分析结果</h1><p>数据分析肯定要有结论，没有结论的数据分析是不完整的。</p><ol><li><p>训练集共200,000条新闻，每条新闻平均907个字符，最短的句子长度为2，最长的句子长度为57921，其中75%以下的数据长度在1131以下。测试集共50,000条新闻，每条新闻平均909个字符，最短句子长度为14，最长句子41861,75%以下的数据长度在1133以下。</p></li><li><p>训练集和测试集就长度来说似乎是同一分布，但是不属于正态分布。</p></li><li><p>把截断长度定为5000？</p></li><li><p>赛题的数据集类别分布存在较为不均匀的情况。在训练集中科技类新闻最多，其次是股票类新闻，最少的新闻是星座新闻。需要用采样方法解决。文章最长的是股票类新闻。不同类别的文章长度不同，可以把长度和句子个数作为一个Feature，以供机器学习模型训练。</p></li><li><p>训练集中总共包括6869个字，最大数字为7549，最小数字为0，其中编号3750的字出现的次数最多，编号3133的字出现的次数最少，仅出现一次，其中字符3750、字符900和字符648在20w新闻的覆盖率接近99%，很有可能是标点符号。</p></li><li><p>900很有可能是句号，2662和885则很有可能为感叹号和问号，3750出现频率很高但是基本不在新闻最后出现，因此初步判断为逗号。按照这种划分，训练集中每条新闻平均句子个数约为19。</p></li><li><p>在训练集中，不同类别新闻出现词汇有特色。但是需要把共有的常用词停用。自然想到利用TF-IDF编码方式。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不要对我有任何期待哦！&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Feature Engineering" scheme="https://superlova.github.io/tags/Feature-Engineering/"/>
    
      <category term="Data Science" scheme="https://superlova.github.io/tags/Data-Science/"/>
    
      <category term="Datawhale" scheme="https://superlova.github.io/tags/Datawhale/"/>
    
  </entry>
  
  <entry>
    <title>【竞赛打卡】零基础入门NLP之新闻文本分类之赛题理解</title>
    <link href="https://superlova.github.io/2020/07/21/%E3%80%90%E7%AB%9E%E8%B5%9B%E6%89%93%E5%8D%A1%E3%80%91%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8NLP%E4%B9%8B%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B9%8B%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3/"/>
    <id>https://superlova.github.io/2020/07/21/%E3%80%90%E7%AB%9E%E8%B5%9B%E6%89%93%E5%8D%A1%E3%80%91%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8NLP%E4%B9%8B%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B9%8B%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3/</id>
    <published>2020-07-21T15:51:00.000Z</published>
    <updated>2020-07-21T16:18:20.216Z</updated>
    
    <content type="html"><![CDATA[<p>这项任务不好做呀，稍不小心就占用了task2的内容。<br><a id="more"></a></p><h1 id="零基础入门NLP之新闻文本分类之赛题理解"><a href="#零基础入门NLP之新闻文本分类之赛题理解" class="headerlink" title="零基础入门NLP之新闻文本分类之赛题理解"></a>零基础入门NLP之新闻文本分类之赛题理解</h1><h2 id="一、现在公开的情报"><a href="#一、现在公开的情报" class="headerlink" title="一、现在公开的情报"></a>一、现在公开的情报</h2><h3 id="1-比赛内容"><a href="#1-比赛内容" class="headerlink" title="1. 比赛内容"></a>1. 比赛内容</h3><p>本次比赛的任务为文本的分类任务。虽然简单，但是想要取得高分还是不容易。</p><p>待分类文本为新闻文本。新闻文本根据来源，分为财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐，共14类。</p><h3 id="2-数据内容"><a href="#2-数据内容" class="headerlink" title="2. 数据内容"></a>2. 数据内容</h3><p>训练集和测试集在<a href="https://tianchi.aliyun.com/competition/entrance/531810/introduction" target="_blank" rel="noopener">官网</a>下载。</p><p>其中训练集是带正确标签的，测试集不带标签，是真正的题目。我们的任务是训练模型，正确分类测试集中每一条新闻的标签。</p><p>训练集由20万条新闻构成，测试集五万条数据。</p><p>每条新闻都被编码为整数序列。每个单词对应一个整数。</p><p>数据集中标签的对应的关系如下：</p><p><code>{&#39;科技&#39;: 0, &#39;股票&#39;: 1, &#39;体育&#39;: 2, &#39;娱乐&#39;: 3, &#39;时政&#39;: 4, &#39;社会&#39;: 5, &#39;教育&#39;: 6, &#39;财经&#39;: 7, &#39;家居&#39;: 8, &#39;游戏&#39;: 9, &#39;房产&#39;: 10, &#39;时尚&#39;: 11, &#39;彩票&#39;: 12, &#39;星座&#39;: 13}</code></p><h3 id="3-赛制"><a href="#3-赛制" class="headerlink" title="3. 赛制"></a>3. 赛制</h3><ul><li>第一阶段（7月15日-9月7日），每天两次提交自己答案的机会，系统根据成绩自动排名，排行榜每小时更新。该排行与最终成绩无关。</li><li>第二阶段（9月7日～9月8日）清空排行榜，7日11：00放出新测试数据。同样每天只能提交两次，每小时更新榜单，9月8日晚上20点的排行即为最终成绩。</li><li>排行前13名选手在9月11日12:00前提交代码，获得奖励。</li></ul><h3 id="4-结果提交"><a href="#4-结果提交" class="headerlink" title="4. 结果提交"></a>4. 结果提交</h3><p>将测试集的label保存成csv格式，上传到<a href="https://tianchi.aliyun.com/competition/entrance/531810/submission/" target="_blank" rel="noopener">这里</a>。</p><p>注意第一行是标题label，从第二行开始写入标签。</p><h3 id="5-评分标准"><a href="#5-评分标准" class="headerlink" title="5. 评分标准"></a>5. 评分标准</h3><p>F1评价指标</p><h3 id="6-其他"><a href="#6-其他" class="headerlink" title="6. 其他"></a>6. 其他</h3><p>可以充分发挥自己的特长来完成各种特征工程，不限制使用任何外部数据和模型。</p><h2 id="二、赛题理解"><a href="#二、赛题理解" class="headerlink" title="二、赛题理解"></a>二、赛题理解</h2><h3 id="1-数据编码"><a href="#1-数据编码" class="headerlink" title="1. 数据编码"></a>1. 数据编码</h3><p>赛题使用的数据为新闻，但是数据已经编码成了整数序列。分词我们不必操心了，但是这种编码方式我们有必要熟悉一下。</p><p>文本数据的编码方式通常有：</p><h4 id="1-1-根据单词表编码"><a href="#1-1-根据单词表编码" class="headerlink" title="1.1 根据单词表编码"></a>1.1 根据单词表编码</h4><p>本题就是根据单词表编码的，每个单词被编码为在单词表中的位置。比如整数40就是单词表中第40个单词。</p><p>本题中最大的数据就是7549，因此推测单词表大小为7550。剩下的特征工程留给下次打卡，要不没得写了XD</p><p>当然你可以基于单词表编码的方法，使用大名鼎鼎的<strong>One-Hot编码</strong>方法，把每个单词对应的整数映射成一个7550维的向量$\mathbf{x}$，该向量的第$i$维$\mathbf{x}_i=1$，其他维度为0。</p><p>One-Hot编码方法的坏处显而易见，那就是数据太过稀疏。好处则是，实践证明，深度学习模型是可以从这种稀疏表示的特征中高效地学习到知识的。</p><h4 id="1-2-词袋模型"><a href="#1-2-词袋模型" class="headerlink" title="1.2 词袋模型"></a>1.2 词袋模型</h4><p>文本数据通常被表示为由字符组成的字符串。我们需要先处理数据，然后才能对其应用机器学习算法。</p><p>在文本分析的语境中，数据集通常被称为语料库（corpus），每个由单个文本表示的数据点被称为文档（document）。</p><p>最简单的处理方法，是<strong>只计算语料库中每个单词在每个文本中的出现频次</strong>。这种文本处理模型称之为<strong>词袋模型</strong>。</p><p>不考虑词语出现的顺序，每个出现过的词汇单独作为一列特征，这些不重复的特征词汇集合为词表。</p><p>每一个文本都可以在很长的词表上统计出一个很多列的特征向量。如果每个文本都出现的词汇，一般被标记为<strong>停用词</strong>不计入特征向量。</p><p>为了搞清楚词袋模型，也就是<code>CountVectorizer</code>到底做了什么，我们执行以下代码：</p><pre><code class="lang-python">bards_words =[&quot;The fool doth think he is wise,&quot;,    &quot;but the wise man knows himself to be a fool&quot;]</code></pre><p>我们导入 CountVectorizer 并将其实例化，然后对 bards_words 进行拟合，如下所示：</p><pre><code class="lang-python">from sklearn.feature_extraction.text import CountVectorizervect = CountVectorizer()vect.fit(bards_words)</code></pre><p>拟合 CountVectorizer 包括训练数据的分词与词表的构建，我们可以通过 vocabulary_ 属性来访问词表：</p><pre><code class="lang-python">print(&quot;Vocabulary size: {}&quot;.format(len(vect.vocabulary_)))print(&quot;Vocabulary content:\n {}&quot;.format(vect.vocabulary_))#------------------#Vocabulary size: 13Vocabulary content:{&#39;the&#39;: 9, &#39;himself&#39;: 5, &#39;wise&#39;: 12, &#39;he&#39;: 4, &#39;doth&#39;: 2, &#39;to&#39;: 11, &#39;knows&#39;: 7,&#39;man&#39;: 8, &#39;fool&#39;: 3, &#39;is&#39;: 6, &#39;be&#39;: 0,  &#39;think&#39;: 10, &#39;but&#39;: 1}</code></pre><p>词表共包含 13 个词，从 “be” 到 “wise”。<br>我们可以调用 transform 方法来创建训练数据的词袋表示：</p><pre><code class="lang-python">bag_of_words = vect.transform(bards_words)print(&quot;bag_of_words: {}&quot;.format(repr(bag_of_words)))#--------------------#bag_of_words: &lt;2x13 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;with 16 stored elements in Compressed Sparse Row format&gt;</code></pre><p>词袋表示保存在一个 SciPy 稀疏矩阵中，这种数据格式只保存非零元素。这个矩阵的形状为 2×13，每行对应于两个数据点之一，每个特征对应于词表中的一个单词。要想查看稀疏矩阵的实际内容，可以使用 toarray 方法将其转换为“密集的”NumPy 数组（保存所有 0 元素）：</p><pre><code class="lang-python">print(&quot;Dense representation of bag_of_words:\n{}&quot;.format(    bag_of_words.toarray()))#---------------------#Dense representation of bag_of_words:[[0 0 1 1 1 0 1 0 0 1 1 0 1][1 1 0 1 0 1 0 1 1 1 0 1 1]]</code></pre><p>删除没有信息量的单词，除了使用<code>min_df</code>参数设定词例至少需要在多少个文档中出现过之外，还可以通过添加停用词的方法。</p><h4 id="1-3-用tf-idf编码数据"><a href="#1-3-用tf-idf编码数据" class="headerlink" title="1.3 用tf-idf编码数据"></a>1.3 用tf-idf编码数据</h4><p>词频 - 逆向文档频率（term frequency–inverse document frequency，tf-idf）方法，对在某个特定文档中经常出现的术语给予很高的权重，但对在语料库的许多文档中都经常出现的术语给予的权重却不高。</p><p>scikit-learn 在两个类中实现了 tf-idf 方法：TfidfTransformer 和 TfidfVectorizer，前者接受 CountVectorizer 生成的稀疏矩阵并将其变换，后者接受文本数据并完成词袋特征提取与 tf-idf 变换。</p><p>单词w在文档d中的tf-idf分数为：</p><script type="math/tex; mode=display">\operatorname{tfidf}(w, d)=\operatorname{tf} \log \left(\frac{N+1}{N_{w}+1}\right)+1</script><p>式中，tf为词频，Term Frequency, 表示一个词在一个文档中的出现频率。该频率最后要除以该文档的长度，用以归一化。</p><p>式中，$N$为总文档数，$N_w$为带有单词$w$的文档数。由于分子比分母大，所以该 $\log$ 值必不可能小于零。</p><pre><code class="lang-python">from sklearn.feature_extraction.text import TfidfVectorizercorpus=[&quot;I come to China to travel&quot;,&quot;This is a car polupar in China&quot;,&quot;I love tea and Apple &quot;,&quot;The work is to write some papers in science&quot;]tfidf = TfidfVectorizer()vector = tfidf.fit_transform(corpus)print(vector)#---------------#(0, 16)    0.4424621378947393(0, 3)    0.348842231691988(0, 15)    0.697684463383976(0, 4)    0.4424621378947393(1, 5)    0.3574550433419527(1, 9)    0.45338639737285463(1, 2)    0.45338639737285463(1, 6)    0.3574550433419527(1, 14)    0.45338639737285463(1, 3)    0.3574550433419527(2, 1)    0.5(2, 0)    0.5(2, 12)    0.5(2, 7)    0.5(3, 10)    0.3565798233381452(3, 8)    0.3565798233381452(3, 11)    0.3565798233381452(3, 18)    0.3565798233381452(3, 17)    0.3565798233381452(3, 13)    0.3565798233381452(3, 5)    0.2811316284405006(3, 6)    0.2811316284405006(3, 15)    0.2811316284405006</code></pre><p>返回值什么意思呢？(0, 16)代表第0个文档，第一个单词在单词表（词袋）中的位置是第16个，该单词的tf-idf值为0.44246213；第二个单词在词袋中第3个位置……</p><p>显然这是个经过压缩的系数矩阵，每一行的元组表明该元素在稀疏矩阵中的位置，其值为右边的tf-idf值，代表一个单词。可以通过<code>.toarray()</code>方法令其恢复到系数矩阵状态。</p><pre><code class="lang-python">print(vector.toarray().shape)print(len(vector.toarray()))print(type(vector.toarray()))print(vector.toarray())#-----------------------------#(4, 19)4&lt;class &#39;numpy.ndarray&#39;&gt;[[0. 0. 0. 0.34884223 0.44246214 0.  0. 0. 0. 0. 0. 0.  0. 0. 0. 0.69768446 0.44246214 0.  0. ] [0. 0. 0.4533864  0.35745504 0. 0.35745504  0.35745504 0. 0. 0.4533864  0. 0.  0. 0. 0.4533864  0. 0. 0.  0. ] [0.5 0.5 0. 0. 0. 0.  0. 0.5 0. 0. 0. 0.  0.5 0. 0. 0. 0. 0.  0. ] [0. 0. 0. 0. 0. 0.28113163  0.28113163 0. 0.35657982 0. 0.35657982 0.35657982  0. 0.35657982 0. 0.28113163 0. 0.35657982  0.35657982]]</code></pre><h4 id="1-4-Hash编码"><a href="#1-4-Hash编码" class="headerlink" title="1.4 Hash编码"></a>1.4 Hash编码</h4><p>无论采用什么编码，只要令每个特征能够独一无二地表示即可。可采用Hash思想。</p><p>对于类别数量很多的分类变量，利用哈希函数将一个数据点转换成一个向量。相比较One-Hot模型，哈希编码维度下降了很多。</p><p>若采用哈希函数</p><pre><code>h(the) mod 5 = 0h(quick) mod 5 = 1h(brown) mod 5 = 1h(fox) mod 5 = 3</code></pre><p>则对于某句话：<br><code>the quick brown fox</code><br>来说，其使用哈希特转换的向量就是：<br><code>(1,2,0,1,0)</code><br>对比one-hot编码向量（在单词表里就这四个单词的情况下）：<br><code>(0001,0010,0100,1000)</code></p><p>在实践中，哈希编码通过调用sklearn的HashingVectorizer实现。</p><p>关于数据的编码及其他特征工程，请看<a href="https://superlova.github.io/2020/07/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/#%E4%B8%80%E3%80%81%E7%B1%BB%E5%88%AB%E7%89%B9%E5%BE%81">这里</a>。</p><h3 id="2-评分标准"><a href="#2-评分标准" class="headerlink" title="2. 评分标准"></a>2. 评分标准</h3><p>分类模型的评分标准非常丰富，通用评价指标有精度和错误率</p><script type="math/tex; mode=display">\operatorname{accuracy}=\frac{T P+T N}{N}, \text { Error Rate }=\frac{F P+F N}{N}</script><p>其中N是样本总数，TP、FP、TN、FN的含义如下表</p><p><img src="/2020/07/21/【竞赛打卡】零基础入门NLP之新闻文本分类之赛题理解/table.png" srcset="/img/loading.gif" alt></p><p>除此之外，准确率、召回率、F1值也是常用的评价指标。</p><p><img src="/2020/07/21/【竞赛打卡】零基础入门NLP之新闻文本分类之赛题理解/metrics.png" srcset="/img/loading.gif" alt></p><p>P-R曲线即召回率R为横轴、精确率P为纵轴画的曲线。分类器的P-R曲线下面积越大，表明分类性能越好。</p><p>ROC曲线分析的是二元分类模型，也就是输出结果只有两种类别的模型。ROC以伪阳性率（FPR）为 X 轴，以真阳性率（TPR）为 Y 轴绘制曲线。AUC（Area Under Curve）被定义为ROC曲线下与坐标轴围成的面积，完美分类器的AUC=1。</p><p><img src="/2020/07/21/【竞赛打卡】零基础入门NLP之新闻文本分类之赛题理解/metrics2.png" srcset="/img/loading.gif" alt></p><h3 id="3-实验环境"><a href="#3-实验环境" class="headerlink" title="3. 实验环境"></a>3. 实验环境</h3><p>你还不知道Colab吗？我不允许有人不知道这么好的东西！Colab是一款在线Python编程工具。使用Colab，让你再也不用下载和安装Anaconda，再也不用纠结显卡驱动！有了它就可以白嫖Google的GPU服务器啦！(<a href="https://colab.research.google.com/" target="_blank" rel="noopener">https://colab.research.google.com/</a>)</p><p>Colab深度学习乞丐炼丹师的最爱！但是想说爱你不容易，各种掉线、内存不足，心酸……有钱还是买带显卡的服务器吧！</p><p>关于如何使用Colab，可以参考知乎的<a href="https://zhuanlan.zhihu.com/p/35063343" target="_blank" rel="noopener">这篇文章</a>。</p><p>（其实使用Colab最大的障碍是，你得有个稳定的VPN……）</p><h3 id="4-解题思路"><a href="#4-解题思路" class="headerlink" title="4. 解题思路"></a>4. 解题思路</h3><p>文本分类问题嘛，相比大家都用LSTM分类过IMDb影评，相当于Hello World之于程序员了。用LSTM分类IMDb影评的笔记我都写好了：<a href="https://superlova.github.io/2020/06/03/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E4%BD%BF%E7%94%A8LSTM%E8%AE%AD%E7%BB%83imdb%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/">这里</a>。<a href="https://www.tensorflow.org/tutorials/text/text_classification_rnn?hl=zh-cn" target="_blank" rel="noopener">Tensorflow的官方教程</a>也有用LSTM分类IMDb影评的Notebook。</p><p>因此使用LSTM的方法可以作为Baseline。</p><h3 id="5-小试牛刀"><a href="#5-小试牛刀" class="headerlink" title="5. 小试牛刀"></a>5. 小试牛刀</h3><p><img src="/2020/07/21/【竞赛打卡】零基础入门NLP之新闻文本分类之赛题理解/score.png" srcset="/img/loading.gif" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这项任务不好做呀，稍不小心就占用了task2的内容。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Feature Engineering" scheme="https://superlova.github.io/tags/Feature-Engineering/"/>
    
      <category term="Data Science" scheme="https://superlova.github.io/tags/Data-Science/"/>
    
      <category term="Datawhale" scheme="https://superlova.github.io/tags/Datawhale/"/>
    
  </entry>
  
  <entry>
    <title>【学习笔记】特征工程</title>
    <link href="https://superlova.github.io/2020/07/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    <id>https://superlova.github.io/2020/07/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</id>
    <published>2020-07-20T08:53:34.000Z</published>
    <updated>2020-07-20T08:59:27.422Z</updated>
    
    <content type="html"><![CDATA[<p>本文翻译自HJ van Veen的Feature Engineering一文，总结了数据竞赛中常用的特征工程方法。<br><a id="more"></a></p><h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><p>本文翻译自HJ van Veen的Feature Engineering一文。由于原文以PPT方式呈现，信息高度压缩，因此在我整理本文过程中，添加了自己的理解。如有错误，敬请指正！</p><p><img src="/2020/07/20/【学习笔记】特征工程/title.png" srcset="/img/loading.gif" alt></p><p><strong>全文概览：</strong></p><p><img src="/2020/07/20/【学习笔记】特征工程/特征工程.png" srcset="/img/loading.gif" alt></p><p>机器学习的特征工程是将原始的输入数据转换成特征，以便于更好的表示潜在的问题、提高预测模型准确性的过程。</p><p>特征工程是数据科学中最具创造性的部分，决定了机器学习模型的性能上限。</p><p>即便是号称端到端的神经网络也需要特征工程，比如cv需要获得HOG，SIFT，whitening, perturbation, image pyramids, rotation, z-scaling, log-scaling, frame-grams, external semantic data等信息。</p><p>机器学习的输入特征包括几种：</p><ul><li>类别特征：如ID、性别等，值的大小无意义。</li><li>数值特征：包括整型、浮点型等，值的大小有意义。</li><li>时间特征：如月份、年份、季度、日期、小时等。</li><li>空间特征：经纬度等，可以转换成邮编，城市等。</li><li>文本特征：文档，自然语言，程序语句等。</li></ul><h2 id="一、类别特征"><a href="#一、类别特征" class="headerlink" title="一、类别特征"></a>一、类别特征</h2><p>分类特征的特点是几乎总是需要处理后才能输入算法。</p><p>类别特征难以估算缺失数据，类别太多（数据维度高）会导致数据稀疏，因此类别特征是特征工程的重点。</p><h3 id="One-Hot编码"><a href="#One-Hot编码" class="headerlink" title="One-Hot编码"></a>One-Hot编码</h3><p>将每个特征编码成长度为K的向量，每个向量只有一个维度值为1，其他值为0。这样做的好处是简单易实现，且数据样本的长度也归一化了。</p><p>比如分类特征{黄，绿，蓝}可以编码成{001,010,100}；{男，女}=&gt;{01,10}；{1,2,3,4,5,6,7,8,9}=&gt;{000000001,…,100000000}</p><p><strong>通常丢弃第一列以避免线性相关。</strong></p><p>比如Pandas中，<code>get_dummies</code>函数有一个参数为<code>drop_first</code>，如果为True就丢弃One-Hot编码后数据的第一列，因为丢弃的一列可以通过其他剩余的k-1列计算得到，这一列也就变成了重复数据。</p><p>缺陷：容易造成数据稀疏，且现有的One-Hot编码实现方式，较难应对缺失数据和没出现过的变量。</p><p>对于类别不多的分类变量，可以采用独热编码。但其实自然语言处理任务中也广泛使用了One-Hot编码。要知道自然语言处理任务的词典大小动辄上万，那么一个单词的One-Hot向量长度也上万，一篇文档转化成One-Hot矩阵，这个数据量就非常可观了。</p><h3 id="Hash编码"><a href="#Hash编码" class="headerlink" title="Hash编码"></a>Hash编码</h3><p>无论采用什么编码，只要令每个特征能够独一无二地表示即可。可采用Hash思想。</p><p>对于类别数量很多的分类变量，利用哈希函数将一个数据点转换成一个向量。相比较One-Hot模型，哈希编码维度下降了很多。</p><p>若采用哈希函数</p><pre><code>h(the) mod 5 = 0h(quick) mod 5 = 1h(brown) mod 5 = 1h(fox) mod 5 = 3</code></pre><p>则对于某句话：<br><code>the quick brown fox</code><br>来说，其使用哈希特转换的向量就是：<br><code>(1,2,0,1,0)</code><br>对比one-hot编码向量（在单词表里就这四个单词的情况下）：<br><code>(0001,0010,0100,1000)</code></p><p>哈希表有如下特性：</p><ul><li>相同的输入可能有相同的输出（一般情况下比例不高）</li><li>不同的输出一定对应不同的输入</li><li>正向计算很简单，反向计算很困难</li><li>根据输入查找输出效率很高</li></ul><p>本部分参考自 <a href="https://www.datalearner.com/blog/1051537932880901" target="_blank" rel="noopener">https://www.datalearner.com/blog/1051537932880901</a></p><h3 id="标签编码"><a href="#标签编码" class="headerlink" title="标签编码"></a>标签编码</h3><p>给予每个类别变量一个独一无二的数字ID。</p><p>假如有三种颜色特征：红、黄、蓝，那么你可能想令红=1，黄=2，蓝=3，这就是标签编码。</p><p>这种编码对于树算法等非线性算法比较有用，好处是不会升维，坏处是会让机器学习算法误以为颜色存在数值大小关系。</p><h3 id="计数编码"><a href="#计数编码" class="headerlink" title="计数编码"></a>计数编码</h3><p>将每个类别的编码定义为其在数据集中出现的次数。比如在数据集中’红’出现了300次，那么’红’的编码就是300。</p><p><code>df.groupby([&#39;category&#39;])[&#39;target&#39;].transform(sum)</code><br>这种做法很常见，也很简单。缺点是对异常值敏感，且不同类别出现次数相同时可能引入冲突。</p><h3 id="计数排序编码"><a href="#计数排序编码" class="headerlink" title="计数排序编码"></a>计数排序编码</h3><p>根据类别变量在训练集中出现的次数<strong>排序</strong></p><p>对异常值不敏感，不会引入冲突。在实际比赛中效果可能出乎意料的好。</p><h3 id="Target编码"><a href="#Target编码" class="headerlink" title="Target编码"></a>Target编码</h3><p>将类别变量编码为分类为正的比例，类似于该类别对正类的贡献指数。</p><p>比如职业类别特征{‘manager’,’engineer’,’scientist’}在数据集中，但凡scientist都使得target=1，那么scientist就编码成1.00。</p><p><img src="/2020/07/20/【学习笔记】特征工程/2020-07-20-11-20-25.png" srcset="/img/loading.gif" alt></p><h3 id="类别嵌入"><a href="#类别嵌入" class="headerlink" title="类别嵌入"></a>类别嵌入</h3><p>由神经网络得到每个类别的嵌入表达，将特征投影到更高维度的空间。在进行文档分类等，原本具有语义相似性的单词映射之后的向量之间的距离也比较小，进而可以帮助我们进一步进行机器学习的应用，这一点比独热模型好很多。</p><p>参考 <a href="https://arxiv.org/abs/1604.06737" target="_blank" rel="noopener">https://arxiv.org/abs/1604.06737</a></p><p><img src="/2020/07/20/【学习笔记】特征工程/2020-07-20-11-21-54.png" srcset="/img/loading.gif" alt></p><h3 id="把Nan也当作一个类别"><a href="#把Nan也当作一个类别" class="headerlink" title="把Nan也当作一个类别"></a>把Nan也当作一个类别</h3><p>只在Nan确定有意义时使用。</p><h3 id="多元编码"><a href="#多元编码" class="headerlink" title="多元编码"></a>多元编码</h3><p>将两个二元分类变量组合，形成四元向量表示</p><p><img src="/2020/07/20/【学习笔记】特征工程/2020-07-19-14-09-28.png" srcset="/img/loading.gif" alt></p><h3 id="扩张编码"><a href="#扩张编码" class="headerlink" title="扩张编码"></a>扩张编码</h3><p>将一个Feature拆分成多个Feature</p><h3 id="合并编码"><a href="#合并编码" class="headerlink" title="合并编码"></a>合并编码</h3><p>将多个Feature合并成一个Feature</p><h2 id="二、数值特征"><a href="#二、数值特征" class="headerlink" title="二、数值特征"></a>二、数值特征</h2><h3 id="舍入"><a href="#舍入" class="headerlink" title="舍入"></a>舍入</h3><p>过高的精度有时是噪音。</p><p>舍入后的数据可以被当作是类别变量。</p><p>舍入前可以log一下，log转换可以将范围很大的值缩小在一定范围内，这对某些异常值的处理也很有效。</p><p><img src="http://www.datalearner.com/resources/blog_images/6a4db741-d9bb-4391-8d24-7214ecd07b3b.jpg" srcset="/img/loading.gif" alt></p><h3 id="按数值大小分箱（Binning）"><a href="#按数值大小分箱（Binning）" class="headerlink" title="按数值大小分箱（Binning）"></a>按数值大小分箱（Binning）</h3><p>数据分箱是一种将多个或多或少连续值分组为较少数量的“箱(bin)”的方法。通过分箱，数值特征转换成类别特征了。</p><p>例如一天24小时可以分成早晨[5,8)，上午[8,11)，中午[11,14)，下午[14,19)，夜晚[10,22)，深夜[19,24)和[24,5)。因为比如中午11点和12点其实没有很大区别，可以使用分箱技巧处理之后可以减少这些“误差”。</p><h3 id="特征缩放（Scaling）"><a href="#特征缩放（Scaling）" class="headerlink" title="特征缩放（Scaling）"></a>特征缩放（Scaling）</h3><p>也称为数据标准化。可以将很大范围的数据限定在指定范围内。由于原始数据的值范围变化很大，在一些机器学习算法中，如果没有标准化，目标函数将无法正常工作。</p><p>特征缩放方法主要有：</p><ul><li>转为标准正态</li><li>最大最小缩放</li><li>对数缩放</li><li>开方缩放 root scale</li></ul><h3 id="估算缺失数据（Imputation）"><a href="#估算缺失数据（Imputation）" class="headerlink" title="估算缺失数据（Imputation）"></a>估算缺失数据（Imputation）</h3><p>由于各种原因，许多真实世界的数据集包含缺失的值，通常编码为空白、NAN或其他占位符。简单删除该条数据项就太可惜了，一个更好的策略是估算缺失的值， 即从数据的已知部分推断它们。</p><p>缺失的值可以用提供的常量值来计算，或使用缺失值所在的每一列的统计数据(平均值不如中位数鲁棒)。处理缺失数据的方法还有很多。</p><p>sklearn的SimpleImputer类就是用来估算缺失值的。<br><a href="https://www.studyai.cn/modules/impute.html" target="_blank" rel="noopener">https://www.studyai.cn/modules/impute.html</a></p><h3 id="特征交叉-feature-interactions"><a href="#特征交叉-feature-interactions" class="headerlink" title="特征交叉(feature interactions)"></a>特征交叉(feature interactions)</h3><p>在回归模型中加入交互项是一种非常常见的处理方式。它可以极大的拓展回归模型对变量之间的依赖的解释。</p><p>举个例子：<a href="https://www.datalearner.com/blog/1051508158689792" target="_blank" rel="noopener">来源</a></p><p>不同特征之间可能相互影响，比如阳光和土壤质量同时决定树木生长高度，我们可以建模：</p><script type="math/tex; mode=display">\text{Tree}=a\times \text{Sun}+b\times \text{Soil}+c</script><p>但是阳光本身也可能影响土壤质量，而我们建立的线性模型事实上是把土壤和阳光当作独立变量的。想要学习线性相关性，我们可以增加一个特征:</p><script type="math/tex; mode=display">\text{Tree}=a\cdot\text{Sun}+b\cdot\text{Soil}+c\cdot(\text{Sun}\cdot\text{Soil})+d</script><p>特征交叉的方法有很多，比如不同特征间进行加减乘除、指数操作等。</p><h3 id="非线性特征在线性模型中的应用"><a href="#非线性特征在线性模型中的应用" class="headerlink" title="非线性特征在线性模型中的应用"></a>非线性特征在线性模型中的应用</h3><ul><li><p>通过多项式核函数(polynomial kernel)和径向基核函数(RBF kernel)将线性不可分的数据映射到高维空间去</p></li><li><p>Leafcoding（随机森林嵌入）（acebook的gbdt+lr这种思路）</p></li><li><p>遗传算法（典型代表gplearn）</p></li><li><p>局部线性嵌入 Locally Linear Embedding，频谱嵌入 Spectral Embedding，t-SNE （降维提取重要特征）</p></li></ul><h3 id="行统计"><a href="#行统计" class="headerlink" title="行统计"></a>行统计</h3><p>统计一行数据中Nan个数、0的个数、负数个数、最大值、最小值、中位数、峰度偏度等</p><h2 id="三、时间特征"><a href="#三、时间特征" class="headerlink" title="三、时间特征"></a>三、时间特征</h2><p>时间变量非常容易出错，需要更好的局部验证方案（如回测）</p><h3 id="将时间映射成环（周期性变量）"><a href="#将时间映射成环（周期性变量）" class="headerlink" title="将时间映射成环（周期性变量）"></a>将时间映射成环（周期性变量）</h3><p>Turn single features, like day_of_week, into two coordinates on a circle</p><p>Ensures that distance between max and min is the same as min and min +1.</p><p>含义是指周六和周天，与周天和周一的距离是一样的。</p><p>Use for day_of_week, day_of_month, hour_of_day, etc.</p><p>就是将大时间项，比如2019年11月11日分解成小时间项的意思。</p><h3 id="趋势线"><a href="#趋势线" class="headerlink" title="趋势线"></a>趋势线</h3><p>数据的变化趋势本身也是信息。因此不要使用诸如total_spend这种总结式变量，要有一些中间变量，诸如spend_in_last_week，spend_in_last_month。展现数据趋势，利于模型获取信息。</p><h3 id="事件编码"><a href="#事件编码" class="headerlink" title="事件编码"></a>事件编码</h3><p>将某日期与重大节日之间的距离也作为特征，比如法定假日、重大体育赛事、周末、每月的第一个星期六等。</p><h2 id="四、空间特征"><a href="#四、空间特征" class="headerlink" title="四、空间特征"></a>四、空间特征</h2><h3 id="将地点视作分类特征"><a href="#将地点视作分类特征" class="headerlink" title="将地点视作分类特征"></a>将地点视作分类特征</h3><ul><li>克里金法 Kriging，空间插值方法</li><li>K-means 聚类</li><li>原始经纬度</li><li>将城市转换为经纬度</li><li>在街道名称中添加邮政编码</li></ul><h3 id="将某地点与关键地点之间的距离也作为特征"><a href="#将某地点与关键地点之间的距离也作为特征" class="headerlink" title="将某地点与关键地点之间的距离也作为特征"></a>将某地点与关键地点之间的距离也作为特征</h3><p>诸如大城市、超市等，对你的任务有重要影响的地区。</p><h3 id="位置事件数据可以指示可疑行为"><a href="#位置事件数据可以指示可疑行为" class="headerlink" title="位置事件数据可以指示可疑行为"></a>位置事件数据可以指示可疑行为</h3><p>比如同时出现在不同城市的两笔交易、在与住所或送货地址不同的城镇中消费、从不在同一个位置消费。</p><h2 id="五、数据探索"><a href="#五、数据探索" class="headerlink" title="五、数据探索"></a>五、数据探索</h2><p>数据探索的目的是提前发现数据的潜在问题，诸如异常值、噪音；然后探索数据的特征工程方法、清洗方法，为数据预处理做准备。</p><p>一开始尝试简单统计量：min、max。</p><p>Incorporate the target so find correlation between signal.</p><p>我的理解是，探索该特征与该数据的label的相关性。</p><h3 id="迭代和Debugging"><a href="#迭代和Debugging" class="headerlink" title="迭代和Debugging"></a>迭代和Debugging</h3><p>特征工程是一个迭代的过程，确保你的Pipeline能够快速迭代。</p><p>Use sub-linear debugging: Output intermediate information on the process, do spurious logging</p><p>使用sub-linear debugging：输出有关过程的中间信息，进行伪记录。</p><p>使用一些帮助快速实验的工具。</p><p>一鸟在手胜过双鸟在林，想法太多不容易成功。</p><h3 id="Label工程"><a href="#Label工程" class="headerlink" title="Label工程"></a>Label工程</h3><p>可以把数据集的标签label给变换一下，当成数据的特征（有点泄漏答案的意思）。</p><ul><li>log变换：$y\rightarrow\log{(y+1)}$、$\exp{y_{pred}}-1$</li><li>平方变换</li><li>Box-Cox变换</li><li>创建一个评分，用来把二元分类target变成回归问题</li><li>训练回归模型，用于预测测试集中不可获取的特征</li></ul><h2 id="六、文本特征"><a href="#六、文本特征" class="headerlink" title="六、文本特征"></a>六、文本特征</h2><p>与类别特征类似，特征工程手段更为丰富，举例：</p><ul><li>Lowercasing,</li><li>Removing non-alphanumeric,</li><li>Repairing,</li><li>Encoding punctuation marks,</li><li>Tokenizing,</li><li>Token-grams,</li><li>skipgrams,</li><li>char-grams,</li><li>Removing stopwords,</li><li>Removing rare words</li><li>and very common words,</li><li>Spelling Correction,</li><li>Chopping,</li><li>Stemming,</li><li>Lemmatization,</li><li>Document features,</li><li>Entitity Insertion &amp; Extraction</li><li>Simplification,</li><li>Word2Vec and GloVe / Doc2Vec,</li><li>String Similarity,</li><li>Reading level,</li><li>Nearest Neighbors,</li><li>TF-IDF,</li><li>BayesSVM, Vectorization, LDA, LSA.</li></ul><h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>从大写字母转换成小写，从unicode转换成ascii，移除非字母字符，修复源文本中的格式问题等。</p><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><ul><li>将句子分成单词token序列，英文可能好做一点，中文之类的语言就需要特定的工具了，比如jieba分词。</li><li>将标点符号也硬编码为token，因为标点可能也代表有用的信息。</li><li>词袋模型（bag-of-word model）</li><li>N元分词：“I like the Beatles” -&gt; [“I like”, “like the”, “the Beatles”]</li><li>Skip-grams：“I like Beatles” -&gt; [“I the”, “like Beatles”]</li><li>Char-grams：“Beatles” -&gt; [“Bea”, “eat”, “atl”, “tle”, “les”]</li><li>Affixes：Same as char-grams, but only the postfixes and prefixe</li></ul><h3 id="删除词"><a href="#删除词" class="headerlink" title="删除词"></a>删除词</h3><ul><li>删除停用词</li><li>删除罕见词</li><li>删除其他常见词，不能反映特征的词</li></ul><h3 id="还原词形-root"><a href="#还原词形-root" class="headerlink" title="还原词形 root"></a>还原词形 root</h3><ul><li>拼写检查</li><li>Chop，只取每个token的前8个字符</li><li>Stem，将token缩减为词根形式</li><li>Lemmatize，词形还原</li></ul><h3 id="更多特征"><a href="#更多特征" class="headerlink" title="更多特征"></a>更多特征</h3><ul><li>文档特征，诸如统计空格、tab、换行、字符、token出现次数等</li><li>添加一些通用的描述，“Microsoft releases Windows” -&gt; “Microsoft (company) releases Windows (application)”</li><li>语法分析树 Parse Tree，NLTK工具包有实现</li><li>Reading level: Compute the reading level of a document.（国外的阅读分级制度）</li></ul><h3 id="相似度"><a href="#相似度" class="headerlink" title="相似度"></a>相似度</h3><ul><li>token相似度：计算两段文本中相同token数</li><li>压缩距离 Compression distance：一段句子是否能被压缩成另外一段</li><li>Levenshitein、Hamming、Jaccard距离，用来衡量两个string的距离，计算将该文本转为另一个文本所需的最小操作次数</li><li>word2vec、glove：计算两向量的余弦距离</li></ul><h3 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h3><ul><li>Term Frequency: 能够降低长文本造成的bias</li><li>Inverse Document Frequency: 降低常用词造成的Bias</li><li>TF-IDF: 辨别在document中最重要的token，删除不重要的token；或者用在数据预处理上，可以使维度下降</li></ul><h3 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h3><ul><li>PCA: 将文本压缩到50~100维的向量</li><li>SVD: 同上</li><li>LDA: 与TF-IDF配套</li><li>LSA: 创建主题向量</li></ul><h3 id="外部模型"><a href="#外部模型" class="headerlink" title="外部模型"></a>外部模型</h3><ul><li>感情分析器：获得text的情感倾向</li><li>主题模型：使用一个dataset创建主题向量，用于另一个任务</li></ul><h2 id="七、泄露的特征-黄金特征"><a href="#七、泄露的特征-黄金特征" class="headerlink" title="七、泄露的特征 / 黄金特征"></a>七、泄露的特征 / 黄金特征</h2><p>特征工程能帮助发现泄露的特征，这些特征可能对你帮助很大。</p><ul><li>比如“逆向”工程：<ul><li>用彩虹表破解MD5哈希。<a href="https://www.cnblogs.com/by-3ks/articles/4137562.html" target="_blank" rel="noopener">彩虹表（Rainbow Table）</a>是一种破解哈希算法的技术，可以破解MD5、HASH等多种密码。</li><li>利用TF-IDF获得术语频率。</li><li>编码样本数据集的顺序。</li><li>编码文件创建日期。</li></ul></li><li>比如规则挖掘：<ul><li>查找简单的规则（并对它们进行编码）以帮助模型决策。</li></ul></li></ul><h2 id="八、案例研究"><a href="#八、案例研究" class="headerlink" title="八、案例研究"></a>八、案例研究</h2><p>Quora重复问题数据集，约440000个问题，将其分成重复问题或非重复问题。作者将自己解决Quora重复问题的过程分享如下：</p><ul><li>First attempt: 词袋模型+逻辑回归</li><li>Second attempt: token之间进行数据的多项式交互</li><li>Third attempt: 使用NLTK的SnowballStemmer进行词干提取</li><li>Fourth attempt: 使用2-grams分词</li><li>Fifth attempt: 添加以下手工构造的特征：<ul><li>归一化问答对的长度</li><li>归一化问答对的compression距离</li><li>计算问答对的词向量之间的余弦距离</li><li>Chargram co-occurence between question pairs.</li><li>计算word出现次数：which，what，where</li></ul></li><li>还能想到更多的改进方法吗？<ul><li>外部或预训练模型？</li><li>Search engine models?</li><li>Logic based models?</li></ul></li></ul><h2 id="九、其他资源参考"><a href="#九、其他资源参考" class="headerlink" title="九、其他资源参考"></a>九、其他资源参考</h2><ul><li><strong>Kaggle forums &amp; kernels:</strong> Far0n, KazAnova, Fchollet, Abhishek, Gilberto Titericz, Leustagos, Owen Zhang, Gert Jacobusse …</li><li><strong>Introduction:</strong> <a href="http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/" target="_blank" rel="noopener">http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/</a></li><li><strong>Books:</strong><ul><li>Mastering Feature Engineering (Alice Zheng),</li><li>Feature Extraction (Isabelle Guyon et al.)</li></ul></li><li><strong>Blogs:</strong><ul><li><a href="https://smerity.com/articles/2016/architectures_are_the_new_feature_engineering.html" target="_blank" rel="noopener">https://smerity.com/articles/2016/architectures_are_the_new_feature_engineering.html</a></li><li><a href="http://hunch.net/~jl/projects/hash_reps/" target="_blank" rel="noopener">http://hunch.net/~jl/projects/hash_reps/</a></li><li><a href="https://blogs.technet.microsoft.com/machinelearning/2014/09/24/online-learning-and-sub-linear-debugging/" target="_blank" rel="noopener">https://blogs.technet.microsoft.com/machinelearning/2014/09/24/online-learning-and-sub-linear-debugging/</a></li><li><a href="http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/" target="_blank" rel="noopener">http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/</a></li><li><a href="http://blog.kaggle.com/2016/08/24/avito-duplicate-ads-detection-winners-interview-1st-place-team-devil-team-stanislav-dmitrii/" target="_blank" rel="noopener">http://blog.kaggle.com/2016/08/24/avito-duplicate-ads-detection-winners-interview-1st-place-team-devil-team-stanislav-dmitrii/</a></li><li><a href="http://www.slideshare.net/DataRobot/featurizing-log-data-before-xgboost" target="_blank" rel="noopener">http://www.slideshare.net/DataRobot/featurizing-log-data-before-xgboost</a></li></ul></li><li><strong>Data:</strong> <a href="https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs" target="_blank" rel="noopener">https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs</a></li><li><strong>Software:</strong> <a href="https://github.com/trevorstephens/gplearn" target="_blank" rel="noopener">https://github.com/trevorstephens/gplearn</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文翻译自HJ van Veen的Feature Engineering一文，总结了数据竞赛中常用的特征工程方法。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
      <category term="translation" scheme="https://superlova.github.io/categories/notes/translation/"/>
    
      <category term="转载" scheme="https://superlova.github.io/categories/notes/translation/%E8%BD%AC%E8%BD%BD/"/>
    
    
      <category term="Machine Learning" scheme="https://superlova.github.io/tags/Machine-Learning/"/>
    
      <category term="Feature Engineering" scheme="https://superlova.github.io/tags/Feature-Engineering/"/>
    
      <category term="Data Science" scheme="https://superlova.github.io/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】CAGFuzz: Coverage-Guided Adversarial Generative Fuzzing Testing of Deep Learning Systems</title>
    <link href="https://superlova.github.io/2020/06/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91CAGFuzz-Coverage-Guided-Adversarial-Generative-Fuzzing-Testing-of-Deep-Learning-Systems/"/>
    <id>https://superlova.github.io/2020/06/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91CAGFuzz-Coverage-Guided-Adversarial-Generative-Fuzzing-Testing-of-Deep-Learning-Systems/</id>
    <published>2020-06-27T16:02:49.000Z</published>
    <updated>2020-07-20T08:51:57.349Z</updated>
    
    <content type="html"><![CDATA[<p>提出了CAGFuzz，这是一种覆盖率指导的灰盒对抗性生成模糊测试方法，可以为目标DNN生成对抗性示例，以发现其潜在缺陷。<br><a id="more"></a></p><p>DeepXplore，使用多个DNN来发现并生成位于这些DNN决策边界之间的对抗性示例。</p><p>DeepHunter，使用变形突变策略来生成新的测试示例。</p><p>DeepGauge，提出了深度神经网络的新覆盖标准。</p><ol><li>为了提高泛化能力，仅从数据的角度添加较小的扰动就非常重要。</li><li>现有研究完全忽略了包含高级语义信息（例如图像对象类别和场景语义）的深度特征约束。使用L0和L∞来限制对抗性示例的像素级变化，这样的约束只能代表对抗实例和原始实例之间的视觉一致性，而不能保证对抗实例和原始实例的高级语义信息之间的一致性。</li></ol><p>具体地，</p><ol><li>双重GAN构造对抗样本生成器AEG<br>CAGFuzz的目标是最大化神经元覆盖范围，并在对目标DNN产生较小扰动的情况下尽可能多地生成对抗性测试示例。同时，生成的示例适用于不同种类的DNN。</li></ol><p>CycleGAN [19]的目标是将图像A转换为具有不同样式的图像B。</p><p>基于CycleGAN，我们的目标是将图像B转换回图像A，以获得与原始图像A类似的图像A’。</p><p>因此，我们将两个具有相反功能的CycleGAN的生成器组合为对抗示例生成器。</p><p>基于几个特定的​​数据集对AEG进行训练，并且不需要依赖任何特定的DNN模型。</p><ol><li>采用网络信息确保两样本语义一致<br>我们提取原始示例和对抗示例的深度特征，并通过相似性度量使其尽可能相似。</li></ol><p>我们使用VGG-19网络[20]提取原始示例和对抗示例的深度语义信息，并使用余弦相似度测量方法来确保对抗示例的深度语义信息与原始示例一致 越多越好。</p><ol><li>结果<br>AGFuzz可以有效地改善目标DNN模型的神经元覆盖范围。证明了由CAGFuzz生成的对抗示例可以发现目标DNN模型中的隐藏缺陷。通过AEG训练的DNN模型的准确性和鲁棒性已得到显着提高。</li></ol><h1 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h1><h2 id="覆盖率引导的灰盒模糊测试"><a href="#覆盖率引导的灰盒模糊测试" class="headerlink" title="覆盖率引导的灰盒模糊测试"></a>覆盖率引导的灰盒模糊测试</h2><p>最新的CGF方法主要包括三个部分：突变，反馈指导和模糊策略</p><h2 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h2><p>生成对抗性示例的想法是增加人们无法与原始示例区分开的干扰。这与GAN [27]生成示例的想法非常相似。</p><p>GAN的生成器G和鉴别器D根据噪声数据交替生成与原始示例非常相似但不完全相同的对抗示例。</p><p>考虑到不同目标DL系统（例如某些带有标签数据的DL系统和其他DL系统的数据集）的差异，我们选择CycleGAN [19]作为对抗性示例生成器的训练模型，因为CycleGAN不需要数据匹配集和标签信息。</p><p>CycleGAN的目标是学习X和Y之间的映射关系G和F。有两个对抗判别器$D_x$和$D_y$，$D_x$分辨图片$x$和转换后的图片$F(x)$。$D_y$相似。</p><p>和其他GAN一样，用损失函数优化映射函数。这里用最小二乘损失。</p><p>本示例的目的是将真实图片和梵高风格的绘画相互转化。<br><img src="/2020/06/28/【论文阅读笔记】CAGFuzz-Coverage-Guided-Adversarial-Generative-Fuzzing-Testing-of-Deep-Learning-Systems/2020-06-28-00-36-54.png" srcset="/img/loading.gif" alt></p><h2 id="VGG-19"><a href="#VGG-19" class="headerlink" title="VGG-19"></a>VGG-19</h2><p>VGG-19网络可以从图像中提取高级语义信息[29]，[30]，可用于识别图像之间的相似性。</p><p>本文将最后一个完整连接层的输出作为特征向量进行融合，以比较对抗性示例与原始示例之间的相似性，并作为过滤生成的对抗性示例的阈值。</p><h2 id="神经网络覆盖率"><a href="#神经网络覆盖率" class="headerlink" title="神经网络覆盖率"></a>神经网络覆盖率</h2><p><img src="/2020/06/28/【论文阅读笔记】CAGFuzz-Coverage-Guided-Adversarial-Generative-Fuzzing-Testing-of-Deep-Learning-Systems/2020-06-28-00-39-59.png" srcset="/img/loading.gif" alt></p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><img src="/2020/06/28/【论文阅读笔记】CAGFuzz-Coverage-Guided-Adversarial-Generative-Fuzzing-Testing-of-Deep-Learning-Systems/2020-06-28-00-41-11.png" srcset="/img/loading.gif" alt></p><p>第一步是数据收集和训练对抗性示例生成器</p><p>将数据集分为两个子集，并作为CycleGAN的输入来训练AEG。</p><p>在根据存储时间等设置了优先级之后，将这些示例放入处理池中，作为模糊测试的原始示例集。</p><p>第二步是对抗示例生成。</p><p>每次从处理池中选择优先的原始示例，并将其用作AEG的输入以生成对抗示例。</p><p>VGG-19处理对抗性示例和原始示例，以提取示例的特征矩阵。</p><p>计算对抗性示例与原始示例之间的特征矩阵的余弦相似度，以确保对抗性示例的深层语义与原始示例一致。</p><p>第三步是使用神经元覆盖率来指导生成过程。</p><p>第二步中生成的对抗示例将输入到被测DNN中以进行覆盖率分析。</p><p>如果发生新的覆盖，则对抗性示例将作为数据集的一部分放入处理池中。</p><p>新的覆盖范围意味着对抗示例的神经元覆盖范围高于原始示例的神经元覆盖范围。</p><p><img src="/2020/06/28/【论文阅读笔记】CAGFuzz-Coverage-Guided-Adversarial-Generative-Fuzzing-Testing-of-Deep-Learning-Systems/2020-06-28-00-44-35.png" srcset="/img/loading.gif" alt></p><p>CAGFuzz的输入包括目标数据集D，给定深度神经网络DNN，最大迭代数N，每个原始示例生成的对抗性示例N1以及top-k的参数K。</p><p>输出是生成的测试示例，可改善目标DNN的覆盖范围。</p><p>在整个模糊测试过程之前，我们需要处理数据集。</p><p>一方面，它被分为两个相等的数据字段（第1行），以训练对抗性示例生成器AEG（第2行）。</p><p>另一方面，所有示例都经过预处理（第3行），并存储在处理池中（第4行）。</p><p>在每个迭代过程中（第5行），根据时间优先级（第6、7行）从处理池中选择原始示例父对象。</p><p>然后，每个原始示例父对象都会生成多次（第8行）。</p><p>对于每一代，对抗性示例生成器AEG用于变异原始示例性父级，以生成对抗性示例数据（第9行）。</p><p>分别提取原始示例父对象和对抗示例数据的深度特征，并计算它们之间的余弦相似度（第10-11行）。</p><p>最后，将原始样本产生的所有对抗性示例按照相似性从高到低排序，并选择其中的前k个作为目标示例（第13行）。</p><p>排名前k位的对抗性示例是具有覆盖范围的反馈（第15行）。</p><p>如果对抗性示例增加了目标DNN的覆盖范围，它们将被存储在处理池中并设置时间优先级（第16-19行）。</p><h2 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h2><p>首先对数据集进行排序，将排好序的数据集储存在队列中。然后将队列分成两部分，训练cycleGAN使用。</p><h2 id="训练对抗样本生成器"><a href="#训练对抗样本生成器" class="headerlink" title="训练对抗样本生成器"></a>训练对抗样本生成器</h2><p>如何把握突变程度degree是关键。本文提出了一个新的对抗样本生成方法，能够保证深层次semantic信息的不变性，且扰动对人类是不可察觉的。</p><p>这个新的方法就是引用了cyclegan，依赖adversarial loss函数添加对抗扰动，且通过cyclic consistency loss控制扰动在人类不可察觉的范围内。</p><p>CycleGAN是怎么做的呢？首先将数据集均匀分成两部分X、Y，模型试图学习两个映射，分别是从X到Y的映射P，以及从Y到X的映射Q。对应地，有两个对抗判别器$D_x$和$D_y$，分别负责判断当前的$x$是来自X的样本还是来自Q生成的样本，以及负责判断当前的$y$是来自Y的样本还是来自P生成的样本。</p><p>对于映射函数P和对应的对抗样本判别器$D_y$，对抗损失函数为：</p><script type="math/tex; mode=display">\begin{aligned}\min _{P} \max _{D} Y V\left(P, D_{Y}, X, Y\right)=E_{y \sim P_{\text {data}}(y)}\left[\log D_{Y}(y)\right] &+\\E_{x \sim P_{\text {data}}(x)}\left[\log \left(1-D_{Y}(P(x))\right)\right] &]\end{aligned}</script><p>最小化映射函数P，最大化对抗判别器$D_y$。</p><p>P映射的目的是生成对抗样本$y’=P(x)$，让$y’$看起来像是从Y中来的一样。这个过程可以理解成，把大量的来自于Y的特性给添加到来自于X的$x$中。同时训练一个辨别器$D_y$，辨别真正的$y$与P生成出来的$y’$。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;提出了CAGFuzz，这是一种覆盖率指导的灰盒对抗性生成模糊测试方法，可以为目标DNN生成对抗性示例，以发现其潜在缺陷。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="Fuzzing" scheme="https://superlova.github.io/tags/Fuzzing/"/>
    
      <category term="Coverage" scheme="https://superlova.github.io/tags/Coverage/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】Towards Evaluating the Robustness of Neural Networks</title>
    <link href="https://superlova.github.io/2020/06/27/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Towards-Evaluating-the-Robustness-of-Neural-Networks/"/>
    <id>https://superlova.github.io/2020/06/27/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Towards-Evaluating-the-Robustness-of-Neural-Networks/</id>
    <published>2020-06-27T13:17:13.000Z</published>
    <updated>2020-06-27T16:01:41.571Z</updated>
    
    <content type="html"><![CDATA[<p>2017年的攻击文章，目标是当时防御性较高的<strong>防御性蒸馏</strong>模型，属于图像分类模型。结果是成功令其鲁棒性下降。文章最后的结论是，做防御的人应该用较先进的攻击手段测试自己的模型，同时应该注意防御对抗样本的迁移特性，即在其他弱模型上生成样本后在目标模型上测试的行为。<br><a id="more"></a></p><blockquote><p>警告！本文为简读，大量省略了原文内容，只留下了我关注的细节。</p></blockquote><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>防御性模型蒸馏（Defensive distillation）是近年来抵御对抗样本攻击的最有效方法之一。防御性模型蒸馏应用于前馈神经网络，只需一次重训练，就能将攻击成功率从95%降至0.5%。</p><p>目前有两种衡量神经网络鲁棒性的方法，一是试图证明一个下界，二是攻击模型，试图展示一个上界。第一种方法显然更加难以实践，但是如果攻击算法不够好，第二种方法得到的结果也没有说服力。</p><p>本文构建一系列攻击手段，可以用于构建鲁棒性上界。</p><p>本文还建议使用高置信度（high-confidence）的对抗性示例来评估模型的鲁棒性。</p><p>对抗样本有转移性，可以使用不安全的模型找出对抗样本，这些对抗样本在采取蒸馏防御的模型上同样有效。</p><p>换句话说，有效的防御手段必须破坏转移性</p><p>总的来说，本文的贡献有以下几点：</p><ol><li>引入了攻击手段，分别以$L_0$，$L_2$，$L_{infty}$作为距离指标。</li><li>调研了优化目标对生成对抗样本的影响。</li></ol><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>目前生成对抗样本的关键问题之一是添加distortion的程度。不同领域的distance metric肯定是不同的。</p><p>本文默认的攻击方法是白盒攻击，因为我们可以通过迁移的方法，将白盒生成的对抗样本迁移到目标样本的黑盒测试中。</p><p>神经网络的robustness定义为生成对抗样本的容易程度。</p><p>本文攻击的对象是以模型蒸馏为防御方法的模型。这种方法能够防御住迄今为止的大部分攻击手段。</p><p>本文攻击的模型皆为图像识别领域的m分类器，输出层为softmax层。这也就意味着输出向量维度为m，$y_i$即为样本分类为i的概率。</p><p>对抗攻击分为带目标的和不带目标的。本文将带目标攻击分成三种情况：</p><p>一般情况：在不是正确标签的标签中随机选择目标类别。</p><p>最佳情况：对所有不正确的类别进行攻击，并报告最难攻击的目标类别。</p><p>在所有评估中，我们执行所有三种类型的攻击：最佳情况，平均情况和最坏情况。</p><p>请注意，如果分类器在80％的时间中仅是准确的，则最佳案例攻击将需要在20％的案例中将其更改为0。</p><p>无论是L0,L2,Loo，没有距离度量是人类感知相似性的完美度量，并且我们没有准确判断哪个距离度量是最佳的。</p><p><strong>防御性蒸馏</strong>：以标准方式在训练数据上训练具有相同架构的网络。当我们在训练该网络时计算softmax时，将其替换为更平滑的softmax版本（将对数除以某个常数T）。</p><p>训练结束后，输入训练集得到模型推断的标签，收集这些标签并代替真实标签，再训练第二个网络。</p><p>这样做的理由是，提出蒸馏防御的人认为，对抗样本是模型过拟合的体现，那么避免过拟合可能会消除高维空间中的盲点。</p><p>但事实上蒸馏不会增加网络健壮性。</p><h1 id="攻击方法"><a href="#攻击方法" class="headerlink" title="攻击方法"></a>攻击方法</h1><h2 id="L-BFGS"><a href="#L-BFGS" class="headerlink" title="L-BFGS"></a>L-BFGS</h2><p>找对抗样本的过程建模为优化过程。<br><img src="/2020/06/27/【论文阅读笔记】Towards-Evaluating-the-Robustness-of-Neural-Networks/2020-06-27-23-41-04.png" srcset="/img/loading.gif" alt><br>loss函数可以取交叉熵。上式求解的是c，使用的距离是$L_2$</p><h2 id="FGSM"><a href="#FGSM" class="headerlink" title="FGSM"></a>FGSM</h2><p>用的是$L_{\infty}$</p><h2 id="JSMA"><a href="#JSMA" class="headerlink" title="JSMA"></a>JSMA</h2><p>Jacobian-based Saliency Map Attack</p><p>JSMA使用的不是softmax的输出，而是softmax的输入，换句话说就是前一层的输出。$L_0$</p><h2 id="DeepFool"><a href="#DeepFool" class="headerlink" title="DeepFool"></a>DeepFool</h2><p>$L_2$</p><h1 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h1><p><img src="/2020/06/27/【论文阅读笔记】Towards-Evaluating-the-Robustness-of-Neural-Networks/2020-06-27-23-54-11.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/27/【论文阅读笔记】Towards-Evaluating-the-Robustness-of-Neural-Networks/2020-06-27-23-54-31.png" srcset="/img/loading.gif" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2017年的攻击文章，目标是当时防御性较高的&lt;strong&gt;防御性蒸馏&lt;/strong&gt;模型，属于图像分类模型。结果是成功令其鲁棒性下降。文章最后的结论是，做防御的人应该用较先进的攻击手段测试自己的模型，同时应该注意防御对抗样本的迁移特性，即在其他弱模型上生成样本后在目标模型上测试的行为。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】Fuzzing: A Survey</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzzing-A-Survey/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzzing-A-Survey/</id>
    <published>2020-06-20T03:59:40.000Z</published>
    <updated>2020-06-26T17:04:36.951Z</updated>
    
    <content type="html"><![CDATA[<p>2018年CyberSecurity收录的一篇关于软件测试中模糊测试的综述。作者来自清华大学。文章名越短越霸气。<br><a id="more"></a></p><blockquote><p>警告！本文在写作过程中大量使用了谷歌翻译。</p></blockquote><h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>模糊测试几乎不需要了解目标，并且可以轻松扩展到大型应用程序，因此已成为最受欢迎的漏洞发现解决方案</p><p>模糊的随机性和盲目性导致发现错误的效率低下</p><p>反馈驱动的模糊模式（feedback-driven fuzzing mode）和遗传算法（genetic algorithms）的结合提供了更灵活和可自定义的模糊框架，并使模糊过程更加智能和高效。</p><h1 id="二、背景"><a href="#二、背景" class="headerlink" title="二、背景"></a>二、背景</h1><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-26-22-37-23.png" srcset="/img/loading.gif" alt></p><h2 id="1-静态分析"><a href="#1-静态分析" class="headerlink" title="1.静态分析"></a>1.静态分析</h2><p>静态分析（Static Analysis）是对在没有实际执行程序的情况下执行的程序的分析。</p><p>通常对源代码执行静态分析，有时还对目标代码执行静态分析。通过分析词法，语法，语义特征以及数据流分析，模型检查，静态分析，可以检测到隐藏的错误。</p><p>静态分析的优点是检测速度快。</p><p>由于缺乏易于使用的漏洞检测模型，因此静态分析工具容易产生大量误报。因此，确定静态分析的结果仍然是一项艰巨的工作。</p><h2 id="2-动态分析"><a href="#2-动态分析" class="headerlink" title="2.动态分析"></a>2.动态分析</h2><p>动态分析（Dynamic Analysis）与静态分析相比，分析人员需要在实际系统或仿真器中执行目标程序。</p><p>通过监视运行状态并分析运行时知识，动态分析工具可以精确地检测程序错误。</p><p>动态分析的优点是精度高，缺点是速度慢，效率低，对测试人员的技术水平要求高，可扩展性差，并且难以进行大规模测试。</p><h2 id="3-符号执行"><a href="#3-符号执行" class="headerlink" title="3.符号执行"></a>3.符号执行</h2><p>符号执行（Symbolic Execution）是另一种发现漏洞的技术。</p><p>通过符号化程序输入，符号执行为每个执行路径维护了一组约束（constraint）。</p><p>执行之后，约束求解器（constraint solvers）将用于求解约束并确定导致执行的输入。</p><p>从技术上讲，符号执行可以覆盖程序中的任何执行路径，并且在小型程序的测试中已显示出良好的效果，但也存在许多限制。</p><p>首先，路径爆炸问题。随着程序规模的增长，执行状态会爆炸，这超出了约束求解器的求解能力。</p><p>第二，环境的相互作用。在符号执行中，当目标程序执行与符号执行环境之外的组件交互时，例如系统调用，处理信号等，可能会出现一致性问题。</p><p>因此符号执行仍然很难扩展到大型应用程序。</p><h2 id="4-模糊测试"><a href="#4-模糊测试" class="headerlink" title="4.模糊测试"></a>4.模糊测试</h2><p>模糊测试（Fuzzing）是目前最流行的漏洞发现技术。</p><p>从概念上讲，模糊测试从为目标应用程序生成大量正常和异常输入开始，并尝试通过将生成的输入提供给目标应用程序并监视执行状态来检测异常。</p><p>与其他技术相比，模糊测试易于部署并且具有良好的可扩展性和适用性，并且可以在有或没有源代码的情况下执行。</p><p>此外，由于模糊测试是在实际执行中执行的，因此它具有很高的准确性。</p><p>而且，模糊测试几乎不需要了解目标应用程序，并且可以轻松扩展到大型应用程序。</p><p>尽管模糊测试存在许多缺点，例如效率低和代码覆盖率低，但是，缺点却胜过缺点，模糊处理已成为当前最有效，最高效的最新漏洞发现技术。</p><h1 id="三、模糊测试介绍"><a href="#三、模糊测试介绍" class="headerlink" title="三、模糊测试介绍"></a>三、模糊测试介绍</h1><h2 id="1-模糊测试的工作过程"><a href="#1-模糊测试的工作过程" class="headerlink" title="1.模糊测试的工作过程"></a>1.模糊测试的工作过程</h2><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-26-22-38-53.png" srcset="/img/loading.gif" alt></p><p>模糊测试包括四个主要阶段，即测试用例生成阶段，测试用例运行阶段，程序执行状态监视和异常分析。</p><p>模糊测试从生成一堆程序输入（即测试用例）开始。生成的测试用例的质量直接影响测试效果。</p><p>一方面，输入应尽可能满足测试程序对输入格式的要求。</p><p>另一方面，应充分破坏输入，以便对这些输入进行处理很可能会使程序失败。</p><p>根据目标程序，输入可以是具有不同文件格式的文件，网络通信数据，具有指定特征的可执行二进制文件等。</p><p>如何生成足够多的测试用例是Fuzzer面临的主要挑战。</p><p>在上一阶段生成测试用例后，将它们馈送到目标程序。</p><p>模糊测试器自动开始和完成目标程序的过程，并驱动目标程序的测试用例处理过程。</p><p>在执行之前，分析人员可以配置目标程序的启动和完成方式，并预定义参数和环境变量。</p><p>通常，模糊处理过程在预定义的超时、程序执行挂起或崩溃时停止。</p><p>模糊器在目标程序执行期间监视执行状态，以防异常和崩溃。</p><p>常用的异常监视方法包括监视特定的系统信号，崩溃和其他违规（violations）。</p><p>当捕获到违规时，模糊器将存储相应的测试用例，以供以后重播和分析。</p><p>在分析阶段，分析人员尝试确定捕获的违规的位置和根本原因。</p><p>自动崩溃分析是另一个重要的研究领域。</p><h2 id="2-模糊测试器的种类"><a href="#2-模糊测试器的种类" class="headerlink" title="2.模糊测试器的种类"></a>2.模糊测试器的种类</h2><h3 id="A-基于生成和基于突变"><a href="#A-基于生成和基于突变" class="headerlink" title="A.基于生成和基于突变"></a>A.基于生成和基于突变</h3><p>模糊器可以分为基于生成（generation based）和基于突变（mutation based）两类。</p><p>对于基于生成的模糊器，需要有关程序输入的知识。</p><p>对于文件格式模糊测试（file format fuzzing），通常会提供一个预定义文件格式的配置文件。测试用例根据配置文件生成。</p><p>有了给定的文件格式知识（file format knowledge），基于生成的模糊器生成的测试用例就可以更轻松地通过程序的验证，并且更有可能测试目标程序的更深层代码。</p><p>但是，如果没有友好的文档，分析文件格式将是一项艰巨的工作。</p><p>因此，基于变异的模糊器更容易启动并且更适用，并且被最新的模糊器广泛使用。</p><p>对于基于突变的模糊器，需要一组有效的初始输入（a set of valid initial inputs）。</p><p>测试用例是通过对初始输入和测试过程中产生的测试用例进行变异而生成的。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-26-22-43-30.png" srcset="/img/loading.gif" alt></p><h3 id="B-黑盒白盒灰盒"><a href="#B-黑盒白盒灰盒" class="headerlink" title="B.黑盒白盒灰盒"></a>B.黑盒白盒灰盒</h3><p>关于对程序源代码的依赖性（the dependence on program source<br>code）和程序分析的程度（the degree of program analysis），模糊器可以分为白盒，灰盒和黑盒（white box, gray box and black box）。</p><p>白盒模糊测试器可以访问程序的源代码，因此可以通过对源代码进行分析以及测试用例如何影响程序运行状态来收集更多信息。</p><p>黑盒模糊器会在不了解目标程序内部的情况下进行模糊测试。</p><p>灰箱模糊器也不使用源代码，但可以通过程序分析获得目标程序的内部信息。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-26-22-44-18.png" srcset="/img/loading.gif" alt></p><h3 id="C-定向模糊和基于覆盖的模糊"><a href="#C-定向模糊和基于覆盖的模糊" class="headerlink" title="C.定向模糊和基于覆盖的模糊"></a>C.定向模糊和基于覆盖的模糊</h3><p>根据探索程序的策略（the strategies of exploring the programs），模糊器可以分为定向模糊（directed fuzzing）和基于覆盖的模糊（coverage-based fuzzing）。</p><p>定向模糊器旨在生成覆盖目标代码和程序目标路径的测试用例（cover target code and target paths of programs），而基于覆盖率的模糊器旨在生成覆盖尽可能多的程序代码的测试用例（cover as much code of programs as possible）。</p><p>定向模糊器期望对程序进行更快的测试，而基于覆盖率的模糊器期望进行更彻底的测试并检测到尽可能多的错误。</p><p>对于定向模糊器和基于覆盖的模糊器，如何提取执行路径的信息是一个关键问题。</p><h3 id="D-哑模糊和智能模糊"><a href="#D-哑模糊和智能模糊" class="headerlink" title="D.哑模糊和智能模糊"></a>D.哑模糊和智能模糊</h3><p>根据对程序执行状态的监视和测试用例的生成之间是否存在反馈（whether there is a feedback between the monitoring of program execution state and testcase generation），模糊器可以分为哑类（dumb fuzz）和智能类（smart fuzz）。</p><p>智能模糊器会根据收集的信息（测试用例如何影响程序行为）来调整测试用例的生成。</p><p>对于基于变异的模糊测试器，反馈信息可用于确定应该对测试用例的哪一部分进行变异以及对它们进行变异的方式。</p><p>哑模糊测试器（Dumb fuzzers）具有更好的测试速度（speed），而智能模糊测试器可以生成更好的测试用例并获得更高的效率（efficiency）。</p><h2 id="3-模糊测试面临的挑战"><a href="#3-模糊测试面临的挑战" class="headerlink" title="3.模糊测试面临的挑战"></a>3.模糊测试面临的挑战</h2><h3 id="A-如何改变种子输入的挑战"><a href="#A-如何改变种子输入的挑战" class="headerlink" title="A.如何改变种子输入的挑战"></a>A.如何改变种子输入的挑战</h3><p>基于变异的模糊测试工具在进行变异时需要回答两个问题：（1）变异的位置，以及（2）变异的方式。</p><p>只有几个关键位置的突变会影响执行的控制流程。因此，如何在测试用例中定位这些关键位置非常重要。</p><p>此外，模糊器改变关键位置的方式是另一个关键问题，即如何确定可以将测试定向到程序有趣路径的值。</p><p>简而言之，测试用例的盲目突变会严重浪费测试资源，更好的变异策略可以显着提高模糊测试的效率。</p><h3 id="B-低代码覆盖率的挑战"><a href="#B-低代码覆盖率的挑战" class="headerlink" title="B.低代码覆盖率的挑战"></a>B.低代码覆盖率的挑战</h3><p>较高的代码覆盖率表示对程序执行状态的覆盖率更高，并且测试更加彻底。发现错误的可能性更高。</p><p>但是，大多数测试用例仅涵盖相同的少数路径。</p><p>因此，仅通过大量生成测试用例并投入测试资源来实现高覆盖率是不明智的选择。</p><p>基于覆盖率的模糊器试图借助程序分析技术（例如程序检测，program instrumentation）来解决问题。</p><h3 id="C-通过验证的挑战"><a href="#C-通过验证的挑战" class="headerlink" title="C.通过验证的挑战"></a>C.通过验证的挑战</h3><p>程序通常在解析和处理之前验证（Validation）输入。</p><p>验证可以保护程序，节省计算资源，并保护程序免受无效输入和恶意构造输入造成的损坏。</p><p>黑盒和灰盒模糊器生成的测试用例很难通过盲目生成策略（blind generation strategy）的验证，从而导致效率很低。</p><h1 id="四、覆盖引导的模糊测试"><a href="#四、覆盖引导的模糊测试" class="headerlink" title="四、覆盖引导的模糊测试"></a>四、覆盖引导的模糊测试</h1><p>为了实现深入而彻底的程序模糊测试，模糊测试人员应尝试<strong>遍历尽可能多的程序运行状态</strong>。</p><p>但是，由于程序行为的不确定性，因此<strong>没有用于程序状态的简单度量</strong>。</p><p>测量代码覆盖率成为一种近似的替代解决方案。代码覆盖率的增加代表了新的程序状态。此外，代码覆盖率很容易测量。</p><p>但是，代码覆盖率是一种近似的度量，因为在实践中，恒定的代码覆盖率并不表示恒定的程序状态数。使用此指标可能会导致某些信息丢失。</p><h2 id="1-代码覆盖率计数"><a href="#1-代码覆盖率计数" class="headerlink" title="1.代码覆盖率计数"></a>1.代码覆盖率计数</h2><p>在程序分析中，程序由基本块（basic blocks）组成。基本块是具有单个入口和出口点的代码段，基本块中的指令将顺序执行，并且只会执行一次。</p><p>在代码覆盖率测量中，最新技术将基本块作为最佳粒度（granularity）。原因包括：（1）基本块是程序执行的最小连贯单位；（2）测量功能或指令会导致信息丢失或冗余；（3）基本块可以由第一条指令的地址标识；以及基本块信息可通过代码检测轻松提取。</p><p>当前，有两种基于基本块的基本测量选择：简单地计算已执行的基本块和计算基本块的跃迁（transitions）。</p><p>在后一种方法中，程序被解释为图，顶点用于表示基本块，边用于表示基本块之间的跃迁。</p><p>后一种方法记录边缘，而前一种方法记录顶点。</p><p>但是实验表明仅对已执行的基本块进行计数将导致严重的信息丢失。</p><p>如图所示，如果首先执行程序路径（BB1，BB2，BB3，BB4），然后执行时遇到路径（BB1，BB2，BB4），则新边（BB2，BB4）信息为丢失。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-11-48.png" srcset="/img/loading.gif" alt></p><h2 id="2-基于覆盖的模糊测试的工作过程"><a href="#2-基于覆盖的模糊测试的工作过程" class="headerlink" title="2.基于覆盖的模糊测试的工作过程"></a>2.基于覆盖的模糊测试的工作过程</h2><p>算法1显示了基于覆盖的模糊器的一般工作过程。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/alg1.png" srcset="/img/loading.gif" alt></p><p>测试从初始给定的种子输入开始。</p><p>在主模糊循环中，模糊器反复选择一个有趣的种子来进行后续的突变和测试用例的生成。然后在模糊器的监视下驱动目标程序以执行生成的测试用例。</p><p>收集触发崩溃的测试用例，并将其他有趣的用例添加到种子库中。</p><p>对于基于覆盖的模糊测试，达到新控制流<strong>边缘的测试用例</strong>被认为很有趣。</p><p>主模糊循环在预先配置的超时或中止信号时停止。</p><p>在模糊测试过程中，模糊器通过各种方法跟踪执行情况。</p><p>基本上，模糊器出于两个目的跟踪执行，即<strong>代码覆盖率</strong>和<strong>安全性违规</strong>（security violations）。</p><p>代码覆盖率信息用于进行彻底的程序状态探索，而安全违规跟踪则用于更好地发现错误。</p><p>下图显示了AFL（American Fuzzy Lop，一个非常有代表性的基于覆盖的模糊器）的工作过程。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-18-50.png" srcset="/img/loading.gif" alt></p><p>在执行覆盖范围收集之前，模糊器将对目标应用程序进行检测。</p><p>在主模糊循环中，提供初始种子输入后，（1）模糊器根据种子选择策略从种子库中选择喜欢的种子，比如AFL则选择最快和最小的种子。（2）根据变异策略对种子文件进行变异，并生成一堆测试用例。</p><p>AFL当前采用一些随机修改和测试用例拼接方法，包括长度和步长变化的顺序位翻转，小整数的顺序加法和减法以及已知有趣的整数（如0、1，INT_MAX等）的顺序插入。（3）测试用例已执行，并且执行情况正在跟踪中。</p><p>收集覆盖率信息以确定有趣的测试用例，即达到新控制流边缘的测试用例。</p><p>有趣的测试用例将添加到种子池中，以进行下一轮运行。</p><h2 id="3-关键问题"><a href="#3-关键问题" class="headerlink" title="3.关键问题"></a>3.关键问题</h2><p>前面的介绍表明，要运行一个高效的、基于覆盖的模糊，需要解决很多问题。最近一些研究如下表。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-22-32.png" srcset="/img/loading.gif" alt></p><h3 id="A-如何获得初始输入？"><a href="#A-如何获得初始输入？" class="headerlink" title="A.如何获得初始输入？"></a>A.如何获得初始输入？</h3><p>大多数最先进的基于覆盖的模糊器都采用了基于突变的测试用例生成策略，这在很大程度上取决于初始种子输入的质量。</p><p>良好的初始种子输入可以显著提高模糊的效率和效果。</p><p>具体来说，</p><p>(1)提供格式良好的种子输入可以节省构建一个种子输入所消耗的大量cpu时间；</p><p>(2)良好的初始输入可以满足复杂文件格式的要求，而复杂文件格式在突变阶段是很难猜测的；</p><p>(3)基于格式良好的种子输入的突变更容易产生测试用例，可以达到更深层次和难以达到的路径；</p><p>(4)良好的种子输入可以在多次测试中重复使用。</p><p>常用的收集种子输入的方法包括使用标准基准、从互联网上抓取和使用现有的POC（Proof of Concept）样本。</p><p>考虑到目标应用输入的多样性，从互联网上抓取是最直观的方法。</p><p>过量的种子输入会导致第一次干运行的时间浪费，从而带来另一个问题，即如何提炼初始语料。</p><p>AFL提供了一个工具，它可以提取一个最小的输入集，以达到相同的代码覆盖率。</p><h3 id="B-如何生成测试用例？"><a href="#B-如何生成测试用例？" class="headerlink" title="B.如何生成测试用例？"></a>B.如何生成测试用例？</h3><p>testcases的质量是影响模糊测试效率和效果的重要因素。</p><p>首先，好的testcases可以在较短的时间内探索更多的程序执行状态，覆盖更多的代码。</p><p>此外，好的测试用例可以针对潜在的脆弱位置，带来更快的程序bug发现。</p><p>因此，如何基于种子输入生成好的测试用例是一个重要的问题。</p><p>种子输入的突变涉及两个关键问题：在哪里突变和用什么值进行突变。</p><p>随着机器学习技术的发展和广泛应用，一些研究尝试使用机器学习技术来辅助生成testcases。</p><p>微软研究院的Godefroid等（2017）利用基于神经网络的统计机器学习技术来自动生成testcases。</p><p>具体来说，他们首先通过机器学习技术从一堆有效输入中学习输入格式，然后利用学习到的知识指导测试用例的生成。</p><p>他们介绍了微软Edge浏览器中PDF解析器的模糊过程。</p><p>虽然实验并没有给出一个令人鼓舞的结果，但仍是一个不错的尝试。</p><p>微软的Rajpal等人（2017）使用神经网络从过去的模糊探索中学习，并预测输入文件中哪些字节要突变。</p><p>Nichols等人（2017）使用生成对抗网络（GAN）模型来帮助用新颖的种子文件重新初始化系统。</p><p>实验表明，GAN比LSTM更快、更有效，并且有助于发现更多的代码路径。</p><h3 id="C-如何从种子池中选择种子？"><a href="#C-如何从种子池中选择种子？" class="headerlink" title="C.如何从种子池中选择种子？"></a>C.如何从种子池中选择种子？</h3><p>模糊器在主模糊循环中新一轮测试开始时，反复从种子池中选择种子进行突变。</p><p>以往的工作已经证明，良好的种子选择策略可以显著提高模糊效率，并帮助更快地找到更多的Bugs。</p><p>通过良好的种子选择策略，模糊器可以</p><ul><li>（1）优先选择更有帮助的种子，包括覆盖更多的代码，更容易触发漏洞；</li><li>（2）减少重复执行路径的浪费，节省计算资源；</li><li>（3）优化选择覆盖更深、更易受攻击的代码的种子，帮助更快地识别隐藏的漏洞。</li></ul><p>Böhme等人（2017）提出了AFLFast，一个基于覆盖的灰盒模糊器。在模糊过程中，AFLFast会测量执行路径的频率，优先处理被模糊次数较少的种子，并为行使低频路径的种子分配更多的能量。</p><p>Rawat等(2017)综合了静态和动态分析来识别难以到达的深层路径，并对到达深层路径的种子进行优先级排序。</p><p>AFLGo将一些易受攻击的代码定义为目标位置，并优化选择离目标位置较近的测试case。</p><p>已知漏洞的特征也可用于种子选择策略。然而，收集耗费资源的信息带来了沉重的开销，降低了模糊的效率。</p><h3 id="D-如何高效地测试应用程序？"><a href="#D-如何高效地测试应用程序？" class="headerlink" title="D.如何高效地测试应用程序？"></a>D.如何高效地测试应用程序？</h3><p>目标应用程序由主模糊循环中的模糊器反复启动和完成。</p><p>对于用户区应用程序的模糊处理，程序的创建和完成将消耗大量的cpu时间。频繁创建和完成该程序将严重降低模糊测试的效率。</p><p>AFL使用forkserver方法，该方法创建一个已加载程序的完全相同的克隆，并在每次运行时重复使用该克隆。</p><h1 id="五、模糊集成技术"><a href="#五、模糊集成技术" class="headerlink" title="五、模糊集成技术"></a>五、模糊集成技术</h1><p>使用随机突变方法的模糊模糊测试策略会导致大量无效测试用例，并且模糊测试效率较低。</p><p>当前，最先进的模糊器通常采用智能模糊策略。</p><p>智能模糊器通过程序分析技术来收集程序控制流和数据流信息，并因此利用收集到的信息来改进测试用例的生成。</p><p>由智能模糊器生成的测试用例具有更好的针对性，更有可能满足程序对数据结构和逻辑判断的要求。</p><p>下图描绘了智能模糊的示意图。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-36-55.png" srcset="/img/loading.gif" alt></p><p>表5中总结了模糊测试中集成的主要技术。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-37-51.png" srcset="/img/loading.gif" alt></p><h2 id="1-测试用例生成"><a href="#1-测试用例生成" class="headerlink" title="1.测试用例生成"></a>1.测试用例生成</h2><p>如前所述，模糊测试中的测试用例是基于生成的方法或基于变异的方法生成的。</p><p>如何生成满足复杂数据结构要求并更有可能触发难以到达的路径的测试用例是一个关键挑战。</p><p>在基于生成的模糊测试中，生成器根据输入数据格式的知识生成测试用例。</p><p>Work（Godefroid et al.2017）使用机器学习技术（特别是递归神经网络）来学习输入文件的语法，并因此使用所学的语法来生成满足格式要求的测试用例。</p><p>更多的最先进的模糊器采用基于变异的模糊策略。通过在突变过程中修改部分种子输入来生成测试用例。</p><p>在盲目的突变模糊化过程中，变异者使用随机值或几个特殊值随机修改种子字节，这被证明是效率很低的。因此，如何确定要修改的位置以及修改中使用的值是另一个关键挑战。</p><h2 id="2-程序执行"><a href="#2-程序执行" class="headerlink" title="2.程序执行"></a>2.程序执行</h2><p>执行阶段涉及的两个关键问题是<strong>如何指导模糊测试过程</strong>以及<strong>如何探索新路径</strong>。</p><p>仪表（Instrumentation）技术用于记录路径执行情况并计算基于覆盖率的模糊测试中的覆盖率信息。</p><p>测试执行过程中的另一个问题是探索新路径。符号执行技术在路径探索中具有天然的优势。</p><p>通过求解约束集，符号执行技术可以计算出满足特定条件要求的值。</p><p>反馈驱动的模糊测试提供了一种有效的引导测试方法，传统和新技术都可以发挥传感器的作用，以在测试执行过程中获取各种信息，并准确地指导模糊测试。</p><h1 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h1><ul><li>反馈驱动的模糊模式（feedback-driven fuzzing mode）和遗传算法（genetic algorithms）的结合</li><li>测试用例生成阶段，测试用例运行阶段，程序执行状态监视和异常分析</li><li>根据探索程序的策略（the strategies of exploring the programs），模糊器可以分为定向模糊（directed fuzzing）和基于覆盖的模糊（coverage-based fuzzing）。</li><li>定向模糊器期望对程序进行更快的测试，而基于覆盖率的模糊器期望进行更彻底的测试并检测到尽可能多的错误。</li><li>对于定向模糊器和基于覆盖的模糊器，如何提取执行路径的信息是一个关键问题。</li><li>根据对程序执行状态的监视和测试用例的生成之间是否存在反馈（whether there is a feedback between the monitoring of program execution state and testcase generation），模糊器可以分为哑类（dumb fuzz）和智能类（smart fuzz）。</li><li>智能模糊器会根据收集的信息（测试用例如何影响程序行为）来调整测试用例的生成。</li><li>对于基于变异的模糊测试器，反馈信息可用于确定应该对测试用例的哪一部分进行变异以及对它们进行变异的方式。</li><li>基于变异的模糊测试工具在进行变异时需要回答两个问题：（1）变异的位置，以及（2）变异的方式。</li><li>覆盖率的定义。定义覆盖率时要防止信息丢失。代码覆盖率的增加代表了新的程序状态。此外，代码覆盖率很容易测量。边缘的测试用例被认为很有趣</li><li>通过验证的挑战。验证可以保护程序，节省计算资源，并保护程序免受无效输入和恶意构造输入造成的损坏。</li><li>一些研究尝试使用机器学习技术来辅助生成testcases。GAN比LSTM更快、更有效，并且有助于发现更多的代码路径。</li><li>如何从种子池中选择种子？</li><li>如何高效地测试应用程序？</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2018年CyberSecurity收录的一篇关于软件测试中模糊测试的综述。作者来自清华大学。文章名越短越霸气。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Fuzzing" scheme="https://superlova.github.io/tags/Fuzzing/"/>
    
      <category term="Software Testing" scheme="https://superlova.github.io/tags/Software-Testing/"/>
    
      <category term="Survey" scheme="https://superlova.github.io/tags/Survey/"/>
    
  </entry>
  
  <entry>
    <title>【学习笔记】LSTM网络结构简介与对应的keras实现</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91LSTM%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AF%B9%E5%BA%94%E7%9A%84keras%E5%AE%9E%E7%8E%B0/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91LSTM%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AF%B9%E5%BA%94%E7%9A%84keras%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-06-20T03:50:37.000Z</published>
    <updated>2020-06-26T12:39:35.089Z</updated>
    
    <content type="html"><![CDATA[<p>从理论和代码两个层面介绍了LSTM网络。<br><a id="more"></a></p><h2 id="一、理论来一波"><a href="#一、理论来一波" class="headerlink" title="一、理论来一波"></a>一、理论来一波</h2><p>循环神经网络（Recurrent Neural Network，RNN）是一类有短期记忆能力的神经网络。在循环神经网络中，神经元不但可以接受其他神经元的信息，也可以接受自身的信息，形成具有环路的网络结构。</p><p><img src="/2020/06/20/【学习笔记】LSTM网络结构简介与对应的keras实现/2020-06-20-11-51-21.png" srcset="/img/loading.gif" alt></p><p>长短期记忆网络（Long Short-Term Memory Network，LSTM）[Gers et al.,2000; Hochreiter et al., 1997] 是循环神经网络的一个变体，可以有效地解决简单循环神经网络的梯度爆炸或消失问题。</p><p><img src="/2020/06/20/【学习笔记】LSTM网络结构简介与对应的keras实现/2020-06-20-11-51-13.png" srcset="/img/loading.gif" alt></p><p>LSTM 网络引入一个新的内部状态（internal state） $\boldsymbol{c}_{t}\in \mathbb{R}^{\boldsymbol{D}}$ 专门进行线性的循环信息传递，同时（非线性地）输出信息给隐藏层的外部状态 $\boldsymbol{h}_{t}\in \mathbb{R}^{\boldsymbol{D}}$ 。这两个状态通过下式计算：</p><script type="math/tex; mode=display">\begin{array}{l}\boldsymbol{c}_{t}=\boldsymbol{f}_{t} \odot \boldsymbol{c}_{t-1}+\boldsymbol{i}_{t} \odot \tilde{\boldsymbol{c}}_{t} \\\boldsymbol{h}_{t}=\boldsymbol{o}_{t} \odot \tanh \left(\boldsymbol{c}_{t}\right)\end{array}</script><p>其中，$\odot$为向量逐元素乘积（代表左右两边向量维度相同）；$\boldsymbol{c}_{t-1}$为上一时刻的记忆单元；$\tilde{\boldsymbol{c}}\in \mathbb{R}^{\boldsymbol{D}}$是通过非线性函数得到的候选状态：</p><script type="math/tex; mode=display">\tilde{\boldsymbol{c}}_{t}=\tanh \left(\boldsymbol{W}_{c} \boldsymbol{x}_{t}+\boldsymbol{U}_{c} \boldsymbol{h}_{t-1}+\boldsymbol{b}_{c}\right)</script><p>在每个时刻 $t$，LSTM 网络的内部状态 $\boldsymbol{c}_{t}$ 记录了到当前时刻为止的历史信息。</p><p>LSTM内部多了三个gate，分别是forget、input、output。$\boldsymbol{f}_{t}\in [0,1]^{\boldsymbol{D}}$、$\boldsymbol{i}_{t}\in [0,1]^{\boldsymbol{D}}$、$\boldsymbol{o}_{t}\in [0,1]^{\boldsymbol{D}}$。这三个门与输入、隐状态和输出的维度应该相同，都是维度为输入序列维度n的向量（其实应该为n+1）$=D$。</p><p>与此同时，三个门的值依赖于$t$时刻的输入$x_t$、$t-1$时刻的隐变量$h_{t-1}$以及不同的权重矩阵($W_i$/$W_f$/$W_o$/$U_i$/$U_f$/$U_o$)。</p><p>门控机制（Gating Mechanism）是用来控制信息传递的路径的手段。</p><ul><li>遗忘门 $\boldsymbol{f}_{t}$ 控制上一个时刻的内部状态$\boldsymbol{c}_{t-1}$ 需要遗忘多少信息。</li><li>输入门 $\boldsymbol{i}_{t}$ 控制当前时刻的候选状态 ̃$\tilde{\boldsymbol{c}}_{t}$ 有多少信息需要保存。</li><li>输出门 $\boldsymbol{o}_{t}$ 控制当前时刻的内部状态 $\boldsymbol{c}_{t}$ 有多少信息需要输出给外部状态 $\boldsymbol{h}_{t}$。</li></ul><p>举个例子，当$\boldsymbol{f}_{t}=\mathbf{0}, \boldsymbol{i}_{t}=\mathbf{1}$时，记忆单元将历史信息清空，并将候选状态向量$\tilde{\boldsymbol{c}}_{t}$写入。但此时记忆单元 $\boldsymbol{c}_{t}$ 依然和上一时刻的历史信息相关。当$\boldsymbol{f}_{t}=\mathbf{1}, \boldsymbol{i}_{t}=\mathbf{0}$时，记忆单元将复制上一时刻的内容，不写入新的信息。</p><p>LSTM 网络中的“门”是一种“软”门，取值在 (0, 1) 之间，表示以一定的比例允许信息通过．三个门的计算方式为：</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{i}_{t} &=\sigma\left(\boldsymbol{W}_{i} \boldsymbol{x}_{t}+\boldsymbol{U}_{i} \boldsymbol{h}_{t-1}+\boldsymbol{b}_{i}\right) \\\boldsymbol{f}_{t} &=\sigma\left(\boldsymbol{W}_{f} \boldsymbol{x}_{t}+\boldsymbol{U}_{f} \boldsymbol{h}_{t-1}+\boldsymbol{b}_{f}\right) \\\boldsymbol{o}_{t} &=\sigma\left(\boldsymbol{W}_{o} \boldsymbol{x}_{t}+\boldsymbol{U}_{o} \boldsymbol{h}_{t-1}+\boldsymbol{b}_{o}\right)\end{aligned}</script><p>其中$\sigma(\cdot)$ 为 Logistic 函数，其输出区间为 (0, 1)；$\boldsymbol{x}_{t}$为当前时刻的输入。</p><h2 id="二、还是得看代码"><a href="#二、还是得看代码" class="headerlink" title="二、还是得看代码"></a>二、还是得看代码</h2><p>下面是我定义的一个专用于IMDb影评情感分析的二分类模型，包装在一个函数中。输入训练集、测试集及其标签，设定好参数就可以运行、训练。可以选择是否保存模型到本地。最后函数返回训练好的模型。</p><p>这个二分类模型中，输入是长度为80的整数列表（maxlen=80），代表着80个不同的单词构成的一句话。</p><p>如果有影评不够80个词，就在影评前面加足够的0，直到这条影评达到80个词为止。如果影评单词量大于80个，便截取前面的80个词。</p><p>每个整数都代表一个单词表中的单词。当然单词表的大小是固定的（num_words=10000个单词），如果出现不在单词表中的单词，固定将其编码成2，表示UNKNOWN（这条设置不在下面的代码中，属于数据预处理）。</p><p>第一层是Embedding层，负责将一句话中的每个单词映射成固定维度的词向量；</p><p>注意，每个单词（在这里是每个整数）都会变成固定维度（embedding_dim=128）的向量，因此每条影评从Embedding层输出后，都会变成80*128的矩阵。</p><p>第二层是LSTM层。如果你看了理论部分的叙述，就知道LSTM层中无论是隐状态$\boldsymbol{c}$、$\boldsymbol{h}$还是三个门$\boldsymbol{f}$、$\boldsymbol{i}$、$\boldsymbol{o}$，他们的维度都是$\boldsymbol{D}$。这个$\boldsymbol{D}$的大小就需要我们用参数<code>lstm_dim=32</code>来定义。这个参数越大，代表LSTM层的参数越多、泛化能力越强，也更难训练、更容易过拟合。</p><p>第三层是单个神经元的sigmoid层，在这里就直接转换成概率并分类了。</p><pre><code class="lang-python">def train_lstm(x_train, y_train, x_test, y_test,                num_words=10000,                maxlen=80,                embedding_dim=128,                lstm_dim=32,                batch_size=32,                epochs=10):    # 接收一个含有 100 个整数的序列，每个整数在 1 到 20000 之间    inputs = Input(shape=(maxlen,), dtype=&#39;int32&#39;, name=&#39;main_input&#39;)    # Embedding 层将输入序列编码为一个稠密向量的序列，    # 每个向量维度为 512。    x = Embedding(input_dim=num_words,                   input_length=maxlen,                   output_dim=embedding_dim,                   name=&#39;embedding&#39;)(inputs)    # LSTM 层把向量序列转换成单个向量，    # 它包含整个序列的上下文信息    lstm_output = LSTM(lstm_dim, name=&#39;lstm&#39;)(x)    # 插入辅助损失，    #使得即使在模型主损失很高的情况下，LSTM 层和 Embedding 层都能被平稳地训练    outputs = Dense(1, activation=&#39;sigmoid&#39;, name=&#39;output&#39;)(lstm_output)    model = Model(inputs=inputs, outputs=outputs)    model.compile(optimizer=&#39;adam&#39;,            loss=&#39;binary_crossentropy&#39;,            metrics=[&#39;accuracy&#39;])    model.fit(x_train, y_train,        batch_size=batch_size,        epochs=epochs,        validation_data=(x_test, y_test,))    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)    print(&#39;Test score:&#39;, score)    print(&#39;Test accuracy:&#39;, acc)    # model.save(&quot;lstm_imdb.h5&quot;)    return model</code></pre><h2 id="三、LSTM返回所有时间步的hidden-state向量"><a href="#三、LSTM返回所有时间步的hidden-state向量" class="headerlink" title="三、LSTM返回所有时间步的hidden state向量"></a>三、LSTM返回所有时间步的hidden state向量</h2><p>数据经过LSTM层，输出的是最后一个时间步得到的output向量（即$\boldsymbol{h}_{finally}$），维度为$\boldsymbol{D}$。</p><p>其实LSTM能够在每个时间步都输出output（即$\boldsymbol{h}_{t}$），只不过我们把这些没到时间的半成品output选择性忽略了。</p><p>如果你想要堆叠LSTM层，也就是LSTM层下面还有LSTM，或者你<strong>需要所有时间步的</strong>$\boldsymbol{h}_{t}$，那么你可以在训练的时候把<code>return_sequences=True</code>写进LSTM参数之中。</p><p><img src="/2020/06/20/【学习笔记】LSTM网络结构简介与对应的keras实现/堆叠rnn.png" srcset="/img/loading.gif" alt></p><p>下面让我们来比较一下<code>return_sequences</code>参数开启之后输出值的变化。</p><h3 id="return-sequences-False"><a href="#return-sequences-False" class="headerlink" title="return_sequences=False"></a>return_sequences=False</h3><p>首先固定随机数种子。</p><pre><code class="lang-python">np.random.seed(0)tf.random.set_seed(0)</code></pre><p>然后构建输入Input向量和LSTM层，此时LSTM层使用默认参数<code>return_sequences=False</code>。</p><pre><code class="lang-python">input1 = Input(shape=(3,1)) # 输入是三维向量lstm1 = LSTM(1)(input1) # 内部hidden和cell的维度为1model = Model(inputs=input1, outputs=lstm1)</code></pre><p>构造一批输入，包括6个句子，每个句子三个单词，然后输入LSTM，查看LSTM层的输出。</p><pre><code class="lang-python">data = np.array([[0.1, 0.2, 0.3],                    [0.3, 0.2, 0.1],                    [0.2, 0.6, 0.3],                    [0.8, 0.2, 0.3],                    [0.3, 0.5, 0.1],                    [0.2, 0.6, 0.2]])print(model.predict(data))</code></pre><p>此时输出为：</p><pre><code class="lang-python">[[0.00844267] [0.00617958] [0.01279002] [0.01231858] [0.009055  ] [0.01108878]]Process finished with exit code 0</code></pre><h3 id="return-sequences-True"><a href="#return-sequences-True" class="headerlink" title="return_sequences=True"></a>return_sequences=True</h3><p>然后打开<code>return_sequences</code>的开关</p><pre><code class="lang-python">lstm1 = LSTM(1, return_sequences=True)(input1)</code></pre><p>此时的输出为：</p><pre><code>[[[0.00190693]  [0.00490441]  [0.00844267]] #  [[0.0055262 ]  [0.00704476]  [0.00617958]] # [[0.00374958]  [0.01259477]  [0.01279002]] # [[0.01337298]  [0.01142679]  [0.01231858]] # [[0.0055262 ]  [0.01206062]  [0.009055  ]] # [[0.00374958]  [0.01259477]  [0.01108878]]] #Process finished with exit code 0</code></pre><p>此为输出所有时间步的hidden state。鉴于一共6个测试输入，每个输入有3个feature，所以时间步也就三步。LSTM的输出结果从6个hidden state变成了6*3个hidden state。</p><h3 id="return-state-True"><a href="#return-state-True" class="headerlink" title="return_state=True"></a>return_state=True</h3><p>我们再来看另一个参数，这个参数能够控制LSTM输出cell state。</p><pre><code class="lang-python">lstm1 = LSTM(1, return_state=True)(input1)</code></pre><pre><code>[array([[0.00844267],       [0.00617958],       [0.01279002],       [0.01231858],       [0.009055  ],       [0.01108878]], dtype=float32), array([[0.00844267],       [0.00617958],       [0.01279002],       [0.01231858],       [0.009055  ],       [0.01108878]], dtype=float32), array([[0.01655067],       [0.01227413],       [0.02506882],       [0.02414548],       [0.01798305],       [0.02187706]], dtype=float32)]Process finished with exit code 0</code></pre><p>开启<code>return_state=True</code>之后，LSTM返回3个array，第一个array和第二个array一样，都是hidden state，和默认返回的一样。第三个array就是最后一个时间步的cell state。</p><h3 id="return-state-True-return-sequences-True"><a href="#return-state-True-return-sequences-True" class="headerlink" title="return_state=True, return_sequences=True"></a>return_state=True, return_sequences=True</h3><p>如果两个开关都打开，则结果变成</p><pre><code class="lang-python">lstm1 = LSTM(1, return_state=True, return_sequences=True)(input1)</code></pre><pre><code>[array([[[0.00190693],        [0.00490441],        [0.00844267]],       [[0.0055262 ],        [0.00704476],        [0.00617958]],       [[0.00374958],        [0.01259477],        [0.01279002]],       [[0.01337298],        [0.01142679],        [0.01231858]],       [[0.0055262 ],        [0.01206062],        [0.009055  ]],       [[0.00374958],        [0.01259477],        [0.01108878]]], dtype=float32), array([[0.00844267],       [0.00617958],       [0.01279002],       [0.01231858],       [0.009055  ],       [0.01108878]], dtype=float32), array([[0.01655067],       [0.01227413],       [0.02506882],       [0.02414548],       [0.01798305],       [0.02187706]], dtype=float32)]Process finished with exit code 0</code></pre><p>还是返回三个array，第一个是所有时间步的hidden state，这是开启<code>return_sequences=True</code>的效果；第二个则是原本LSTM的输出hidden state；第三个是开启<code>return_state=True</code>的效果，返回最后一个时间步的cell state</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从理论和代码两个层面介绍了LSTM网络。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="RNN" scheme="https://superlova.github.io/tags/RNN/"/>
    
      <category term="LSTM" scheme="https://superlova.github.io/tags/LSTM/"/>
    
      <category term="Keras" scheme="https://superlova.github.io/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】Deep Text Classification Can be Fooled</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Deep-Text-Classification-Can-be-Fooled/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Deep-Text-Classification-Can-be-Fooled/</id>
    <published>2020-06-20T01:20:42.000Z</published>
    <updated>2020-06-23T12:41:07.656Z</updated>
    
    <content type="html"><![CDATA[<p>国内人民大学的一篇论文，被IJCAI-2018接收。主要研究文本领域的对抗样本生成，被测模型是文本分类领域的模型。<br><a id="more"></a></p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>当前的对抗样本生成领域集中在图像的扰动和生成，文本领域少有涉及。</p><p><strong>文本对抗样本应当满足</strong>：</p><ul><li>使模型分类错误</li><li>与原样本相比，扰动难以察觉</li><li>实用性，即文本含义不发生改变</li></ul><p><strong>本文采用的生成思路</strong>：</p><ul><li>三种扰动策略：插入、修改和删除</li><li>自然语言水印</li><li>白盒+黑盒</li></ul><blockquote><p>自然语言水印（Natural Language Watermarking）是通过修改文本元素（如线条，文字或字符）的外观，或更改文本格式或字体（例如，通过-文字中的单词和字母间距）来嵌入信息的技术。</p></blockquote><h2 id="2-目标模型和数据集"><a href="#2-目标模型和数据集" class="headerlink" title="2. 目标模型和数据集"></a>2. 目标模型和数据集</h2><p><strong>字符级模型</strong>：</p><ul><li>以字母为单位，编码长度为字母表大小（26+空白符个数）</li><li>结构：6conv + 3fc</li><li>数据集：DBPedia，包含14个类别，56000训练、70000测试</li></ul><p><strong>单词级模型</strong>：</p><ul><li>以单词为单位，编码长度为单词表大小（数万到数十万）</li><li>结构：embedding + conv + maxpooling + fc(带dropout) + softmax</li><li>数据集：影评MR、产品评价CR、产品意见MPQA，都是二分类</li></ul><h2 id="3-白盒攻击"><a href="#3-白盒攻击" class="headerlink" title="3. 白盒攻击"></a>3. 白盒攻击</h2><p>所谓白盒攻击，就是在已知被测模型内部信息的情况下开展的攻击。由于已知信息较多，所以攻击起来也比较容易。</p><p>白盒攻击生成对抗样本的思想在图像领域用的比较多。比如利用网络参数和损失函数进行指导攻击过程的FGSM算法。</p><p>本文采用的白盒攻击手段，也是利用模型内部的参数和网络训练时的损失函数作为引导，但是不会直接生成对抗样本，而是<strong>首先识别对分类有重大贡献的文本项</strong>。</p><h3 id="HTP：Hot-Training-Phrases"><a href="#HTP：Hot-Training-Phrases" class="headerlink" title="HTP：Hot Training Phrases"></a>HTP：Hot Training Phrases</h3><p>以字符级模型为例，识别过程如下：</p><ol><li>输入训练样本x，计算cost gradients ∇x C(M, x, label)；</li><li>每个样本x选取令gradient最大的前50个字符定义为<strong>hot character</strong>；</li><li>包含3个及以上hot characters的单词定义为<strong>hot word</strong>；</li><li>相邻的hot words定义为<strong>hot phrase</strong>；</li><li>不同类别有不同的hot phrase，代表着该类对分类贡献最大的词组；</li><li>每个类别中最常出现的hot phrase定义为<strong>Hot Training Phrases (HTPs)</strong>。</li></ol><p>下图是DBPedia的Building类别文本数据集中的HTP词汇排名前10。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/2020-06-23-20-11-30.png" srcset="/img/loading.gif" alt></p><h3 id="HSP：Hot-Sample-Phrases"><a href="#HSP：Hot-Sample-Phrases" class="headerlink" title="HSP：Hot Sample Phrases"></a>HSP：Hot Sample Phrases</h3><p>给定样本x，识别x中的hot phrase作为操作位置，该位置的单词或词组就定义为<strong>Hot Sample Phrases (HSPs)</strong>。</p><h3 id="Attacking-Character-level-DNN"><a href="#Attacking-Character-level-DNN" class="headerlink" title="Attacking Character-level DNN"></a>Attacking Character-level DNN</h3><h4 id="Insertion"><a href="#Insertion" class="headerlink" title="Insertion"></a><strong>Insertion</strong></h4><p>通过在样本的HSP位置插入以下内容实现变异操作：</p><ul><li>HTP；</li><li>可有可无的事实（文本水印算法生成）；</li><li>不伤害文本主语义的伪造事实（文本水印算法生成）。</li></ul><p>下面是三个通过插入红色文本造成标签改变的例子。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/2020-06-23-20-11-43.png" srcset="/img/loading.gif" alt="Figure2"><br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/2020-06-23-20-11-56.png" srcset="/img/loading.gif" alt="Figure3"><br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure4.png" srcset="/img/loading.gif" alt="Figure4"></p><h4 id="Modification"><a href="#Modification" class="headerlink" title="Modification"></a><strong>Modification</strong></h4><p>对HSP稍加操作，比如typo-based watermarking technique（基于错别字的水印技术）：</p><ul><li>(1)替换以常见的错误拼写（需要有错别字语料库）</li><li>(2)替换以外观相似的字符</li></ul><p>下图是替换操作后生成对抗样本的一个例子。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure5.png" srcset="/img/loading.gif" alt></p><p>下图是将film替换成flim后模型内部损失函数梯度的改变。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure6.png" srcset="/img/loading.gif" alt></p><h4 id="Removal"><a href="#Removal" class="headerlink" title="Removal"></a><strong>Removal</strong></h4><p>删除HSP可降低模型对样本的confidence。只能删除HSPs中起辅助作用的词，要不然会改变本来的含义。</p><p>下面是通过删除来导致置信程度下降的例子。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure7.png" srcset="/img/loading.gif" alt></p><h4 id="Combination"><a href="#Combination" class="headerlink" title="Combination"></a><strong>Combination</strong></h4><p>组合上述三种手法。</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure8.png" srcset="/img/loading.gif" alt></p><h3 id="Attacking-Word-level-DNN"><a href="#Attacking-Word-level-DNN" class="headerlink" title="Attacking Word-level DNN"></a>Attacking Word-level DNN</h3><p>单词级模型也是同理，不仅如此，甚至省了hot-character这一步。下面是几个例子。</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure9.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure10.png" srcset="/img/loading.gif" alt></p><h2 id="4-黑盒攻击"><a href="#4-黑盒攻击" class="headerlink" title="4. 黑盒攻击"></a>4. 黑盒攻击</h2><p>黑盒攻击显然不能通过比较Cost Gradient的方式确定HTP和HSP了。但是我们可以采用其他方法确定HTP和HSP。</p><p>具体地，我们通过生成一些测试样本来探测目标模型，判断哪些是Hot Phrases。</p><p>生成方法：</p><ul><li>用若干空格逐个代替单词（空格个数与单词长度相同）</li><li>将测试样本的分类结果与种子进行比较</li><li>偏差越大，相应单词对正确分类的重要性就越大</li><li>带来最大偏差的单词被标识为种子样本的HSP</li></ul><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure11.png" srcset="/img/loading.gif" alt></p><p>下面是黑盒攻击确定的HTP之后进行攻击的例子：</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure12.png" srcset="/img/loading.gif" alt></p><h2 id="5-Evaluation"><a href="#5-Evaluation" class="headerlink" title="5. Evaluation"></a>5. Evaluation</h2><h3 id="Q1-Can-our-method-perform-effective-source-target-misclassification-attack"><a href="#Q1-Can-our-method-perform-effective-source-target-misclassification-attack" class="headerlink" title="Q1: Can our method perform effective source/target misclassification attack?"></a>Q1: Can our method perform effective source/target misclassification attack?</h3><p>这个问题是问本方法能不能对模型实行定向的攻击，即“指哪打哪”，无论哪个类别的样本都能通过适当修改，突变成指定类别。</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Fig13.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Fig14.png" srcset="/img/loading.gif" alt></p><p>通过上表可知，source栏是源类别。target栏是目标类别，No栏是样本编号。本来都是类别source中定义的样本，经过右边三栏的突变方法，最终都以较高置信度被模型分类成了target栏中的类别。可以证明此方法确实能实现定向突变、定向攻击。</p><h3 id="Q2-Can-the-adversarial-samples-avoid-being-distinguished-by-human-observers-and-still-keep-the-utility"><a href="#Q2-Can-the-adversarial-samples-avoid-being-distinguished-by-human-observers-and-still-keep-the-utility" class="headerlink" title="Q2: Can the adversarial samples avoid being distinguished by human observers and still keep the utility?"></a>Q2: Can the adversarial samples avoid being distinguished by human observers and still keep the utility?</h3><p>这个问题是问对抗样本是不是能够避免被人类识别。毕竟文本突变还是很容易被人类识别的。</p><p>本论文是这么设计实验的：</p><ul><li>找23名学生，每个人都提供了20个文本样本，其中一半带有扰动，对每个样本进行手动分类</li><li>如果他们认为样品是人为修改的，则要求他们查明修改的位置</li><li>原样本准确率：94.2%</li><li>扰动样本准确率：94.8%</li><li>总共生成594个变化，有240个被受试者标记为已修改的位置，其中12个正确。准确率为12/240 = 5.0％，召回率为12/594 = 2.0％</li></ul><p>可以看到虽然样本数比较小，但是结果还是很显著的，在那23个同学都比较靠谱的前提下，该算法还是能够保证生成的文本与原文本差距不大的。</p><h3 id="Q3-Is-our-method-efficient-enough"><a href="#Q3-Is-our-method-efficient-enough" class="headerlink" title="Q3: Is our method efficient enough?"></a>Q3: Is our method efficient enough?</h3><p>算法效率其实不是很重要，毕竟在实践中，攻击者往往愿意花费更多时间来制作理想的对抗性样本。</p><p>白盒攻击（计算梯度、确定HTP），总共116小时，平均每类8.29小时；<br>黑盒攻击（生成样本、确定HTP），总共107小时，平均每类7.63小时。</p><h3 id="Q4-White-box-and-black-box-which-is-more-powerful"><a href="#Q4-White-box-and-black-box-which-is-more-powerful" class="headerlink" title="Q4: White-box and black-box, which is more powerful?"></a>Q4: White-box and black-box, which is more powerful?</h3><p>两种方式都有效并且彼此互补。</p><p>下图分别是黑盒和白盒生成的HTP比较，可以看到都是比较类似的。</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Fig15.png" srcset="/img/loading.gif" alt></p><h2 id="6-读后感"><a href="#6-读后感" class="headerlink" title="6. 读后感"></a>6. 读后感</h2><p>其实本篇文章的思想并不复杂，核心是确定一段文本的HTP和HSP。所谓HTP可以认为是，模型一看到这种词就相信这句话是该类别的了。那如果把类别1的句子x中的HSP给替换成类别2的HTP，的确可能让模型以为句子x是类别2的句子了。</p><p>所以延伸出来一个方向，那就是确定HSP和HTP的方法上。对于白盒攻击，还是查看内部的信息，然后计算梯度，这是一种比较传统的方法。对于黑盒攻击，则是遍历所有可能删除的单词，从结果上来看，比较这些删除单词的重要程度。</p><p>所以说有没有其他方法能够衡量单词的重要程度？这是一个值得研究的方向。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;国内人民大学的一篇论文，被IJCAI-2018接收。主要研究文本领域的对抗样本生成，被测模型是文本分类领域的模型。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="DNN" scheme="https://superlova.github.io/tags/DNN/"/>
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
  </entry>
  
  <entry>
    <title>【学习笔记】机器学习中处理文本数据的常用方法</title>
    <link href="https://superlova.github.io/2020/06/09/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%A4%84%E7%90%86%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/06/09/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%A4%84%E7%90%86%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2020-06-09T14:52:34.000Z</published>
    <updated>2020-07-21T14:29:46.670Z</updated>
    
    <content type="html"><![CDATA[<p>总结词袋模型、Tf-idf等文本特征提取方法<br><a id="more"></a></p><h2 id="一、词袋模型"><a href="#一、词袋模型" class="headerlink" title="一、词袋模型"></a>一、词袋模型</h2><p>文本数据通常被表示为由字符组成的字符串。我们需要先处理数据，然后才能对其应用机器学习算法。</p><p>在文本分析的语境中，数据集通常被称为语料库（corpus），每个由单个文本表示的数据点被称为文档（document）。</p><p>最简单的处理方法，是<strong>只计算语料库中每个单词在每个文本中的出现频次</strong>。这种文本处理模型称之为<strong>词袋模型</strong>。</p><p>不考虑词语出现的顺序，每个出现过的词汇单独作为一列特征，这些不重复的特征词汇集合为词表。</p><p>每一个文本都可以在很长的词表上统计出一个很多列的特征向量。如果每个文本都出现的词汇，一般被标记为<strong>停用词</strong>不计入特征向量。</p><p>为了搞清楚词袋模型，也就是<code>CountVectorizer</code>到底做了什么，我们执行以下代码：</p><pre><code class="lang-python">bards_words =[&quot;The fool doth think he is wise,&quot;,    &quot;but the wise man knows himself to be a fool&quot;]</code></pre><p>我们导入 CountVectorizer 并将其实例化，然后对 bards_words 进行拟合，如下所示：</p><pre><code class="lang-python">from sklearn.feature_extraction.text import CountVectorizervect = CountVectorizer()vect.fit(bards_words)</code></pre><p>拟合 CountVectorizer 包括训练数据的分词与词表的构建，我们可以通过 vocabulary_ 属性来访问词表：</p><pre><code class="lang-python">print(&quot;Vocabulary size: {}&quot;.format(len(vect.vocabulary_)))print(&quot;Vocabulary content:\n {}&quot;.format(vect.vocabulary_))#------------------#Vocabulary size: 13Vocabulary content:{&#39;the&#39;: 9, &#39;himself&#39;: 5, &#39;wise&#39;: 12, &#39;he&#39;: 4, &#39;doth&#39;: 2, &#39;to&#39;: 11, &#39;knows&#39;: 7,&#39;man&#39;: 8, &#39;fool&#39;: 3, &#39;is&#39;: 6, &#39;be&#39;: 0,  &#39;think&#39;: 10, &#39;but&#39;: 1}</code></pre><p>词表共包含 13 个词，从 “be” 到 “wise”。<br>我们可以调用 transform 方法来创建训练数据的词袋表示：</p><pre><code class="lang-python">bag_of_words = vect.transform(bards_words)print(&quot;bag_of_words: {}&quot;.format(repr(bag_of_words)))#--------------------#bag_of_words: &lt;2x13 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;with 16 stored elements in Compressed Sparse Row format&gt;</code></pre><p>词袋表示保存在一个 SciPy 稀疏矩阵中，这种数据格式只保存非零元素。这个矩阵的形状为 2×13，每行对应于两个数据点之一，每个特征对应于词表中的一个单词。要想查看稀疏矩阵的实际内容，可以使用 toarray 方法将其转换为“密集的”NumPy 数组（保存所有 0 元素）：</p><pre><code class="lang-python">print(&quot;Dense representation of bag_of_words:\n{}&quot;.format(    bag_of_words.toarray()))#---------------------#Dense representation of bag_of_words:[[0 0 1 1 1 0 1 0 0 1 1 0 1][1 1 0 1 0 1 0 1 1 1 0 1 1]]</code></pre><p>删除没有信息量的单词，除了使用<code>min_df</code>参数设定词例至少需要在多少个文档中出现过之外，还可以通过添加停用词的方法。</p><h2 id="二、用tf-idf缩放数据"><a href="#二、用tf-idf缩放数据" class="headerlink" title="二、用tf-idf缩放数据"></a>二、用tf-idf缩放数据</h2><p>词频 - 逆向文档频率（term frequency–inverse document frequency，tf-idf）方法，对在某个特定文档中经常出现的术语给予很高的权重，但对在语料库的许多文档中都经常出现的术语给予的权重却不高。</p><p>scikit-learn 在两个类中实现了 tf-idf 方法：TfidfTransformer 和 TfidfVectorizer，前者接受 CountVectorizer 生成的稀疏矩阵并将其变换，后者接受文本数据并完成词袋特征提取与 tf-idf 变换。</p><p>单词w在文档d中的tf-idf分数为：</p><p><img src="/2020/06/09/【学习笔记】机器学习中处理文本数据的常用方法/2020-06-09-23-20-54.png" srcset="/img/loading.gif" alt></p><p>式中，tf为词频，Term Frequency, 表示一个词在一个文档中的出现频率。该频率最后要除以该文档的长度，用以归一化。</p><p>式中，$N$为总文档数，$N_w$为带有单词$w$的文档数。由于分子比分母大，所以该 $\log$ 值必不可能小于零。</p><pre><code class="lang-python">from sklearn.feature_extraction.text import TfidfVectorizercorpus=[&quot;I come to China to travel&quot;,&quot;This is a car polupar in China&quot;,&quot;I love tea and Apple &quot;,&quot;The work is to write some papers in science&quot;]tfidf = TfidfVectorizer()vector = tfidf.fit_transform(corpus)print(vector)#---------------#(0, 16)    0.4424621378947393(0, 3)    0.348842231691988(0, 15)    0.697684463383976(0, 4)    0.4424621378947393(1, 5)    0.3574550433419527(1, 9)    0.45338639737285463(1, 2)    0.45338639737285463(1, 6)    0.3574550433419527(1, 14)    0.45338639737285463(1, 3)    0.3574550433419527(2, 1)    0.5(2, 0)    0.5(2, 12)    0.5(2, 7)    0.5(3, 10)    0.3565798233381452(3, 8)    0.3565798233381452(3, 11)    0.3565798233381452(3, 18)    0.3565798233381452(3, 17)    0.3565798233381452(3, 13)    0.3565798233381452(3, 5)    0.2811316284405006(3, 6)    0.2811316284405006(3, 15)    0.2811316284405006</code></pre><p>返回值什么意思呢？(0, 16)代表第0个文档，第一个单词在单词表（词袋）中的位置是第16个，该单词的tf-idf值为0.44246213；第二个单词在词袋中第3个位置……</p><p>显然这是个经过压缩的系数矩阵，每一行的元组表明该元素在稀疏矩阵中的位置，其值为右边的tf-idf值，代表一个单词。可以通过<code>.toarray()</code>方法令其恢复到系数矩阵状态。</p><pre><code class="lang-python">print(vector.toarray().shape)print(len(vector.toarray()))print(type(vector.toarray()))print(vector.toarray())#-----------------------------#(4, 19)4&lt;class &#39;numpy.ndarray&#39;&gt;[[0. 0. 0. 0.34884223 0.44246214 0.  0. 0. 0. 0. 0. 0.  0. 0. 0. 0.69768446 0.44246214 0.  0. ] [0. 0. 0.4533864  0.35745504 0. 0.35745504  0.35745504 0. 0. 0.4533864  0. 0.  0. 0. 0.4533864  0. 0. 0.  0. ] [0.5 0.5 0. 0. 0. 0.  0. 0.5 0. 0. 0. 0.  0.5 0. 0. 0. 0. 0.  0. ] [0. 0. 0. 0. 0. 0.28113163  0.28113163 0. 0.35657982 0. 0.35657982 0.35657982  0. 0.35657982 0. 0.28113163 0. 0.35657982  0.35657982]]</code></pre><h2 id="三、多元词袋"><a href="#三、多元词袋" class="headerlink" title="三、多元词袋"></a>三、多元词袋</h2><p>词袋模型将一段文档拆分成单词后，忽略了单词的上下文可能对文档的含义造成影响。</p><h2 id="四、英语的词干提取与词形还原"><a href="#四、英语的词干提取与词形还原" class="headerlink" title="四、英语的词干提取与词形还原"></a>四、英语的词干提取与词形还原</h2><h2 id="五、中文的分词"><a href="#五、中文的分词" class="headerlink" title="五、中文的分词"></a>五、中文的分词</h2><h2 id="六、主题建模与文档聚类"><a href="#六、主题建模与文档聚类" class="headerlink" title="六、主题建模与文档聚类"></a>六、主题建模与文档聚类</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结词袋模型、Tf-idf等文本特征提取方法&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Machine Learning" scheme="https://superlova.github.io/tags/Machine-Learning/"/>
    
      <category term="IMDb" scheme="https://superlova.github.io/tags/IMDb/"/>
    
  </entry>
  
  <entry>
    <title>【经验分享】IMDb数据集的预处理</title>
    <link href="https://superlova.github.io/2020/06/09/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91IMDb%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <id>https://superlova.github.io/2020/06/09/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91IMDb%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86/</id>
    <published>2020-06-09T14:48:03.000Z</published>
    <updated>2020-06-10T07:01:36.220Z</updated>
    
    <content type="html"><![CDATA[<p>IMDb从官网下载与从keras直接调用的处理方法是不同的。<br><a id="more"></a></p><h2 id="一、IMDb数据集的处理方法"><a href="#一、IMDb数据集的处理方法" class="headerlink" title="一、IMDb数据集的处理方法"></a>一、IMDb数据集的处理方法</h2><h3 id="1-官网下载法"><a href="#1-官网下载法" class="headerlink" title="1. 官网下载法"></a>1. 官网下载法</h3><pre><code class="lang-python">import pandas as pdimport numpy as npfrom sklearn.datasets import load_files</code></pre><pre><code class="lang-shell">!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz!tar -zxvf aclImdb_v1.tar.gz!ls</code></pre><p>对于 v1.0 版数据，其训练集大小是 75 000，而不是 25 000，因为其中还包含 50 000 个用于无监督学习的无标签文档。</p><p>在进行后续操作之前，建议先将这 50 000 个无标签文档从训练集中剔除。</p><pre><code class="lang-bash">!mkdir aclImdb/train_unlabel!mv aclImdb/train/unsupBow.feat aclImdb/train_unlabel!mv aclImdb/train/urls_unsup.txt aclImdb/train_unlabel!mv aclImdb/train/unsup aclImdb/train_unlabel</code></pre><pre><code class="lang-python">reviews_train = load_files(&quot;aclImdb/train/&quot;)text_train, y_train = reviews_train.data, reviews_train.targetreviews_test = load_files(&quot;aclImdb/test/&quot;)text_test, y_test = reviews_test.data, reviews_test.target# 删掉HTML换行符text_train = [doc.replace(b&quot;&lt;br /&gt;&quot;, b&quot; &quot;) for doc in text_train]text_test = [doc.replace(b&quot;&lt;br /&gt;&quot;, b&quot; &quot;) for doc in text_test]print(&quot;type of text_train: {}&quot;.format(type(text_train))) # 查看训练集类型：listprint(&quot;length of text_train: {}&quot;.format(len(text_train))) # 查看训练集大小print(&quot;text_train[1]:\n{}&quot;.format(text_train[1])) # 查看第二段文本print(&quot;Samples per class (training): {}&quot;.format(np.bincount(y_train))) # 查看数据集是否均等#------------------------------------------------#type of text_train: &lt;class &#39;list&#39;&gt;length of text_train: 25000text_train[1]:b&#39;Words can\&#39;t describe how bad this movie is. I can\&#39;t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\xc3\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\&#39;t list them here, but just mention the coloring of the plane. They didn\&#39;t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\&#39; side all the time in the movie, because the good guys were so stupid. &quot;Executive Decision&quot; should without a doubt be you\&#39;re choice over this one, even the &quot;Turbulence&quot;-movies are better. In fact, every other movie in the world is better than this one.&#39;Samples per class (training): [12500 12500]</code></pre><p>采用词袋模型整理数据</p><pre><code class="lang-python">vect = CountVectorizer().fit(text_train)X_train = vect.transform(text_train)print(&quot;X_train:\n{}&quot;.format(repr(X_train)))#---------------------------#X_train:&lt;25000x74849 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;with 3431196 stored elements in Compressed Sparse Row format&gt;</code></pre><p>X_train 是训练数据的词袋表示，其形状为 25 000×74 849，这表示词表中包含 74 849 个元素。数据被保存为 SciPy 稀疏矩阵。</p><p>访问词表的另一种方法是使用向量器（vectorizer）的 get_feature_name 方法，它将返回一个列表，每个元素对应于一个特征：</p><p>feature_names = vect.get_feature_names()<br>print(“Number of features: {}”.format(len(feature_names)))<br>print(“First 20 features:\n{}”.format(feature_names[:20]))<br>print(“Features 20010 to 20030:\n{}”.format(feature_names[20010:20030]))<br>print(“Every 2000th feature:\n{}”.format(feature_names[::2000]))</p><p>Number of features: 74849<br>First 20 features:<br>[‘00’, ‘000’, ‘0000000000001’, ‘00001’, ‘00015’, ‘000s’, ‘001’, ‘003830’,<br>‘006’, ‘007’, ‘0079’, ‘0080’, ‘0083’, ‘0093638’, ‘00am’, ‘00pm’, ‘00s’,’01’, ‘01pm’, ‘02’]<br>Features 20010 to 20030:<br>[‘dratted’, ‘draub’, ‘draught’, ‘draughts’, ‘draughtswoman’, ‘draw’, ‘drawback’,<br>‘drawbacks’, ‘drawer’, ‘drawers’, ‘drawing’, ‘drawings’, ‘drawl’,<br>‘drawled’, ‘drawling’, ‘drawn’, ‘draws’, ‘draza’, ‘dre’, ‘drea’]<br>Every 2000th feature:<br>[‘00’, ‘aesir’, ‘aquarian’, ‘barking’, ‘blustering’, ‘beête’, ‘chicanery’,<br>‘condensing’, ‘cunning’, ‘detox’, ‘draper’, ‘enshrined’, ‘favorit’, ‘freezer’,<br>‘goldman’, ‘hasan’, ‘huitieme’, ‘intelligible’, ‘kantrowitz’, ‘lawful’,<br>‘maars’, ‘megalunged’, ‘mostey’, ‘norrland’, ‘padilla’, ‘pincher’,<br>‘promisingly’, ‘receptionist’, ‘rivals’, ‘schnaas’, ‘shunning’, ‘sparse’,<br>‘subset’, ‘temptations’, ‘treatises’, ‘unproven’, ‘walkman’, ‘xylophonist’]</p><p>词表的前 10 个元素都是数字。所有这些数字都出现在评论中的某处，因此被提取为单词。</p><h3 id="2-使用keras自带的IMDb数据集"><a href="#2-使用keras自带的IMDb数据集" class="headerlink" title="2. 使用keras自带的IMDb数据集"></a>2. 使用keras自带的IMDb数据集</h3><pre><code class="lang-python">from tensorflow.keras.datasets import imdb(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000) # 仅保留训练数据中前10000个最经常出现的单词，低频单词被舍弃print(&#39;len of X_train: {}&#39;.format(len(X_train)))print(&#39;shape of X_train: {}&#39;.format(X_train.shape))print(&#39;first of X_train: {}&#39;.format(X_train[0]))print(&#39;training sample per class: {}&#39;.format(np.bincount(y_train)))#-------------------#len of X_train: 25000shape of X_train: (25000,)first of X_train: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]training sample per class: [12500 12500]</code></pre><p>可以看到keras已经把IMDb数据集给提前整理过了。此处每条数据都是一个向量，每个数值代表一个单词。数值的大小代表了该单词在单词表中的位置。显然，每条数据向量的长度不一定相同。</p><p>为了方便处理，我们可以规定每条文档的长度为maxlen</p><pre><code class="lang-python">from tensorflow.keras.preprocessing import sequenceprint(&#39;Pad sequences (samples x time)&#39;)x_train = sequence.pad_sequences(x_train, maxlen=maxlen)x_test = sequence.pad_sequences(x_test, maxlen=maxlen)print(&#39;x_train shape:&#39;, x_train.shape)print(&#39;x_test shape:&#39;, x_test.shape)#-------------------#Pad sequences (samples x time)x_train shape: (25000, 80)x_test shape: (25000, 80)</code></pre><p>训练集中一共25000条文档，其中12500个正类，12500个负类。每个文档都是由80个数字组成的向量。测试集亦然。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;IMDb从官网下载与从keras直接调用的处理方法是不同的。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="IMDb" scheme="https://superlova.github.io/tags/IMDb/"/>
    
      <category term="preprocessing" scheme="https://superlova.github.io/tags/preprocessing/"/>
    
  </entry>
  
  <entry>
    <title>【经验分享】停电了怎么办？Python获取Windows电源连接信息</title>
    <link href="https://superlova.github.io/2020/06/08/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91%E5%81%9C%E7%94%B5%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9FPython%E8%8E%B7%E5%8F%96Windows%E7%94%B5%E6%BA%90%E8%BF%9E%E6%8E%A5%E4%BF%A1%E6%81%AF/"/>
    <id>https://superlova.github.io/2020/06/08/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91%E5%81%9C%E7%94%B5%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9FPython%E8%8E%B7%E5%8F%96Windows%E7%94%B5%E6%BA%90%E8%BF%9E%E6%8E%A5%E4%BF%A1%E6%81%AF/</id>
    <published>2020-06-08T01:42:45.000Z</published>
    <updated>2020-06-08T02:15:04.116Z</updated>
    
    <content type="html"><![CDATA[<p>一旦停电，就令笔记本电脑发出响声、发送信息……。看似简单的功能，该如何利用Python实现呢？<br><a id="more"></a></p><p>采用笔记本电脑办公的好处是不必害怕突然停电。然而笔记本电脑不可能使用电池工作太久，此时必须尽快通知管理人员，恢复供电。</p><p>看似简单的功能，只需在Windows中注册一个HANDLE，负责接收电源适配器更改这一事件即可。但是本人没有Windows编程和系统编程的经验，只对Python熟悉。如何实现这一功能？</p><p>废话不多说，下面是代码。</p><pre><code class="lang-python">import win32conimport win32apiimport win32guiimport timefrom ctypes import POINTER, windll, Structure, cast, CFUNCTYPE, c_int, c_uint, c_void_p, c_boolfrom comtypes import GUIDfrom ctypes.wintypes import HANDLE, DWORDPBT_POWERSETTINGCHANGE = 0x8013GUID_CONSOLE_DISPLAY_STATE = &#39;{6FE69556-704A-47A0-8F24-C28D936FDA47}&#39;GUID_ACDC_POWER_SOURCE = &#39;{5D3E9A59-E9D5-4B00-A6BD-FF34FF516548}&#39;GUID_BATTERY_PERCENTAGE_REMAINING = &#39;{A7AD8041-B45A-4CAE-87A3-EECBB468A9E1}&#39;GUID_MONITOR_POWER_ON = &#39;{02731015-4510-4526-99E6-E5A17EBD1AEA}&#39;GUID_SYSTEM_AWAYMODE = &#39;{98A7F580-01F7-48AA-9C0F-44352C29E5C0}&#39;class POWERBROADCAST_SETTING(Structure):    _fields_ = [(&quot;PowerSetting&quot;, GUID),                (&quot;DataLength&quot;, DWORD),                (&quot;Data&quot;, DWORD)]def wndproc(hwnd, msg, wparam, lparam):    if msg == win32con.WM_POWERBROADCAST:        if wparam == win32con.PBT_APMPOWERSTATUSCHANGE:            print(&#39;Power status has changed&#39;)        if wparam == win32con.PBT_APMRESUMEAUTOMATIC:            print(&#39;System resume&#39;)        if wparam == win32con.PBT_APMRESUMESUSPEND:            print(&#39;System resume by user input&#39;)        if wparam == win32con.PBT_APMSUSPEND:            print(&#39;System suspend&#39;)        if wparam == PBT_POWERSETTINGCHANGE:            print(&#39;Power setting changed...&#39;)            settings = cast(lparam, POINTER(POWERBROADCAST_SETTING)).contents            power_setting = str(settings.PowerSetting)            data_length = settings.DataLength            data = settings.Data            if power_setting == GUID_CONSOLE_DISPLAY_STATE:                if data == 0: print(&#39;Display off&#39;)                if data == 1: print(&#39;Display on&#39;)                if data == 2: print(&#39;Display dimmed&#39;)            elif power_setting == GUID_ACDC_POWER_SOURCE:                if data == 0: print(&#39;AC power&#39;)                if data == 1:                    print(&#39;Battery power&#39;)                    #################################################                    playsound(&#39;alert.mp3&#39;) # 此处自定义你的操作                    #################################################                if data == 2: print(&#39;Short term power&#39;)            elif power_setting == GUID_BATTERY_PERCENTAGE_REMAINING:                print(&#39;battery remaining: %s&#39; % data)            elif power_setting == GUID_MONITOR_POWER_ON:                if data == 0: print(&#39;Monitor off&#39;)                if data == 1: print(&#39;Monitor on&#39;)            elif power_setting == GUID_SYSTEM_AWAYMODE:                if data == 0: print(&#39;Exiting away mode&#39;)                if data == 1: print(&#39;Entering away mode&#39;)            else:                print(&#39;unknown GUID&#39;)        return True    return Falseif __name__ == &quot;__main__&quot;:    print(&quot;*** STARTING ***&quot;)    hinst = win32api.GetModuleHandle(None)    wndclass = win32gui.WNDCLASS()    wndclass.hInstance = hinst    wndclass.lpszClassName = &quot;testWindowClass&quot;    CMPFUNC = CFUNCTYPE(c_bool, c_int, c_uint, c_uint, c_void_p)    wndproc_pointer = CMPFUNC(wndproc)    wndclass.lpfnWndProc = {win32con.WM_POWERBROADCAST : wndproc_pointer}    try:        myWindowClass = win32gui.RegisterClass(wndclass)        hwnd = win32gui.CreateWindowEx(win32con.WS_EX_LEFT,                                     myWindowClass,                                     &quot;testMsgWindow&quot;,                                     0,                                     0,                                     0,                                     win32con.CW_USEDEFAULT,                                     win32con.CW_USEDEFAULT,                                     0,                                     0,                                     hinst,                                     None)    except Exception as e:        print(&quot;Exception: %s&quot; % str(e))    if hwnd is None:        print(&quot;hwnd is none!&quot;)    else:        print(&quot;hwnd: %s&quot; % hwnd)    guids_info = {                    &#39;GUID_MONITOR_POWER_ON&#39; : GUID_MONITOR_POWER_ON,                    &#39;GUID_SYSTEM_AWAYMODE&#39; : GUID_SYSTEM_AWAYMODE,                    &#39;GUID_CONSOLE_DISPLAY_STATE&#39; : GUID_CONSOLE_DISPLAY_STATE,                    &#39;GUID_ACDC_POWER_SOURCE&#39; : GUID_ACDC_POWER_SOURCE,                    &#39;GUID_BATTERY_PERCENTAGE_REMAINING&#39; : GUID_BATTERY_PERCENTAGE_REMAINING                 }    for name, guid_info in guids_info.items():        result = windll.user32.RegisterPowerSettingNotification(HANDLE(hwnd), GUID(guid_info), DWORD(0))        print(&#39;registering&#39;, name)        print(&#39;result:&#39;, hex(result))        print(&#39;lastError:&#39;, win32api.GetLastError())        print()    print(&#39;\nEntering loop&#39;)    while True:        win32gui.PumpWaitingMessages()        time.sleep(1)</code></pre><p>COM: The Component Object Model 组件对象模型，是微软的一套软件组件的二进制接口标准。COM使得跨编程语言的进程间通信、动态对象创建成为可能。</p><p>COM实质上是一种语言无关的对象实现方式，这使其可以在创建环境不同的场合、甚至跨计算机的分布环境下被复用。COM允许复用这些对象，而不必知道对象内部是如何实现，因为组件实现者必须提供良好定义的接口从而屏蔽实现细节。通过引用计数，组件对象自己负责动态创建与销毁，从而屏蔽了不同编程语言之间的内存分配语义差异。</p><p>对于某些应用程序来说，COM已经部分被.NET框架取代。.NET Framework是新一代的Microsoft Windows应用程序开发平台。</p><p>COM是基于组件对象方式概念来设计的，在基础中，至少要让每个组件都可以支持二个功能：</p><p>查询组件中有哪些接口<br>让组件做自我生命管理，此概念的实践即为引用计数（Reference Counting）</p><p>GUID 是一个 128 位整数（16 字节），COM将其用于计算机和网络的唯一标识符。全局唯一标识符（英语：Globally Unique Identifier，缩写：GUID；发音为/ˈɡuːɪd/或/ˈɡwɪd/）是一种由算法生成的唯一标识，通常表示成32个16进制数字（0－9，A－F）组成的字符串，如：{21EC2020-3AEA-1069-A2DD-08002B30309D}，它实质上是一个128位长的二进制整数。</p><p>Windows操作系统使用GUID来标识COM对象中的类和界面。一个脚本可以不需知道DLL的位置和名字直接通过GUID来激活其中的类或对象。</p><p>参考：<a href="https://stackoverflow.com/questions/48720924/python-3-detect-monitor-power-state-in-windows" target="_blank" rel="noopener">https://stackoverflow.com/questions/48720924/python-3-detect-monitor-power-state-in-windows</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一旦停电，就令笔记本电脑发出响声、发送信息……。看似简单的功能，该如何利用Python实现呢？&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Windows" scheme="https://superlova.github.io/tags/Windows/"/>
    
      <category term="PowerOff" scheme="https://superlova.github.io/tags/PowerOff/"/>
    
  </entry>
  
  <entry>
    <title>【经验分享】TensorFlow模型训练和保存</title>
    <link href="https://superlova.github.io/2020/06/03/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91TensorFlow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E4%BF%9D%E5%AD%98/"/>
    <id>https://superlova.github.io/2020/06/03/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91TensorFlow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E4%BF%9D%E5%AD%98/</id>
    <published>2020-06-03T14:35:56.000Z</published>
    <updated>2020-06-03T14:40:27.579Z</updated>
    
    <content type="html"><![CDATA[<p>使用LSTM训练最简单的IMDB影评分类任务，总结文本分类任务常见流程。<br><a id="more"></a></p><h2 id="1-模型训练和保存"><a href="#1-模型训练和保存" class="headerlink" title="1. 模型训练和保存"></a>1. 模型训练和保存</h2><h3 id="1-1-训练结束时保存"><a href="#1-1-训练结束时保存" class="headerlink" title="1.1 训练结束时保存"></a>1.1 训练结束时保存</h3><p>训练模型，使用fit函数。fit函数的参数如下。</p><pre><code class="lang-python">fit(    x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,    validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,    sample_weight=None, initial_epoch=0, steps_per_epoch=None,    validation_steps=None, validation_batch_size=None, validation_freq=1,    max_queue_size=10, workers=1, use_multiprocessing=False)</code></pre><p>x：训练数据<br>y：训练标签<br>batch_size：批次大小，默认为32<br>validation_data：在每个epoch结束之时计算loss等其他模型性能指标，不用做训练。<br>epoch：训练轮次<br>verbose：输出的详细程度，为1则输出进度条，表明每个epoch训练完成度；为0则什么也不输出，为2则很啰嗦地输出所有信息</p><p>最后保存模型用<code>model.save(&#39;xxx.h5&#39;)</code>，这里模型格式为HDF5，因此结尾为h5。</p><pre><code class="lang-python">model.fit(X_train, y_train, validation_data=(X_test, y_test), epoch=10, batch_size=64) scores = model.evaluate(X_test, y_test, verbose=0)print(&quot;Accuracy: %.2f%%&quot; % (scores[1]*100))model.save(&#39;models/sentiment-lstm.h5&#39;)</code></pre><h3 id="1-2-在训练期间保存模型（以-checkpoints-形式保存）"><a href="#1-2-在训练期间保存模型（以-checkpoints-形式保存）" class="headerlink" title="1.2 在训练期间保存模型（以 checkpoints 形式保存）"></a>1.2 在训练期间保存模型（以 checkpoints 形式保存）</h3><p>您可以使用训练好的模型而无需从头开始重新训练，或在您打断的地方开始训练，以防止训练过程没有保存。<code>tf.keras.callbacks.ModelCheckpoint</code> 允许在训练的过程中和结束时回调保存的模型。</p><pre><code class="lang-python">checkpoint_path = &quot;training_1/cp.ckpt&quot;checkpoint_dir = os.path.dirname(checkpoint_path)# 创建一个保存模型权重的回调函数cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,                                                 save_weights_only=True,                                                 verbose=1)# 使用新的回调函数训练模型model.fit(train_images,           train_labels,            epochs=10,          validation_data=(test_images,test_labels),          callbacks=[cp_callback])  # 通过回调训练# 这可能会生成与保存优化程序状态相关的警告。# 这些警告（以及整个笔记本中的类似警告）是防止过时使用，可以忽略。</code></pre><p>这将创建一个 TensorFlow checkpoint 文件集合，这些文件在每个 epoch 结束时更新</p><pre><code>cp.ckpt.data-00001-of-00002cp.ckpt.data-00000-of-00002  cp.ckpt.index</code></pre><p>默认的 tensorflow 格式仅保存最近的5个 checkpoint 。</p><h3 id="1-3-手动保存权重"><a href="#1-3-手动保存权重" class="headerlink" title="1.3 手动保存权重"></a>1.3 手动保存权重</h3><p>不必等待epoch结束，通过执行<code>save_weights</code>就可以生成ckpt文件。</p><pre><code class="lang-python"># 保存权重model.save_weights(&#39;./checkpoints/my_checkpoint&#39;)</code></pre><h2 id="2-模型加载"><a href="#2-模型加载" class="headerlink" title="2. 模型加载"></a>2. 模型加载</h2><h3 id="2-1-从h5文件中恢复"><a href="#2-1-从h5文件中恢复" class="headerlink" title="2.1 从h5文件中恢复"></a>2.1 从h5文件中恢复</h3><pre><code class="lang-python"># 重新创建完全相同的模型model=load_model(&#39;models/sentiment-lstm.h5&#39;)# 加载后重新编译模型，否则您将失去优化器的状态model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) model.summary()</code></pre><p>加载模型的时候，损失函数等参数需要重新设置。</p><h3 id="2-2-从ckpt文件中断点续训"><a href="#2-2-从ckpt文件中断点续训" class="headerlink" title="2.2 从ckpt文件中断点续训"></a>2.2 从ckpt文件中断点续训</h3><p>仅恢复模型的权重时，必须具有与原始模型具有相同网络结构的模型。</p><pre><code class="lang-python"># 这个模型与ckpt保存的一样架构，只不过没经过fit训练model = create_model()# 加载权重model.load_weights(checkpoint_path)</code></pre><p>我们可以对回调函数增加一些新的设置，之前的回调函数每个epoch都覆盖掉之前的ckpt，现在我们想每过5个epoch保存一个新的断点：</p><pre><code class="lang-python"># 在文件名中包含 epoch (使用 `str.format`)checkpoint_path = &quot;training_2/cp-{epoch:04d}.ckpt&quot;checkpoint_dir = os.path.dirname(checkpoint_path)# 创建一个回调，每 5 个 epochs 保存模型的权重cp_callback = tf.keras.callbacks.ModelCheckpoint(    filepath=checkpoint_path,     verbose=1,     save_weights_only=True,    period=5)</code></pre><p>利用新的回调训练，并随后选择最新的断点文件：</p><pre><code class="lang-python"># 使用新的回调训练模型model.fit(train_images,               train_labels,              epochs=50,               callbacks=[cp_callback],              validation_data=(test_images,test_labels),              verbose=0)# 选择新的断点latest = tf.train.latest_checkpoint(checkpoint_dir)&gt;&gt;&gt; &#39;training_2/cp-0050.ckpt&#39;# 加载以前保存的权重model.load_weights(latest)</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用LSTM训练最简单的IMDB影评分类任务，总结文本分类任务常见流程。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="TensorFlow" scheme="https://superlova.github.io/tags/TensorFlow/"/>
    
      <category term="SaveModel" scheme="https://superlova.github.io/tags/SaveModel/"/>
    
  </entry>
  
  <entry>
    <title>【学习笔记】使用LSTM训练imdb情感分类模型</title>
    <link href="https://superlova.github.io/2020/06/03/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E4%BD%BF%E7%94%A8LSTM%E8%AE%AD%E7%BB%83imdb%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/"/>
    <id>https://superlova.github.io/2020/06/03/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E4%BD%BF%E7%94%A8LSTM%E8%AE%AD%E7%BB%83imdb%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-06-03T10:03:29.000Z</published>
    <updated>2020-06-03T14:41:37.751Z</updated>
    
    <content type="html"><![CDATA[<p>使用LSTM训练最简单的IMDB影评分类任务，总结文本分类任务常见流程。<br><a id="more"></a></p><h2 id="1-查看数据集"><a href="#1-查看数据集" class="headerlink" title="1. 查看数据集"></a>1. 查看数据集</h2><h3 id="1-1-官网上的数据集压缩包"><a href="#1-1-官网上的数据集压缩包" class="headerlink" title="1.1 官网上的数据集压缩包"></a>1.1 官网上的数据集压缩包</h3><p>从IMDB官网上下载的数据集，是一个压缩包<code>aclImdb_v1.tar.gz</code>。解压后的目录如下：<br><img src="/2020/06/03/【学习笔记】使用LSTM训练imdb情感分类模型/2020-06-03-18-12-58.png" srcset="/img/loading.gif" alt></p><ul><li><code>test</code></li><li><code>train</code></li><li><code>imdb.vocab</code></li><li><code>imdbEr.txt</code></li><li><code>README</code></li></ul><p>其内部不仅有完整的影评文件，还包含该影评的链接等信息。</p><h3 id="1-2-keras自带的数据集"><a href="#1-2-keras自带的数据集" class="headerlink" title="1.2 keras自带的数据集"></a>1.2 keras自带的数据集</h3><p>keras里的IMDB影评数据集，内部结构分为两个部分：影评部分和情感标签部分，也就是数据集的X和y部分。</p><p>X部分的每条影评都被编码为一个整数列表。另外，每个单词的在单词表中的编码越小，代表在影评中出现频率越高。这使得我们能在取数据时指定只使用某一出现频率内范围的单词（其他单词由于出现频率太低，可以直接标记为未知）。</p><p>“0”在数据集中代表“未知”单词。</p><p>我们采用内置的<code>load_data</code>函数来取出数据。</p><pre><code class="lang-python">tf.keras.datasets.imdb.load_data(    path=&#39;imdb.npz&#39;, num_words=None, skip_top=0, maxlen=None, seed=113,    start_char=1, oov_char=2, index_from=3, **kwargs)</code></pre><p>num_words: 即设定取出现频率在前num_words的单词。如果不填，所有单词表中的单词都会标记。<br>skip_top: 设定前skip_top频率出现的单词不予标记。这可能是由于高频出现的单词信息量太低（如the、a等）。<br>maxlen: 设定最大影评长度，超过该长度的影评都会被截断。<br>x_train, x_test: 返回影评列表，长度为影评个数（25000个训练，25000个测试），每个影评是整数数组。<br>y_train, y_test: 返回整数数组，长度为影评个数，代表影评的情感倾向（0或1）。</p><pre><code class="lang-python">from tensorflow.keras.datasets import imdbmax_features = 50000 # 取前50000个最常见的单词，组建词典(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)</code></pre><p>需要注意的是这个<code>max_features</code>与数据集的数目没有关系，不要搞混了。</p><h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h2><pre><code class="lang-python">from tensorflow.keras.preprocessing import sequenceprint(&#39;Pad sequences (samples x time)&#39;)x_train = sequence.pad_sequences(x_train, maxlen=maxlen)x_test = sequence.pad_sequences(x_test, maxlen=maxlen)X_trainarray([[    0,     0,     0, ...,    19,   178,    32],       [    0,     0,     0, ...,    16,   145,    95],       [    0,     0,     0, ...,     7,   129,   113],       ...,       [    0,     0,     0, ...,     4,  3586, 22459],       [    0,     0,     0, ...,    12,     9,    23],       [    0,     0,     0, ...,   204,   131,     9]], dtype=int32)</code></pre><p>经过这个函数处理，每条影评被规整成了长度为500的整形元素列表，长度不够500个单词的影评，在最前面加0；长度不够的则在最后截断。</p><h2 id="3-模型构建"><a href="#3-模型构建" class="headerlink" title="3. 模型构建"></a>3. 模型构建</h2><p><strong>Embedding层</strong></p><p>在最开始我们加入了Embedding层，max_features是字典长度，也可以说是one-hot向量长度。<br>input_length=500为每个序列为500个单词构成。<br>input_shape=(max_features,)表明one-hot的维度，这两个都可以不填，直接通过fit的时候推断出来</p><p><strong>LSTM层</strong></p><p>LSTM层的参数是output_dim，这个参数可以自定义，因为它不受之前影响，只表明输出的维度。</p><p>同时也是是门结构（forget门、update门、output门）的维度。之所以理解成维度，是因为LSTM中隐藏单元个数这个概念不好理解。其实该参数名称为<code>units</code>，官方说法就是“隐藏单元个数”。</p><p>LSTM层的输入是形如（samples，timesteps，input_dim）的3D张量；输出是形如（samples，timesteps，output_dim）的3D张量，或者返回形如（samples，output_dim）的2D张量。二者区别在于，若LSTM层中参数<code>return_sequences=True</code>，就返回带时间步的张量。</p><p>若我们有很多LSTM层，我们可以把很多LSTM层串在一起，为了方便LSTM层与层之间的信息传递，可以设置<code>return_sequences=True</code>。但是最后一个LSTM层return_sequences通常为false，此时输出的就是每个样本的结果张量。</p><p>假如我们输入有25000个句子，每个句子都由500个单词组成，而每个单词用64维的词向量表示。那么样本数目samples=25000，时间步timesteps=500（可以简单地理解timesteps就是输入序列的长度input_length），前一层Embedding词向量输出维度input_dim=128。</p><p>也就是说通过LSTM，把词的维度由128转变成了100。</p><p>在LSTM层中还可以设置Dropout，这一点在之后会详细说明。</p><p><strong>全连接层</strong></p><p>汇总至一个神经元的全连接层，即sigmoid层，判断0或1即可。</p><pre><code class="lang-python">from tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Embedding, LSTMmodel = Sequential() model.add(Embedding(max_features, 128, input_length=500, input_shape=(max_features,))) model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))model.add(Dense(1, activation=&#39;sigmoid&#39;)) model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) print(model.summary())</code></pre><h2 id="4-模型训练和保存"><a href="#4-模型训练和保存" class="headerlink" title="4. 模型训练和保存"></a>4. 模型训练和保存</h2><pre><code class="lang-python">model.fit(X_train, y_train, validation_data=(X_test, y_test), epoch=10, batch_size=64) scores = model.evaluate(X_test, y_test, verbose=0)print(&quot;Accuracy: %.2f%%&quot; % (scores[1]*100))model.save(&#39;models/sentiment-lstm.h5&#39;)</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用LSTM训练最简单的IMDB影评分类任务，总结文本分类任务常见流程。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="LSTM" scheme="https://superlova.github.io/tags/LSTM/"/>
    
      <category term="IMDB" scheme="https://superlova.github.io/tags/IMDB/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/</id>
    <published>2020-06-02T06:16:03.000Z</published>
    <updated>2020-07-21T11:11:57.828Z</updated>
    
    <content type="html"><![CDATA[<p>本文总结了常见的nlp领域的对抗样本生成及攻击方法。<br><a id="more"></a></p><p>翻译腔预警！长文预警！</p><h1 id="一、Introduction"><a href="#一、Introduction" class="headerlink" title="一、Introduction"></a>一、Introduction</h1><p>为代表的神经网络在最近几年取得了较大的成功。然而先前的研究表明，DNN等深度学习模型容易受到精心构建的对抗样本的攻击，这些攻击算法在原有样本基础上产生一些不可察觉的扰动，欺骗DNN给出错误的预测。</p><p>此类对抗样本攻击手段广泛应用于图像识别，图像分类任务等，但是此类攻击手段在自然语言处理nlp任务中表现不佳，究其原因是图像与文本之间的内在差异，使得图像识别任务中的攻击方法无法直接使用于nlp领域。</p><p>目前针对深度学习系统的对抗样本研究有以下三个角度：第一，通过给数据集添加无法被人类察觉的扰动来欺骗模型；第二，故意更改神经网络内部的输出值和权重；第三，检测深度神经网络的弱点，找到防御攻击的解决方案。</p><h2 id="为什么CV领域的攻击手段不能直接迁移到NLP领域？"><a href="#为什么CV领域的攻击手段不能直接迁移到NLP领域？" class="headerlink" title="为什么CV领域的攻击手段不能直接迁移到NLP领域？"></a>为什么CV领域的攻击手段不能直接迁移到NLP领域？</h2><p>由于图像和文本数据之间的内在差异，对图像的对抗攻击方法不能直接应用于后者。</p><p><strong>首先，图像数据（例如像素值）是数值特征，但是文本数据本质上是离散的特征。</strong></p><p>如果我们将文本数据采用文本向量化方法转化成数值向量，然后应用在图像攻击中常用的基于梯度的对抗攻击时，生成的对抗样本为无效字符或无意义的单词序列[157]。</p><p>如果我们采用词嵌入算法得到具有语义的词嵌入空间，但是如果采用基于梯度的对抗攻击，也会产生无法与词嵌入空间中的任何词匹配的向量[38]。</p><p><strong>其次，对文本的扰动很容易被察觉</strong></p><p>图像的扰动是人眼难以察觉的像素值的微小变化。人类可以正确地对扰动图像进行分类而模型不可以，这表明深度神经模型的鲁棒性较差。</p><p>但是对于文本的对抗性攻击，人类很容易察觉到很小的扰动。例如，替换字符或单词会生成无效的单词或语法错误的句子。</p><p>此外，它将大大改变句子的语义。在这种情况下，即使人类也无法提供“正确”的预测。</p><h2 id="其他类似的综述"><a href="#其他类似的综述" class="headerlink" title="其他类似的综述"></a>其他类似的综述</h2><ul><li>[9]针对不同类别的<strong>机器学习系统</strong>的攻击和防御进行了全面的综述</li><li>[35]从安全角度总结了对抗性攻击的防御措施。介绍对象不仅限于机器学习算法，而且包括其他安全相关应用的对抗样本防御措施，以及如何有效地<strong>评估攻击和防御手段</strong>，建立了根据动机、限制、性能的<strong>分类方法</strong>。</li><li>[13]全面的总结了从2008年到2018年的十年中，<strong>计算机视觉</strong>和<strong>网络安全</strong>方面的对抗性攻击研究的发展，提供了有关攻击和防御<strong>效果的详细分析</strong>。</li><li>[79]从数据驱动的角度研究对抗样本攻击和防御问题，<strong>根据学习阶段（即训练阶段和测试阶段）分析</strong>了攻击和防御手段。</li><li>[154]回顾了当前<strong>针对各种深度神经网络的攻击</strong>手段和研究成果</li><li>[2]对<strong>计算机视觉</strong>任务中使用的<strong>深度学习模型</strong>的对抗性攻击和<strong>防御手段</strong>进行了全面综述</li></ul><p>本文针对文本深度学习模型的攻击和防御进行全面的综述，涵盖了来自各个方面的信息。论文来源包括ACL，COLING，NAACL，EMNLP，ICLR，AAAI，IJCAI在内的顶级会议。论文指标：论文质量，方法新颖度，引文数量。</p><p>本文贡献：</p><ol><li>全面调研了迄今为止的文本领域的深度神经网络对抗样本生成算法，并使用不同的分类方案；</li><li>讨论了一些未解决的新颖的topic</li></ol><h1 id="二、Overview"><a href="#二、Overview" class="headerlink" title="二、Overview"></a>二、Overview</h1><h2 id="深度学习模型对抗性攻击的一般分类法"><a href="#深度学习模型对抗性攻击的一般分类法" class="headerlink" title="深度学习模型对抗性攻击的一般分类法"></a>深度学习模型对抗性攻击的一般分类法</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul><li>深度神经网络（Deep Neural Network, DNN）：略</li><li>扰动（Perturbation）：这里的扰动指自然或人为添加到测试集中的噪声，旨在使深度学习模型出错</li><li>对抗样本（Adversarial Examples）：对深度学习模型添加最坏扰动（worst-case perturbation）而生成的样本。在分类任务下，理想的DNN仍能将对抗样本分类为正确的类别，而目标DNN（victim）则以较高的置信程度误判样本的类别。</li></ul><p>假设$x$为原样本，$x’$为对抗样本，$\eta$为最坏情况的扰动，$f(x)$为深度学习模型，$y$为$x$的正确类别，$y’$为$x$的错误类别，则对抗样本形式化定义为：</p><script type="math/tex; mode=display">\begin{array}{c}\mathbf{x}^{\prime}=\mathbf{x}+\eta, f(\mathbf{x})=\mathbf{y}, \mathbf{x} \in \mathbf{X}, \\f\left(\mathbf{x}^{\prime}\right) \neq \mathbf{y} \\\text { or } f\left(\mathbf{x}^{\prime}\right)=\mathbf{y}^{\prime}, \mathbf{y}^{\prime} \neq \mathbf{y}\end{array}</script><ul><li>对抗攻击（或者说，对抗样本生成）的目标是$f(x’)\neq y$或者$f(x’)=y’$</li></ul><h3 id="分类标准-Threat-Model"><a href="#分类标准-Threat-Model" class="headerlink" title="分类标准 Threat Model"></a>分类标准 Threat Model</h3><p><span id="Threat_Model" style.display="none"></span></p><ul><li>根据模型信息利用程度，分为黑盒攻击和白盒攻击<ul><li>不必访问DNN的体系结构、参数、损失函数、激活函数和训练数据的攻击手段称为黑盒攻击，黑盒攻击通过测试集或检查DNN输出来生成对抗样本。</li><li>对应地，白盒攻击基于上述的DNN的结构细节信息。黑盒攻击需要的信息量更少，因此是一种更有吸引力的攻击手段；但是白盒攻击往往更有效。</li></ul></li><li>根据是否能够令模型误判为一个特定的错误结果，分为目标攻击和无目标攻击。显然指定目标的攻击手段更加严格。对于二分类任务，目标攻击即为非目标攻击。</li><li>根据攻击算法生成的扰动的粒度，可以分类攻击手段，比如针对图像像素的攻击，针对字符、单词、句嵌入的攻击等</li><li>根据产生对抗样本的动机，可以把对抗样本生成算法分成攻击方法和防御方法。攻击算法旨在检查DNN的鲁棒性，而防御算法则进一步利用生成的对抗样本增强DNN的鲁棒性。</li></ul><h3 id="衡量标准-Measurements"><a href="#衡量标准-Measurements" class="headerlink" title="衡量标准 Measurements"></a>衡量标准 Measurements</h3><ul><li><strong>扰动限制（Perturbation Constraint）</strong></li></ul><p>扰动$\eta$不应更改输入的真实类别标签。以分类任务为例，理想的DNN分类器将能够正确辨别对抗样本。$\eta$也不能太小，以免最终对目标DNN没有影响。</p><p>理想情况下，有效$\eta$是在受限范围内影响最大的噪声。</p><p>[132]添加图像领域的扰动限制$(\mathbf{x}+\eta) \in[0,1]^{n}$以确保对抗样本具有与原始数据相同的像素值范围</p><p>[40]用最大范数约束扰动：$|\eta|_{\infty} \leq \epsilon$。最大范数的含义是求向量中的最大分量。因此该限制保证任何特定像素的变化不会超过某个量$\epsilon$。</p><p>在计算机视觉领域，max-norm、$L_2$、$L_0$都可以用于控制扰动大小，而文本领域则有所不同，</p><ul><li><strong>攻击效果度量</strong></li></ul><p>攻击算法可以使得模型性能大幅下降，则衡量攻击算法可以直接使用模型度量指标。比如分类任务的精度、F1和AUC，文本生成任务的困惑度、BLEU评价指标等。</p><h2 id="深度学习技术在自然语言处理中的应用"><a href="#深度学习技术在自然语言处理中的应用" class="headerlink" title="深度学习技术在自然语言处理中的应用"></a>深度学习技术在自然语言处理中的应用</h2><p><span id="Models" style.display="none"> <span><br>前馈神经网络（FNN），卷积神经网络（CNN），循环神经网络（RNN）是NLP任务中最常使用的神经网络。</span></span></p><p>Seq2Seq[131]和Attention机制[8]是最新的NLP技术，强化学习（Reinforcement learning）和生成模型（generative models）也取得了不错的效果[152]。[100，152]讨论了NLP领域的神经网络应用状况。</p><h3 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h3><p>前馈神经网络（Feed Forward Networks）一般指完全由全连接层构成的网络。这种网络分成多个层，每一层有多个神经元，一层中的每个神经元都与下一层中的每个神经元相连接。这种网络无法记录元素顺序，不能处理文本序列。</p><h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><p>卷积神经网络（Convolutional Neural Networks）一般由卷积层、池化层和最后的全连接层构成。著名的卷积网络架构包括典型的LeNet、AlexNet、Vgg、GoogLeNet、ResNet、DenseNet等。卷积神经网络在计算机视觉领域取得了成功。</p><p>卷积层使用卷积运算来提取有意义的输入模式。另外卷积层也对输入顺序敏感，因此可以用来处理文本数据。[59]采用CNN对句子分类，[156]提出将CNN用于字符级别的文本分类方法。[12、29、30、34、76]则对上述CNN应用做了对抗样本评估。</p><h3 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h3><p>循环神经网络（Recurrent Neural Networks）通过在计算图中引入循环，能够编码时间顺序，在处理顺序数据方面具有令人印象深刻的性能。</p><p>递归神经网络（Recursive Neural Networks）将循环神经网络拓扑从顺序结构扩展到树结构；双向RNN则对输入采用从前向后和从后向前两个方面进行建模；长短期记忆（Long Short-Term Memory, LSTM）网络通过控制信息的三个门（即输入门，忘记门和输出门）的组合，实现长期记忆；GRU是LSTM的简化版本，它仅包含两个门，因此在计算成本方面更加高效。</p><p>各种LSTM变体：[21、50、112、133、141、146]。<br>对这些RNN模型的对抗攻击：[34、53、54、91、103、112、118、130、157]。</p><h3 id="序列到序列学习"><a href="#序列到序列学习" class="headerlink" title="序列到序列学习"></a>序列到序列学习</h3><p>序列到序列学习（Seq2Seq）[131]是深度学习的重要突破之一。Seq2Seq模型由两个RNN组成：一个处理输入并将其压缩为矢量表示的编码器（Encoder），以及一个预测输出的解码器（Decoder）。</p><p>隐变量分层循环编码器/解码器（VHRED）模型[122]是最近流行的Seq2Seq模型，该模型利用子序列之间的复杂依赖性生成序列。</p><p>[24]是采用Seq2Seq模型的第一个神经机器翻译（NMT）模型之一。OpenNMT [63]是最近提出的Seq2Seq NMT模型，已成为NMT的基准工作之一。</p><p>随着它们的广泛应用，攻击工作也应运而生[22，30，98，127]。</p><h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p>注意力机制（Attention）[8]是深度学习的另一个突破。最初开发它是为了克服编码Seq2Seq模型中所需的长序列的困难[27]。注意力机制使解码器可以回顾源序列的隐藏状态，将这些隐藏状态按照注意力加权平均，作为解码器的附加输入。</p><p>NLP中的自注意力[136]用来查看序列中的周围单词，以获得更多上下文相关的单词表示形式[152]，而不是查看原始注意力模型中的输入序列。</p><p>BiDAF [121]是一种用于机器理解的双向注意力流机制，并在提出时取得了出色的性能。</p><p>[54，127]通过对抗样本评估了该模型的鲁棒性，是率先使用对抗样本攻击文本DNN的几部作品。其他基于注意力的DNN [25，107]最近也受到了对抗攻击[29，91]。</p><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p>强化学习（Reinforcement Learning）通过在智能体执行离散操作后给予不同的奖励来训练智能体。在NLP中，强化学习框架通常由一个智能体（Agent，以DNN实现），一个策略（Policy，指导行动）和一个奖励（Reward）组成。智能体根据策略选择一个动作（例如，预测序列中的下一个单词），然后相应地更新其内部状态，直到到达计算奖励的序列末尾为止。</p><p>到目前为止，在NLP中攻击强化学习模型的工作有限，比如[98]。</p><h3 id="深度生成模型"><a href="#深度生成模型" class="headerlink" title="深度生成模型"></a>深度生成模型</h3><p>深度生成模型（Deep Generative Models）能够生成与隐空间（Latent Space）中的真实数据（Ground Truth）非常相似的真实数据实例，比如用于生成文本。但是深度生成模型不容易训练和评估，这阻碍了它们在许多实际应用中的广泛使用[152]。</p><p>近年来，提出了两个强大的深度生成模型，即生成对抗网络（GAN）[39]和变分自动编码器（VAE）[62]。</p><p>GAN [39]由两个对抗网络组成：生成器和鉴别器。鉴别器将鉴别真实样本和生成的样本，而生成器将生成旨在欺骗鉴别器的真实样本。GAN使用最小-最大损失函数来同时训练两个神经网络。</p><p>VAE由编码器（Encoder）和生成器（Generator）网络组成。编码器将输入编码到隐空间中，生成器从隐空间中生成样本。</p><p>尽管它们已被用于生成文本，但到目前为止，尚无任何作品使用对抗样本来检验其健壮性。</p><h1 id="三、FROM-IMAGE-TO-TEXT"><a href="#三、FROM-IMAGE-TO-TEXT" class="headerlink" title="三、FROM IMAGE TO TEXT"></a>三、FROM IMAGE TO TEXT</h1><h2 id="计算机视觉领域的对抗攻击技术"><a href="#计算机视觉领域的对抗攻击技术" class="headerlink" title="计算机视觉领域的对抗攻击技术"></a>计算机视觉领域的对抗攻击技术</h2><p>有关计算机视觉中的攻击工作的全面概述，请参阅参考文献[2]。另外，[17、40、95、104、105、132、157]是计算机视觉中颇有代表性的对抗攻击算法。</p><h3 id="L-BFGS"><a href="#L-BFGS" class="headerlink" title="L-BFGS"></a>L-BFGS</h3><p>Szegedy等人率先提出了对抗样本的概念[132]。他将生成对抗样本的过程建模成最优化问题：</p><script type="math/tex; mode=display">\eta=\arg \min _{\eta} \lambda\|\eta\|_{2}^{2}+J\left(\mathbf{x}+\eta, y^{\prime}\right) \quad \text { s.t. } \quad(\mathbf{x}+\eta) \in[0,1]^{n}</script><p>其中$\eta$是扰动，$\lambda$是超参数，$\mathbf{x}$是输入样例，$y$和$y’$分别是正确标签和错误标签，$J(x,y)$是DNN的损失函数。他们采用Box-constrained Limited memory Broyden-Fletcher-Goldfarb-Shanno算法优化求解，因此得名L-BFGS算法。整个优化过程可能迭代多次。</p><h3 id="Fast-Gradient-Sign-Method-FGSM"><a href="#Fast-Gradient-Sign-Method-FGSM" class="headerlink" title="Fast Gradient Sign Method (FGSM)"></a>Fast Gradient Sign Method (FGSM)</h3><p><span style.display="none" id="FGSM"></span><br>L-BFGS计算扰动的方法的计算代价过高，因此Goodfellow[40]提出了一个简化版本。与L-BFGS算法的先固定$y’$、确定最有效的$\eta$的方法不同，FGSM算法先固定$|\eta|_{\infty}$，然后最小化损失函数$J$。然后用一阶泰勒级数逼近，并得到$\eta$的闭式解[143]：</p><script type="math/tex; mode=display">\begin{array}{c}\eta=\arg \min _{\eta} J(\mathbf{x}+\eta, y) \text { s.t. }\|\eta\|_{\infty} \leq \epsilon \\\eta=\arg \min _{\eta} J(\mathbf{x}, y)+\eta^{\mathrm{T}} \nabla_{\mathbf{x}} J(\mathbf{x}, y) \text { s.t. }\|\eta\|_{\infty} \leq \epsilon \\\eta=\epsilon \cdot \operatorname{sign}\left(\nabla_{\mathbf{x}} J(\mathbf{x}, \mathbf{y})\right)\end{array}</script><p>其中$\epsilon$是攻击者设置的参数，用于控制扰动的大小。$sign(x)$是一个符号函数，当$x&gt; 0$时返回1，当$x &lt;0$时返回-1，否则返回0。$\nabla_{x}J(x,y)$表示损失函数相对于输入的梯度，可以通过反向传播计算出来。</p><h3 id="Jacobian-Saliency-Map-Adversary-JSMA"><a href="#Jacobian-Saliency-Map-Adversary-JSMA" class="headerlink" title="Jacobian Saliency Map Adversary (JSMA)"></a>Jacobian Saliency Map Adversary (JSMA)</h3><p><span style.display="none" id="JSMA"></span><br>JSMA使用其雅可比矩阵（Jacobian Matrix）评估神经模型对每个输入特征对输出的灵敏度。雅可比矩阵形成对抗显着性图（adversarial saliency maps），给每个输入特征对目标攻击的贡献进行排名，然后在对抗显着性图中选择一个特征做扰动。</p><p>给定输入$\mathbf{x}$，对应的雅可比矩阵为：</p><script type="math/tex; mode=display">\operatorname{Jacb}_{F}[i, j]=\frac{\partial F_{i}}{\partial \mathbf{x}_{j}}</script><p>其中$\mathbf{x}_i$是输入的第i个特征（component），$F_j$是输出的第j个特征。F的分量代表着logit值，$J_F[i,j]$度量了$F_j$对$\mathbf{x}_i$的敏感程度（sensitivity）。</p><h3 id="C-amp-W-Attack"><a href="#C-amp-W-Attack" class="headerlink" title="C&amp;W Attack"></a>C&amp;W Attack</h3><p><span style.display="none" id="C_W"></span><br>Carlini and Wagner [17]旨在评估防御性蒸馏策略[49]，以缓解对抗性攻击。C&amp;W算法的优化目标：</p><script type="math/tex; mode=display">\eta=\arg \min _{\eta}\|\eta\|_{p}+\lambda J\left(\mathbf{x}+\eta, y^{\prime}\right) \quad \text { s.t. } \quad(\mathbf{x}+\eta) \in[0,1]^{n}</script><p>C&amp;W算法使用$L_p$范数来限制扰动，其中$p=0,2,\infty$，并提出了7种不同的损失函数$J$。</p><h3 id="DeepFool"><a href="#DeepFool" class="headerlink" title="DeepFool"></a>DeepFool</h3><p>DeepFool [95]是一个迭代的L2正则化算法。</p><p>作者首先假设神经网络是线性的，因此可以使用超平面将不同类分开。</p><p>作者基于此假设找到了最佳解决方案，并构建了对抗样本。</p><p>为了解决神经网络的非线性问题，他们重复了这一过程，直到找到一个真实的对抗示例。</p><h3 id="Substitute-Attack"><a href="#Substitute-Attack" class="headerlink" title="Substitute Attack"></a>Substitute Attack</h3><p>上述代表性作品都是白盒方法，需要对神经模型的参数和结构有全面的了解。实际上，由于对模型的访问受限，攻击者并非总是能够以白盒方式制造对抗样本。</p><p>Papernot等人解决了该限制，[104]引入了黑盒攻击策略。</p><p>他们<strong>训练了一个替代模型</strong>，以通过查询目标模型获得的标签来近似目标模型的决策边界。然后，他们对该替代品进行了白盒攻击，并据此生成了对抗样本。</p><p>具体来说，他们在生成替代DNN的对抗示例时<strong>采用了FSGM和JSMA</strong>。</p><h3 id="GAN-like-Attack"><a href="#GAN-like-Attack" class="headerlink" title="GAN-like Attack"></a>GAN-like Attack</h3><p>另一种黑盒攻击方法利用了生成对抗网络（GAN）。</p><p>Zhao等人[157]首先在训练集X上训练了生成模型WGAN，WGAN可以生成与X遵循相同分布的数据。然后分别训练了一个逆变器（inverter），以通过最大程度地减少重构误差（reconstruction error），将数据样本x映射到隐密集空间（latent dense space）中。</p><p>他们不是在扰动$x$，而是先从$x$在隐空间中对应的变量$z$的邻近样本中搜索$z^<em>$，然后将$z^</em>$映射回$x^<em>$，并检查$x^</em>$是否会改变预测。</p><p>他们介绍了两种搜索算法：迭代随机搜索和混合收缩搜索（iterative stochastic search and hybrid shrinking search）。</p><p>前者使用扩大策略逐渐扩大搜索空间，而后者则使用缩小策略，从大范围开始并递归地缩小搜索范围的上限。</p><h2 id="图像攻击算法和文本攻击算法的对比"><a href="#图像攻击算法和文本攻击算法的对比" class="headerlink" title="图像攻击算法和文本攻击算法的对比"></a>图像攻击算法和文本攻击算法的对比</h2><h3 id="离散输入与连续输入"><a href="#离散输入与连续输入" class="headerlink" title="离散输入与连续输入"></a>离散输入与连续输入</h3><p>图像输入是连续的，通常该方法使用$L_p$范数来测量原始数据点与被扰动数据点之间的距离。</p><p>但是，文本数据是离散的。针对文本扰动的变量或距离测量方法难以构建。</p><p>也可以将文本数据映射到连续数据，然后采用计算机视觉的攻击方法。</p><h3 id="可感知与不可感知"><a href="#可感知与不可感知" class="headerlink" title="可感知与不可感知"></a>可感知与不可感知</h3><p>人们通常不容易察觉到图像像素的微小变化，因此，对抗样本不会改变人类的判断力，而只会使DNN模型蒙蔽。</p><p>但是，人类很容易察觉到文本上的小变化，例如字符或单词的变化，从而导致攻击失败。</p><p>可以在输入文本DNN模型之前通过拼写检查和语法检查来识别或纠正更改。</p><h3 id="语义与无语义"><a href="#语义与无语义" class="headerlink" title="语义与无语义"></a>语义与无语义</h3><p>就图像而言，微小的变化通常不会改变图像的语义（Semantic），因为它们是微不足道且不可感知的。</p><p>但是，对文本的干扰会轻易改变单词和句子的语义，因此很容易被检测到并严重影响模型的输出。</p><p>更改输入的语义违反了对抗攻击的目的，即在欺骗目标DNN时保持正确的标签不变。</p><h2 id="文本向量化方法"><a href="#文本向量化方法" class="headerlink" title="文本向量化方法"></a>文本向量化方法</h2><p>DNN模型需要向量作为输入，对于图像任务，通常的方法是使用像素值将向量/矩阵作为DNN输入。</p><p>但是对于文本模型，需要特殊操作才能将文本转换为矢量。</p><p>方法主要有三种：基于单词计数的编码，one-hot编码和密集编码（又称为特征嵌入），后两种主要用于文本应用程序的DNN模型中。</p><h3 id="基于单词计数的编码方法"><a href="#基于单词计数的编码方法" class="headerlink" title="基于单词计数的编码方法"></a>基于单词计数的编码方法</h3><p>词袋模型（Bag-of-Word, BOW），TF-IDF编码。</p><h3 id="One-Hot编码"><a href="#One-Hot编码" class="headerlink" title="One-Hot编码"></a>One-Hot编码</h3><p>略</p><h3 id="密集编码"><a href="#密集编码" class="headerlink" title="密集编码"></a>密集编码</h3><p>Word2Vec [90]使用连续词袋（CBOW）和 Skip-gram 模型来生成单词的密集表示，即单词嵌入。词嵌入的基本假设是出现在相似上下文中的单词具有相似含义。词嵌入在某种程度上减轻了向量化文本数据的离散性和数据稀疏性问题[36]。</p><p>除词嵌入外，doc2vec和para2vec [69]等词嵌入的扩展能直接将句子/段落编码为密集向量。</p><h2 id="文本扰动测量"><a href="#文本扰动测量" class="headerlink" title="文本扰动测量"></a>文本扰动测量</h2><p>文本扰动的度量与图像扰动完全不同。通常，扰动的大小是通过原始数据$x$与它的对抗样本$x’$之间的距离测量的。</p><p>但是在文本中，距离测量还需要考虑语法正确性，句法正确性和语义保留性 (grammar correctness, syntax correctness and semantic-preservance)。</p><h3 id="基于范数的度量方法"><a href="#基于范数的度量方法" class="headerlink" title="基于范数的度量方法"></a>基于范数的度量方法</h3><p>直接使用范数来度量词向量、词嵌入向量之间的距离。</p><h3 id="语法和句法相关的指标"><a href="#语法和句法相关的指标" class="headerlink" title="语法和句法相关的指标"></a>语法和句法相关的指标</h3><p><strong>语法检查</strong>和<strong>句法检查</strong>器可以用于度量该指标，用来保证对抗样本也符合正确的语法和句法。</p><p><strong>困惑度</strong>（Perplexity）通常用于衡量语言模型的质量。在一篇综述文献[91]中，作者使用困惑来确保生成的对抗样本（句子）有效。</p><p><strong>转义</strong>（Paraphrase）将一段文本转成另外一个语言，本身可被视作生成对抗样本。转义的有效性取决于生成模型的有效性。</p><h3 id="语义相似度度量"><a href="#语义相似度度量" class="headerlink" title="语义相似度度量"></a>语义相似度度量</h3><p>一般采用向量间距离度量指标来作为词向量的语义相似度度量指标。给定两个n维的词向量$\mathbf{p}=(p_1,p_2,\dots,p_n)$和$\mathbf{q}=(q_1,q_2,\dots,q_n)$，有如下定义：</p><ul><li>欧氏距离：  <script type="math/tex; mode=display">d(\mathbf{p}, \mathbf{q})=\sqrt{\left(p_{1}-q_{1}\right)^{2}+\left(p_{2}-q_{2}\right)^{2}+\cdots+\left(p_{n}-q_{n}\right)^{2}}</script>-余弦相似度<script type="math/tex; mode=display">\cos (\mathrm{p}, \mathrm{q})=\frac{\sum_{i=1}^{n} p_{i} \times q_{i}}{\sqrt{\sum_{i=1}^{n}\left(p_{i}\right)^{2}} \times \sqrt{\sum_{i=1}^{n}\left(q_{i}\right)^{2}}}</script></li></ul><h3 id="编辑距离"><a href="#编辑距离" class="headerlink" title="编辑距离"></a>编辑距离</h3><p>编辑距离是一类衡量字符串转化成另一字符串时，需要进行的最小操作数。不同的编辑距离，区别在于不同的字符串操作。</p><ul><li>Levenshtein Distance 使用插入，移除和替换操作</li><li>Word Mover’s Distance (WMD) [68] 计算的是两词嵌入向量互相转换的编辑距离，它测量一个文档的单词在词嵌入空间中变成另一文档的单词所需进行的最少操作[38]。通过计算下面这个最优化问题来计算距离：</li></ul><script type="math/tex; mode=display">\begin{array}{c}\min \sum_{i, j=1}^{n} \mathbf{T}_{i j} \mid \mathbf{e}_{\mathbf{i}}-\mathbf{e}_{\mathbf{j}} \|_{2} \\\text {s.t.}, \sum_{j=1}^{n} \mathbf{T}_{i j}=d_{i}, \forall i \in\{i, \ldots, n\}, \sum_{i=1}^{n} \mathbf{T}_{i j}=d_{i}^{\prime}, \forall j \in\{i, \ldots, n\}\end{array}</script><p>其中$\mathbf{e}_i$和$\mathbf{e}_j$分别是单词$i$和$j$的词嵌入向量；$n$是单词总数；$\mathbf{d}$和$\mathbf{d}’$分别是两文档经过归一化的词袋向量；$\mathrm{T} \in \mathcal{R}^{n \times n}$是流动矩阵（Flow Matrix，所有可能的源和目的地对之间的流量），$\mathrm{T}_{i j} \leq 0$代表了$\mathbf{d}$空间的单词$i$转变成$\mathbf{d}’$空间的单词$j$时，要改变的单词数目。</p><h3 id="杰卡德相似度（Jaccard-similarity-coefficient）"><a href="#杰卡德相似度（Jaccard-similarity-coefficient）" class="headerlink" title="杰卡德相似度（Jaccard similarity coefficient）"></a>杰卡德相似度（Jaccard similarity coefficient）</h3><p>杰卡德相似度计算的是有限样本集合间元素的相似程度，计算方法为：</p><script type="math/tex; mode=display">J(A, B)=\frac{|A \cap B|}{|A \cup B|}</script><p>$A$、$B$是两段文档或者两句话，$|A\cap B|$是同时出现在两文档中的单词数目，$|A\cup B|$是两文档的单词总数，重复出现的单词不予计数。</p><h1 id="四、ATTACKING-NEURAL-MODELS-IN-NLP-THE-SOTA"><a href="#四、ATTACKING-NEURAL-MODELS-IN-NLP-THE-SOTA" class="headerlink" title="四、ATTACKING NEURAL MODELS IN NLP: THE SOTA"></a>四、ATTACKING NEURAL MODELS IN NLP: THE SOTA</h1><h2 id="文本领域的深度学习系统攻击方法之分类"><a href="#文本领域的深度学习系统攻击方法之分类" class="headerlink" title="文本领域的深度学习系统攻击方法之分类"></a>文本领域的深度学习系统攻击方法之分类</h2><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/Categories_of_adv_attack_methods_on_textual_DL_models.png" srcset="/img/loading.gif" alt></p><p>如<a href="#Threat_Model">分类标准 Threat Model</a>所述，可以把攻击方法按一下分类标准分类：</p><ul><li>模型内部信息</li><li>根据被攻击模型的应用场景</li><li>根据是否带目标</li><li>根据扰动粒度</li><li>根据<a href="#Models">被攻击模型类型</a></li></ul><h2 id="白盒攻击"><a href="#白盒攻击" class="headerlink" title="白盒攻击"></a>白盒攻击</h2><p>攻击需要访问模型的完整信息，包括体系结构，参数，损失函数，激活函数，输入和输出数据。白盒攻击通常会针对特定模型尽可能严酷的攻击，包括添加扰动。白盒攻击通常非常有效果。</p><h3 id="基于FGSM的攻击"><a href="#基于FGSM的攻击" class="headerlink" title="基于FGSM的攻击"></a>基于FGSM的攻击</h3><p>FGSM算法我们<a href="#FGSM">已有讨论</a>。很多文本模型攻击方法都是受到FGSM启发.</p><p>TextFool [76]采用了FGSM的概念，通过使用反向传播计算损失梯度$\nabla_x J$，根据损失梯度的大小估计文本项的贡献，标识出对文本分类任务有重大贡献的项，这些项被称为Hot Character。包含足够Hot Character的短语被称为HTP。针对HTP，采用三种类型的攻击：插入（另外类别的HTP），修改（该样本自带的HTP字符或视觉上相近的字符）和删除（该样本自带的HTP字符）。最后在CNN文本分类器上评估了这三种策略及其组合[156]。该工作的缺陷在于，这些方法是手动进行的。</p><blockquote><p>关于本文的讨论在<a href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Deep-Text-Classification-Can-be-Fooled/">这里</a>。</p></blockquote><p>[117]中的工作采用了与TextFool相同的思想，但是它提供了一个remove-addition-replacement策略，该策略首先尝试<strong>删除</strong>对文本分类任务贡献最大（使用损失梯度来衡量）的副词（$w_i$）。如果此步骤输出句子语法不正确，则取消删除，该方法将在$w_i$之前<strong>插入</strong>单词$p_j$。从候选库中选择$p_j$，其中候选词（candidate words）是同义词、错别字（typos）和类型特定的关键字（genre specific keywords）（通过词频（term frequency）确定）。如果插入算法尝试过的所有$p_j$都不能令输出的成本梯度达到最高，则放弃插入，该方法将$w_i$<strong>替换</strong>为$p_j$。</p><p>由于该方法按单词的贡献等级对单词进行排序，并根据顺序制作对抗性样本，因此这是一种贪婪的方法，始终会获得最少的操作，直到输出变化为止。为了避免被人类感知，作者限制了替换/添加的单词，以不影响原始单词的语法和词性（part-of-Speech, POS）。</p><p>虽然恶意软件检测不是典型的文本应用程序，我们仍可以将攻击文本DNN的方法应用于攻击恶意软件检测DNN。在恶意软件检测中，可移植可执行文件（portable executable, PE）用二元向量${x_1,\dots,x_m}$b表示，其中$x_i\in{0,1}$表示PE是否存在，$m$是PE个数。</p><p>[3]的作者研究了生成二进制编码的对抗样本的方法。为了不改变对抗样本的功能，他们使用了四种限制方法（bounding methods）来生成扰动。前两种方法为FSGM$^k$ [67]，即FGSM的多步改进版，通过引入确定性舍入（dFGSM$^k$）和随机舍入（rFGSM$^k$）来限制二进制域中的扰动，类似于图像领域的$L_{\infty}$球约束[40]。第三种方法是多步位梯度上升法（multi-step Bit Gradient Ascent, BGA$^k$），如果损失函数的第$j$偏导数大于或等于损失梯度的$L_2$范数除以$\sqrt{m}$，则设置对应第$j$个二进制位为1。第四种方法是多步位坐标上升法（multi-step Bit Coordinate Ascent, BCA$^k$），通过考虑损失函数的最大对应部分导数的特征，每一步更新一个位（太难翻译了）。该工作还提出了一个对抗学习框架，旨在增强恶意软件检测模型的鲁棒性。</p><p>[114]攻击恶意软件检测DNN，通过扰动二进制序列的嵌入表示，并将扰动后的词嵌入序列重建为二进制。具体地，他们在原始二进制序列后附加了一个统一的随机字节序列（Payload），再将新的二进制附加到原二进制程序嵌入表示中，并且执行FGSM时只更新Payload部分。反复执行扰动，直到检测器输出错误的预测为止。由于仅对Payload而不是对整个输入执行扰动，因此此方法将保留恶意软件的功能。最后，他们通过将对抗样本的嵌入表示在有效嵌入空间中找与其最接近的邻居，将其重构为有效的二进制文件。</p><p>AdvGen[23]是一种基于梯度的攻击神经机器翻译（NMT）模型的方法。首先，它会考虑损失函数的梯度以及一个单词与其替换单词（即对抗性单词）之间的距离，从而生成对抗样本。用语言模型来识别给定单词的最可能替换单词，因为语言模型可使对抗样本保留更多的语义。然后AdvGen将生成的对抗样本合并到NMT模型的解码器中以防御攻击。</p><p>上述基于FGSM的算法都利用了损失函数的梯度，但大部分使用梯度本身而不是像FGSM那样使用梯度的正负号或量级。也有许多研究直接采用FGSM进行对抗训练，即在训练模型时将其用作正则化工具。</p><h3 id="基于JSMA的攻击"><a href="#基于JSMA的攻击" class="headerlink" title="基于JSMA的攻击"></a>基于JSMA的攻击</h3><p>JSMA我们<a href="#JSMA">已有讨论</a>。[103]使用正向导数（forward derivative）作为JSMA矩阵来找到最有利于生成对抗样本的方向。网络的雅可比行列式是通过利用计算图展开来计算的[96]。作者针对两种RNN模型构建了对抗样本，被攻击的RNN模型分别应用于分类任务和序列生成。</p><p>对于分类RNN，输出分量$j$对应的雅可比矩阵的第$j$列，即$Jac_F[:,j]$。对于每个单词$i$，扰动的方向定义为：</p><script type="math/tex; mode=display">\begin{array}{l}\operatorname{sign}\left(\operatorname{Jac} b_{F}\left(x^{\prime}\right)\left[i, g\left(x^{\prime}\right)\right]\right), \\g\left(x^{\prime}\right)=\arg \max _{0,1}\left(p_{j}\right)\end{array}</script><p>$p_j$是输出向量中目标类的概率，这在JSMA中是logit而不是概率。作者还将扰动后的样本投影到嵌入空间中，获得最近的词嵌入向量</p><p>对于序列生成RNN，计算完雅可比矩阵后，将输入时间步$i$更改为雅可比矩阵中的较高值，将输出时间步$j$更改为雅可比矩阵中的较低值。</p><p>[43,44]是首项对恶意软件检测DNN进行攻击的工作。使用二进制指示器特征向量来表示应用程序，通过采用JSMA在输入特征向量上制作对抗样本。为了确保由扰动引起的修改不会对应用程序造成太大影响，从而使恶意软件应用程序的功能保持完整，作者使用$L_1$范数将功能总数限制为20，更改数目限制为20。</p><p>此外，作者提供了三种防御攻击的方法，即特征缩减（feature reduction），精简（distillation）和对抗训练（adversarial training）。他们发现对抗训练是最有效的防御方法。</p><h3 id="基于C-amp-W的攻击方法"><a href="#基于C-amp-W的攻击方法" class="headerlink" title="基于C&amp;W的攻击方法"></a>基于C&amp;W的攻击方法</h3><p>C&amp;W我们<a href="#C_W">已有讨论</a>。</p><p>[130]中的工作采用C＆W方法攻击病历预测模型，该模型用于检测每位患者的病历中的易感事件和测量结果，为临床使用提供指导。该模型使用LSTM。</p><p>给定病人的病历数据为$X^{i} \in \mathbf{R}^{d \times t_{i}}$，其中$d$是每条数据的特征个数，$t_i$是医疗检查的时间指数。对抗样本的生成公式如下：</p><script type="math/tex; mode=display">\min _{\hat{X}} \max \left\{-\epsilon,\left[logit\left(\mathbf{x}^{\prime}\right)\right]_{y}-[logit(\mathbf{x})]_{y^{\prime}}\right\}+\lambda\left\|\mathbf{x}^{\prime}-\mathbf{x}\right\|_{1}</script><p>其中$logit(\cdot)$表示网络输出的logit，$\lambda$是控制正则项大小的超参数，$y$和$y’$分别是原始类别和突变目标类别。作者还从扰动幅度和攻击的结构两个角度评估了生成的对抗样本。最后使用对抗样本来计算EHR的敏感性分数（susceptibility score）以及不同测量值的累积敏感性分数（cumulative susceptibility score）。</p><p>Seq2Sick [22]使用两种带目标攻击方法攻击Seq2seq模型：非重叠攻击（non-overlapping attack）和关键字攻击（keywords attack）。</p><p>非重叠攻击是指生成与原始输出完全不同的对抗序列。作者提出了一种类似于铰链（hinge-like）的损失函数，可以在神经网络的logit层上进行优化：</p><script type="math/tex; mode=display">\sum_{i=1}^{|K|} \min _{t \in[M]}\left\{m_{t}\left(\max \left\{-\epsilon, \max _{y \neq k_{i}}\left\{z_{t}^{(y)}\right\}-z_{t}^{\left(k_{i}\right)}\right\}\right)\right\}</script><p>其中$z_t$是输入对抗样本后的模型logit层输出。</p><p>关键字攻击是指攻击模型，使得预期关键字出现在输出中。作者还是将优化放在了logit层上，并试图确保目标关键字的logit在所有单词中最大。此外，他们定义了掩码函数m以解决关键字冲突问题。添加掩码后的损失函数为：</p><script type="math/tex; mode=display">L_{\text {keywords}}=\sum_{i=1}^{|K|} \min _{t \in[M]}\left\{m_{t}\left(\max \left\{-\epsilon, \max _{y \neq k_{i}}\left\{z_{t}^{(y)}\right\}-z_{t}^{\left(k_{i}\right)}\right\}\right)\right\}</script><p>其中$k_i$表示输出单词中的第$i$个单词。为了确保生成的词嵌入向量是有效的，作者还引入了两种正则化项：group lasso 正则化来增强group稀疏性；group 梯度正则化使对抗样本位于有效的嵌入空间范围内。</p><h3 id="基于方向（导数）的攻击"><a href="#基于方向（导数）的攻击" class="headerlink" title="基于方向（导数）的攻击"></a>基于方向（导数）的攻击</h3><p>HotFlip [30]执行原子翻转操作以生成对抗样本。HotFlip没有利用损失函数的梯度，而是使用方向导数。具体而言，HotFlip将字符级操作（即交换，插入和删除）表示为输入空间中的向量，并通过针对这些操作向量的方向导数来估计损失的变化。具体来说，给定输入的One-Hot表示，第i个单词的第j个字符的变化（比如从a变到b）可以由以下向量表示：</p><script type="math/tex; mode=display">\vec{v}_{i j b}=\left(0, . . ;\left(0, . .(0, . .-1,0, . ., 1,0)_{j}, . .0\right)_{i} ; 0, . .\right),</script><p>其中最内层向量$j$的内部，-1的位置在字母表中为a，1的位置在字母表中为b。用这个向量来模拟操作。那么可以通过沿操作矢量的方向导数最大化损失变化的一阶近似值来找到最佳的字符交换：</p><script type="math/tex; mode=display">\max \nabla_{x} J(x, y)^{T} \cdot \vec{v}_{i j b}=\max _{i j v} \frac{\partial J^{(b)}}{\partial x_{i j}}-\frac{\partial J^{(a)}}{\partial x_{i j}}</script><p>其中$J(x,y)$是模型的损失函数，输入为$x$，真实输出为$y$。这个方法不仅可以表示字符替换，还可以表示插入和删除字符。在第i个字的第j个位置插入也可以当作一个字符翻转，然后再进行更多的翻转，因为字符是向右移位的，直到字的末尾。字符删除则是多次字符翻转，因为字符是向左移位的。利用集束搜索（Beam Search），HotFlip可以有效地找到多次翻转的最佳方向。</p><p>[29]扩展了HotFlip的功能，使其可以进行目标攻击。除了HotFlip中提供的交换，插入和删除功能外，作者还提出了受控攻击（controlled attack）：使输出序列中特定单词消失的方法，以及目标攻击（targeted attack）：以预计的单词替换输出序列中的特定单词。为了实现这些攻击，他们使损失函数$J (x,y_t )$最大化，并使$J (x,y^{′}_t )$最小化，其中$t$是受控攻击的目标词，$t′$是替换$t$的词。</p><p>此外，他们还提出了三种类型的攻击，提供多种文本修改方法。在one-hot攻击中，他们对文本中的所有词进行了最优操作。在Greedy攻击中，他们除了从整个文本中挑选出最佳操作外，还进行了另一次向前和向后的传递。在波束搜索攻击中，他们用波束搜索代替了greedy中的搜索方法。在本作提出的所有攻击中，作者都设置了最大修改次数的阈值，例如，允许20%的字符被修改。</p><h3 id="基于注意力的攻击"><a href="#基于注意力的攻击" class="headerlink" title="基于注意力的攻击"></a>基于注意力的攻击</h3><p><span id="ref14" style.display="none"></span><br>[14]的作者为了比较CNN与RNN的鲁棒性，提出了两种白盒攻击。他们利用模型的内部注意力分布来寻找关键句子，模型赋予该句子较大的权重，从而得出正确答案。然后，他们将获得注意力最高的词与已知词汇中随机选择的词进行交换。他们还进行了另一种白盒攻击，将获得最高注意力的整句去掉。虽然他们关注的是基于注意力的模型，但他们的攻击并没有研究注意力机制本身，而是仅仅利用了注意力部分的输出（即注意力得分）。</p><h3 id="基于重编程的攻击"><a href="#基于重编程的攻击" class="headerlink" title="基于重编程的攻击"></a>基于重编程的攻击</h3><p><span id="Reprogramming" style.display="none"></span><br>[97]采用对抗重编程（adversarial reprogramming, AP）来攻击序列神经分类器。训练一个对抗重编程函数$g_{\theta}$，在不修改DNN参数的情况下，将被攻击的DNN重新用于执行另一个任务（如问题分类到名称分类）。AP采用迁移学习的思想，但保持参数不变。在白盒攻击中，作者应用Gumbel-Softmax来训练可以在离散数据上工作的$g_{\theta}$。作者在各种文本分类任务上评估了他们的方法，并证实了他们方法的有效性。</p><h3 id="混合方法"><a href="#混合方法" class="headerlink" title="混合方法"></a>混合方法</h3><p>[38]针对CNN模型，应用FGSM和DeepFool对输入文本的词嵌入进行扰动。作者通过使用词移动距离（Word Mover’s Distance，WMD）作为距离测量，将对抗样本舍入（Rounded）到最近的有意义的词向量。在情感分析和文本分类数据集上的评估表明，WMD是控制扰动的合格度量。</p><h3 id="白盒攻击总结"><a href="#白盒攻击总结" class="headerlink" title="白盒攻击总结"></a><strong>白盒攻击总结</strong></h3><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/white_box_attack_methods_table.png" srcset="/img/loading.gif" alt></p><h2 id="黑盒攻击"><a href="#黑盒攻击" class="headerlink" title="黑盒攻击"></a>黑盒攻击</h2><p>黑盒攻击不能获得神经网络内部信息，但是可以获得输入和输出。这种攻击方法经常依靠启发式算法生成对抗样本。鉴于现实生活中不能获得模型信息，因此黑盒攻击往往更加实用。本文将文本领域的黑盒攻击分成五类。</p><h3 id="连词对抗器"><a href="#连词对抗器" class="headerlink" title="连词对抗器"></a>连词对抗器</h3><p>[54]是第一个攻击阅读理解系统的研究。作者提出了连词对抗器（concatenation adversaries），即在段落末尾附加一些无意义的句子。这些分散网络精力的句子不会改变段落的语义和Ground Truth，但会欺骗神经模型。分心句子要么是精心生成的信息句子，要么是从常用词池随机取20个以并任意词序构建的句子。</p><p>这两种扰动都是通过迭代查询神经网络获得的，直到输出发生变化。</p><p>图2说明了参考文献[54]中的一个例子，加入干扰句（蓝色）后，答案从正确的（绿色）变为不正确的（红色）。</p><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/fig_2.png" srcset="/img/loading.gif" alt></p><p>[142]的作者通过改变分心句子放置的位置，以及扩大生成分心句子的假答案集，改进了这项工作，呈现了新的对抗样本，有助于训练更健壮的神经模型。</p><p>[14]利用分心句子来评估其阅读理解模型的鲁棒性。他们从常用词池中使用随机的10个词，结合所有问题词和所有错误答案候选的词来生成分心的句子。作者还通过同义词替换最常出现的词，进行简单的词级黑盒攻击。作者还提供了两种<a href="#ref14">白盒策略</a>。</p><p>图3说明了连词攻击的一般工作流程。</p><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/fig_3.png" srcset="/img/loading.gif" alt></p><p>正确的输出(即MRC任务中的答案)通常被利用来生成扭曲的输出，稍后这些输出将被用来构建分散注意力的内容。将分心内容附加到原始段落中，形成被攻击的DNN的对抗性输入。分心的内容不会分散人类和理想DNN的注意力，但会使易受攻击的DNN产生错误的输出。</p><h3 id="编辑对抗器"><a href="#编辑对抗器" class="headerlink" title="编辑对抗器"></a>编辑对抗器</h3><p>[12]中的工作对神经机器翻译应用的输入数据进行了两种方式的扰动。<strong>合成</strong>(Synthetic)，即进行字符顺序的改变，如交换、中间随机（即随机改变除首尾字符以外的字符顺序）、完全随机（即随机改变所有字符的顺序）和键盘类型（keyboard type）。他们还收集了自然生成的拼写错误（typos）和错别字（misspellings）作为对抗单元（adversaries）。</p><p>[98]的作者还攻击了用于对话生成的神经模型。他们在对话语境中应用了各种扰动，即Random Swap（随机转置相邻的标记）和Stopword Dropout（随机删除停顿词）、Paraphrasing（用其转述替换单词）、语法错误（如将动词改成错误的时态），以及添加否定策略（否定源输入的动词根）和反义词策略（将动词、形容词或副词改成其反义词）。</p><p>DeepWordBug[34]使用字符转换来生成对抗样本。首先确定了重要的“标记（token）”，即给模型输出造成大量影响的那些单词或字符，影响程度依赖一个评价函数，输入模型的输出向量，输出评分。然后修改这些token，包括替换、删除、添加和交换四种策略。作者在各种NLP任务上评估了他们的方法，例如，文本分类、情感分析和垃圾邮件检测。</p><p>[73]中的工作完善了[34]中的评分函数。此外这项工作还有采用了JSMA的白盒攻击版本。通过使用四种文本相似性测量方法进行扰动限制：文本的编辑距离；Jaccard相似性系数；词向量的欧氏距离；词嵌入的余弦相似性。他们的方法只在情感分析任务上进行了评估。图4是参考文献[73]中的一个编辑对抗的例子，在这个例子中，只有少数的编辑操作会误导分类器给出错误的预测。</p><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/fig_4.png" srcset="/img/loading.gif" alt></p><p>[110]攻击文本分类模型提供了一种概率方法来选择要替换的词。首先收集现有语料库中该词的所有同义词，然后通过测量其对分类概率的影响，从同义词中选择一个拟替代词（proposed substitute words）。导致模型分类概率发生最显著变化的词将被选中。作者还结合词的显著性来确定替换顺序。词显著性（word saliency）是指如果将一个词设置为未知，输出分类概率的变化程度。</p><p>[91]的作者提出了一种在自然语言推理（NLI）中自动生成违反一组给定一阶逻辑约束的对抗样本的方法。他们提出了一个不一致性损失（inconsistency loss）来衡量一组句子导致模型违反规则的程度。对抗样本生成的过程是寻找规则中变量与句子之间的映射，使不一致性损失最大化的过程。这些句子是由低困惑度（由语言模型定义）的句子组成。为了生成低困惑性的对抗句样本，他们使用了三种编辑扰动。(i)改变其中一个输入句中的一个词；(ii)从其中一个输入句中删除一个解析子树（parse subtree）；(iii)将语料库中一个句子的一个解析子树插入到另一个句子的解析树（parse tree）中。</p><p>[5]中的工作采用遗传算法(GA)生成对抗样本，能够使得原文中最小化单词替换的数量同时可以让被攻击模型的结果发生改变。作者采用了GA中的交叉和突变操作来产生扰动。他们测量了单词替换的有效性，以衡量对被攻击DNNs的影响。他们的攻击主要集中在情感分析和文本蕴含（textual entailment）DNNs上。</p><p>[19]提出了一种对可分化神经计算机（Differentiable Neural Computer, DNC）进行对抗性攻击的框架工作。DNC是一种以DNN为中央控制器的计算机，运行在外部内存模块上，执行数据处理操作。他们使用两种自动化且可扩展的策略，生成语法正确的对抗样本，供问答领域使用。他们还使用了蜕变变换（metamorphic transformation）。第一个策略：Pick-n-Plug，由一个Pick操作符和Plug操作符组成，pick操作符从源任务域中选择一句作为对抗性插入，plug操作符将这些句子注入到另一个目标任务中，没有改变句子的Ground Truth。另一个策略是Pick-Permute-Plug，在从源任务中抽取句子后增加一个permute操作符，扩展了Pick-n-Plug生成对抗样本的能力。Permute操作的具体做法是将特定对抗样本中的单词进行其同义词替换，以产生更大范围的攻击。</p><p>[155]提出了一种基于编辑的方法MHA（Metropolis-Hastings Attack），旨在提供流畅有效的对抗性攻击。MHA基于语言模型和MetropolisHastings（M-H）采样。作者使用M-H采样来生成替换旧词的词（用于替换操作）和随机词（用于插入操作）。语言模型用于保证替换/插入/删除操作后的句子的流畅性。作者提出了黑盒和白盒两种版本。两者唯一的区别是在选择最可能操作的词时，对预选功能的定义。图5展示了编辑对抗样本的一般工作流程。通过替换、删除、插入和交换等编辑策略对句子、单词或字符进行扰动。</p><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/fig_5.png" srcset="/img/loading.gif" alt></p><h3 id="基于释义的对抗器"><a href="#基于释义的对抗器" class="headerlink" title="基于释义的对抗器"></a>基于释义的对抗器</h3><p>SCPNs[53]通过将给定句子和目标句法形式输入到encoder-decoder架构中，产生具有期望句法的释义。该方法首先对原句进行编码，然后将反译产生的释义和目标句法树输入到解码器中，其输出是原句的目标释义。创新点在于解析模板的选择和处理。作者从SCPNs中分别训练了一个解析生成器（parse generator），并在PARANMT-50M数据集中选取了20个最常见的模板。</p><p>在使用选定的解析模板生成解析后，他们通过检查n-gram重叠（overlap ）和基于解析的相似性（paraphrase-based similarity），进一步修剪了非可感句子（non-sensible sentences）。被攻击的分类器可以正确地预测原始句子的标签，但在其释义上却失败了，这被认为是对抗性的例子。</p><p>SCPNs在情感分析和文本包涵（textual entailment）DNNs上进行了评估，并显示出对被攻击模型的显著影响。虽然这种方法使用目标策略来生成对抗样本，但它没有指定目标输出。因此，我们将其归为非目标攻击。</p><p>[127]中的工作使用了创建语义等价的对抗样本（semantically equivalent adversaries, SEA）的释义生成技术的思想。作者生成了一个输入句子$x$的释义，并从$f$中得到预测，直到改变原始预测。同时，他们考虑了与$x′$的语义等同，即如果$x$与$x′$语义等同，则为1，否则为0，如下式所示。</p><script type="math/tex; mode=display">\operatorname{SEA}\left(\mathbf{x}, \mathbf{x}^{\prime}\right)=\mathbf{1}\left[\operatorname{Sem} E q\left(x, x^{\prime}\right) \wedge f(\mathbf{x}) \neq f\left(\mathbf{x}^{\prime}\right)\right]</script><p>之后，本工作提出了一种基于语义等价规则的方法，将这些生成的对抗样本泛化为语义等价规则，以理解和修复影响最大的bug。</p><p>图6描述了基于释义的对抗样本算法生成原则，我们把源文本的释义当作对抗样本。生成释义时添加扰动。</p><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/fig_6.png" srcset="/img/loading.gif" alt></p><h3 id="基于GAN的对抗样本生成器"><a href="#基于GAN的对抗样本生成器" class="headerlink" title="基于GAN的对抗样本生成器"></a>基于GAN的对抗样本生成器</h3><p>采用GAN的目的是为了使对抗样本更加自然。</p><p>[157]提出的生成对抗样本的模型由两个关键组件组成：一个GAN，生成虚假的数据样本；一个转换器，将输入$x$映射到其潜伏表示$z′$。这两个组件通过最小化原始输入和对抗样本之间的重构误差来对原始输入进行训练。通过识别$z′$附近的扰动样本$\hat{z}$在潜密空间中进行扰动。作者提出了两种搜索方法，即迭代随机搜索（iterative stochastic search）和混合收缩搜索（hybrid shrinking search）来识别合适的$\hat{z}$。该工作既适用于图像数据，也适用于文本数据，因为它从本质上消除了文本数据的离散属性所带来的问题。作者对他们的方法在三个应用上进行了评估，即：文本包含、机器翻译和图像分类。然而，每次求解使模型出错的$\hat{z}$都需要重新查询攻击模型并运行算法，相当耗时。</p><h3 id="基于替换的方法"><a href="#基于替换的方法" class="headerlink" title="基于替换的方法"></a>基于替换的方法</h3><p>[52]中的工作提出了一个攻击RNN模型的黑盒框架，用于恶意软件检测。该框架包括两个模型：生成RNN和替换RNN。生成式RNN基于seq2seq模型[131]，旨在从恶意软件的API序列中生成对抗性的API序列。具体来说，生成一小段API序列，并将该序列插入到输入序列之后。替代RNN是一种具有注意力机制的双向RNN，它要模仿被攻击RNN的行为。因此，生成对抗样本不会查询原来的被攻击RNN，而是查询它的替代RNN。替换的RNN会在恶意软件和良性程序序列数据集上进行训练，以生成RNN的Gumbel-Softmax为输出。在这里，由于生成性RNN的原始输出是离散的，所以使用Gumbel-softmax来实现两个RNN模型的联合训练。具体来说，它可以使梯度从生成性RNN反推到替代性RNN。该方法对API进行攻击，API表示为一个One-Hot向量，即给定$M$个API，第$i$个API的向量是一个$M$维的二进制向量，即第$i$维为1，其他维度为0。</p><h3 id="重编程"><a href="#重编程" class="headerlink" title="重编程"></a>重编程</h3><p><a href="#Reprogramming">如前所述</a>，[97]提供了黑盒和白盒两种攻击版本。在黑盒攻击中，作者将序列生成建模为强化学习任务，对抗重训练函数$g_{\theta}$是强化学习中的policy网络。作者采用基于强化学习的优化算法训练$g_{\theta}$。</p><h3 id="黑盒攻击总结"><a href="#黑盒攻击总结" class="headerlink" title="黑盒攻击总结"></a>黑盒攻击总结</h3><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/black_box_attack_methods_table_part_1.png" srcset="/img/loading.gif" alt><br><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/black_box_attack_methods_table_part_2.png" srcset="/img/loading.gif" alt></p><h2 id="多模态任务攻击"><a href="#多模态任务攻击" class="headerlink" title="多模态任务攻击"></a>多模态任务攻击</h2><p>有些模型执行跨模态的任务，比如一些神经模型包含一个内部组件，执行图像到文本或语音到文本的转换。虽然这些攻击并不是针对纯文本数据的，但为了全面回顾，我们简单介绍一下有代表性的攻击。</p><h3 id="图像到文本模型的攻击方法"><a href="#图像到文本模型的攻击方法" class="headerlink" title="图像到文本模型的攻击方法"></a>图像到文本模型的攻击方法</h3><p>图像到文本模型是一类根据图像的语义内容为图像生成文本描述的技术。</p><h4 id="攻击光学字符识别模型"><a href="#攻击光学字符识别模型" class="headerlink" title="攻击光学字符识别模型"></a>攻击光学字符识别模型</h4><p>光学字符识别（Optical Character Recognition, OCR）是典型的多模态学习任务，它将图像作为输入，并输出识别的文本。[129]提出了对OCR的白盒攻击和后续的NLP应用。首先使用原始文本来渲染一个干净的图像（转换DNNs），然后在WordNet中找到满足编辑距离阈值的反义词。只有那些有效（valid）且保持语义不一致的反义词才会被保留。之后，该方法在干净的图像中找到包含上述单词的行，可以用它们所选择的反义词来替换。然后，该方法将目标词转化为目标序列。给定输入/目标图像和序列，作者将对抗样本生成问题建模为一个优化问题。</p><script type="math/tex; mode=display">\begin{array}{c}\min _{\omega} c \cdot J_{C T C} f\left(\mathbf{x}^{\prime}, t^{\prime}\right)+\left\|\mathbf{x}-\mathbf{x}^{\prime}\right\|_{2}^{2} \\\mathbf{x}^{\prime}=(\alpha \cdot \tanh (\omega)+\beta) / 2 \\\alpha=\left(\mathbf{x}_{\max }-\mathbf{x}_{\min }\right) / 2, \beta=\left(\mathbf{x}_{\max }+\mathbf{x}_{\min }\right) / 2 \\J_{C T C}(f(\mathbf{x}, t))=-\log p(t \mid \mathbf{x})\end{array}</script><p>其中$f(\mathbf{x})$代表神经网络模型，$J_{CTC}(\cdot)$代表CTC（Connectionist Temporal Classification）损失函数，$\mathbf{x}$是损失图像，$t$是真实（Ground Truth）序列，$x^{‘}$是对抗样本，$t^{‘}$是目标序列，$\omega,\alpha,\beta$是生成对抗样本时为了满足box-constraint条件$\mathbf{x}^{\prime} \in\left[\mathbf{x}_{\min }, \mathbf{x}_{\max }\right]^{p}$的参数。$p$是确保生成有效对抗样本$x^{‘}$所需的像素个数。在对抗样本生成完毕后，以对抗样本替换图像中相应行。</p><p>作者从三个方面对该方法进行了评估：单字识别、整篇文档识别以及基于识别文本的NLP应用（具体为情感分析和文档分类）。他们还发现，所提出的方法存在着可转移性（transferability）低和物理可实现性（physical realizability）低等局限性。</p><h4 id="攻击场景文本识别模型"><a href="#攻击场景文本识别模型" class="headerlink" title="攻击场景文本识别模型"></a>攻击场景文本识别模型</h4><p>场景文本识别（Scene Text Recognition, STR）是一种图像到文字的应用，整个图像直接被映射成字串。相比之下，OCR中的识别是一个流水线过程：首先将单词分割成字符，然后对单个字符进行识别。AdaptiveAttack[153]评估了对场景文本识别进行对抗性攻击的可能性。作者提出了两种攻击方式，即基本攻击和自适应攻击。基本攻击与参考文献[129]中的工作类似，它也将对抗式实例生成表述为一个优化问题。</p><script type="math/tex; mode=display">\begin{array}{l}\min _{\omega} J_{C T C} f\left(\mathbf{x}^{\prime}, t^{\prime}\right)+\lambda \mathcal{D}\left(\mathbf{x}, \mathbf{x}^{\prime}\right), \\\mathbf{x}^{\prime}=\tanh (\omega)\end{array}</script><p>其中$\mathcal{D}(\cdot)$是欧氏距离。</p><p>与[129]的不同之处在于$x′$的定义，以及$x$、$x′$之间的距离测量($L_2$法则 vs. 欧氏距离)，以及参数$\lambda$，它平衡了作为对抗样本和接近原始图像的重要性。由于寻找合适的$\lambda$相当耗时，作者提出了另一种方法来自适应地寻找$\lambda$。他们将这种方法命名为Adaptive Attack，他们将顺序分类任务的似然（likelihood）定义为遵循高斯分布，并推导出顺序对抗样本的自适应优化为：</p><script type="math/tex; mode=display">\min \frac{\left\|\mathrm{x}-\mathrm{x}^{\prime}\right\|_{2}^{2}}{\lambda_{1}^{2}}+\frac{J_{C T C} f\left(\mathrm{x}^{\prime}, t^{\prime}\right)}{\lambda_{2}^{2}}+\log \lambda_{1}^{2}+T \log \lambda_{2}^{2}+\frac{1}{\lambda_{2}^{2}}</script><p>其中$\lambda_1,\lambda_2$是用来平衡扰动与CTC损失函数的两个参数。作者在令输出中的插入文本、删除文本和替换文本的任务上评估了他们提出的方法。结果表明，自适应攻击比基本攻击快得多。</p><h4 id="攻击图像字幕生成模型"><a href="#攻击图像字幕生成模型" class="headerlink" title="攻击图像字幕生成模型"></a>攻击图像字幕生成模型</h4><p>图像字幕（Image Captioning）是另一个多模态学习任务，它将图像作为输入，并生成一个描述其视觉内容的文本字幕。Show-and-Fool[20]生成对抗样本来攻击基于CNN-RNN的图像字幕模型。被攻击的CNN-RNN模型采用CNN作为编码器进行图像特征提取，RNN作为解码器进行字幕生成。Show-and-Fool有两种攻击策略：预期目标字幕(targeted caption)（即生成的字幕与预期目标字幕相匹配）和预期目标关键词（targeted keywords）（即生成的字幕包含目标关键词）。形式化定义如下：</p><script type="math/tex; mode=display">\begin{array}{c}\min _{\omega} c \cdot J\left(\mathbf{x}^{\prime}\right)+\left\|\mathbf{x}^{\prime}-\mathbf{x}\right\|_{2}^{2} \\\mathbf{x}^{\prime}=\mathbf{x}+\eta \\x=\tanh (y), \quad \mathbf{x}^{\prime}=\tanh (\omega+y)\end{array}</script><p>其中$c&gt;0$是预先定义的正则化常数，$\eta$是扰动，$\omega,y$是控制$\mathbf{x}^{\prime} \in[-1,1]^{n}$的参数。两种策略的区别在于损失函数$J(\cdot)$的定义。</p><p>targeted caption策略的targeted caption定义为$S=\left(S_{1}, S_{2}, \ldots S_{t}, \ldots S_{N}\right)$，其中$S_t$为单词表中第$t$个单词的index，$N$是caption的长度。损失函数定义为：</p><script type="math/tex; mode=display">J_{S, l o g i t}\left(\mathbf{x}^{\prime}\right)=\sum_{t=2}^{N-1} \max \left\{-\epsilon, \max _{k \neq S_{t}}\left\{z_{t}^{(k)}\right\}-z_{t}^{\left(S_{t}\right)}\right\}</script><p>其中$S_t$是目标单词，$z_t^{(S_t)}$是目标单词的logit。这个方法实质上是最小化了$S_t$的logit与除$S_t$外的最大logit的距离。</p><p>targeted keywords策略。给定targeted keywords $\mathcal{K}:=K_{1}, \ldots, K_{M}$，损失函数定义为：</p><script type="math/tex; mode=display">J_{K, \text {logit}}\left(\mathrm{x}^{\prime}\right)=\sum_{j=1}^{M} \min _{t \in[N]}\left\{\max \left\{-\epsilon, \max _{k \neq K_{j}}\left\{z_{t}^{(k)}\right\}-z_{t}^{\left(K_{j}\right)}\right\}\right\}</script><p>作者对Show-and-Tell[137]进行了大量的实验，并改变了攻击损失中的参数。他们发现，Show-and-Fool不仅在攻击基于CNN-RNN的图像字幕模型Showand-Tell上有效，而且在另一个模型Show-Attend-and-Tell[147]上也具有很强的转移能力（transferable ）。</p><h4 id="攻击视觉问题回答模型"><a href="#攻击视觉问题回答模型" class="headerlink" title="攻击视觉问题回答模型"></a>攻击视觉问题回答模型</h4><p>视觉问题回答（Visual Question Answering, VQA）是指，给定一张图像和一个关于图像的自然语言问题，VQA要用自然语言提供一个准确的答案。[148]中的工作提出了一种迭代优化方法来攻击两种VQA模型。提出的目标函数可以最大化目标答案的概率，并在该距离低于阈值时，对与原始图像距离较小的对抗样本的偏好进行减权。</p><p>具体来说，该目标包含三个部分。第一部分类似于STR任务中的公式</p><script type="math/tex; mode=display">\begin{array}{l}\min _{\omega} J f\left(\mathbf{x}^{\prime}, t^{\prime}\right)+\lambda \mathcal{D}\left(\mathbf{x}, \mathbf{x}^{\prime}\right)\end{array}</script><p>，将损失函数替换为VQA模型的损失，并使用$\left|\mathbf{x}-\mathbf{x}^{\prime}\right|_{2} / \sqrt{N}$作为$x′$和$x$之间的距离。</p><p>第二部分使softmax输出与预测值的差值最大化，当其与目标答案不同时，就会使其差值最大化。</p><p>第三部分确保$x′$和$x$之间的距离在一个阈值之下。</p><p>通过检查是否比之前的攻击获得更好的成功率，以及模型预测目标答案的置信度得分来评估攻击。根据评估结果，作者得出结论：注意力（attention）、边界盒定位（bounding box localization）和组成式内部结构（compositional internal structures）容易受到对抗性攻击。这项工作还攻击了一个图像字幕神经模型。</p><h4 id="攻击视觉语义嵌入模型"><a href="#攻击视觉语义嵌入模型" class="headerlink" title="攻击视觉语义嵌入模型"></a>攻击视觉语义嵌入模型</h4><p>视觉语义嵌入（Visual-semantic Embeddings, VSE）目的是将自然语言和底层视觉世界连接起来。在VSE中，图像和描述性文本（标题）的嵌入空间都被联合优化和对齐。</p><p>[125]通过在测试集中生成对抗样本，对最新的VSE模型进行攻击，并评估了VSE模型的鲁棒性。通过引入三种方法对文本部分进行攻击。(i)利用WordNet中的超义词/同义词（hypernymy/hyponymy）关系替换图像标题中的名词；(ii)将数字改为不同的数字，并在必要时将相应的名词单数化或复数化；(iii)检测关系，将不可互换的名词短语打乱或替换介词。</p><p>这种方法可以认为是一种黑盒攻击。</p><h3 id="语音转文字模型攻击方法"><a href="#语音转文字模型攻击方法" class="headerlink" title="语音转文字模型攻击方法"></a>语音转文字模型攻击方法</h3><p>语音转文字（Speech-to-text）也称为语音识别，任务是自动识别口语并将其翻译成文本。[18]攻击了基于LSTM的最先进的语音转文字神经网络Deep Speech。给定一个自然波形，作者构造了一个音频扰动，这个扰动几乎听不到，但可以通过添加到原始波形中进行识别。该扰动的构建采用了C&amp;W方法的思想(参考<a href="#C_W">这里</a>)，即通过最大的像素变化量来测量图像失真。在此基础上，他们通过计算音频的相对响度来测量音频失真，并提出使用CTC损失来完成优化任务。然后他们用Adam优化器解决了这个任务[61]。</p><h3 id="多模态攻击技术总结"><a href="#多模态攻击技术总结" class="headerlink" title="多模态攻击技术总结"></a>多模态攻击技术总结</h3><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/cross_modal_attack_methods_table.png" srcset="/img/loading.gif" alt></p><h2 id="按应用划分的基准数据集"><a href="#按应用划分的基准数据集" class="headerlink" title="按应用划分的基准数据集"></a>按应用划分的基准数据集</h2><p>近年来，神经网络在不同的NLP领域获得了成功，包括文本分类、阅读理解、机器翻译、文本摘要、问题回答、对话生成等等。在本节中，我们将从NLP应用的角度回顾目前关于神经网络生成对抗样本的作品。表4根据其应用领域总结了我们在本文中回顾的作品。</p><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/datasets_table.png" srcset="/img/loading.gif" alt></p><p>我们还在表中列出了这些作品中使用的基准数据集作为辅助信息。如果想了解更多，我们推荐到我们收集的链接/参考文献中进一步获得数据集的详细描述。请注意，帮助生成对抗样本的辅助数据集并不包括在内。我们只介绍用于评估被攻击神经网络的数据集。</p><h3 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h3><p>大多数综述类文章都集中于神经网络分类任务的攻击算法上。情感分析任务试图将文本按照情感倾向分成几类（积极、消极、中立），性别识别、语法错误检测和恶意软件检测可以被框定为二元分类问题。关系提取可以表述为单分类或多分类问题。预测医疗状态是一个多类问题，类是由医学专家定义的。这些作品通常使用多个数据集来评估其攻击策略，以显示其方法的通用性和鲁棒性。</p><p>[76]使用DBpedia本体数据集[71]将文档样本分类为14个高级类。[38]使用IMDB电影评论[83]进行情感分析，使用NLTK包提供的Reuters-2和Reuters-5新闻数据集进行分类。[103]使用一个未指定的电影评论数据集进行情感分析，并使用IMDB电影评论[83]和NLTK包10提供的Reuters-2和Reuters-5新闻线数据集进行分类。[117]也使用IMDB电影评论数据集进行情感分析，还对和Twitter数据集进行了性别分类。[34]对Enron垃圾邮件数据集[89]进行垃圾邮件检测，并采用[156]中的6个大型数据集，即AG’s新闻、搜狗新闻[138]、DBPedia本体数据集、Yahoo！Answers进行文本分类和Yelp评论、亚马逊评论[88]进行情感分析。[30]也使用AG’s新闻进行文本分类，使用斯坦福情感树库（Stanford Sentiment Treebank，SST）数据集[128]进行情感分析。[118]对三个任务进行评估：情感分析（IMDB电影评论，Elec[55]，Rotten Tomatoes[102]），文本分类（DBpedia Ontology数据集和RCV1[72]）和语法错误检测（FCE-public[150]）。[130]用真实世界的电子健康记录数据生成了神经医疗状态预测系统的对抗样本。</p><p>许多作品攻击恶意软件检测模型。[43，44]对神经恶意软件检测系统进行攻击，使用DREBIN数据集，其中包含正常和恶意android应用程序[7]。[114]收集正常 windows应用文件，并使用微软恶意软件分类挑战数据集[113]作为恶意部分。[52]从某网站抓取180个程序及相应的行为报告进行恶意软件分析。在抓取的程序中，有70%是恶意软件。[97]以文本分类神经模型为目标，使用四个数据集来评估其攻击方法，分别是姓氏分类数据集、问题分类实验数据[75]、阿拉伯语推文情感分类数据集[1]和IMDB电影评论数据集。[145]将关系提取建模为一个分类问题，目标是预测给定文本提及的实体对之间存在的关系。他们使用了两个关系数据集，NYT数据集[111]和UW数据集[78]。[10]的目标是提高神经网络对联合实体和关系提取的功效。与参考文献[145]中的方法不同，作者将关系提取任务建模为一个多标签头选择（multi-label head selection）问题。他们的工作中使用了四个数据集，ACE04数据集[28]、CoNLL04 EC任务[115]、荷兰房地产分类(DREC)数据集[11]和不良药物事件(ADE)[45]。</p><h3 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h3><p>机器翻译工作在两个数据集上，其中一个使用源语言，另一个是目标语言。</p><p>[12]使用为IWSLT 2016[87]准备的TED talks并行语料来测试NMT系统。它还收集了法语、德语和捷克语料用于生成自然噪声，以建立一个查找表，其中包含可能的词汇替换。这些替换词随后被用于生成对抗样本。[29]也使用了同样的TED talks语料，并使用了德语对英语、捷克语对英语、法语对英语。</p><h3 id="机器理解"><a href="#机器理解" class="headerlink" title="机器理解"></a>机器理解</h3><p>机器理解数据集通常向机器提供上下文文档或段落。基于对上下文的理解，机器理解模型可以回答一个问题。</p><p>Jia和Liang是最早考虑文本对抗的人之一，他们将神经机器理解模型作为目标[54]。他们使用斯坦福答题数据集（SQuAD）来评估他们的攻击对神经机器理解模型的影响。SQuAD是一个被广泛认可的机器理解基准数据集。[142]沿用了前人的工作，也在SQuAD数据集上进行了研究。虽然参考文献[14]的重点是开发一个健壮的机器理解模型，而不是攻击MC模型，但作者使用对抗样本来评估他们提出的系统。他们使用MovieQA多选题回答数据集[134]进行评估。参考文献[19]针对可分化神经计算机(DNC)的攻击，DNC是一种具有DNN的新型计算机。它利用bAbI任务对逻辑问题回答的攻击进行了评估。</p><h3 id="文本摘要"><a href="#文本摘要" class="headerlink" title="文本摘要"></a>文本摘要</h3><p>文本摘要的目标是用简洁的表达方式来概括给定文档或段落的核心意思。参考文献[22]评估了他们对包括文本摘要在内的多种应用的攻击，它使用DUC2003,18 DUC2004,19和Gigaword20来评估对抗样本的有效性。</p><h3 id="文本蕴涵"><a href="#文本蕴涵" class="headerlink" title="文本蕴涵"></a>文本蕴涵</h3><p>文本蕴涵（Textual entailment，TE）的基本任务是判断两个文本片段有指向关系。当认为一个文本片段真实时，可以推断出另一个文本片断的真实性。也就是指，一个文本片段蕴涵了另一个文本片段的知识。可以分别称蕴涵的文本(entailing texts)为文本(text)，被蕴涵的文本(entailed texts)为假设(hypothesis)。文本蕴涵关系不是纯粹的逻辑推理，它的条件更为宽松，可以这样定义：如果一个人读了$t$能够推论$h$<strong>非常可能</strong>是真实的，那么$t$蕴涵 $h$ $(t\Rightarrow h)$。</p><p>[56]在两个entailment数据集上评估了各种模型，Stanford Natural Lauguage Inference（SNLI）[15]和SciTail[58]。[91]也使用了SNLI数据集，还使用了MultiNLI[144]数据集。</p><h3 id="词性标注"><a href="#词性标注" class="headerlink" title="词性标注"></a>词性标注</h3><p>词性标注（Part-of-Speech tagging 或 POS tagging）是指对于句子中的每个词都指派一个合适的词性，也就是要确定每个词是名词、动词、形容词或其他词性的过程，又称词类标注或者简称标注。词性标注是自然语言处理中的一项基础任务，在语音识别、信息检索及自然语言处理的许多领域都发挥着重要的作用。</p><p>[151]采用了参考文献[93]中的方法，通过引入对抗性训练来构建一个更健壮的神经网络，但它将该策略（稍作修改）应用于POS标记。通过对正常和对抗样本的混合训练，作者发现对抗样本不仅有助于提高标记精度，而且有助于下游的依赖性解析任务，在不同的序列标记任务中普遍有效。</p><p>他们在评估中使用的数据集包括：《华尔街日报》（WSJ）部分的Penn Treebank（PTB）[85]和Universal Dependencies（UD）v1.2[99]的树库。</p><h3 id="对话生成"><a href="#对话生成" class="headerlink" title="对话生成"></a>对话生成</h3><p>对话生成（Dialogue Generation）是Siri和Alexa等现实世界虚拟助手的基本组件，它是为用户给出的帖子自动生成响应的文本生成任务。</p><p>[98]是最早攻击对话生成模型的作品之一。它使用Ubuntu对话语料库[82]和动态知识图谱网络与协作通信代理(CoCoA)数据集[47]来评估其两种攻击策略。</p><h3 id="跨模态应用"><a href="#跨模态应用" class="headerlink" title="跨模态应用"></a>跨模态应用</h3><p>[129]使用希拉里-克林顿的电子邮件以图像的形式对OCR系统进行了对抗性实例的评估。它还使用Rotten Tomatoes和IMDB评论数据集对NLP应用进行了攻击。[153]中的工作攻击了为场景文本识别设计的神经网络。作者在三个裁剪字图像识别的标准基准上进行了实验，即街景文本数据集（SVT）[139]ICDAR 2013数据集（IC13）[57]和IIIT 5K字数据集（IIIT5K）[92]。[20]对图像字幕神经模型进行攻击。使用的数据集是微软COCO（MSCOCO）数据集[77]。[148]致力于攻击图像字幕和视觉问题回答的神经模型的问题。对于第一个任务，它使用Visual Genome数据集[64]。对于第二个任务，它使用参考文献[6]中收集和处理的VQA数据集。[125]致力于视觉-语义嵌入（Visual-Semantic Embedding）应用，其中使用了MSCOCO数据集。[18]针对语音识别问题。使用的数据集是Mozilla Common Voice数据集</p><h3 id="多应用"><a href="#多应用" class="headerlink" title="多应用"></a>多应用</h3><p>一些作品将他们的攻击方法改编成不同的应用，即评估他们的方法在不同应用中的可转移性。</p><p>[22]对序列到序列模型进行了攻击。具体来说，它评估了对两个应用的攻击：文本摘要和机器翻译。对于文本摘要，如前所述，它使用了三个数据集DUC2003、DUC2004和Gigaword。对于机器翻译，它采样了一个子集形式WMT’16多模态翻译数据集。参考文献[53]提出了生成句法对抗性的译文，并对情感分析和文本包含应用的攻击进行了评估。它使用SST进行情感分析，使用SICK[86]进行文本缩略。参考文献[157]是一种在神经模型上生成对抗样本的通用方法。研究的应用包括图像分类(MINIST数字图像数据集)、文本缩略(SNLI)和机器翻译。参考文献[93]评估了对五个数据集的攻击，涵盖了情感分析（IMDB电影评论、Elec产品评论、Rotten Tomatoes电影评论）和文本分类（DBpedia本体、RCV1新闻文章）。参考文献[127]的目标是情感分析和视觉问题回答。对于情感分析，它使用Rotten Tomato电影评论和IMDB电影评论数据集。对于视觉问题回答，它在Zhu等人[158]提供的数据集上进行测试。</p><h1 id="五、DEFENSE"><a href="#五、DEFENSE" class="headerlink" title="五、DEFENSE"></a>五、DEFENSE</h1><p>为神经网络生成对抗样本的一个重要目的是利用这些对抗样本来增强模型的鲁棒性[40]。在文本DNN中，有两种常见的方式来实现这一目标：对抗性训练和知识蒸馏。对抗性训练在模型训练过程中加入对抗样本。知识蒸馏则是对神经网络模型进行操作，训练一个新的模型。</p><p>在本节中，我们将介绍一些属于这两个方向的代表性研究。关于机器学习和深度学习模型及应用的更全面的防御策略，请参考参考文献[2，13]。</p><h2 id="对抗性训练"><a href="#对抗性训练" class="headerlink" title="对抗性训练"></a>对抗性训练</h2><h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>数据增强将原始数据扩充以对抗样本，试图在训练阶段令模型接收更多样本的训练。在被攻击的DNN上用对抗样本进行额外训练，用来对抗黑盒攻击。</p><p>[54]的作者试图通过在包含对抗样本的增强数据集上进行训练来增强阅读理解模型。实验表明，数据增强对使用相同对抗样本的攻击是有效的、稳健的。然而，他们的工作也证明了这种增强策略在面对其他类型的对抗样本的攻击时仍然是脆弱的。[142]也有类似的想法来增强训练数据集，但选择了信息量更大的对抗样本。[56]中的工作是用对抗样本来训练text entailment系统，使系统更加健壮。作者提出了三种方法来生成更多具有多样化特征的数据。(1)基于知识的，用几个给定的知识库中提供的超词/同义词（hypernym/hyponym）替换单词;(2)手工制作，在现有的entailment中增加否定词;(3)基于神经模型的，利用seq2seq模型，通过强制执行损失函数来衡量原始假说和预测假说之间的交叉熵来生成entailment实例。在训练过程中，他们采用了生成式对抗网络的思想，训练一个判别器和一个生成器，并在判别器的优化步骤中加入对抗实例。[12]中的工作探索了另一种数据增强的方式。它将平均字符嵌入作为一个词的表示，并将其纳入到输入中。这种方法对字符加扰如swap、mid和Rand等本质上不敏感，因此可以抵御工作中提出的这些加扰攻击造成的噪声。但是，这种防御对其他不扰乱字符命令的攻击无效。</p><p>表5给出了参考文献[54]中对抗性训练的有效性的一个例子。</p><p><img src="/2020/06/02/【论文阅读笔记】Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/adversarial_training_example_table.png" srcset="/img/loading.gif" alt></p><p>作者指出，在对对抗样本进行训练时，需要精心设计对抗样本，以改进模型。从表中两种攻击方法的结果可以看出这一点。</p><h3 id="模型正则化"><a href="#模型正则化" class="headerlink" title="模型正则化"></a>模型正则化</h3><p>模型正则化（Model regularization）强制令对抗样本作为正则项，在训练网络时进行联合优化。</p><script type="math/tex; mode=display">\min \left(J(f(x), y)+\lambda J\left(f\left(x^{\prime}\right), y\right)\right)</script><p>其中$\lambda$是超参数。</p><p>受[40]启发，[93]以线性近似的方式构建对抗式训练，</p><script type="math/tex; mode=display">\begin{array}{c}-\log p\left(\left.y|x+-\epsilon g /||g|\right|_{2}, ; \theta\right) \\g=\partial_{x} \log p(y \mid x ; \hat{\theta})\end{array}</script><p>其中$|g|_{2}$是$L_2$范数正则项，$\theta$是神经网络的参数，$\hat{\theta}$是$\theta$的一份静态拷贝。</p><p>与[40]不同的是，作者以词嵌入的方式进行了对抗生成和训练。此外，他们还扩展了之前关于攻击图像深度神经模型的工作[94]，其中局部分布平滑度（local distribution smoothness, LDS）被定义为两个分布（原始数据和对抗数据）的KL散度的负值。LDS衡量了模型对本地和 “虚拟 “对抗方向的扰动的鲁棒性。对抗样本被计算为模型分布对KL散度最敏感的方向。他们还将这种攻击策略应用在词嵌入上，并通过添加对抗例作为正则器进行对抗性训练。</p><p>[118]中的工作沿用了参考文献[93]的思想，并在LSTM上扩展了对抗性训练。作者沿用了FGSM，将对抗性训练作为正则器加入其中。但为了提升对抗样本的可解释性，即对抗例的词嵌入应该是词汇中的有效词嵌入，他们引入了一个方向向量，将扰动嵌入与有效词嵌入关联起来。</p><p>[145]简单地采用了参考文献[93]中利用的正则器，但将扰动应用于预先训练好的词嵌入，并且应用于不同的任务：关系提取。其他采用参考文献[93]的类似工作还有参考文献[10，118，145，151]。</p><h3 id="鲁棒优化"><a href="#鲁棒优化" class="headerlink" title="鲁棒优化"></a>鲁棒优化</h3><p>鲁棒优化（Robust Optimization）是提升深度学习系统鲁棒性的方法。</p><p>Madry等[84]将DNN模型学习投向min-max(鞍点)公式的鲁棒优化，它是由一个内侧非凹最大化问题(攻击)和一个外侧非凸最小化问题(防御)组成。根据Danskin定理，内侧最大化器处的梯度与min-max问题的下降方向相对应，因此优化仍可应用反向传播进行。该方法通过普遍训练和学习，成功地证明了DNN对对抗性图像的鲁棒性。</p><p>参考文献[3]采用了该思想，并应用在处理离散数据的恶意软件检测DNN上。其学习目标拟定为</p><script type="math/tex; mode=display">\theta^{*}=\arg \min _{\theta} \mathbb{E}_{(x, y) \sim D}\left[\max _{x^{\prime} \in S(x)} L\left(\theta, x^{\prime}, y\right)\right]</script><p>其中，$S(x)$是一组二元指示向量，用于保存恶意软件$x$的功能，$L$为原始分类模型的损失函数，$y$为真实标签，$\theta$为可学习参数，$D$表示数据样本$x$的分布。值得注意的是，本文所提出的鲁棒优化方法是一个通用的框架，在这个框架下，其他的对抗性训练策略都有自然的解释。</p><h2 id="模型蒸馏"><a href="#模型蒸馏" class="headerlink" title="模型蒸馏"></a>模型蒸馏</h2><p>Papernot等人[106]提出了模型蒸馏（distillation）作为另一种可能的对抗性例子的防御方法。其原理是利用原DNN的softmax输出（如classfication DNN中的类概率）来训练第二个DNN，该DNN与原DNN的结构相同。同时通过引入温度参数T来修改原DNN的softmax输出。</p><script type="math/tex; mode=display">q_{i}=\frac{\exp \left(z_{i} / T\right)}{\sum_{k} \exp \left(z_{k} / T\right)}</script><p>其中$z_i$是softmax层的输入，$T$控制着知识压缩的程度，$T=1$时上式退化成普通softmax函数，$T$很大时，$q_i$接近均匀分布；$T$很小时，函数会倾向于输出极值。</p><p>[44]对离散数据上的DNN采用蒸馏防御，并应用高温T，因为高温softmax被证明可以降低模型对小扰动的敏感性[106]。作者用原始数据集的增强和原始DNN的softmax输出训练了第二个DNN。从评价中，他们发现对抗式训练比使用蒸馏法更有效（啊这？）。</p><h1 id="六、DISCUSSIONS-AND-OPEN-ISSUES"><a href="#六、DISCUSSIONS-AND-OPEN-ISSUES" class="headerlink" title="六、DISCUSSIONS AND OPEN ISSUES"></a>六、DISCUSSIONS AND OPEN ISSUES</h1><p>与在DNN上生成图像对抗性例子相比，生成文本对抗性例子的历史相对较短，因为在离散数据上进行扰动，同时保留有效的句法、语法和语义更具挑战性。</p><p>我们在本节中讨论了一些问题，并对未来的发展方向提出了建议。</p><h2 id="可感知性"><a href="#可感知性" class="headerlink" title="可感知性"></a>可感知性</h2><p>可感知性（Perceivability）</p><p>图像像素的扰动通常很难被感知，因此不影响人类的判断，但却能骗过深度神经网络。然而，对文本的扰动是显而易见的，无论扰动是翻转字符还是改变单词。无效词和语法错误很容易被人类识别，也很容易被语法检查软件检测出来，因此这种扰动很难攻击真正的NLP系统。</p><p>然而，许多研究工作都会产生这种类型的对抗性例子。只有在利用对抗性例子来对被攻击的DNN模型进行健壮化的情况下，这种方法才是可以接受的。</p><p>从语义保护的角度来看，改变一个句子中的一个词有时会极大地改变其语义，并且很容易被人类发现。对于NLP的应用，如阅读理解、情感分析等，为了不改变应该的输出，需要精心设计对抗性例子。否则，正确的输出和扰动的输出都会改变，违反了生成对抗性例子的目的。</p><p>只有少数作品考虑了这个约束。因此，对于实际的攻击，我们需要提出一些方法，使扰动不仅无法察觉，而且还能保留正确的语法和语义。</p><h2 id="可迁移性"><a href="#可迁移性" class="headerlink" title="可迁移性"></a>可迁移性</h2><p>可迁移性（Transferability）是对抗样本的普遍性质。它反映了攻击算法的泛化能力（通用性）。可迁移性的含义为，算法为一个模型生成的对抗样本也能影响另外一个模型（即跨模型泛化）或影响另外一个数据集（即跨数据泛化）的能力。由于深度神经网络的细节对攻击方法影响不大，因此这一特性在黑盒攻击中更常被利用。也有研究证明[81]无目标攻击生成的对抗样本比目标攻击生成的样本更具可迁移性。</p><p>可迁移性可以从三个层次来度量：(i)相同架构，不同数据；(ii)不同架构，相同应用；(iii)不同架构，不同数据[154]。虽然目前关于文本攻击的工作涵盖了这三个层次，但与原模型相比，转移攻击另一个模型表现的算法性能仍然大幅下降，即泛化能力差。</p><h2 id="自动化程度"><a href="#自动化程度" class="headerlink" title="自动化程度"></a>自动化程度</h2><p>在白盒攻击中，利用DNN的损失函数可以自动识别文本中受影响最大的点（如字符、单词），然后对这些点进行攻击，自动修改相应的文本。在黑盒攻击中，有些攻击，如 “替换”操作会训练一个替换的DNN，并对替换的DNN应用白盒攻击策略。以上操作都可以自动实现。</p><p>然而，大多数其他作品都是以人工的方式制作对抗性例子。例如[54]将人工选择的无意义段落进行连接，以愚弄阅读理解系统，发现被攻击的DNN的漏洞。很多研究工作都效仿[54]，不以实际攻击为目的，更多的是研究目标网络的健壮性。<strong>这些手工工作既耗时又不实用</strong>。</p><h2 id="新架构"><a href="#新架构" class="headerlink" title="新架构"></a>新架构</h2><p>虽然大多数常见的文本DNN已经从对抗性攻击的角度得到了关注，但许多DNN至今没有受到攻击，例如生成式神经模型：生成式对抗网络（GANs）和变异自动编码器（VAEs）。在NLP中，它们被用来生成文本。深度生成模型需要更复杂的技能进行模型训练。这将解释这些技术到目前为止主要被对抗性攻击所忽视。未来的工作可以考虑为这些生成式DNN生成对抗性的例子。</p><p>另一个例子是可分化神经计算机（DNC）。到目前为止，只有一项工作对DNC进行了攻击[19]。</p><p>注意力机制以某种方式成为大多数顺序模型中的标准组件。但一直没有研究该机制本身的工作。相反，作品要么是攻击包含注意力的整体系统，要么是利用注意力分数来识别扰动的词[14]。</p><h2 id="迭代生成-vs-一次生成"><a href="#迭代生成-vs-一次生成" class="headerlink" title="迭代生成 vs. 一次生成"></a>迭代生成 vs. 一次生成</h2><p>迭代攻击根据被攻击的DNN模型输出的梯度反复搜索和更新扰动。因此，它表现出较高的质量和有效性。也就是说，扰动可以足够小，难以防御。</p><p>然而，这些方法通常需要很长的时间来寻找合适的扰动，为实时攻击带来了障碍。因此，有人提出一次性攻击来解决这个问题。FGSM[40]就是一次性攻击的一个例子。直观地讲，一次性攻击比迭代攻击快得多，但效果较差，而且容易被防御[153]。当在实际应用上设计攻击方法时，攻击者需要仔细考虑攻击的效率和效果之间的权衡。</p><h1 id="七、CONCLUSION"><a href="#七、CONCLUSION" class="headerlink" title="七、CONCLUSION"></a>七、CONCLUSION</h1><p>本文首次在深度神经网络上生成文本对抗性实例的方向上进行了全面的调查。</p><p>我们回顾了最近的研究工作，并制定分类方案来整理现有的文献。</p><p>此外，我们还从不同方面对其进行了总结和分析。</p><p>我们试图为研究人员提供一个很好的参考，以深入了解该研究课题中的挑战、方法和问题，并对未来的发展方向有所启示。</p><p>我们希望在了解对抗性攻击的基础上，提出更多稳健的深度神经模型。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文总结了常见的nlp领域的对抗样本生成及攻击方法。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="Adversarial Attacks" scheme="https://superlova.github.io/tags/Adversarial-Attacks/"/>
    
      <category term="survey" scheme="https://superlova.github.io/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】 Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/</id>
    <published>2020-06-02T06:02:29.000Z</published>
    <updated>2020-06-26T17:30:26.814Z</updated>
    
    <content type="html"><![CDATA[<p>通过模糊测试的方法进行数据增强，数据增强新思路。新加坡国立大学作品，被ICSE’2020接收。<br><a id="more"></a></p><h1 id="内容概要"><a href="#内容概要" class="headerlink" title="内容概要"></a>内容概要</h1><ul><li>增强DNN的训练数据，从而增强其鲁棒性</li><li>将DNN数据扩充问题视为优化问题</li><li>使用遗传搜索来生成最合适的输入数据变体，用于训练DNN</li><li>学习识别跳过增强来加速训练</li><li>improve the robust accuracy of the DNN</li><li>reduce the average DNN training time by 25%, while still improving robust accuracy</li></ul><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>过拟合产生的问题：</p><ol><li>泛化性降低，测试集效果差；</li><li>鲁棒性不足，不能抵御样本微小扰动</li></ol><p>鲁棒性有两种：</p><ol><li>对抗鲁棒性，应对的是人为构造的扰动；</li><li>自然扰动鲁棒性，应对自然条件的变化。</li></ol><p>本文关注的是后一种鲁棒，采用数据增强手段模拟不同自然条件下的样本变化</p><h2 id="数据增强：传统软件"><a href="#数据增强：传统软件" class="headerlink" title="数据增强：传统软件"></a>数据增强：传统软件</h2><p>improves the generalization of generated programs by augmenting existing test suites</p><p>测试用例生成技术：随机测试，基于搜索的进化测试，符号执行，灰箱模糊测试等</p><p>AFL：涵盖更多的程序路径使我们能够找到代表性的测试并涵盖更多的程序功能</p><h2 id="数据增强：提升模型鲁棒性——研究现状"><a href="#数据增强：提升模型鲁棒性——研究现状" class="headerlink" title="数据增强：提升模型鲁棒性——研究现状"></a>数据增强：提升模型鲁棒性——研究现状</h2><p>基于梯度下降的鲁棒优化：</p><ul><li>尝试根据损失函数生成最差的变体，并将其添加到训练集中。</li><li>在自然环境变化（对于视觉应用）中突出显示的空间变换的输入空间是高度非凸的</li></ul><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-10-37.png" srcset="/img/loading.gif" alt></p><p>几乎所有用于提高鲁棒性的技术都会通过分析训练后的模型并随后生成对抗性示例在新数据上重新训练模型</p><h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ul><li>将数据扩充形式化为优化问题，利用模糊测试（遗传算法）求解</li><li>提出选择性扩充策略，仅选择部分数据点进行扩充</li></ul><h1 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h1><h2 id="模糊测试"><a href="#模糊测试" class="headerlink" title="模糊测试"></a>模糊测试</h2><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-11-29.png" srcset="/img/loading.gif" alt></p><h2 id="Robustness-of-DNN"><a href="#Robustness-of-DNN" class="headerlink" title="Robustness of DNN"></a>Robustness of DNN</h2><p>DNN很容易遭受微小扰动的影响，产生完全不同的决策。DNN抵御输入扰动的能力被认为是鲁棒性。</p><p>由于这项工作聚焦于自然生成的而不是人工合成的扰动，因此像GAN等技术不被考虑在内。</p><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>数据增强是一种扩充数据集、避免样本少导致过拟合的有效方法。增强效果受增强方法影响很大。一般认为数据增强后训练的模型鲁棒性能得到一定程度的提升。</p><h1 id="SENSEI工具"><a href="#SENSEI工具" class="headerlink" title="SENSEI工具"></a>SENSEI工具</h1><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>生成增强样本的过程，是多目标优化过程。</p><p>一方面求扰动δ，使得损失函数L最大；另一方面求模型参数θ，使损失函数L最小；求得此时的δ和θ。本质是一个二元优化找鞍点的问题。</p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-20-58.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-21-07.png" srcset="/img/loading.gif" alt></p><h2 id="优化思路"><a href="#优化思路" class="headerlink" title="优化思路"></a>优化思路</h2><p>基于模糊测试的方法（如引导搜索）能更有效地找到要训练的数据点的最佳Mutator，从而提高鲁棒性</p><p>并非训练数据集中的所有数据点都很难学习。一些数据点代表训练集中的理想示例，而另一些则令人困惑；</p><p>对所有这些点进行相同的处理可能会浪费宝贵的训练时间。因此仅在具有挑战性的数据点上花费扩充工作。</p><h2 id="整体算法"><a href="#整体算法" class="headerlink" title="整体算法"></a>整体算法</h2><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-21-37.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-21-43.png" srcset="/img/loading.gif" alt></p><p>Optimal Augmentation Module<br>选择最难的样本（L13~16）<br>Selective Augmentation Module<br>跳过突变不大的样本（L10~12,17）<br>数据增强过程是在训练时即时发生的</p><h2 id="遗传算法部分"><a href="#遗传算法部分" class="headerlink" title="遗传算法部分"></a>遗传算法部分</h2><p>将染色体表示为一组操作，该操作将应用于给定输入以获得真实的变化</p><p>将x旋转1度，然后将其平移一个像素，模拟相机在现实生活中的角度和移动，来得出图像（x）的真实变化（x’）</p><p>种群是代表当前解决方案子集的一组染色体</p><p>种群由两个遗传算子组成：突变和杂交</p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-22-47.png" srcset="/img/loading.gif" alt></p><p>通过合并两个随机选择的现有染色体来完成交叉以创建新染色体</p><ul><li>c1 = {旋转：1，平移：2，剪切：-0.15}和</li><li>c2 = {旋转：-1，平移：-3，剪切：0.1}</li><li>C = {旋转：1, 平移：-3，剪切：0.1}</li></ul><p>杂交算子在1和染色体长度（l）之间生成随机数r，取c1的1到r部分，与c2的r+1到l部分拼合成新的染色体</p><p>突变算子通过随机改变染色体中的单个操作（改变参数）来执行突变。</p><p>始终将生成的转换向量（染色体）应用于原始图像（而不是应用于已转换的数据），以防止生成的数据不真实</p><p>生成新种群后，将对其进行评估，并且仅将最佳集合作为当前种群传递给下一代（原算法L17）</p><p>适应度函数的设计在GA中起着重要作用，以测量给定解决方案的质量<br>根据DNN的经验损失定义适应度函数</p><script type="math/tex; mode=display">f_{\text {loss}}\left(x^{\prime}\right)=L\left(\theta, x^{\prime}, y\right)</script><p>在DNN的增强训练中应使用遭受DNN损失更大的变体，以使DNN更加健壮</p><h2 id="选择性增强"><a href="#选择性增强" class="headerlink" title="选择性增强"></a>选择性增强</h2><p>Sensei-SA会跳过已由M鲁棒分类的数据点<br>基于分类的鲁棒性：模型正确地分类了x和所有未改变类别的Mutator（x′）<br>基于损失的鲁棒性：x的预测损失或未改变类别（x’）的任何预测损失不大于损失阈值</p><p>如果种子是鲁棒的，则Sensei-SA不会对其进行数据增强；除非在随后的训练中将种子错误地分类，或预测损失小于阈值</p><h2 id="图像扰动"><a href="#图像扰动" class="headerlink" title="图像扰动"></a>图像扰动</h2><p>仿射变换操作、像素操作<br>旋转（x，d）：在[-30，30]范围内将x旋转d度。<br>平移（x，d）：在图像大小的[-10％，10％]范围内水平或垂直将x按d像素平移。<br>剪切（x，d）：水平剪切x，剪切因子d在[-0.1，0.1]范围内。<br>缩放（x，d）：以[0.9,1.1]的缩放系数d放大/缩小x<br>亮度（x，d）：在[-32，32]范围内为x的每个像素统一加减一个值<br>对比度（x，d）：将x的每个像素的RGB值按[0.8，1.2]范围内的因子d缩放。</p><h2 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h2><p>鲁棒性精度（robust accuracy）是指测试集中DNN的预测不随任何小的现实扰动而改变的图像比例</p><script type="math/tex; mode=display">\text {robust accuracy}=\frac{\text {nRobustInstances}}{\text {nInstances}}</script><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><h2 id="1-Sensei是否可以有效解决鞍点问题？"><a href="#1-Sensei是否可以有效解决鞍点问题？" class="headerlink" title="1.Sensei是否可以有效解决鞍点问题？"></a>1.Sensei是否可以有效解决鞍点问题？</h2><p>关键是检查Sensei是否确实有效比最先进的技术更有效地找到损耗最大的变体<br>W-10在每一步为每个图像随机生成十个扰动，并用模型表现最差的图像替换原始图像<br>结果表明，Sensei更有效地解决了内部最大化问题<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-26-16.png" srcset="/img/loading.gif" alt></p><h2 id="2-Sensei是否比基于对抗样本再训练方法表现更好"><a href="#2-Sensei是否比基于对抗样本再训练方法表现更好" class="headerlink" title="2.Sensei是否比基于对抗样本再训练方法表现更好"></a>2.Sensei是否比基于对抗样本再训练方法表现更好</h2><p>对抗样本再训练方法：<br>i）使用原始训练数据训练模型；<br>ii）通过我们的转换（即使DNN蒙混的变体）生成对抗性示例；<br>iii）选择最佳对抗性示例，添加训练数据，然后重新训练5个模型</p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-26-58.png" srcset="/img/loading.gif" alt></p><h2 id="3-Sensei能否提高鲁棒性同时保持精度"><a href="#3-Sensei能否提高鲁棒性同时保持精度" class="headerlink" title="3.Sensei能否提高鲁棒性同时保持精度"></a>3.Sensei能否提高鲁棒性同时保持精度</h2><p>mixup 是一种数据增强方法。mixup和Sensei都总体上改善了泛化性能。实际上，在标准泛化方面，mixup比Sensei更好；但是，在改善现实世界中自然发生的Mutator的鲁棒性方面，mixup效果不佳。<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-27-21.png" srcset="/img/loading.gif" alt></p><h2 id="4-选择性数据增强（-Sensei-SA-）的效果和效率"><a href="#4-选择性数据增强（-Sensei-SA-）的效果和效率" class="headerlink" title="4.选择性数据增强（ Sensei-SA ）的效果和效率"></a>4.选择性数据增强（ Sensei-SA ）的效果和效率</h2><p>与W-10相比，Sensei-SA减少了25％的训练时间，而鲁棒性则提高了3％。<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-27-38.png" srcset="/img/loading.gif" alt></p><h2 id="5-对超参数的敏感程度"><a href="#5-对超参数的敏感程度" class="headerlink" title="5.对超参数的敏感程度"></a>5.对超参数的敏感程度</h2><p>突变体集合规模最好为10~15</p><p>神经元覆盖率在鲁棒性评估方面表现出与损失函数相似的性能</p><p>基于神经元覆盖的适应度函数比基于损失的适应度函数将训练时间增加了50％。 原因是神经元覆盖率的计算比训练损失要昂贵<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-27-55.png" srcset="/img/loading.gif" alt><br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-28-00.png" srcset="/img/loading.gif" alt></p><p>在判断样本鲁棒性上，基于损失的选择均优于基于分类的选择。</p><p>基于损失的选择足以跳过足够数量的数据点，从而平均减少25％的训练时间。<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-28-12.png" srcset="/img/loading.gif" alt></p><p>Loss threshold越大，训练时间越短，然而鲁棒准确性也下降</p><p>Cifar10数据集比其他数据集对loss threshold更为敏感<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-28-22.png" srcset="/img/loading.gif" alt></p><h1 id="Threads-to-Validity"><a href="#Threads-to-Validity" class="headerlink" title="Threads to Validity"></a>Threads to Validity</h1><p>our results may not generalize to other datasets, or models, or for other applications</p><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><h2 id="测试充足性指标"><a href="#测试充足性指标" class="headerlink" title="测试充足性指标"></a>测试充足性指标</h2><ul><li>DeepXplore，Neuron Coverage</li><li>DeepGauge，k截面神经元覆盖率和神经元边界覆盖率</li><li>惊奇度 surprise adequacy</li><li>MODE，执行状态差分分析以识别模型的错误特征，然后在此基础上执行训练输入选择</li></ul><h2 id="测试用例生成"><a href="#测试用例生成" class="headerlink" title="测试用例生成"></a>测试用例生成</h2><ul><li>对抗性测试，有选择地修改几个像素，将对抗性实例的生成建模为优化问题，并使用一阶优化算法解决优化问题。生成机器学习也可以用来生成对抗性输入</li><li>但是对于自然产生的变化（旋转和平移等），由于其变换非凸，不利于一阶优化</li><li>TensorFuzz，不适合我们的数据增强驱动的鲁棒性训练目标</li><li>DeepTest和DeepRoad，通过metamorphic testing来生成暴露DNN bug的测试用例</li></ul><h2 id="测试合并策略，Test-incorporation-strategy"><a href="#测试合并策略，Test-incorporation-strategy" class="headerlink" title="测试合并策略，Test incorporation strategy"></a>测试合并策略，Test incorporation strategy</h2><ul><li>绝大多数DNN测试用例生成技术首先使用经过训练的DNN生成测试（或对抗实例），然后使用它们重新训练DNN，以提高其准确性或健壮性。</li><li>AutoAugment ，使用强化学习在搜索空间中找到最佳的扩增策略，从而使神经网络达到最高精度</li><li>Mixup，是最近提出的最先进的数据增强技术，但是在良性变异中，鲁棒性不佳。</li><li>Engstrom，除了没用遗传算法之外都一样</li></ul><h2 id="稳健性模型，Robust-models"><a href="#稳健性模型，Robust-models" class="headerlink" title="稳健性模型，Robust models"></a>稳健性模型，Robust models</h2><ul><li>基于正则化的白盒方法，通过修改DNN损失函数，并在标准经验损失中加入一个不变量来正则化，提高深度神经网络模型的鲁棒性</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过模糊测试的方法进行数据增强，数据增强新思路。新加坡国立大学作品，被ICSE’2020接收。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Fuzz Testing" scheme="https://superlova.github.io/tags/Fuzz-Testing/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91EDA-Easy-Data-Augmentation-Techniques-for-Boosting-Performance-on-Text-Classification-Tasks/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91EDA-Easy-Data-Augmentation-Techniques-for-Boosting-Performance-on-Text-Classification-Tasks/</id>
    <published>2020-06-02T06:01:54.000Z</published>
    <updated>2020-06-02T06:50:44.567Z</updated>
    
    <content type="html"><![CDATA[<p>这篇论文介绍了一个文本领域的数据增强工具，提出了一些数据增强方法。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇论文介绍了一个文本领域的数据增强工具，提出了一些数据增强方法。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="Text Classification" scheme="https://superlova.github.io/tags/Text-Classification/"/>
    
  </entry>
  
  <entry>
    <title>Datawhale——SVHN——Task05：模型集成</title>
    <link href="https://superlova.github.io/2020/06/02/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task05%EF%BC%9A%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90/"/>
    <id>https://superlova.github.io/2020/06/02/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task05%EF%BC%9A%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90/</id>
    <published>2020-06-02T02:18:31.000Z</published>
    <updated>2020-06-03T00:37:16.358Z</updated>
    
    <content type="html"><![CDATA[<p>三个臭皮匠，顶个诸葛亮。<br><a id="more"></a></p><h2 id="1-集成学习"><a href="#1-集成学习" class="headerlink" title="1. 集成学习"></a>1. 集成学习</h2><p>集成学习的一般结构，是首先产生一组“个体学习器”，再用<strong>某种策略</strong>将其结合起来。类似于“三个臭皮匠，顶个诸葛亮”的思想。</p><p><img src="/2020/06/02/Datawhale——SVHN——Task05：模型集成/2020-06-02-22-32-43.png" srcset="/img/loading.gif" alt></p><p>如果自己的<strong>个体学习器</strong>性能不是很令人满意，使用集成学习将能够提升一定的性能，集成学习器一般都能够获得比个体学习器要好的效果。</p><p>集成学习效果要提升，要尽可能满足两个条件：</p><ol><li>个体学习器性能不太差；</li><li>个体学习器之间不能太相似，结构、所用数据差异越大越好。</li></ol><p>可以证明，如果个体学习器之间的决策误差不存在关联，决策相互独立，那么随着个体学习器数量的增多，集成学习器的错误率将指数下降。</p><p>根据个体学习器的生成方式，目前的集成学习方法分成两大类：</p><ol><li>个体学习器之间存在强依赖关系、必须串行生成的序列化方法，代表为Boosting；</li><li>学习器之间不存在强依赖关系、可以并行的方法，代表为Bagging和随机森林。</li></ol><p>集成学习只能在一定程度上提高精度，并需要耗费较大的训练时间。具体的集成学习方法需要与验证集划分方法结合。</p><h3 id="1-1-Boosting"><a href="#1-1-Boosting" class="headerlink" title="1.1 Boosting"></a>1.1 Boosting</h3><p>Boosting算法是一类能将弱学习器提升为强学习器的算法。基本思想是：先利用初始训练集训练一个基本学习器，再基于基本学习器的表现，对训练样本做出调整，改变样本分布，使得先前被分类错误的训练样本在随后受到更多关注。如此重复训练，直到基学习器的数目达到指定的数值。最终将这几个基学习器进行加权结合。</p><h3 id="1-2-Bagging"><a href="#1-2-Bagging" class="headerlink" title="1.2 Bagging"></a>1.2 Bagging</h3><p>欲得到泛化性能强的集成学习模型，个体学习器之间应当相互独立。但是完全独立是做不到的，即便模型架构完全不同、训练数据完全不一样，这些个体学习器也是为了解决同一个任务而训练的，训练数据之间肯定存在关系，从而导致模型的决策存在相关性。因此Bagging算法就是想要尽可能提升个体学习器之间的差异性。</p><p>一种可能的做法是对训练样本进行采样，产生若干个不同的子集，每个子集都训练一个个体学习器。但是这样学习得到的个体学习器都没能获得足够的训练样本，因此我们可以进行折中，采用互相存在交集的分割方法分割数据集，然后训练模型。</p><p>随机森林本质上是许多决策树的集合，其中每棵树都和其他树略有不同。随机森林背后的思想是，每棵树的预测可能都相对较好，但可能对部分数据过拟合。如果构造很多树，并且每棵树的预测都很好，但都以不同的方式过拟合，那么我们可以对这些树的结果取平均值来降低过拟合。既能减少过拟合又能保持树的预测能力，这可以在数学上严格证明。</p><h2 id="2-深度学习中的集成方法"><a href="#2-深度学习中的集成方法" class="headerlink" title="2. 深度学习中的集成方法"></a>2. 深度学习中的集成方法</h2><h3 id="2-1-Dropout"><a href="#2-1-Dropout" class="headerlink" title="2.1 Dropout"></a>2.1 Dropout</h3><p>每个训练批次中，在更新权重之前，随机让一部分的节点停止工作，增加模型训练时的精度提升难度。</p><p><img src="/2020/06/02/Datawhale——SVHN——Task05：模型集成/2020-06-02-23-33-21.png" srcset="/img/loading.gif" alt></p><p>需要注意的是，训练的时候加dropout，测试的时候以及实际使用时，是不需要dropout的。这就像平时训练的时候腿上绑上沙袋，战时就能够获得更卓越的效果。有效的缓解模型过拟合</p><p><img src="/2020/06/02/Datawhale——SVHN——Task05：模型集成/2020-06-02-23-36-15.png" srcset="/img/loading.gif" alt></p><p>直观来讲，Dropout法使得每个节点都无法单纯依赖其他节点而滥竽充数，因为随时随地自己的同伴就可能被dropout。这样训练时，每个节点都会学到更多的知识。从而提升整体学习器的性能。因此这也算是集成学习。</p><h3 id="2-2-测试集数据扩增"><a href="#2-2-测试集数据扩增" class="headerlink" title="2.2 测试集数据扩增"></a>2.2 测试集数据扩增</h3><p>测试集数据扩增（Test Time Augmentation，简称TTA）也是常用的集成学习技巧，数据扩增不仅可以在训练时候用，而且可以同样在预测时候进行数据扩增，对同一个样本预测三次，然后对三次结果进行平均。</p><h2 id="3-结果后处理"><a href="#3-结果后处理" class="headerlink" title="3. 结果后处理"></a>3. 结果后处理</h2><ul><li>统计图片中每个位置字符出现的频率，使用规则修正结果；</li><li>单独训练一个字符长度预测模型，用来预测图片中字符个数，并修正结果。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;三个臭皮匠，顶个诸葛亮。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="datawhale" scheme="https://superlova.github.io/tags/datawhale/"/>
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Ensemble" scheme="https://superlova.github.io/tags/Ensemble/"/>
    
      <category term="Boosting" scheme="https://superlova.github.io/tags/Boosting/"/>
    
      <category term="Bagging" scheme="https://superlova.github.io/tags/Bagging/"/>
    
  </entry>
  
  <entry>
    <title>numpy拼合数组方法大全</title>
    <link href="https://superlova.github.io/2020/06/01/numpy%E6%8B%BC%E5%90%88%E6%95%B0%E7%BB%84/"/>
    <id>https://superlova.github.io/2020/06/01/numpy%E6%8B%BC%E5%90%88%E6%95%B0%E7%BB%84/</id>
    <published>2020-06-01T08:39:58.000Z</published>
    <updated>2020-06-02T04:23:43.383Z</updated>
    
    <content type="html"><![CDATA[<p>numpy的一大特色就是其内部的矩阵向量运算。矩阵之间的拼接方法，你掌握多少？<br><a id="more"></a></p><h2 id="1-append拼接"><a href="#1-append拼接" class="headerlink" title="1. append拼接"></a>1. append拼接</h2><p>我们都知道对于Python原生列表list来说，append是最方便的添加元素的方法，一句list.append(elem)就能在列表最后添加一个元素。</p><p>在numpy中，append也是一个直观且好用的方法，np.append(A,B)能够直接拼合两个ndarray数组。</p><p>首先我们新建两个三维数组，一个全为零，一个全为一。</p><pre><code class="lang-python">C = np.zeros((2,2,2))D = np.ones((2,2,2))print(&quot;C: &quot;, C, C.shape)print(&quot;D: &quot;, D, D.shape)C:  [[[0. 0.]  [0. 0.]] [[0. 0.]  [0. 0.]]] shape=(2, 2, 2)D:  [[[1. 1.]  [1. 1.]] [[1. 1.]  [1. 1.]]] shape=(2, 2, 2)</code></pre><p>然后我们采用不同的方法将其拼合在一起。</p><p>首先是append(C,D)这种直观的方法，可以看到C和D都被展开成了一维。</p><pre><code class="lang-python">np.append(C,D)array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])</code></pre><p>在很多时候我们希望数组拼接时能够保持原有的维度，按照行拼接/列拼接/其他维度拼接。此时只需要改动append的参数axis即可。</p><pre><code class="lang-python">np.append(C,D,axis=0)array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.append(C,D,axis=1)array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])np.append(C,D,axis=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><p>对于三维数组，axis=0为层，axis=1为行，axis=2为列。这不难理解，因为确定单位数组中元素位置的坐标就是(层，行，列)</p><h2 id="2-concatenate拼接"><a href="#2-concatenate拼接" class="headerlink" title="2. concatenate拼接"></a>2. concatenate拼接</h2><p>concatenate从字面意义上就让人明白这个函数专门负责数组拼接。不仅仅是两个，还可以负责多个数组一起拼接。理论上来说concatenate的速度和内存消耗都比append要小，但我并没有实际做实验验证。</p><pre><code class="lang-python">np.concatenate((C,D)) # default axis=0array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.concatenate((C,D), axis=1) # =np.append(C,D,axis=1)array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])</code></pre><h2 id="3-stack系列"><a href="#3-stack系列" class="headerlink" title="3. stack系列"></a>3. stack系列</h2><p>stack系列函数包括np.stack/hstack/vstack/dstack/column_stack/row_stack，顾名思义，hstack是按照横向拼接，vstack竖着拼接，dstack则是层叠数组。其实我最烦这种抽象描述了，因为二维数组和三维数组/高维数组的抽象描述根本不一致，还是axis好。不明白axis的同学可以看<a href="https://superlova.github.io/2020/05/19/numpy%E4%B8%ADaxis%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/">这篇文章</a>。</p><pre><code class="lang-python">np.hstack((C,D)) # = np.append(C,D,axis=1) = np.column_stack()array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])np.vstack((C,D)) # =np.append(C,D,axis=0) = np.row_stack()array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.dstack((C,D)) # =np.append(C,D,aixs=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><h2 id="4-np-r"><a href="#4-np-r" class="headerlink" title="4. np.r_[]"></a>4. np.r_[]</h2><p>神奇的numpy总能给出神奇的解法。np.r_是构建数组/拼合数组的最简便写法，但不一定是好理解的。这种写法和之前写的append没什么不同，但是更加简洁。你也可以使用np.r_做出更加复杂的功能。</p><p>一言以蔽之，np.r_[]表达式能够快速使得多个在中括号里面的array/array切片，按照axis=0拼接起来。</p><p>np.r_[]存在两种使用情况：</p><ol><li>如果中括号内部是由若干逗号(comma,)分隔的array，就将他们按照axis=0拼接起来。</li><li>如果中括号内部包括矩阵切片(slices)或者标量(scalars)，就将他们全部变成一维数组首尾相接。</li></ol><p><strong>注意：</strong></p><ul><li>中括号<code>[3:6:1]</code>内部代表的切片，其含义相当于<code>np.arange(3,6,1)</code>，即在<code>[3,6)</code>范围内，从3开始走一步取一个元素，也就是<code>[3,4,5]</code>。</li><li>中括号<code>[0:5:3j]</code>在最后加了字母<code>j</code>，相当于<code>np.linspace(0,5,3,endpoint=True)</code>，在<code>[0,5]</code>范围内，均匀地取三个元素。</li></ul><pre><code class="lang-python">np.r_[C,D] # =np.append(C,D,axis=0)array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.r_[0:10:3, 0:5:4j]array([0.        , 3.        , 6.        , 9.        , 0.        ,       1.66666667, 3.33333333, 5.        ])</code></pre><p>在中括号内，如果最开始是一个<strong>特定的字符串</strong>，np.r_会试图根据字符串的含义，改变其输出格式。</p><ul><li><code>np.r_[&#39;r&#39;, index_expression]</code>和<code>np.r_[&#39;c&#39;, index_expression]</code>将输出从array类型转变成matrix类型。<code>np.r_[&#39;c&#39;, index_expression]</code>会把一维index_expression组装成N*1的列向量。</li></ul><pre><code class="lang-python">np.r_[&quot;r&quot;, 0:10:3, 0:5:4j]matrix([[0.        , 3.        , 6.        , 9.        , 0.        ,         1.66666667, 3.33333333, 5.        ]])np.r_[&quot;c&quot;, 0:10:3, 0:5:4j]matrix([[0.        ],        [3.        ],        [6.        ],        [9.        ],        [0.        ],        [1.66666667],        [3.33333333],        [5.        ]])</code></pre><ul><li><code>np.r_[&quot;n&quot;, index_expression]</code>前面字符串是整数，则拼接时将会按照axis=n进行拼接。</li></ul><pre><code class="lang-python">np.r_[&quot;-1&quot;,C,D]array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><h2 id="5-np-c"><a href="#5-np-c" class="headerlink" title="5. np.c_"></a>5. np.c_</h2><p>在日常使用时，我们经常需要按照最后一个维度拼合两个数组，也就是np.r_[‘-1’,index_expression]。此时我们可以直接使用<code>np.c_[]</code></p><pre><code class="lang-python">np.c_[C,D] # =np.append(C,D,axis=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])np.c_[0:10:3, 0:5:4j]array([[0.        , 0.        ],       [3.        , 1.66666667],       [6.        , 3.33333333],       [9.        , 5.        ]])</code></pre><p>关于numpy中的<code>np.c_</code>和<code>np.r_</code>相关知识，可以参考<a href="https://numpy.org/devdocs/reference/generated/numpy.r_.html#numpy.r_" target="_blank" rel="noopener">官方文档</a>，里面有关于中括号前参数的详细解释。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;numpy的一大特色就是其内部的矩阵向量运算。矩阵之间的拼接方法，你掌握多少？&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="array" scheme="https://superlova.github.io/tags/array/"/>
    
      <category term="numpy" scheme="https://superlova.github.io/tags/numpy/"/>
    
      <category term="concatenate" scheme="https://superlova.github.io/tags/concatenate/"/>
    
  </entry>
  
</feed>
