<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Superlova</title>
  
  <subtitle>Welcome...</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://superlova.github.io/"/>
  <updated>2020-06-22T15:08:24.958Z</updated>
  <id>https://superlova.github.io/</id>
  
  <author>
    <name>Superlova</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【论文阅读笔记】DeepCT: Tomographic Combinatorial Testing for Deep Learning Systems</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91DeepCT-Tomographic-Combinatorial-Testing-for-Deep-Learning-Systems/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91DeepCT-Tomographic-Combinatorial-Testing-for-Deep-Learning-Systems/</id>
    <published>2020-06-20T04:13:28.000Z</published>
    <updated>2020-06-22T15:08:24.958Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91DeepTest-Automated-Testing-of-Deep-Neural-Network-driven-Autonomous-Cars/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91DeepTest-Automated-Testing-of-Deep-Neural-Network-driven-Autonomous-Cars/</id>
    <published>2020-06-20T04:12:52.000Z</published>
    <updated>2020-06-22T15:08:51.094Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Deep-Gauge-Multi-Granularity-Testing-Criteria-for-Deep-Learning-Systems/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Deep-Gauge-Multi-Granularity-Testing-Criteria-for-Deep-Learning-Systems/</id>
    <published>2020-06-20T04:11:58.000Z</published>
    <updated>2020-06-22T15:08:04.455Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】DeepXplore: Automated Whitebox Testing of Deep Learning Systems</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91DeepXplore-Automated-Whitebox-Testing-of-Deep-Learning-Systems/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91DeepXplore-Automated-Whitebox-Testing-of-Deep-Learning-Systems/</id>
    <published>2020-06-20T04:09:20.000Z</published>
    <updated>2020-06-22T15:08:39.243Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】Fuzzing: A Survey</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzzing-A-Survey/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzzing-A-Survey/</id>
    <published>2020-06-20T03:59:40.000Z</published>
    <updated>2020-06-26T17:04:36.951Z</updated>
    
    <content type="html"><![CDATA[<p>2018年CyberSecurity收录的一篇关于软件测试中模糊测试的综述。作者来自清华大学。文章名越短越霸气。<br><a id="more"></a></p><blockquote><p>警告！本文在写作过程中大量使用了谷歌翻译。</p></blockquote><h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>模糊测试几乎不需要了解目标，并且可以轻松扩展到大型应用程序，因此已成为最受欢迎的漏洞发现解决方案</p><p>模糊的随机性和盲目性导致发现错误的效率低下</p><p>反馈驱动的模糊模式（feedback-driven fuzzing mode）和遗传算法（genetic algorithms）的结合提供了更灵活和可自定义的模糊框架，并使模糊过程更加智能和高效。</p><h1 id="二、背景"><a href="#二、背景" class="headerlink" title="二、背景"></a>二、背景</h1><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-26-22-37-23.png" srcset="/img/loading.gif" alt></p><h2 id="1-静态分析"><a href="#1-静态分析" class="headerlink" title="1.静态分析"></a>1.静态分析</h2><p>静态分析（Static Analysis）是对在没有实际执行程序的情况下执行的程序的分析。</p><p>通常对源代码执行静态分析，有时还对目标代码执行静态分析。通过分析词法，语法，语义特征以及数据流分析，模型检查，静态分析，可以检测到隐藏的错误。</p><p>静态分析的优点是检测速度快。</p><p>由于缺乏易于使用的漏洞检测模型，因此静态分析工具容易产生大量误报。因此，确定静态分析的结果仍然是一项艰巨的工作。</p><h2 id="2-动态分析"><a href="#2-动态分析" class="headerlink" title="2.动态分析"></a>2.动态分析</h2><p>动态分析（Dynamic Analysis）与静态分析相比，分析人员需要在实际系统或仿真器中执行目标程序。</p><p>通过监视运行状态并分析运行时知识，动态分析工具可以精确地检测程序错误。</p><p>动态分析的优点是精度高，缺点是速度慢，效率低，对测试人员的技术水平要求高，可扩展性差，并且难以进行大规模测试。</p><h2 id="3-符号执行"><a href="#3-符号执行" class="headerlink" title="3.符号执行"></a>3.符号执行</h2><p>符号执行（Symbolic Execution）是另一种发现漏洞的技术。</p><p>通过符号化程序输入，符号执行为每个执行路径维护了一组约束（constraint）。</p><p>执行之后，约束求解器（constraint solvers）将用于求解约束并确定导致执行的输入。</p><p>从技术上讲，符号执行可以覆盖程序中的任何执行路径，并且在小型程序的测试中已显示出良好的效果，但也存在许多限制。</p><p>首先，路径爆炸问题。随着程序规模的增长，执行状态会爆炸，这超出了约束求解器的求解能力。</p><p>第二，环境的相互作用。在符号执行中，当目标程序执行与符号执行环境之外的组件交互时，例如系统调用，处理信号等，可能会出现一致性问题。</p><p>因此符号执行仍然很难扩展到大型应用程序。</p><h2 id="4-模糊测试"><a href="#4-模糊测试" class="headerlink" title="4.模糊测试"></a>4.模糊测试</h2><p>模糊测试（Fuzzing）是目前最流行的漏洞发现技术。</p><p>从概念上讲，模糊测试从为目标应用程序生成大量正常和异常输入开始，并尝试通过将生成的输入提供给目标应用程序并监视执行状态来检测异常。</p><p>与其他技术相比，模糊测试易于部署并且具有良好的可扩展性和适用性，并且可以在有或没有源代码的情况下执行。</p><p>此外，由于模糊测试是在实际执行中执行的，因此它具有很高的准确性。</p><p>而且，模糊测试几乎不需要了解目标应用程序，并且可以轻松扩展到大型应用程序。</p><p>尽管模糊测试存在许多缺点，例如效率低和代码覆盖率低，但是，缺点却胜过缺点，模糊处理已成为当前最有效，最高效的最新漏洞发现技术。</p><h1 id="三、模糊测试介绍"><a href="#三、模糊测试介绍" class="headerlink" title="三、模糊测试介绍"></a>三、模糊测试介绍</h1><h2 id="1-模糊测试的工作过程"><a href="#1-模糊测试的工作过程" class="headerlink" title="1.模糊测试的工作过程"></a>1.模糊测试的工作过程</h2><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-26-22-38-53.png" srcset="/img/loading.gif" alt></p><p>模糊测试包括四个主要阶段，即测试用例生成阶段，测试用例运行阶段，程序执行状态监视和异常分析。</p><p>模糊测试从生成一堆程序输入（即测试用例）开始。生成的测试用例的质量直接影响测试效果。</p><p>一方面，输入应尽可能满足测试程序对输入格式的要求。</p><p>另一方面，应充分破坏输入，以便对这些输入进行处理很可能会使程序失败。</p><p>根据目标程序，输入可以是具有不同文件格式的文件，网络通信数据，具有指定特征的可执行二进制文件等。</p><p>如何生成足够多的测试用例是Fuzzer面临的主要挑战。</p><p>在上一阶段生成测试用例后，将它们馈送到目标程序。</p><p>模糊测试器自动开始和完成目标程序的过程，并驱动目标程序的测试用例处理过程。</p><p>在执行之前，分析人员可以配置目标程序的启动和完成方式，并预定义参数和环境变量。</p><p>通常，模糊处理过程在预定义的超时、程序执行挂起或崩溃时停止。</p><p>模糊器在目标程序执行期间监视执行状态，以防异常和崩溃。</p><p>常用的异常监视方法包括监视特定的系统信号，崩溃和其他违规（violations）。</p><p>当捕获到违规时，模糊器将存储相应的测试用例，以供以后重播和分析。</p><p>在分析阶段，分析人员尝试确定捕获的违规的位置和根本原因。</p><p>自动崩溃分析是另一个重要的研究领域。</p><h2 id="2-模糊测试器的种类"><a href="#2-模糊测试器的种类" class="headerlink" title="2.模糊测试器的种类"></a>2.模糊测试器的种类</h2><h3 id="A-基于生成和基于突变"><a href="#A-基于生成和基于突变" class="headerlink" title="A.基于生成和基于突变"></a>A.基于生成和基于突变</h3><p>模糊器可以分为基于生成（generation based）和基于突变（mutation based）两类。</p><p>对于基于生成的模糊器，需要有关程序输入的知识。</p><p>对于文件格式模糊测试（file format fuzzing），通常会提供一个预定义文件格式的配置文件。测试用例根据配置文件生成。</p><p>有了给定的文件格式知识（file format knowledge），基于生成的模糊器生成的测试用例就可以更轻松地通过程序的验证，并且更有可能测试目标程序的更深层代码。</p><p>但是，如果没有友好的文档，分析文件格式将是一项艰巨的工作。</p><p>因此，基于变异的模糊器更容易启动并且更适用，并且被最新的模糊器广泛使用。</p><p>对于基于突变的模糊器，需要一组有效的初始输入（a set of valid initial inputs）。</p><p>测试用例是通过对初始输入和测试过程中产生的测试用例进行变异而生成的。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-26-22-43-30.png" srcset="/img/loading.gif" alt></p><h3 id="B-黑盒白盒灰盒"><a href="#B-黑盒白盒灰盒" class="headerlink" title="B.黑盒白盒灰盒"></a>B.黑盒白盒灰盒</h3><p>关于对程序源代码的依赖性（the dependence on program source<br>code）和程序分析的程度（the degree of program analysis），模糊器可以分为白盒，灰盒和黑盒（white box, gray box and black box）。</p><p>白盒模糊测试器可以访问程序的源代码，因此可以通过对源代码进行分析以及测试用例如何影响程序运行状态来收集更多信息。</p><p>黑盒模糊器会在不了解目标程序内部的情况下进行模糊测试。</p><p>灰箱模糊器也不使用源代码，但可以通过程序分析获得目标程序的内部信息。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-26-22-44-18.png" srcset="/img/loading.gif" alt></p><h3 id="C-定向模糊和基于覆盖的模糊"><a href="#C-定向模糊和基于覆盖的模糊" class="headerlink" title="C.定向模糊和基于覆盖的模糊"></a>C.定向模糊和基于覆盖的模糊</h3><p>根据探索程序的策略（the strategies of exploring the programs），模糊器可以分为定向模糊（directed fuzzing）和基于覆盖的模糊（coverage-based fuzzing）。</p><p>定向模糊器旨在生成覆盖目标代码和程序目标路径的测试用例（cover target code and target paths of programs），而基于覆盖率的模糊器旨在生成覆盖尽可能多的程序代码的测试用例（cover as much code of programs as possible）。</p><p>定向模糊器期望对程序进行更快的测试，而基于覆盖率的模糊器期望进行更彻底的测试并检测到尽可能多的错误。</p><p>对于定向模糊器和基于覆盖的模糊器，如何提取执行路径的信息是一个关键问题。</p><h3 id="D-哑模糊和智能模糊"><a href="#D-哑模糊和智能模糊" class="headerlink" title="D.哑模糊和智能模糊"></a>D.哑模糊和智能模糊</h3><p>根据对程序执行状态的监视和测试用例的生成之间是否存在反馈（whether there is a feedback between the monitoring of program execution state and testcase generation），模糊器可以分为哑类（dumb fuzz）和智能类（smart fuzz）。</p><p>智能模糊器会根据收集的信息（测试用例如何影响程序行为）来调整测试用例的生成。</p><p>对于基于变异的模糊测试器，反馈信息可用于确定应该对测试用例的哪一部分进行变异以及对它们进行变异的方式。</p><p>哑模糊测试器（Dumb fuzzers）具有更好的测试速度（speed），而智能模糊测试器可以生成更好的测试用例并获得更高的效率（efficiency）。</p><h2 id="3-模糊测试面临的挑战"><a href="#3-模糊测试面临的挑战" class="headerlink" title="3.模糊测试面临的挑战"></a>3.模糊测试面临的挑战</h2><h3 id="A-如何改变种子输入的挑战"><a href="#A-如何改变种子输入的挑战" class="headerlink" title="A.如何改变种子输入的挑战"></a>A.如何改变种子输入的挑战</h3><p>基于变异的模糊测试工具在进行变异时需要回答两个问题：（1）变异的位置，以及（2）变异的方式。</p><p>只有几个关键位置的突变会影响执行的控制流程。因此，如何在测试用例中定位这些关键位置非常重要。</p><p>此外，模糊器改变关键位置的方式是另一个关键问题，即如何确定可以将测试定向到程序有趣路径的值。</p><p>简而言之，测试用例的盲目突变会严重浪费测试资源，更好的变异策略可以显着提高模糊测试的效率。</p><h3 id="B-低代码覆盖率的挑战"><a href="#B-低代码覆盖率的挑战" class="headerlink" title="B.低代码覆盖率的挑战"></a>B.低代码覆盖率的挑战</h3><p>较高的代码覆盖率表示对程序执行状态的覆盖率更高，并且测试更加彻底。发现错误的可能性更高。</p><p>但是，大多数测试用例仅涵盖相同的少数路径。</p><p>因此，仅通过大量生成测试用例并投入测试资源来实现高覆盖率是不明智的选择。</p><p>基于覆盖率的模糊器试图借助程序分析技术（例如程序检测，program instrumentation）来解决问题。</p><h3 id="C-通过验证的挑战"><a href="#C-通过验证的挑战" class="headerlink" title="C.通过验证的挑战"></a>C.通过验证的挑战</h3><p>程序通常在解析和处理之前验证（Validation）输入。</p><p>验证可以保护程序，节省计算资源，并保护程序免受无效输入和恶意构造输入造成的损坏。</p><p>黑盒和灰盒模糊器生成的测试用例很难通过盲目生成策略（blind generation strategy）的验证，从而导致效率很低。</p><h1 id="四、覆盖引导的模糊测试"><a href="#四、覆盖引导的模糊测试" class="headerlink" title="四、覆盖引导的模糊测试"></a>四、覆盖引导的模糊测试</h1><p>为了实现深入而彻底的程序模糊测试，模糊测试人员应尝试<strong>遍历尽可能多的程序运行状态</strong>。</p><p>但是，由于程序行为的不确定性，因此<strong>没有用于程序状态的简单度量</strong>。</p><p>测量代码覆盖率成为一种近似的替代解决方案。代码覆盖率的增加代表了新的程序状态。此外，代码覆盖率很容易测量。</p><p>但是，代码覆盖率是一种近似的度量，因为在实践中，恒定的代码覆盖率并不表示恒定的程序状态数。使用此指标可能会导致某些信息丢失。</p><h2 id="1-代码覆盖率计数"><a href="#1-代码覆盖率计数" class="headerlink" title="1.代码覆盖率计数"></a>1.代码覆盖率计数</h2><p>在程序分析中，程序由基本块（basic blocks）组成。基本块是具有单个入口和出口点的代码段，基本块中的指令将顺序执行，并且只会执行一次。</p><p>在代码覆盖率测量中，最新技术将基本块作为最佳粒度（granularity）。原因包括：（1）基本块是程序执行的最小连贯单位；（2）测量功能或指令会导致信息丢失或冗余；（3）基本块可以由第一条指令的地址标识；以及基本块信息可通过代码检测轻松提取。</p><p>当前，有两种基于基本块的基本测量选择：简单地计算已执行的基本块和计算基本块的跃迁（transitions）。</p><p>在后一种方法中，程序被解释为图，顶点用于表示基本块，边用于表示基本块之间的跃迁。</p><p>后一种方法记录边缘，而前一种方法记录顶点。</p><p>但是实验表明仅对已执行的基本块进行计数将导致严重的信息丢失。</p><p>如图所示，如果首先执行程序路径（BB1，BB2，BB3，BB4），然后执行时遇到路径（BB1，BB2，BB4），则新边（BB2，BB4）信息为丢失。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-11-48.png" srcset="/img/loading.gif" alt></p><h2 id="2-基于覆盖的模糊测试的工作过程"><a href="#2-基于覆盖的模糊测试的工作过程" class="headerlink" title="2.基于覆盖的模糊测试的工作过程"></a>2.基于覆盖的模糊测试的工作过程</h2><p>算法1显示了基于覆盖的模糊器的一般工作过程。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/alg1.png" srcset="/img/loading.gif" alt></p><p>测试从初始给定的种子输入开始。</p><p>在主模糊循环中，模糊器反复选择一个有趣的种子来进行后续的突变和测试用例的生成。然后在模糊器的监视下驱动目标程序以执行生成的测试用例。</p><p>收集触发崩溃的测试用例，并将其他有趣的用例添加到种子库中。</p><p>对于基于覆盖的模糊测试，达到新控制流<strong>边缘的测试用例</strong>被认为很有趣。</p><p>主模糊循环在预先配置的超时或中止信号时停止。</p><p>在模糊测试过程中，模糊器通过各种方法跟踪执行情况。</p><p>基本上，模糊器出于两个目的跟踪执行，即<strong>代码覆盖率</strong>和<strong>安全性违规</strong>（security violations）。</p><p>代码覆盖率信息用于进行彻底的程序状态探索，而安全违规跟踪则用于更好地发现错误。</p><p>下图显示了AFL（American Fuzzy Lop，一个非常有代表性的基于覆盖的模糊器）的工作过程。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-18-50.png" srcset="/img/loading.gif" alt></p><p>在执行覆盖范围收集之前，模糊器将对目标应用程序进行检测。</p><p>在主模糊循环中，提供初始种子输入后，（1）模糊器根据种子选择策略从种子库中选择喜欢的种子，比如AFL则选择最快和最小的种子。（2）根据变异策略对种子文件进行变异，并生成一堆测试用例。</p><p>AFL当前采用一些随机修改和测试用例拼接方法，包括长度和步长变化的顺序位翻转，小整数的顺序加法和减法以及已知有趣的整数（如0、1，INT_MAX等）的顺序插入。（3）测试用例已执行，并且执行情况正在跟踪中。</p><p>收集覆盖率信息以确定有趣的测试用例，即达到新控制流边缘的测试用例。</p><p>有趣的测试用例将添加到种子池中，以进行下一轮运行。</p><h2 id="3-关键问题"><a href="#3-关键问题" class="headerlink" title="3.关键问题"></a>3.关键问题</h2><p>前面的介绍表明，要运行一个高效的、基于覆盖的模糊，需要解决很多问题。最近一些研究如下表。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-22-32.png" srcset="/img/loading.gif" alt></p><h3 id="A-如何获得初始输入？"><a href="#A-如何获得初始输入？" class="headerlink" title="A.如何获得初始输入？"></a>A.如何获得初始输入？</h3><p>大多数最先进的基于覆盖的模糊器都采用了基于突变的测试用例生成策略，这在很大程度上取决于初始种子输入的质量。</p><p>良好的初始种子输入可以显著提高模糊的效率和效果。</p><p>具体来说，</p><p>(1)提供格式良好的种子输入可以节省构建一个种子输入所消耗的大量cpu时间；</p><p>(2)良好的初始输入可以满足复杂文件格式的要求，而复杂文件格式在突变阶段是很难猜测的；</p><p>(3)基于格式良好的种子输入的突变更容易产生测试用例，可以达到更深层次和难以达到的路径；</p><p>(4)良好的种子输入可以在多次测试中重复使用。</p><p>常用的收集种子输入的方法包括使用标准基准、从互联网上抓取和使用现有的POC（Proof of Concept）样本。</p><p>考虑到目标应用输入的多样性，从互联网上抓取是最直观的方法。</p><p>过量的种子输入会导致第一次干运行的时间浪费，从而带来另一个问题，即如何提炼初始语料。</p><p>AFL提供了一个工具，它可以提取一个最小的输入集，以达到相同的代码覆盖率。</p><h3 id="B-如何生成测试用例？"><a href="#B-如何生成测试用例？" class="headerlink" title="B.如何生成测试用例？"></a>B.如何生成测试用例？</h3><p>testcases的质量是影响模糊测试效率和效果的重要因素。</p><p>首先，好的testcases可以在较短的时间内探索更多的程序执行状态，覆盖更多的代码。</p><p>此外，好的测试用例可以针对潜在的脆弱位置，带来更快的程序bug发现。</p><p>因此，如何基于种子输入生成好的测试用例是一个重要的问题。</p><p>种子输入的突变涉及两个关键问题：在哪里突变和用什么值进行突变。</p><p>随着机器学习技术的发展和广泛应用，一些研究尝试使用机器学习技术来辅助生成testcases。</p><p>微软研究院的Godefroid等（2017）利用基于神经网络的统计机器学习技术来自动生成testcases。</p><p>具体来说，他们首先通过机器学习技术从一堆有效输入中学习输入格式，然后利用学习到的知识指导测试用例的生成。</p><p>他们介绍了微软Edge浏览器中PDF解析器的模糊过程。</p><p>虽然实验并没有给出一个令人鼓舞的结果，但仍是一个不错的尝试。</p><p>微软的Rajpal等人（2017）使用神经网络从过去的模糊探索中学习，并预测输入文件中哪些字节要突变。</p><p>Nichols等人（2017）使用生成对抗网络（GAN）模型来帮助用新颖的种子文件重新初始化系统。</p><p>实验表明，GAN比LSTM更快、更有效，并且有助于发现更多的代码路径。</p><h3 id="C-如何从种子池中选择种子？"><a href="#C-如何从种子池中选择种子？" class="headerlink" title="C.如何从种子池中选择种子？"></a>C.如何从种子池中选择种子？</h3><p>模糊器在主模糊循环中新一轮测试开始时，反复从种子池中选择种子进行突变。</p><p>以往的工作已经证明，良好的种子选择策略可以显著提高模糊效率，并帮助更快地找到更多的Bugs。</p><p>通过良好的种子选择策略，模糊器可以</p><ul><li>（1）优先选择更有帮助的种子，包括覆盖更多的代码，更容易触发漏洞；</li><li>（2）减少重复执行路径的浪费，节省计算资源；</li><li>（3）优化选择覆盖更深、更易受攻击的代码的种子，帮助更快地识别隐藏的漏洞。</li></ul><p>Böhme等人（2017）提出了AFLFast，一个基于覆盖的灰盒模糊器。在模糊过程中，AFLFast会测量执行路径的频率，优先处理被模糊次数较少的种子，并为行使低频路径的种子分配更多的能量。</p><p>Rawat等(2017)综合了静态和动态分析来识别难以到达的深层路径，并对到达深层路径的种子进行优先级排序。</p><p>AFLGo将一些易受攻击的代码定义为目标位置，并优化选择离目标位置较近的测试case。</p><p>已知漏洞的特征也可用于种子选择策略。然而，收集耗费资源的信息带来了沉重的开销，降低了模糊的效率。</p><h3 id="D-如何高效地测试应用程序？"><a href="#D-如何高效地测试应用程序？" class="headerlink" title="D.如何高效地测试应用程序？"></a>D.如何高效地测试应用程序？</h3><p>目标应用程序由主模糊循环中的模糊器反复启动和完成。</p><p>对于用户区应用程序的模糊处理，程序的创建和完成将消耗大量的cpu时间。频繁创建和完成该程序将严重降低模糊测试的效率。</p><p>AFL使用forkserver方法，该方法创建一个已加载程序的完全相同的克隆，并在每次运行时重复使用该克隆。</p><h1 id="五、模糊集成技术"><a href="#五、模糊集成技术" class="headerlink" title="五、模糊集成技术"></a>五、模糊集成技术</h1><p>使用随机突变方法的模糊模糊测试策略会导致大量无效测试用例，并且模糊测试效率较低。</p><p>当前，最先进的模糊器通常采用智能模糊策略。</p><p>智能模糊器通过程序分析技术来收集程序控制流和数据流信息，并因此利用收集到的信息来改进测试用例的生成。</p><p>由智能模糊器生成的测试用例具有更好的针对性，更有可能满足程序对数据结构和逻辑判断的要求。</p><p>下图描绘了智能模糊的示意图。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-36-55.png" srcset="/img/loading.gif" alt></p><p>表5中总结了模糊测试中集成的主要技术。</p><p><img src="/2020/06/20/【论文阅读笔记】Fuzzing-A-Survey/2020-06-27-00-37-51.png" srcset="/img/loading.gif" alt></p><h2 id="1-测试用例生成"><a href="#1-测试用例生成" class="headerlink" title="1.测试用例生成"></a>1.测试用例生成</h2><p>如前所述，模糊测试中的测试用例是基于生成的方法或基于变异的方法生成的。</p><p>如何生成满足复杂数据结构要求并更有可能触发难以到达的路径的测试用例是一个关键挑战。</p><p>在基于生成的模糊测试中，生成器根据输入数据格式的知识生成测试用例。</p><p>Work（Godefroid et al.2017）使用机器学习技术（特别是递归神经网络）来学习输入文件的语法，并因此使用所学的语法来生成满足格式要求的测试用例。</p><p>更多的最先进的模糊器采用基于变异的模糊策略。通过在突变过程中修改部分种子输入来生成测试用例。</p><p>在盲目的突变模糊化过程中，变异者使用随机值或几个特殊值随机修改种子字节，这被证明是效率很低的。因此，如何确定要修改的位置以及修改中使用的值是另一个关键挑战。</p><h2 id="2-程序执行"><a href="#2-程序执行" class="headerlink" title="2.程序执行"></a>2.程序执行</h2><p>执行阶段涉及的两个关键问题是<strong>如何指导模糊测试过程</strong>以及<strong>如何探索新路径</strong>。</p><p>仪表（Instrumentation）技术用于记录路径执行情况并计算基于覆盖率的模糊测试中的覆盖率信息。</p><p>测试执行过程中的另一个问题是探索新路径。符号执行技术在路径探索中具有天然的优势。</p><p>通过求解约束集，符号执行技术可以计算出满足特定条件要求的值。</p><p>反馈驱动的模糊测试提供了一种有效的引导测试方法，传统和新技术都可以发挥传感器的作用，以在测试执行过程中获取各种信息，并准确地指导模糊测试。</p><h1 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h1><ul><li>反馈驱动的模糊模式（feedback-driven fuzzing mode）和遗传算法（genetic algorithms）的结合</li><li>测试用例生成阶段，测试用例运行阶段，程序执行状态监视和异常分析</li><li>根据探索程序的策略（the strategies of exploring the programs），模糊器可以分为定向模糊（directed fuzzing）和基于覆盖的模糊（coverage-based fuzzing）。</li><li>定向模糊器期望对程序进行更快的测试，而基于覆盖率的模糊器期望进行更彻底的测试并检测到尽可能多的错误。</li><li>对于定向模糊器和基于覆盖的模糊器，如何提取执行路径的信息是一个关键问题。</li><li>根据对程序执行状态的监视和测试用例的生成之间是否存在反馈（whether there is a feedback between the monitoring of program execution state and testcase generation），模糊器可以分为哑类（dumb fuzz）和智能类（smart fuzz）。</li><li>智能模糊器会根据收集的信息（测试用例如何影响程序行为）来调整测试用例的生成。</li><li>对于基于变异的模糊测试器，反馈信息可用于确定应该对测试用例的哪一部分进行变异以及对它们进行变异的方式。</li><li>基于变异的模糊测试工具在进行变异时需要回答两个问题：（1）变异的位置，以及（2）变异的方式。</li><li>覆盖率的定义。定义覆盖率时要防止信息丢失。代码覆盖率的增加代表了新的程序状态。此外，代码覆盖率很容易测量。边缘的测试用例被认为很有趣</li><li>通过验证的挑战。验证可以保护程序，节省计算资源，并保护程序免受无效输入和恶意构造输入造成的损坏。</li><li>一些研究尝试使用机器学习技术来辅助生成testcases。GAN比LSTM更快、更有效，并且有助于发现更多的代码路径。</li><li>如何从种子池中选择种子？</li><li>如何高效地测试应用程序？</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2018年CyberSecurity收录的一篇关于软件测试中模糊测试的综述。作者来自清华大学。文章名越短越霸气。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Software Testing" scheme="https://superlova.github.io/tags/Software-Testing/"/>
    
      <category term="Fuzzing" scheme="https://superlova.github.io/tags/Fuzzing/"/>
    
      <category term="Survey" scheme="https://superlova.github.io/tags/Survey/"/>
    
  </entry>
  
  <entry>
    <title>【学习笔记】LSTM网络结构简介与对应的keras实现</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91LSTM%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AF%B9%E5%BA%94%E7%9A%84keras%E5%AE%9E%E7%8E%B0/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91LSTM%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AF%B9%E5%BA%94%E7%9A%84keras%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-06-20T03:50:37.000Z</published>
    <updated>2020-06-26T12:39:35.089Z</updated>
    
    <content type="html"><![CDATA[<p>从理论和代码两个层面介绍了LSTM网络。<br><a id="more"></a></p><h2 id="一、理论来一波"><a href="#一、理论来一波" class="headerlink" title="一、理论来一波"></a>一、理论来一波</h2><p>循环神经网络（Recurrent Neural Network，RNN）是一类有短期记忆能力的神经网络。在循环神经网络中，神经元不但可以接受其他神经元的信息，也可以接受自身的信息，形成具有环路的网络结构。</p><p><img src="/2020/06/20/【学习笔记】LSTM网络结构简介与对应的keras实现/2020-06-20-11-51-21.png" srcset="/img/loading.gif" alt></p><p>长短期记忆网络（Long Short-Term Memory Network，LSTM）[Gers et al.,2000; Hochreiter et al., 1997] 是循环神经网络的一个变体，可以有效地解决简单循环神经网络的梯度爆炸或消失问题。</p><p><img src="/2020/06/20/【学习笔记】LSTM网络结构简介与对应的keras实现/2020-06-20-11-51-13.png" srcset="/img/loading.gif" alt></p><p>LSTM 网络引入一个新的内部状态（internal state） $\boldsymbol{c}_{t}\in \mathbb{R}^{\boldsymbol{D}}$ 专门进行线性的循环信息传递，同时（非线性地）输出信息给隐藏层的外部状态 $\boldsymbol{h}_{t}\in \mathbb{R}^{\boldsymbol{D}}$ 。这两个状态通过下式计算：</p><script type="math/tex; mode=display">\begin{array}{l}\boldsymbol{c}_{t}=\boldsymbol{f}_{t} \odot \boldsymbol{c}_{t-1}+\boldsymbol{i}_{t} \odot \tilde{\boldsymbol{c}}_{t} \\\boldsymbol{h}_{t}=\boldsymbol{o}_{t} \odot \tanh \left(\boldsymbol{c}_{t}\right)\end{array}</script><p>其中，$\odot$为向量逐元素乘积（代表左右两边向量维度相同）；$\boldsymbol{c}_{t-1}$为上一时刻的记忆单元；$\tilde{\boldsymbol{c}}\in \mathbb{R}^{\boldsymbol{D}}$是通过非线性函数得到的候选状态：</p><script type="math/tex; mode=display">\tilde{\boldsymbol{c}}_{t}=\tanh \left(\boldsymbol{W}_{c} \boldsymbol{x}_{t}+\boldsymbol{U}_{c} \boldsymbol{h}_{t-1}+\boldsymbol{b}_{c}\right)</script><p>在每个时刻 $t$，LSTM 网络的内部状态 $\boldsymbol{c}_{t}$ 记录了到当前时刻为止的历史信息。</p><p>LSTM内部多了三个gate，分别是forget、input、output。$\boldsymbol{f}_{t}\in [0,1]^{\boldsymbol{D}}$、$\boldsymbol{i}_{t}\in [0,1]^{\boldsymbol{D}}$、$\boldsymbol{o}_{t}\in [0,1]^{\boldsymbol{D}}$。这三个门与输入、隐状态和输出的维度应该相同，都是维度为输入序列维度n的向量（其实应该为n+1）$=D$。</p><p>与此同时，三个门的值依赖于$t$时刻的输入$x_t$、$t-1$时刻的隐变量$h_{t-1}$以及不同的权重矩阵($W_i$/$W_f$/$W_o$/$U_i$/$U_f$/$U_o$)。</p><p>门控机制（Gating Mechanism）是用来控制信息传递的路径的手段。</p><ul><li>遗忘门 $\boldsymbol{f}_{t}$ 控制上一个时刻的内部状态$\boldsymbol{c}_{t-1}$ 需要遗忘多少信息。</li><li>输入门 $\boldsymbol{i}_{t}$ 控制当前时刻的候选状态 ̃$\tilde{\boldsymbol{c}}_{t}$ 有多少信息需要保存。</li><li>输出门 $\boldsymbol{o}_{t}$ 控制当前时刻的内部状态 $\boldsymbol{c}_{t}$ 有多少信息需要输出给外部状态 $\boldsymbol{h}_{t}$。</li></ul><p>举个例子，当$\boldsymbol{f}_{t}=\mathbf{0}, \boldsymbol{i}_{t}=\mathbf{1}$时，记忆单元将历史信息清空，并将候选状态向量$\tilde{\boldsymbol{c}}_{t}$写入。但此时记忆单元 $\boldsymbol{c}_{t}$ 依然和上一时刻的历史信息相关。当$\boldsymbol{f}_{t}=\mathbf{1}, \boldsymbol{i}_{t}=\mathbf{0}$时，记忆单元将复制上一时刻的内容，不写入新的信息。</p><p>LSTM 网络中的“门”是一种“软”门，取值在 (0, 1) 之间，表示以一定的比例允许信息通过．三个门的计算方式为：</p><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{i}_{t} &=\sigma\left(\boldsymbol{W}_{i} \boldsymbol{x}_{t}+\boldsymbol{U}_{i} \boldsymbol{h}_{t-1}+\boldsymbol{b}_{i}\right) \\\boldsymbol{f}_{t} &=\sigma\left(\boldsymbol{W}_{f} \boldsymbol{x}_{t}+\boldsymbol{U}_{f} \boldsymbol{h}_{t-1}+\boldsymbol{b}_{f}\right) \\\boldsymbol{o}_{t} &=\sigma\left(\boldsymbol{W}_{o} \boldsymbol{x}_{t}+\boldsymbol{U}_{o} \boldsymbol{h}_{t-1}+\boldsymbol{b}_{o}\right)\end{aligned}</script><p>其中$\sigma(\cdot)$ 为 Logistic 函数，其输出区间为 (0, 1)；$\boldsymbol{x}_{t}$为当前时刻的输入。</p><h2 id="二、还是得看代码"><a href="#二、还是得看代码" class="headerlink" title="二、还是得看代码"></a>二、还是得看代码</h2><p>下面是我定义的一个专用于IMDb影评情感分析的二分类模型，包装在一个函数中。输入训练集、测试集及其标签，设定好参数就可以运行、训练。可以选择是否保存模型到本地。最后函数返回训练好的模型。</p><p>这个二分类模型中，输入是长度为80的整数列表（maxlen=80），代表着80个不同的单词构成的一句话。</p><p>如果有影评不够80个词，就在影评前面加足够的0，直到这条影评达到80个词为止。如果影评单词量大于80个，便截取前面的80个词。</p><p>每个整数都代表一个单词表中的单词。当然单词表的大小是固定的（num_words=10000个单词），如果出现不在单词表中的单词，固定将其编码成2，表示UNKNOWN（这条设置不在下面的代码中，属于数据预处理）。</p><p>第一层是Embedding层，负责将一句话中的每个单词映射成固定维度的词向量；</p><p>注意，每个单词（在这里是每个整数）都会变成固定维度（embedding_dim=128）的向量，因此每条影评从Embedding层输出后，都会变成80*128的矩阵。</p><p>第二层是LSTM层。如果你看了理论部分的叙述，就知道LSTM层中无论是隐状态$\boldsymbol{c}$、$\boldsymbol{h}$还是三个门$\boldsymbol{f}$、$\boldsymbol{i}$、$\boldsymbol{o}$，他们的维度都是$\boldsymbol{D}$。这个$\boldsymbol{D}$的大小就需要我们用参数<code>lstm_dim=32</code>来定义。这个参数越大，代表LSTM层的参数越多、泛化能力越强，也更难训练、更容易过拟合。</p><p>第三层是单个神经元的sigmoid层，在这里就直接转换成概率并分类了。</p><pre><code class="lang-python">def train_lstm(x_train, y_train, x_test, y_test,                num_words=10000,                maxlen=80,                embedding_dim=128,                lstm_dim=32,                batch_size=32,                epochs=10):    # 接收一个含有 100 个整数的序列，每个整数在 1 到 20000 之间    inputs = Input(shape=(maxlen,), dtype=&#39;int32&#39;, name=&#39;main_input&#39;)    # Embedding 层将输入序列编码为一个稠密向量的序列，    # 每个向量维度为 512。    x = Embedding(input_dim=num_words,                   input_length=maxlen,                   output_dim=embedding_dim,                   name=&#39;embedding&#39;)(inputs)    # LSTM 层把向量序列转换成单个向量，    # 它包含整个序列的上下文信息    lstm_output = LSTM(lstm_dim, name=&#39;lstm&#39;)(x)    # 插入辅助损失，    #使得即使在模型主损失很高的情况下，LSTM 层和 Embedding 层都能被平稳地训练    outputs = Dense(1, activation=&#39;sigmoid&#39;, name=&#39;output&#39;)(lstm_output)    model = Model(inputs=inputs, outputs=outputs)    model.compile(optimizer=&#39;adam&#39;,            loss=&#39;binary_crossentropy&#39;,            metrics=[&#39;accuracy&#39;])    model.fit(x_train, y_train,        batch_size=batch_size,        epochs=epochs,        validation_data=(x_test, y_test,))    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)    print(&#39;Test score:&#39;, score)    print(&#39;Test accuracy:&#39;, acc)    # model.save(&quot;lstm_imdb.h5&quot;)    return model</code></pre><h2 id="三、LSTM返回所有时间步的hidden-state向量"><a href="#三、LSTM返回所有时间步的hidden-state向量" class="headerlink" title="三、LSTM返回所有时间步的hidden state向量"></a>三、LSTM返回所有时间步的hidden state向量</h2><p>数据经过LSTM层，输出的是最后一个时间步得到的output向量（即$\boldsymbol{h}_{finally}$），维度为$\boldsymbol{D}$。</p><p>其实LSTM能够在每个时间步都输出output（即$\boldsymbol{h}_{t}$），只不过我们把这些没到时间的半成品output选择性忽略了。</p><p>如果你想要堆叠LSTM层，也就是LSTM层下面还有LSTM，或者你<strong>需要所有时间步的</strong>$\boldsymbol{h}_{t}$，那么你可以在训练的时候把<code>return_sequences=True</code>写进LSTM参数之中。</p><p><img src="/2020/06/20/【学习笔记】LSTM网络结构简介与对应的keras实现/堆叠rnn.png" srcset="/img/loading.gif" alt></p><p>下面让我们来比较一下<code>return_sequences</code>参数开启之后输出值的变化。</p><h3 id="return-sequences-False"><a href="#return-sequences-False" class="headerlink" title="return_sequences=False"></a>return_sequences=False</h3><p>首先固定随机数种子。</p><pre><code class="lang-python">np.random.seed(0)tf.random.set_seed(0)</code></pre><p>然后构建输入Input向量和LSTM层，此时LSTM层使用默认参数<code>return_sequences=False</code>。</p><pre><code class="lang-python">input1 = Input(shape=(3,1)) # 输入是三维向量lstm1 = LSTM(1)(input1) # 内部hidden和cell的维度为1model = Model(inputs=input1, outputs=lstm1)</code></pre><p>构造一批输入，包括6个句子，每个句子三个单词，然后输入LSTM，查看LSTM层的输出。</p><pre><code class="lang-python">data = np.array([[0.1, 0.2, 0.3],                    [0.3, 0.2, 0.1],                    [0.2, 0.6, 0.3],                    [0.8, 0.2, 0.3],                    [0.3, 0.5, 0.1],                    [0.2, 0.6, 0.2]])print(model.predict(data))</code></pre><p>此时输出为：</p><pre><code class="lang-python">[[0.00844267] [0.00617958] [0.01279002] [0.01231858] [0.009055  ] [0.01108878]]Process finished with exit code 0</code></pre><h3 id="return-sequences-True"><a href="#return-sequences-True" class="headerlink" title="return_sequences=True"></a>return_sequences=True</h3><p>然后打开<code>return_sequences</code>的开关</p><pre><code class="lang-python">lstm1 = LSTM(1, return_sequences=True)(input1)</code></pre><p>此时的输出为：</p><pre><code>[[[0.00190693]  [0.00490441]  [0.00844267]] #  [[0.0055262 ]  [0.00704476]  [0.00617958]] # [[0.00374958]  [0.01259477]  [0.01279002]] # [[0.01337298]  [0.01142679]  [0.01231858]] # [[0.0055262 ]  [0.01206062]  [0.009055  ]] # [[0.00374958]  [0.01259477]  [0.01108878]]] #Process finished with exit code 0</code></pre><p>此为输出所有时间步的hidden state。鉴于一共6个测试输入，每个输入有3个feature，所以时间步也就三步。LSTM的输出结果从6个hidden state变成了6*3个hidden state。</p><h3 id="return-state-True"><a href="#return-state-True" class="headerlink" title="return_state=True"></a>return_state=True</h3><p>我们再来看另一个参数，这个参数能够控制LSTM输出cell state。</p><pre><code class="lang-python">lstm1 = LSTM(1, return_state=True)(input1)</code></pre><pre><code>[array([[0.00844267],       [0.00617958],       [0.01279002],       [0.01231858],       [0.009055  ],       [0.01108878]], dtype=float32), array([[0.00844267],       [0.00617958],       [0.01279002],       [0.01231858],       [0.009055  ],       [0.01108878]], dtype=float32), array([[0.01655067],       [0.01227413],       [0.02506882],       [0.02414548],       [0.01798305],       [0.02187706]], dtype=float32)]Process finished with exit code 0</code></pre><p>开启<code>return_state=True</code>之后，LSTM返回3个array，第一个array和第二个array一样，都是hidden state，和默认返回的一样。第三个array就是最后一个时间步的cell state。</p><h3 id="return-state-True-return-sequences-True"><a href="#return-state-True-return-sequences-True" class="headerlink" title="return_state=True, return_sequences=True"></a>return_state=True, return_sequences=True</h3><p>如果两个开关都打开，则结果变成</p><pre><code class="lang-python">lstm1 = LSTM(1, return_state=True, return_sequences=True)(input1)</code></pre><pre><code>[array([[[0.00190693],        [0.00490441],        [0.00844267]],       [[0.0055262 ],        [0.00704476],        [0.00617958]],       [[0.00374958],        [0.01259477],        [0.01279002]],       [[0.01337298],        [0.01142679],        [0.01231858]],       [[0.0055262 ],        [0.01206062],        [0.009055  ]],       [[0.00374958],        [0.01259477],        [0.01108878]]], dtype=float32), array([[0.00844267],       [0.00617958],       [0.01279002],       [0.01231858],       [0.009055  ],       [0.01108878]], dtype=float32), array([[0.01655067],       [0.01227413],       [0.02506882],       [0.02414548],       [0.01798305],       [0.02187706]], dtype=float32)]Process finished with exit code 0</code></pre><p>还是返回三个array，第一个是所有时间步的hidden state，这是开启<code>return_sequences=True</code>的效果；第二个则是原本LSTM的输出hidden state；第三个是开启<code>return_state=True</code>的效果，返回最后一个时间步的cell state</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从理论和代码两个层面介绍了LSTM网络。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="RNN" scheme="https://superlova.github.io/tags/RNN/"/>
    
      <category term="LSTM" scheme="https://superlova.github.io/tags/LSTM/"/>
    
      <category term="Keras" scheme="https://superlova.github.io/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】Deep Text Classification Can be Fooled</title>
    <link href="https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Deep-Text-Classification-Can-be-Fooled/"/>
    <id>https://superlova.github.io/2020/06/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Deep-Text-Classification-Can-be-Fooled/</id>
    <published>2020-06-20T01:20:42.000Z</published>
    <updated>2020-06-23T12:41:07.656Z</updated>
    
    <content type="html"><![CDATA[<p>国内人民大学的一篇论文，被IJCAI-2018接收。主要研究文本领域的对抗样本生成，被测模型是文本分类领域的模型。<br><a id="more"></a></p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>当前的对抗样本生成领域集中在图像的扰动和生成，文本领域少有涉及。</p><p><strong>文本对抗样本应当满足</strong>：</p><ul><li>使模型分类错误</li><li>与原样本相比，扰动难以察觉</li><li>实用性，即文本含义不发生改变</li></ul><p><strong>本文采用的生成思路</strong>：</p><ul><li>三种扰动策略：插入、修改和删除</li><li>自然语言水印</li><li>白盒+黑盒</li></ul><blockquote><p>自然语言水印（Natural Language Watermarking）是通过修改文本元素（如线条，文字或字符）的外观，或更改文本格式或字体（例如，通过-文字中的单词和字母间距）来嵌入信息的技术。</p></blockquote><h2 id="2-目标模型和数据集"><a href="#2-目标模型和数据集" class="headerlink" title="2. 目标模型和数据集"></a>2. 目标模型和数据集</h2><p><strong>字符级模型</strong>：</p><ul><li>以字母为单位，编码长度为字母表大小（26+空白符个数）</li><li>结构：6conv + 3fc</li><li>数据集：DBPedia，包含14个类别，56000训练、70000测试</li></ul><p><strong>单词级模型</strong>：</p><ul><li>以单词为单位，编码长度为单词表大小（数万到数十万）</li><li>结构：embedding + conv + maxpooling + fc(带dropout) + softmax</li><li>数据集：影评MR、产品评价CR、产品意见MPQA，都是二分类</li></ul><h2 id="3-白盒攻击"><a href="#3-白盒攻击" class="headerlink" title="3. 白盒攻击"></a>3. 白盒攻击</h2><p>所谓白盒攻击，就是在已知被测模型内部信息的情况下开展的攻击。由于已知信息较多，所以攻击起来也比较容易。</p><p>白盒攻击生成对抗样本的思想在图像领域用的比较多。比如利用网络参数和损失函数进行指导攻击过程的FGSM算法。</p><p>本文采用的白盒攻击手段，也是利用模型内部的参数和网络训练时的损失函数作为引导，但是不会直接生成对抗样本，而是<strong>首先识别对分类有重大贡献的文本项</strong>。</p><h3 id="HTP：Hot-Training-Phrases"><a href="#HTP：Hot-Training-Phrases" class="headerlink" title="HTP：Hot Training Phrases"></a>HTP：Hot Training Phrases</h3><p>以字符级模型为例，识别过程如下：</p><ol><li>输入训练样本x，计算cost gradients ∇x C(M, x, label)；</li><li>每个样本x选取令gradient最大的前50个字符定义为<strong>hot character</strong>；</li><li>包含3个及以上hot characters的单词定义为<strong>hot word</strong>；</li><li>相邻的hot words定义为<strong>hot phrase</strong>；</li><li>不同类别有不同的hot phrase，代表着该类对分类贡献最大的词组；</li><li>每个类别中最常出现的hot phrase定义为<strong>Hot Training Phrases (HTPs)</strong>。</li></ol><p>下图是DBPedia的Building类别文本数据集中的HTP词汇排名前10。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/2020-06-23-20-11-30.png" srcset="/img/loading.gif" alt></p><h3 id="HSP：Hot-Sample-Phrases"><a href="#HSP：Hot-Sample-Phrases" class="headerlink" title="HSP：Hot Sample Phrases"></a>HSP：Hot Sample Phrases</h3><p>给定样本x，识别x中的hot phrase作为操作位置，该位置的单词或词组就定义为<strong>Hot Sample Phrases (HSPs)</strong>。</p><h3 id="Attacking-Character-level-DNN"><a href="#Attacking-Character-level-DNN" class="headerlink" title="Attacking Character-level DNN"></a>Attacking Character-level DNN</h3><h4 id="Insertion"><a href="#Insertion" class="headerlink" title="Insertion"></a><strong>Insertion</strong></h4><p>通过在样本的HSP位置插入以下内容实现变异操作：</p><ul><li>HTP；</li><li>可有可无的事实（文本水印算法生成）；</li><li>不伤害文本主语义的伪造事实（文本水印算法生成）。</li></ul><p>下面是三个通过插入红色文本造成标签改变的例子。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/2020-06-23-20-11-43.png" srcset="/img/loading.gif" alt="Figure2"><br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/2020-06-23-20-11-56.png" srcset="/img/loading.gif" alt="Figure3"><br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure4.png" srcset="/img/loading.gif" alt="Figure4"></p><h4 id="Modification"><a href="#Modification" class="headerlink" title="Modification"></a><strong>Modification</strong></h4><p>对HSP稍加操作，比如typo-based watermarking technique（基于错别字的水印技术）：</p><ul><li>(1)替换以常见的错误拼写（需要有错别字语料库）</li><li>(2)替换以外观相似的字符</li></ul><p>下图是替换操作后生成对抗样本的一个例子。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure5.png" srcset="/img/loading.gif" alt></p><p>下图是将film替换成flim后模型内部损失函数梯度的改变。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure6.png" srcset="/img/loading.gif" alt></p><h4 id="Removal"><a href="#Removal" class="headerlink" title="Removal"></a><strong>Removal</strong></h4><p>删除HSP可降低模型对样本的confidence。只能删除HSPs中起辅助作用的词，要不然会改变本来的含义。</p><p>下面是通过删除来导致置信程度下降的例子。<br><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure7.png" srcset="/img/loading.gif" alt></p><h4 id="Combination"><a href="#Combination" class="headerlink" title="Combination"></a><strong>Combination</strong></h4><p>组合上述三种手法。</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure8.png" srcset="/img/loading.gif" alt></p><h3 id="Attacking-Word-level-DNN"><a href="#Attacking-Word-level-DNN" class="headerlink" title="Attacking Word-level DNN"></a>Attacking Word-level DNN</h3><p>单词级模型也是同理，不仅如此，甚至省了hot-character这一步。下面是几个例子。</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure9.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure10.png" srcset="/img/loading.gif" alt></p><h2 id="4-黑盒攻击"><a href="#4-黑盒攻击" class="headerlink" title="4. 黑盒攻击"></a>4. 黑盒攻击</h2><p>黑盒攻击显然不能通过比较Cost Gradient的方式确定HTP和HSP了。但是我们可以采用其他方法确定HTP和HSP。</p><p>具体地，我们通过生成一些测试样本来探测目标模型，判断哪些是Hot Phrases。</p><p>生成方法：</p><ul><li>用若干空格逐个代替单词（空格个数与单词长度相同）</li><li>将测试样本的分类结果与种子进行比较</li><li>偏差越大，相应单词对正确分类的重要性就越大</li><li>带来最大偏差的单词被标识为种子样本的HSP</li></ul><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure11.png" srcset="/img/loading.gif" alt></p><p>下面是黑盒攻击确定的HTP之后进行攻击的例子：</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Figure12.png" srcset="/img/loading.gif" alt></p><h2 id="5-Evaluation"><a href="#5-Evaluation" class="headerlink" title="5. Evaluation"></a>5. Evaluation</h2><h3 id="Q1-Can-our-method-perform-effective-source-target-misclassification-attack"><a href="#Q1-Can-our-method-perform-effective-source-target-misclassification-attack" class="headerlink" title="Q1: Can our method perform effective source/target misclassification attack?"></a>Q1: Can our method perform effective source/target misclassification attack?</h3><p>这个问题是问本方法能不能对模型实行定向的攻击，即“指哪打哪”，无论哪个类别的样本都能通过适当修改，突变成指定类别。</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Fig13.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Fig14.png" srcset="/img/loading.gif" alt></p><p>通过上表可知，source栏是源类别。target栏是目标类别，No栏是样本编号。本来都是类别source中定义的样本，经过右边三栏的突变方法，最终都以较高置信度被模型分类成了target栏中的类别。可以证明此方法确实能实现定向突变、定向攻击。</p><h3 id="Q2-Can-the-adversarial-samples-avoid-being-distinguished-by-human-observers-and-still-keep-the-utility"><a href="#Q2-Can-the-adversarial-samples-avoid-being-distinguished-by-human-observers-and-still-keep-the-utility" class="headerlink" title="Q2: Can the adversarial samples avoid being distinguished by human observers and still keep the utility?"></a>Q2: Can the adversarial samples avoid being distinguished by human observers and still keep the utility?</h3><p>这个问题是问对抗样本是不是能够避免被人类识别。毕竟文本突变还是很容易被人类识别的。</p><p>本论文是这么设计实验的：</p><ul><li>找23名学生，每个人都提供了20个文本样本，其中一半带有扰动，对每个样本进行手动分类</li><li>如果他们认为样品是人为修改的，则要求他们查明修改的位置</li><li>原样本准确率：94.2%</li><li>扰动样本准确率：94.8%</li><li>总共生成594个变化，有240个被受试者标记为已修改的位置，其中12个正确。准确率为12/240 = 5.0％，召回率为12/594 = 2.0％</li></ul><p>可以看到虽然样本数比较小，但是结果还是很显著的，在那23个同学都比较靠谱的前提下，该算法还是能够保证生成的文本与原文本差距不大的。</p><h3 id="Q3-Is-our-method-efficient-enough"><a href="#Q3-Is-our-method-efficient-enough" class="headerlink" title="Q3: Is our method efficient enough?"></a>Q3: Is our method efficient enough?</h3><p>算法效率其实不是很重要，毕竟在实践中，攻击者往往愿意花费更多时间来制作理想的对抗性样本。</p><p>白盒攻击（计算梯度、确定HTP），总共116小时，平均每类8.29小时；<br>黑盒攻击（生成样本、确定HTP），总共107小时，平均每类7.63小时。</p><h3 id="Q4-White-box-and-black-box-which-is-more-powerful"><a href="#Q4-White-box-and-black-box-which-is-more-powerful" class="headerlink" title="Q4: White-box and black-box, which is more powerful?"></a>Q4: White-box and black-box, which is more powerful?</h3><p>两种方式都有效并且彼此互补。</p><p>下图分别是黑盒和白盒生成的HTP比较，可以看到都是比较类似的。</p><p><img src="/2020/06/20/【论文阅读笔记】Deep-Text-Classification-Can-be-Fooled/Fig15.png" srcset="/img/loading.gif" alt></p><h2 id="6-读后感"><a href="#6-读后感" class="headerlink" title="6. 读后感"></a>6. 读后感</h2><p>其实本篇文章的思想并不复杂，核心是确定一段文本的HTP和HSP。所谓HTP可以认为是，模型一看到这种词就相信这句话是该类别的了。那如果把类别1的句子x中的HSP给替换成类别2的HTP，的确可能让模型以为句子x是类别2的句子了。</p><p>所以延伸出来一个方向，那就是确定HSP和HTP的方法上。对于白盒攻击，还是查看内部的信息，然后计算梯度，这是一种比较传统的方法。对于黑盒攻击，则是遍历所有可能删除的单词，从结果上来看，比较这些删除单词的重要程度。</p><p>所以说有没有其他方法能够衡量单词的重要程度？这是一个值得研究的方向。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;国内人民大学的一篇论文，被IJCAI-2018接收。主要研究文本领域的对抗样本生成，被测模型是文本分类领域的模型。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
      <category term="DNN" scheme="https://superlova.github.io/tags/DNN/"/>
    
  </entry>
  
  <entry>
    <title>【学习笔记】机器学习中处理文本数据的常用方法</title>
    <link href="https://superlova.github.io/2020/06/09/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%A4%84%E7%90%86%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/06/09/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%A4%84%E7%90%86%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2020-06-09T14:52:34.000Z</published>
    <updated>2020-06-10T00:44:12.566Z</updated>
    
    <content type="html"><![CDATA[<p>总结词袋模型、Tf-idf等文本特征提取方法<br><a id="more"></a></p><h2 id="一、词袋模型"><a href="#一、词袋模型" class="headerlink" title="一、词袋模型"></a>一、词袋模型</h2><p>文本数据通常被表示为由字符组成的字符串。我们需要先处理数据，然后才能对其应用机器学习算法。</p><p>在文本分析的语境中，数据集通常被称为语料库（corpus），每个由单个文本表示的数据点被称为文档（document）。</p><p>最简单的处理方法，是<strong>只计算语料库中每个单词在每个文本中的出现频次</strong>。这种文本处理模型称之为<strong>词袋模型</strong>。</p><p>不考虑词语出现的顺序，每个出现过的词汇单独作为一列特征，这些不重复的特征词汇集合为词表。</p><p>每一个文本都可以在很长的词表上统计出一个很多列的特征向量。如果每个文本都出现的词汇，一般被标记为<strong>停用词</strong>不计入特征向量。</p><p>为了搞清楚词袋模型，也就是<code>CountVectorizer</code>到底做了什么，我们执行以下代码：</p><pre><code class="lang-python">bards_words =[&quot;The fool doth think he is wise,&quot;,    &quot;but the wise man knows himself to be a fool&quot;]</code></pre><p>我们导入 CountVectorizer 并将其实例化，然后对 bards_words 进行拟合，如下所示：</p><pre><code class="lang-python">from sklearn.feature_extraction.text import CountVectorizervect = CountVectorizer()vect.fit(bards_words)</code></pre><p>拟合 CountVectorizer 包括训练数据的分词与词表的构建，我们可以通过 vocabulary_ 属性来访问词表：</p><pre><code class="lang-python">print(&quot;Vocabulary size: {}&quot;.format(len(vect.vocabulary_)))print(&quot;Vocabulary content:\n {}&quot;.format(vect.vocabulary_))#------------------#Vocabulary size: 13Vocabulary content:{&#39;the&#39;: 9, &#39;himself&#39;: 5, &#39;wise&#39;: 12, &#39;he&#39;: 4, &#39;doth&#39;: 2, &#39;to&#39;: 11, &#39;knows&#39;: 7,&#39;man&#39;: 8, &#39;fool&#39;: 3, &#39;is&#39;: 6, &#39;be&#39;: 0,  &#39;think&#39;: 10, &#39;but&#39;: 1}</code></pre><p>词表共包含 13 个词，从 “be” 到 “wise”。<br>我们可以调用 transform 方法来创建训练数据的词袋表示：</p><pre><code class="lang-python">bag_of_words = vect.transform(bards_words)print(&quot;bag_of_words: {}&quot;.format(repr(bag_of_words)))#--------------------#bag_of_words: &lt;2x13 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;with 16 stored elements in Compressed Sparse Row format&gt;</code></pre><p>词袋表示保存在一个 SciPy 稀疏矩阵中，这种数据格式只保存非零元素。这个矩阵的形状为 2×13，每行对应于两个数据点之一，每个特征对应于词表中的一个单词。要想查看稀疏矩阵的实际内容，可以使用 toarray 方法将其转换为“密集的”NumPy 数组（保存所有 0 元素）：</p><pre><code class="lang-python">print(&quot;Dense representation of bag_of_words:\n{}&quot;.format(    bag_of_words.toarray()))#---------------------#Dense representation of bag_of_words:[[0 0 1 1 1 0 1 0 0 1 1 0 1][1 1 0 1 0 1 0 1 1 1 0 1 1]]</code></pre><p>删除没有信息量的单词，除了使用<code>min_df</code>参数设定词例至少需要在多少个文档中出现过之外，还可以通过添加停用词的方法。</p><h2 id="二、用tf-idf缩放数据"><a href="#二、用tf-idf缩放数据" class="headerlink" title="二、用tf-idf缩放数据"></a>二、用tf-idf缩放数据</h2><p>词频 - 逆向文档频率（term frequency–inverse document frequency，tf-idf）方法，对在某个特定文档中经常出现的术语给予很高的权重，但对在语料库的许多文档中都经常出现的术语给予的权重却不高。</p><p>scikit-learn 在两个类中实现了 tf-idf 方法：TfidfTransformer 和 TfidfVectorizer，前者接受 CountVectorizer 生成的稀疏矩阵并将其变换，后者接受文本数据并完成词袋特征提取与 tf-idf 变换。</p><p>单词w在文档d中的tf-idf分数为：</p><p><img src="/2020/06/09/【学习笔记】机器学习中处理文本数据的常用方法/2020-06-09-23-20-54.png" srcset="/img/loading.gif" alt></p><p>式中，tf为词频，Term Frequency, 表示一个词在一个文档中的出现频率。该频率最后要除以该文档的长度，用以归一化。</p><p>式中，$N$为总文档数，$N_w$为带有单词$w$的文档数。由于分子比分母大，所以该 $\log$ 值必不可能小于零。</p><pre><code class="lang-python">from sklearn.feature_extraction.text import TfidfVectorizercorpus=[&quot;I come to China to travel&quot;,&quot;This is a car polupar in China&quot;,&quot;I love tea and Apple &quot;,&quot;The work is to write some papers in science&quot;]tfidf = TfidfVectorizer()vector = tfidf.fit_transform(corpus)print(vector)#---------------#(0, 16)    0.4424621378947393(0, 3)    0.348842231691988(0, 15)    0.697684463383976(0, 4)    0.4424621378947393(1, 5)    0.3574550433419527(1, 9)    0.45338639737285463(1, 2)    0.45338639737285463(1, 6)    0.3574550433419527(1, 14)    0.45338639737285463(1, 3)    0.3574550433419527(2, 1)    0.5(2, 0)    0.5(2, 12)    0.5(2, 7)    0.5(3, 10)    0.3565798233381452(3, 8)    0.3565798233381452(3, 11)    0.3565798233381452(3, 18)    0.3565798233381452(3, 17)    0.3565798233381452(3, 13)    0.3565798233381452(3, 5)    0.2811316284405006(3, 6)    0.2811316284405006(3, 15)    0.2811316284405006</code></pre><p>返回值什么意思呢？(0, 16)代表第0个文档，第一个单词在单词表（词袋）中的位置是第16个，该单词的tf-idf值为0.44246213；第二个单词在词袋中第3个位置……</p><p>显然这是个经过压缩的系数矩阵，每一行的元组表明该元素在稀疏矩阵中的位置，其值为右边的tf-idf值，代表一个单词。可以通过<code>.toarray()</code>方法令其恢复到系数矩阵状态。</p><pre><code class="lang-python">print(vector.toarray().shape)print(len(vector.toarray()))print(type(vector.toarray()))print(vector.toarray())#-----------------------------#(4, 19)4&lt;class &#39;numpy.ndarray&#39;&gt;[[0. 0. 0. 0.34884223 0.44246214 0.  0. 0. 0. 0. 0. 0.  0. 0. 0. 0.69768446 0.44246214 0.  0. ] [0. 0. 0.4533864  0.35745504 0. 0.35745504  0.35745504 0. 0. 0.4533864  0. 0.  0. 0. 0.4533864  0. 0. 0.  0. ] [0.5 0.5 0. 0. 0. 0.  0. 0.5 0. 0. 0. 0.  0.5 0. 0. 0. 0. 0.  0. ] [0. 0. 0. 0. 0. 0.28113163  0.28113163 0. 0.35657982 0. 0.35657982 0.35657982  0. 0.35657982 0. 0.28113163 0. 0.35657982  0.35657982]]</code></pre><h2 id="三、多元词袋"><a href="#三、多元词袋" class="headerlink" title="三、多元词袋"></a>三、多元词袋</h2><p>词袋模型将一段文档拆分成单词后，忽略了单词的上下文可能对文档的含义造成影响。</p><p>因此可以通过</p><h2 id="四、英语的词干提取与词形还原"><a href="#四、英语的词干提取与词形还原" class="headerlink" title="四、英语的词干提取与词形还原"></a>四、英语的词干提取与词形还原</h2><h2 id="五、中文的分词"><a href="#五、中文的分词" class="headerlink" title="五、中文的分词"></a>五、中文的分词</h2><h2 id="六、主题建模与文档聚类"><a href="#六、主题建模与文档聚类" class="headerlink" title="六、主题建模与文档聚类"></a>六、主题建模与文档聚类</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结词袋模型、Tf-idf等文本特征提取方法&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Machine Learning" scheme="https://superlova.github.io/tags/Machine-Learning/"/>
    
      <category term="IMDb" scheme="https://superlova.github.io/tags/IMDb/"/>
    
  </entry>
  
  <entry>
    <title>【经验分享】IMDb数据集的预处理</title>
    <link href="https://superlova.github.io/2020/06/09/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91IMDb%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <id>https://superlova.github.io/2020/06/09/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91IMDb%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86/</id>
    <published>2020-06-09T14:48:03.000Z</published>
    <updated>2020-06-10T07:01:36.220Z</updated>
    
    <content type="html"><![CDATA[<p>IMDb从官网下载与从keras直接调用的处理方法是不同的。<br><a id="more"></a></p><h2 id="一、IMDb数据集的处理方法"><a href="#一、IMDb数据集的处理方法" class="headerlink" title="一、IMDb数据集的处理方法"></a>一、IMDb数据集的处理方法</h2><h3 id="1-官网下载法"><a href="#1-官网下载法" class="headerlink" title="1. 官网下载法"></a>1. 官网下载法</h3><pre><code class="lang-python">import pandas as pdimport numpy as npfrom sklearn.datasets import load_files</code></pre><pre><code class="lang-shell">!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz!tar -zxvf aclImdb_v1.tar.gz!ls</code></pre><p>对于 v1.0 版数据，其训练集大小是 75 000，而不是 25 000，因为其中还包含 50 000 个用于无监督学习的无标签文档。</p><p>在进行后续操作之前，建议先将这 50 000 个无标签文档从训练集中剔除。</p><pre><code class="lang-bash">!mkdir aclImdb/train_unlabel!mv aclImdb/train/unsupBow.feat aclImdb/train_unlabel!mv aclImdb/train/urls_unsup.txt aclImdb/train_unlabel!mv aclImdb/train/unsup aclImdb/train_unlabel</code></pre><pre><code class="lang-python">reviews_train = load_files(&quot;aclImdb/train/&quot;)text_train, y_train = reviews_train.data, reviews_train.targetreviews_test = load_files(&quot;aclImdb/test/&quot;)text_test, y_test = reviews_test.data, reviews_test.target# 删掉HTML换行符text_train = [doc.replace(b&quot;&lt;br /&gt;&quot;, b&quot; &quot;) for doc in text_train]text_test = [doc.replace(b&quot;&lt;br /&gt;&quot;, b&quot; &quot;) for doc in text_test]print(&quot;type of text_train: {}&quot;.format(type(text_train))) # 查看训练集类型：listprint(&quot;length of text_train: {}&quot;.format(len(text_train))) # 查看训练集大小print(&quot;text_train[1]:\n{}&quot;.format(text_train[1])) # 查看第二段文本print(&quot;Samples per class (training): {}&quot;.format(np.bincount(y_train))) # 查看数据集是否均等#------------------------------------------------#type of text_train: &lt;class &#39;list&#39;&gt;length of text_train: 25000text_train[1]:b&#39;Words can\&#39;t describe how bad this movie is. I can\&#39;t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\xc3\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\&#39;t list them here, but just mention the coloring of the plane. They didn\&#39;t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\&#39; side all the time in the movie, because the good guys were so stupid. &quot;Executive Decision&quot; should without a doubt be you\&#39;re choice over this one, even the &quot;Turbulence&quot;-movies are better. In fact, every other movie in the world is better than this one.&#39;Samples per class (training): [12500 12500]</code></pre><p>采用词袋模型整理数据</p><pre><code class="lang-python">vect = CountVectorizer().fit(text_train)X_train = vect.transform(text_train)print(&quot;X_train:\n{}&quot;.format(repr(X_train)))#---------------------------#X_train:&lt;25000x74849 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;with 3431196 stored elements in Compressed Sparse Row format&gt;</code></pre><p>X_train 是训练数据的词袋表示，其形状为 25 000×74 849，这表示词表中包含 74 849 个元素。数据被保存为 SciPy 稀疏矩阵。</p><p>访问词表的另一种方法是使用向量器（vectorizer）的 get_feature_name 方法，它将返回一个列表，每个元素对应于一个特征：</p><p>feature_names = vect.get_feature_names()<br>print(“Number of features: {}”.format(len(feature_names)))<br>print(“First 20 features:\n{}”.format(feature_names[:20]))<br>print(“Features 20010 to 20030:\n{}”.format(feature_names[20010:20030]))<br>print(“Every 2000th feature:\n{}”.format(feature_names[::2000]))</p><p>Number of features: 74849<br>First 20 features:<br>[‘00’, ‘000’, ‘0000000000001’, ‘00001’, ‘00015’, ‘000s’, ‘001’, ‘003830’,<br>‘006’, ‘007’, ‘0079’, ‘0080’, ‘0083’, ‘0093638’, ‘00am’, ‘00pm’, ‘00s’,’01’, ‘01pm’, ‘02’]<br>Features 20010 to 20030:<br>[‘dratted’, ‘draub’, ‘draught’, ‘draughts’, ‘draughtswoman’, ‘draw’, ‘drawback’,<br>‘drawbacks’, ‘drawer’, ‘drawers’, ‘drawing’, ‘drawings’, ‘drawl’,<br>‘drawled’, ‘drawling’, ‘drawn’, ‘draws’, ‘draza’, ‘dre’, ‘drea’]<br>Every 2000th feature:<br>[‘00’, ‘aesir’, ‘aquarian’, ‘barking’, ‘blustering’, ‘beête’, ‘chicanery’,<br>‘condensing’, ‘cunning’, ‘detox’, ‘draper’, ‘enshrined’, ‘favorit’, ‘freezer’,<br>‘goldman’, ‘hasan’, ‘huitieme’, ‘intelligible’, ‘kantrowitz’, ‘lawful’,<br>‘maars’, ‘megalunged’, ‘mostey’, ‘norrland’, ‘padilla’, ‘pincher’,<br>‘promisingly’, ‘receptionist’, ‘rivals’, ‘schnaas’, ‘shunning’, ‘sparse’,<br>‘subset’, ‘temptations’, ‘treatises’, ‘unproven’, ‘walkman’, ‘xylophonist’]</p><p>词表的前 10 个元素都是数字。所有这些数字都出现在评论中的某处，因此被提取为单词。</p><h3 id="2-使用keras自带的IMDb数据集"><a href="#2-使用keras自带的IMDb数据集" class="headerlink" title="2. 使用keras自带的IMDb数据集"></a>2. 使用keras自带的IMDb数据集</h3><pre><code class="lang-python">from tensorflow.keras.datasets import imdb(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000) # 仅保留训练数据中前10000个最经常出现的单词，低频单词被舍弃print(&#39;len of X_train: {}&#39;.format(len(X_train)))print(&#39;shape of X_train: {}&#39;.format(X_train.shape))print(&#39;first of X_train: {}&#39;.format(X_train[0]))print(&#39;training sample per class: {}&#39;.format(np.bincount(y_train)))#-------------------#len of X_train: 25000shape of X_train: (25000,)first of X_train: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]training sample per class: [12500 12500]</code></pre><p>可以看到keras已经把IMDb数据集给提前整理过了。此处每条数据都是一个向量，每个数值代表一个单词。数值的大小代表了该单词在单词表中的位置。显然，每条数据向量的长度不一定相同。</p><p>为了方便处理，我们可以规定每条文档的长度为maxlen</p><pre><code class="lang-python">from tensorflow.keras.preprocessing import sequenceprint(&#39;Pad sequences (samples x time)&#39;)x_train = sequence.pad_sequences(x_train, maxlen=maxlen)x_test = sequence.pad_sequences(x_test, maxlen=maxlen)print(&#39;x_train shape:&#39;, x_train.shape)print(&#39;x_test shape:&#39;, x_test.shape)#-------------------#Pad sequences (samples x time)x_train shape: (25000, 80)x_test shape: (25000, 80)</code></pre><p>训练集中一共25000条文档，其中12500个正类，12500个负类。每个文档都是由80个数字组成的向量。测试集亦然。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;IMDb从官网下载与从keras直接调用的处理方法是不同的。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="IMDb" scheme="https://superlova.github.io/tags/IMDb/"/>
    
      <category term="preprocessing" scheme="https://superlova.github.io/tags/preprocessing/"/>
    
  </entry>
  
  <entry>
    <title>【经验分享】停电了怎么办？Python获取Windows电源连接信息</title>
    <link href="https://superlova.github.io/2020/06/08/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91%E5%81%9C%E7%94%B5%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9FPython%E8%8E%B7%E5%8F%96Windows%E7%94%B5%E6%BA%90%E8%BF%9E%E6%8E%A5%E4%BF%A1%E6%81%AF/"/>
    <id>https://superlova.github.io/2020/06/08/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91%E5%81%9C%E7%94%B5%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9FPython%E8%8E%B7%E5%8F%96Windows%E7%94%B5%E6%BA%90%E8%BF%9E%E6%8E%A5%E4%BF%A1%E6%81%AF/</id>
    <published>2020-06-08T01:42:45.000Z</published>
    <updated>2020-06-08T02:15:04.116Z</updated>
    
    <content type="html"><![CDATA[<p>一旦停电，就令笔记本电脑发出响声、发送信息……。看似简单的功能，该如何利用Python实现呢？<br><a id="more"></a></p><p>采用笔记本电脑办公的好处是不必害怕突然停电。然而笔记本电脑不可能使用电池工作太久，此时必须尽快通知管理人员，恢复供电。</p><p>看似简单的功能，只需在Windows中注册一个HANDLE，负责接收电源适配器更改这一事件即可。但是本人没有Windows编程和系统编程的经验，只对Python熟悉。如何实现这一功能？</p><p>废话不多说，下面是代码。</p><pre><code class="lang-python">import win32conimport win32apiimport win32guiimport timefrom ctypes import POINTER, windll, Structure, cast, CFUNCTYPE, c_int, c_uint, c_void_p, c_boolfrom comtypes import GUIDfrom ctypes.wintypes import HANDLE, DWORDPBT_POWERSETTINGCHANGE = 0x8013GUID_CONSOLE_DISPLAY_STATE = &#39;{6FE69556-704A-47A0-8F24-C28D936FDA47}&#39;GUID_ACDC_POWER_SOURCE = &#39;{5D3E9A59-E9D5-4B00-A6BD-FF34FF516548}&#39;GUID_BATTERY_PERCENTAGE_REMAINING = &#39;{A7AD8041-B45A-4CAE-87A3-EECBB468A9E1}&#39;GUID_MONITOR_POWER_ON = &#39;{02731015-4510-4526-99E6-E5A17EBD1AEA}&#39;GUID_SYSTEM_AWAYMODE = &#39;{98A7F580-01F7-48AA-9C0F-44352C29E5C0}&#39;class POWERBROADCAST_SETTING(Structure):    _fields_ = [(&quot;PowerSetting&quot;, GUID),                (&quot;DataLength&quot;, DWORD),                (&quot;Data&quot;, DWORD)]def wndproc(hwnd, msg, wparam, lparam):    if msg == win32con.WM_POWERBROADCAST:        if wparam == win32con.PBT_APMPOWERSTATUSCHANGE:            print(&#39;Power status has changed&#39;)        if wparam == win32con.PBT_APMRESUMEAUTOMATIC:            print(&#39;System resume&#39;)        if wparam == win32con.PBT_APMRESUMESUSPEND:            print(&#39;System resume by user input&#39;)        if wparam == win32con.PBT_APMSUSPEND:            print(&#39;System suspend&#39;)        if wparam == PBT_POWERSETTINGCHANGE:            print(&#39;Power setting changed...&#39;)            settings = cast(lparam, POINTER(POWERBROADCAST_SETTING)).contents            power_setting = str(settings.PowerSetting)            data_length = settings.DataLength            data = settings.Data            if power_setting == GUID_CONSOLE_DISPLAY_STATE:                if data == 0: print(&#39;Display off&#39;)                if data == 1: print(&#39;Display on&#39;)                if data == 2: print(&#39;Display dimmed&#39;)            elif power_setting == GUID_ACDC_POWER_SOURCE:                if data == 0: print(&#39;AC power&#39;)                if data == 1:                    print(&#39;Battery power&#39;)                    #################################################                    playsound(&#39;alert.mp3&#39;) # 此处自定义你的操作                    #################################################                if data == 2: print(&#39;Short term power&#39;)            elif power_setting == GUID_BATTERY_PERCENTAGE_REMAINING:                print(&#39;battery remaining: %s&#39; % data)            elif power_setting == GUID_MONITOR_POWER_ON:                if data == 0: print(&#39;Monitor off&#39;)                if data == 1: print(&#39;Monitor on&#39;)            elif power_setting == GUID_SYSTEM_AWAYMODE:                if data == 0: print(&#39;Exiting away mode&#39;)                if data == 1: print(&#39;Entering away mode&#39;)            else:                print(&#39;unknown GUID&#39;)        return True    return Falseif __name__ == &quot;__main__&quot;:    print(&quot;*** STARTING ***&quot;)    hinst = win32api.GetModuleHandle(None)    wndclass = win32gui.WNDCLASS()    wndclass.hInstance = hinst    wndclass.lpszClassName = &quot;testWindowClass&quot;    CMPFUNC = CFUNCTYPE(c_bool, c_int, c_uint, c_uint, c_void_p)    wndproc_pointer = CMPFUNC(wndproc)    wndclass.lpfnWndProc = {win32con.WM_POWERBROADCAST : wndproc_pointer}    try:        myWindowClass = win32gui.RegisterClass(wndclass)        hwnd = win32gui.CreateWindowEx(win32con.WS_EX_LEFT,                                     myWindowClass,                                     &quot;testMsgWindow&quot;,                                     0,                                     0,                                     0,                                     win32con.CW_USEDEFAULT,                                     win32con.CW_USEDEFAULT,                                     0,                                     0,                                     hinst,                                     None)    except Exception as e:        print(&quot;Exception: %s&quot; % str(e))    if hwnd is None:        print(&quot;hwnd is none!&quot;)    else:        print(&quot;hwnd: %s&quot; % hwnd)    guids_info = {                    &#39;GUID_MONITOR_POWER_ON&#39; : GUID_MONITOR_POWER_ON,                    &#39;GUID_SYSTEM_AWAYMODE&#39; : GUID_SYSTEM_AWAYMODE,                    &#39;GUID_CONSOLE_DISPLAY_STATE&#39; : GUID_CONSOLE_DISPLAY_STATE,                    &#39;GUID_ACDC_POWER_SOURCE&#39; : GUID_ACDC_POWER_SOURCE,                    &#39;GUID_BATTERY_PERCENTAGE_REMAINING&#39; : GUID_BATTERY_PERCENTAGE_REMAINING                 }    for name, guid_info in guids_info.items():        result = windll.user32.RegisterPowerSettingNotification(HANDLE(hwnd), GUID(guid_info), DWORD(0))        print(&#39;registering&#39;, name)        print(&#39;result:&#39;, hex(result))        print(&#39;lastError:&#39;, win32api.GetLastError())        print()    print(&#39;\nEntering loop&#39;)    while True:        win32gui.PumpWaitingMessages()        time.sleep(1)</code></pre><p>COM: The Component Object Model 组件对象模型，是微软的一套软件组件的二进制接口标准。COM使得跨编程语言的进程间通信、动态对象创建成为可能。</p><p>COM实质上是一种语言无关的对象实现方式，这使其可以在创建环境不同的场合、甚至跨计算机的分布环境下被复用。COM允许复用这些对象，而不必知道对象内部是如何实现，因为组件实现者必须提供良好定义的接口从而屏蔽实现细节。通过引用计数，组件对象自己负责动态创建与销毁，从而屏蔽了不同编程语言之间的内存分配语义差异。</p><p>对于某些应用程序来说，COM已经部分被.NET框架取代。.NET Framework是新一代的Microsoft Windows应用程序开发平台。</p><p>COM是基于组件对象方式概念来设计的，在基础中，至少要让每个组件都可以支持二个功能：</p><p>查询组件中有哪些接口<br>让组件做自我生命管理，此概念的实践即为引用计数（Reference Counting）</p><p>GUID 是一个 128 位整数（16 字节），COM将其用于计算机和网络的唯一标识符。全局唯一标识符（英语：Globally Unique Identifier，缩写：GUID；发音为/ˈɡuːɪd/或/ˈɡwɪd/）是一种由算法生成的唯一标识，通常表示成32个16进制数字（0－9，A－F）组成的字符串，如：{21EC2020-3AEA-1069-A2DD-08002B30309D}，它实质上是一个128位长的二进制整数。</p><p>Windows操作系统使用GUID来标识COM对象中的类和界面。一个脚本可以不需知道DLL的位置和名字直接通过GUID来激活其中的类或对象。</p><p>参考：<a href="https://stackoverflow.com/questions/48720924/python-3-detect-monitor-power-state-in-windows" target="_blank" rel="noopener">https://stackoverflow.com/questions/48720924/python-3-detect-monitor-power-state-in-windows</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一旦停电，就令笔记本电脑发出响声、发送信息……。看似简单的功能，该如何利用Python实现呢？&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Windows" scheme="https://superlova.github.io/tags/Windows/"/>
    
      <category term="PowerOff" scheme="https://superlova.github.io/tags/PowerOff/"/>
    
  </entry>
  
  <entry>
    <title>【经验分享】TensorFlow模型训练和保存</title>
    <link href="https://superlova.github.io/2020/06/03/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91TensorFlow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E4%BF%9D%E5%AD%98/"/>
    <id>https://superlova.github.io/2020/06/03/%E3%80%90%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E3%80%91TensorFlow%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E4%BF%9D%E5%AD%98/</id>
    <published>2020-06-03T14:35:56.000Z</published>
    <updated>2020-06-03T14:40:27.579Z</updated>
    
    <content type="html"><![CDATA[<p>使用LSTM训练最简单的IMDB影评分类任务，总结文本分类任务常见流程。<br><a id="more"></a></p><h2 id="1-模型训练和保存"><a href="#1-模型训练和保存" class="headerlink" title="1. 模型训练和保存"></a>1. 模型训练和保存</h2><h3 id="1-1-训练结束时保存"><a href="#1-1-训练结束时保存" class="headerlink" title="1.1 训练结束时保存"></a>1.1 训练结束时保存</h3><p>训练模型，使用fit函数。fit函数的参数如下。</p><pre><code class="lang-python">fit(    x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,    validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,    sample_weight=None, initial_epoch=0, steps_per_epoch=None,    validation_steps=None, validation_batch_size=None, validation_freq=1,    max_queue_size=10, workers=1, use_multiprocessing=False)</code></pre><p>x：训练数据<br>y：训练标签<br>batch_size：批次大小，默认为32<br>validation_data：在每个epoch结束之时计算loss等其他模型性能指标，不用做训练。<br>epoch：训练轮次<br>verbose：输出的详细程度，为1则输出进度条，表明每个epoch训练完成度；为0则什么也不输出，为2则很啰嗦地输出所有信息</p><p>最后保存模型用<code>model.save(&#39;xxx.h5&#39;)</code>，这里模型格式为HDF5，因此结尾为h5。</p><pre><code class="lang-python">model.fit(X_train, y_train, validation_data=(X_test, y_test), epoch=10, batch_size=64) scores = model.evaluate(X_test, y_test, verbose=0)print(&quot;Accuracy: %.2f%%&quot; % (scores[1]*100))model.save(&#39;models/sentiment-lstm.h5&#39;)</code></pre><h3 id="1-2-在训练期间保存模型（以-checkpoints-形式保存）"><a href="#1-2-在训练期间保存模型（以-checkpoints-形式保存）" class="headerlink" title="1.2 在训练期间保存模型（以 checkpoints 形式保存）"></a>1.2 在训练期间保存模型（以 checkpoints 形式保存）</h3><p>您可以使用训练好的模型而无需从头开始重新训练，或在您打断的地方开始训练，以防止训练过程没有保存。<code>tf.keras.callbacks.ModelCheckpoint</code> 允许在训练的过程中和结束时回调保存的模型。</p><pre><code class="lang-python">checkpoint_path = &quot;training_1/cp.ckpt&quot;checkpoint_dir = os.path.dirname(checkpoint_path)# 创建一个保存模型权重的回调函数cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,                                                 save_weights_only=True,                                                 verbose=1)# 使用新的回调函数训练模型model.fit(train_images,           train_labels,            epochs=10,          validation_data=(test_images,test_labels),          callbacks=[cp_callback])  # 通过回调训练# 这可能会生成与保存优化程序状态相关的警告。# 这些警告（以及整个笔记本中的类似警告）是防止过时使用，可以忽略。</code></pre><p>这将创建一个 TensorFlow checkpoint 文件集合，这些文件在每个 epoch 结束时更新</p><pre><code>cp.ckpt.data-00001-of-00002cp.ckpt.data-00000-of-00002  cp.ckpt.index</code></pre><p>默认的 tensorflow 格式仅保存最近的5个 checkpoint 。</p><h3 id="1-3-手动保存权重"><a href="#1-3-手动保存权重" class="headerlink" title="1.3 手动保存权重"></a>1.3 手动保存权重</h3><p>不必等待epoch结束，通过执行<code>save_weights</code>就可以生成ckpt文件。</p><pre><code class="lang-python"># 保存权重model.save_weights(&#39;./checkpoints/my_checkpoint&#39;)</code></pre><h2 id="2-模型加载"><a href="#2-模型加载" class="headerlink" title="2. 模型加载"></a>2. 模型加载</h2><h3 id="2-1-从h5文件中恢复"><a href="#2-1-从h5文件中恢复" class="headerlink" title="2.1 从h5文件中恢复"></a>2.1 从h5文件中恢复</h3><pre><code class="lang-python"># 重新创建完全相同的模型model=load_model(&#39;models/sentiment-lstm.h5&#39;)# 加载后重新编译模型，否则您将失去优化器的状态model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) model.summary()</code></pre><p>加载模型的时候，损失函数等参数需要重新设置。</p><h3 id="2-2-从ckpt文件中断点续训"><a href="#2-2-从ckpt文件中断点续训" class="headerlink" title="2.2 从ckpt文件中断点续训"></a>2.2 从ckpt文件中断点续训</h3><p>仅恢复模型的权重时，必须具有与原始模型具有相同网络结构的模型。</p><pre><code class="lang-python"># 这个模型与ckpt保存的一样架构，只不过没经过fit训练model = create_model()# 加载权重model.load_weights(checkpoint_path)</code></pre><p>我们可以对回调函数增加一些新的设置，之前的回调函数每个epoch都覆盖掉之前的ckpt，现在我们想每过5个epoch保存一个新的断点：</p><pre><code class="lang-python"># 在文件名中包含 epoch (使用 `str.format`)checkpoint_path = &quot;training_2/cp-{epoch:04d}.ckpt&quot;checkpoint_dir = os.path.dirname(checkpoint_path)# 创建一个回调，每 5 个 epochs 保存模型的权重cp_callback = tf.keras.callbacks.ModelCheckpoint(    filepath=checkpoint_path,     verbose=1,     save_weights_only=True,    period=5)</code></pre><p>利用新的回调训练，并随后选择最新的断点文件：</p><pre><code class="lang-python"># 使用新的回调训练模型model.fit(train_images,               train_labels,              epochs=50,               callbacks=[cp_callback],              validation_data=(test_images,test_labels),              verbose=0)# 选择新的断点latest = tf.train.latest_checkpoint(checkpoint_dir)&gt;&gt;&gt; &#39;training_2/cp-0050.ckpt&#39;# 加载以前保存的权重model.load_weights(latest)</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用LSTM训练最简单的IMDB影评分类任务，总结文本分类任务常见流程。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="TensorFlow" scheme="https://superlova.github.io/tags/TensorFlow/"/>
    
      <category term="SaveModel" scheme="https://superlova.github.io/tags/SaveModel/"/>
    
  </entry>
  
  <entry>
    <title>【学习笔记】使用LSTM训练imdb情感分类模型</title>
    <link href="https://superlova.github.io/2020/06/03/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E4%BD%BF%E7%94%A8LSTM%E8%AE%AD%E7%BB%83imdb%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/"/>
    <id>https://superlova.github.io/2020/06/03/%E3%80%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E4%BD%BF%E7%94%A8LSTM%E8%AE%AD%E7%BB%83imdb%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-06-03T10:03:29.000Z</published>
    <updated>2020-06-03T14:41:37.751Z</updated>
    
    <content type="html"><![CDATA[<p>使用LSTM训练最简单的IMDB影评分类任务，总结文本分类任务常见流程。<br><a id="more"></a></p><h2 id="1-查看数据集"><a href="#1-查看数据集" class="headerlink" title="1. 查看数据集"></a>1. 查看数据集</h2><h3 id="1-1-官网上的数据集压缩包"><a href="#1-1-官网上的数据集压缩包" class="headerlink" title="1.1 官网上的数据集压缩包"></a>1.1 官网上的数据集压缩包</h3><p>从IMDB官网上下载的数据集，是一个压缩包<code>aclImdb_v1.tar.gz</code>。解压后的目录如下：<br><img src="/2020/06/03/【学习笔记】使用LSTM训练imdb情感分类模型/2020-06-03-18-12-58.png" srcset="/img/loading.gif" alt></p><ul><li><code>test</code></li><li><code>train</code></li><li><code>imdb.vocab</code></li><li><code>imdbEr.txt</code></li><li><code>README</code></li></ul><p>其内部不仅有完整的影评文件，还包含该影评的链接等信息。</p><h3 id="1-2-keras自带的数据集"><a href="#1-2-keras自带的数据集" class="headerlink" title="1.2 keras自带的数据集"></a>1.2 keras自带的数据集</h3><p>keras里的IMDB影评数据集，内部结构分为两个部分：影评部分和情感标签部分，也就是数据集的X和y部分。</p><p>X部分的每条影评都被编码为一个整数列表。另外，每个单词的在单词表中的编码越小，代表在影评中出现频率越高。这使得我们能在取数据时指定只使用某一出现频率内范围的单词（其他单词由于出现频率太低，可以直接标记为未知）。</p><p>“0”在数据集中代表“未知”单词。</p><p>我们采用内置的<code>load_data</code>函数来取出数据。</p><pre><code class="lang-python">tf.keras.datasets.imdb.load_data(    path=&#39;imdb.npz&#39;, num_words=None, skip_top=0, maxlen=None, seed=113,    start_char=1, oov_char=2, index_from=3, **kwargs)</code></pre><p>num_words: 即设定取出现频率在前num_words的单词。如果不填，所有单词表中的单词都会标记。<br>skip_top: 设定前skip_top频率出现的单词不予标记。这可能是由于高频出现的单词信息量太低（如the、a等）。<br>maxlen: 设定最大影评长度，超过该长度的影评都会被截断。<br>x_train, x_test: 返回影评列表，长度为影评个数（25000个训练，25000个测试），每个影评是整数数组。<br>y_train, y_test: 返回整数数组，长度为影评个数，代表影评的情感倾向（0或1）。</p><pre><code class="lang-python">from tensorflow.keras.datasets import imdbmax_features = 50000 # 取前50000个最常见的单词，组建词典(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)</code></pre><p>需要注意的是这个<code>max_features</code>与数据集的数目没有关系，不要搞混了。</p><h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h2><pre><code class="lang-python">from tensorflow.keras.preprocessing import sequenceprint(&#39;Pad sequences (samples x time)&#39;)x_train = sequence.pad_sequences(x_train, maxlen=maxlen)x_test = sequence.pad_sequences(x_test, maxlen=maxlen)X_trainarray([[    0,     0,     0, ...,    19,   178,    32],       [    0,     0,     0, ...,    16,   145,    95],       [    0,     0,     0, ...,     7,   129,   113],       ...,       [    0,     0,     0, ...,     4,  3586, 22459],       [    0,     0,     0, ...,    12,     9,    23],       [    0,     0,     0, ...,   204,   131,     9]], dtype=int32)</code></pre><p>经过这个函数处理，每条影评被规整成了长度为500的整形元素列表，长度不够500个单词的影评，在最前面加0；长度不够的则在最后截断。</p><h2 id="3-模型构建"><a href="#3-模型构建" class="headerlink" title="3. 模型构建"></a>3. 模型构建</h2><p><strong>Embedding层</strong></p><p>在最开始我们加入了Embedding层，max_features是字典长度，也可以说是one-hot向量长度。<br>input_length=500为每个序列为500个单词构成。<br>input_shape=(max_features,)表明one-hot的维度，这两个都可以不填，直接通过fit的时候推断出来</p><p><strong>LSTM层</strong></p><p>LSTM层的参数是output_dim，这个参数可以自定义，因为它不受之前影响，只表明输出的维度。</p><p>同时也是是门结构（forget门、update门、output门）的维度。之所以理解成维度，是因为LSTM中隐藏单元个数这个概念不好理解。其实该参数名称为<code>units</code>，官方说法就是“隐藏单元个数”。</p><p>LSTM层的输入是形如（samples，timesteps，input_dim）的3D张量；输出是形如（samples，timesteps，output_dim）的3D张量，或者返回形如（samples，output_dim）的2D张量。二者区别在于，若LSTM层中参数<code>return_sequences=True</code>，就返回带时间步的张量。</p><p>若我们有很多LSTM层，我们可以把很多LSTM层串在一起，为了方便LSTM层与层之间的信息传递，可以设置<code>return_sequences=True</code>。但是最后一个LSTM层return_sequences通常为false，此时输出的就是每个样本的结果张量。</p><p>假如我们输入有25000个句子，每个句子都由500个单词组成，而每个单词用64维的词向量表示。那么样本数目samples=25000，时间步timesteps=500（可以简单地理解timesteps就是输入序列的长度input_length），前一层Embedding词向量输出维度input_dim=128。</p><p>也就是说通过LSTM，把词的维度由128转变成了100。</p><p>在LSTM层中还可以设置Dropout，这一点在之后会详细说明。</p><p><strong>全连接层</strong></p><p>汇总至一个神经元的全连接层，即sigmoid层，判断0或1即可。</p><pre><code class="lang-python">from tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Embedding, LSTMmodel = Sequential() model.add(Embedding(max_features, 128, input_length=500, input_shape=(max_features,))) model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))model.add(Dense(1, activation=&#39;sigmoid&#39;)) model.compile(loss=&#39;binary_crossentropy&#39;,optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) print(model.summary())</code></pre><h2 id="4-模型训练和保存"><a href="#4-模型训练和保存" class="headerlink" title="4. 模型训练和保存"></a>4. 模型训练和保存</h2><pre><code class="lang-python">model.fit(X_train, y_train, validation_data=(X_test, y_test), epoch=10, batch_size=64) scores = model.evaluate(X_test, y_test, verbose=0)print(&quot;Accuracy: %.2f%%&quot; % (scores[1]*100))model.save(&#39;models/sentiment-lstm.h5&#39;)</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用LSTM训练最简单的IMDB影评分类任务，总结文本分类任务常见流程。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="LSTM" scheme="https://superlova.github.io/tags/LSTM/"/>
    
      <category term="IMDB" scheme="https://superlova.github.io/tags/IMDB/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Adversarial-Attacks-on-Deep-Learning-Models-in-Natural-Language-Processing-A-Survey/</id>
    <published>2020-06-02T06:16:03.000Z</published>
    <updated>2020-06-02T06:50:40.788Z</updated>
    
    <content type="html"><![CDATA[<p>文本领域的对抗样本生成技术综述。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;文本领域的对抗样本生成技术综述。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="survey" scheme="https://superlova.github.io/tags/survey/"/>
    
      <category term="Adversarial Attacks" scheme="https://superlova.github.io/tags/Adversarial-Attacks/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】 Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/</id>
    <published>2020-06-02T06:02:29.000Z</published>
    <updated>2020-06-26T17:30:26.814Z</updated>
    
    <content type="html"><![CDATA[<p>通过模糊测试的方法进行数据增强，数据增强新思路。新加坡国立大学作品，被ICSE’2020接收。<br><a id="more"></a></p><h1 id="内容概要"><a href="#内容概要" class="headerlink" title="内容概要"></a>内容概要</h1><ul><li>增强DNN的训练数据，从而增强其鲁棒性</li><li>将DNN数据扩充问题视为优化问题</li><li>使用遗传搜索来生成最合适的输入数据变体，用于训练DNN</li><li>学习识别跳过增强来加速训练</li><li>improve the robust accuracy of the DNN</li><li>reduce the average DNN training time by 25%, while still improving robust accuracy</li></ul><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>过拟合产生的问题：</p><ol><li>泛化性降低，测试集效果差；</li><li>鲁棒性不足，不能抵御样本微小扰动</li></ol><p>鲁棒性有两种：</p><ol><li>对抗鲁棒性，应对的是人为构造的扰动；</li><li>自然扰动鲁棒性，应对自然条件的变化。</li></ol><p>本文关注的是后一种鲁棒，采用数据增强手段模拟不同自然条件下的样本变化</p><h2 id="数据增强：传统软件"><a href="#数据增强：传统软件" class="headerlink" title="数据增强：传统软件"></a>数据增强：传统软件</h2><p>improves the generalization of generated programs by augmenting existing test suites</p><p>测试用例生成技术：随机测试，基于搜索的进化测试，符号执行，灰箱模糊测试等</p><p>AFL：涵盖更多的程序路径使我们能够找到代表性的测试并涵盖更多的程序功能</p><h2 id="数据增强：提升模型鲁棒性——研究现状"><a href="#数据增强：提升模型鲁棒性——研究现状" class="headerlink" title="数据增强：提升模型鲁棒性——研究现状"></a>数据增强：提升模型鲁棒性——研究现状</h2><p>基于梯度下降的鲁棒优化：</p><ul><li>尝试根据损失函数生成最差的变体，并将其添加到训练集中。</li><li>在自然环境变化（对于视觉应用）中突出显示的空间变换的输入空间是高度非凸的</li></ul><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-10-37.png" srcset="/img/loading.gif" alt></p><p>几乎所有用于提高鲁棒性的技术都会通过分析训练后的模型并随后生成对抗性示例在新数据上重新训练模型</p><h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ul><li>将数据扩充形式化为优化问题，利用模糊测试（遗传算法）求解</li><li>提出选择性扩充策略，仅选择部分数据点进行扩充</li></ul><h1 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h1><h2 id="模糊测试"><a href="#模糊测试" class="headerlink" title="模糊测试"></a>模糊测试</h2><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-11-29.png" srcset="/img/loading.gif" alt></p><h2 id="Robustness-of-DNN"><a href="#Robustness-of-DNN" class="headerlink" title="Robustness of DNN"></a>Robustness of DNN</h2><p>DNN很容易遭受微小扰动的影响，产生完全不同的决策。DNN抵御输入扰动的能力被认为是鲁棒性。</p><p>由于这项工作聚焦于自然生成的而不是人工合成的扰动，因此像GAN等技术不被考虑在内。</p><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>数据增强是一种扩充数据集、避免样本少导致过拟合的有效方法。增强效果受增强方法影响很大。一般认为数据增强后训练的模型鲁棒性能得到一定程度的提升。</p><h1 id="SENSEI工具"><a href="#SENSEI工具" class="headerlink" title="SENSEI工具"></a>SENSEI工具</h1><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>生成增强样本的过程，是多目标优化过程。</p><p>一方面求扰动δ，使得损失函数L最大；另一方面求模型参数θ，使损失函数L最小；求得此时的δ和θ。本质是一个二元优化找鞍点的问题。</p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-20-58.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-21-07.png" srcset="/img/loading.gif" alt></p><h2 id="优化思路"><a href="#优化思路" class="headerlink" title="优化思路"></a>优化思路</h2><p>基于模糊测试的方法（如引导搜索）能更有效地找到要训练的数据点的最佳Mutator，从而提高鲁棒性</p><p>并非训练数据集中的所有数据点都很难学习。一些数据点代表训练集中的理想示例，而另一些则令人困惑；</p><p>对所有这些点进行相同的处理可能会浪费宝贵的训练时间。因此仅在具有挑战性的数据点上花费扩充工作。</p><h2 id="整体算法"><a href="#整体算法" class="headerlink" title="整体算法"></a>整体算法</h2><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-21-37.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-21-43.png" srcset="/img/loading.gif" alt></p><p>Optimal Augmentation Module<br>选择最难的样本（L13~16）<br>Selective Augmentation Module<br>跳过突变不大的样本（L10~12,17）<br>数据增强过程是在训练时即时发生的</p><h2 id="遗传算法部分"><a href="#遗传算法部分" class="headerlink" title="遗传算法部分"></a>遗传算法部分</h2><p>将染色体表示为一组操作，该操作将应用于给定输入以获得真实的变化</p><p>将x旋转1度，然后将其平移一个像素，模拟相机在现实生活中的角度和移动，来得出图像（x）的真实变化（x’）</p><p>种群是代表当前解决方案子集的一组染色体</p><p>种群由两个遗传算子组成：突变和杂交</p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-22-47.png" srcset="/img/loading.gif" alt></p><p>通过合并两个随机选择的现有染色体来完成交叉以创建新染色体</p><ul><li>c1 = {旋转：1，平移：2，剪切：-0.15}和</li><li>c2 = {旋转：-1，平移：-3，剪切：0.1}</li><li>C = {旋转：1, 平移：-3，剪切：0.1}</li></ul><p>杂交算子在1和染色体长度（l）之间生成随机数r，取c1的1到r部分，与c2的r+1到l部分拼合成新的染色体</p><p>突变算子通过随机改变染色体中的单个操作（改变参数）来执行突变。</p><p>始终将生成的转换向量（染色体）应用于原始图像（而不是应用于已转换的数据），以防止生成的数据不真实</p><p>生成新种群后，将对其进行评估，并且仅将最佳集合作为当前种群传递给下一代（原算法L17）</p><p>适应度函数的设计在GA中起着重要作用，以测量给定解决方案的质量<br>根据DNN的经验损失定义适应度函数</p><script type="math/tex; mode=display">f_{\text {loss}}\left(x^{\prime}\right)=L\left(\theta, x^{\prime}, y\right)</script><p>在DNN的增强训练中应使用遭受DNN损失更大的变体，以使DNN更加健壮</p><h2 id="选择性增强"><a href="#选择性增强" class="headerlink" title="选择性增强"></a>选择性增强</h2><p>Sensei-SA会跳过已由M鲁棒分类的数据点<br>基于分类的鲁棒性：模型正确地分类了x和所有未改变类别的Mutator（x′）<br>基于损失的鲁棒性：x的预测损失或未改变类别（x’）的任何预测损失不大于损失阈值</p><p>如果种子是鲁棒的，则Sensei-SA不会对其进行数据增强；除非在随后的训练中将种子错误地分类，或预测损失小于阈值</p><h2 id="图像扰动"><a href="#图像扰动" class="headerlink" title="图像扰动"></a>图像扰动</h2><p>仿射变换操作、像素操作<br>旋转（x，d）：在[-30，30]范围内将x旋转d度。<br>平移（x，d）：在图像大小的[-10％，10％]范围内水平或垂直将x按d像素平移。<br>剪切（x，d）：水平剪切x，剪切因子d在[-0.1，0.1]范围内。<br>缩放（x，d）：以[0.9,1.1]的缩放系数d放大/缩小x<br>亮度（x，d）：在[-32，32]范围内为x的每个像素统一加减一个值<br>对比度（x，d）：将x的每个像素的RGB值按[0.8，1.2]范围内的因子d缩放。</p><h2 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h2><p>鲁棒性精度（robust accuracy）是指测试集中DNN的预测不随任何小的现实扰动而改变的图像比例</p><script type="math/tex; mode=display">\text {robust accuracy}=\frac{\text {nRobustInstances}}{\text {nInstances}}</script><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><h2 id="1-Sensei是否可以有效解决鞍点问题？"><a href="#1-Sensei是否可以有效解决鞍点问题？" class="headerlink" title="1.Sensei是否可以有效解决鞍点问题？"></a>1.Sensei是否可以有效解决鞍点问题？</h2><p>关键是检查Sensei是否确实有效比最先进的技术更有效地找到损耗最大的变体<br>W-10在每一步为每个图像随机生成十个扰动，并用模型表现最差的图像替换原始图像<br>结果表明，Sensei更有效地解决了内部最大化问题<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-26-16.png" srcset="/img/loading.gif" alt></p><h2 id="2-Sensei是否比基于对抗样本再训练方法表现更好"><a href="#2-Sensei是否比基于对抗样本再训练方法表现更好" class="headerlink" title="2.Sensei是否比基于对抗样本再训练方法表现更好"></a>2.Sensei是否比基于对抗样本再训练方法表现更好</h2><p>对抗样本再训练方法：<br>i）使用原始训练数据训练模型；<br>ii）通过我们的转换（即使DNN蒙混的变体）生成对抗性示例；<br>iii）选择最佳对抗性示例，添加训练数据，然后重新训练5个模型</p><p><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-26-58.png" srcset="/img/loading.gif" alt></p><h2 id="3-Sensei能否提高鲁棒性同时保持精度"><a href="#3-Sensei能否提高鲁棒性同时保持精度" class="headerlink" title="3.Sensei能否提高鲁棒性同时保持精度"></a>3.Sensei能否提高鲁棒性同时保持精度</h2><p>mixup 是一种数据增强方法。mixup和Sensei都总体上改善了泛化性能。实际上，在标准泛化方面，mixup比Sensei更好；但是，在改善现实世界中自然发生的Mutator的鲁棒性方面，mixup效果不佳。<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-27-21.png" srcset="/img/loading.gif" alt></p><h2 id="4-选择性数据增强（-Sensei-SA-）的效果和效率"><a href="#4-选择性数据增强（-Sensei-SA-）的效果和效率" class="headerlink" title="4.选择性数据增强（ Sensei-SA ）的效果和效率"></a>4.选择性数据增强（ Sensei-SA ）的效果和效率</h2><p>与W-10相比，Sensei-SA减少了25％的训练时间，而鲁棒性则提高了3％。<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-27-38.png" srcset="/img/loading.gif" alt></p><h2 id="5-对超参数的敏感程度"><a href="#5-对超参数的敏感程度" class="headerlink" title="5.对超参数的敏感程度"></a>5.对超参数的敏感程度</h2><p>突变体集合规模最好为10~15</p><p>神经元覆盖率在鲁棒性评估方面表现出与损失函数相似的性能</p><p>基于神经元覆盖的适应度函数比基于损失的适应度函数将训练时间增加了50％。 原因是神经元覆盖率的计算比训练损失要昂贵<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-27-55.png" srcset="/img/loading.gif" alt><br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-28-00.png" srcset="/img/loading.gif" alt></p><p>在判断样本鲁棒性上，基于损失的选择均优于基于分类的选择。</p><p>基于损失的选择足以跳过足够数量的数据点，从而平均减少25％的训练时间。<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-28-12.png" srcset="/img/loading.gif" alt></p><p>Loss threshold越大，训练时间越短，然而鲁棒准确性也下降</p><p>Cifar10数据集比其他数据集对loss threshold更为敏感<br><img src="/2020/06/02/【论文阅读笔记】Fuzz-Testing-based-Data-Augmentation-to-Improve-Robustness-of-Deep-Neural-Networks/2020-06-27-01-28-22.png" srcset="/img/loading.gif" alt></p><h1 id="Threads-to-Validity"><a href="#Threads-to-Validity" class="headerlink" title="Threads to Validity"></a>Threads to Validity</h1><p>our results may not generalize to other datasets, or models, or for other applications</p><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><h2 id="测试充足性指标"><a href="#测试充足性指标" class="headerlink" title="测试充足性指标"></a>测试充足性指标</h2><ul><li>DeepXplore，Neuron Coverage</li><li>DeepGauge，k截面神经元覆盖率和神经元边界覆盖率</li><li>惊奇度 surprise adequacy</li><li>MODE，执行状态差分分析以识别模型的错误特征，然后在此基础上执行训练输入选择</li></ul><h2 id="测试用例生成"><a href="#测试用例生成" class="headerlink" title="测试用例生成"></a>测试用例生成</h2><ul><li>对抗性测试，有选择地修改几个像素，将对抗性实例的生成建模为优化问题，并使用一阶优化算法解决优化问题。生成机器学习也可以用来生成对抗性输入</li><li>但是对于自然产生的变化（旋转和平移等），由于其变换非凸，不利于一阶优化</li><li>TensorFuzz，不适合我们的数据增强驱动的鲁棒性训练目标</li><li>DeepTest和DeepRoad，通过metamorphic testing来生成暴露DNN bug的测试用例</li></ul><h2 id="测试合并策略，Test-incorporation-strategy"><a href="#测试合并策略，Test-incorporation-strategy" class="headerlink" title="测试合并策略，Test incorporation strategy"></a>测试合并策略，Test incorporation strategy</h2><ul><li>绝大多数DNN测试用例生成技术首先使用经过训练的DNN生成测试（或对抗实例），然后使用它们重新训练DNN，以提高其准确性或健壮性。</li><li>AutoAugment ，使用强化学习在搜索空间中找到最佳的扩增策略，从而使神经网络达到最高精度</li><li>Mixup，是最近提出的最先进的数据增强技术，但是在良性变异中，鲁棒性不佳。</li><li>Engstrom，除了没用遗传算法之外都一样</li></ul><h2 id="稳健性模型，Robust-models"><a href="#稳健性模型，Robust-models" class="headerlink" title="稳健性模型，Robust models"></a>稳健性模型，Robust models</h2><ul><li>基于正则化的白盒方法，通过修改DNN损失函数，并在标准经验损失中加入一个不变量来正则化，提高深度神经网络模型的鲁棒性</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过模糊测试的方法进行数据增强，数据增强新思路。新加坡国立大学作品，被ICSE’2020接收。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="Fuzz Testing" scheme="https://superlova.github.io/tags/Fuzz-Testing/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91EDA-Easy-Data-Augmentation-Techniques-for-Boosting-Performance-on-Text-Classification-Tasks/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91EDA-Easy-Data-Augmentation-Techniques-for-Boosting-Performance-on-Text-Classification-Tasks/</id>
    <published>2020-06-02T06:01:54.000Z</published>
    <updated>2020-06-02T06:50:44.567Z</updated>
    
    <content type="html"><![CDATA[<p>这篇论文介绍了一个文本领域的数据增强工具，提出了一些数据增强方法。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇论文介绍了一个文本领域的数据增强工具，提出了一些数据增强方法。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="Text Classification" scheme="https://superlova.github.io/tags/Text-Classification/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读笔记】A survey on Image Data Augmentation for Deep Learning</title>
    <link href="https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91A-survey-on-Image-Data-Augmentation-for-Deep-Learning/"/>
    <id>https://superlova.github.io/2020/06/02/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%91A-survey-on-Image-Data-Augmentation-for-Deep-Learning/</id>
    <published>2020-06-02T06:01:16.000Z</published>
    <updated>2020-06-02T06:52:12.004Z</updated>
    
    <content type="html"><![CDATA[<p>图像领域的对抗样本生成技术综述。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;图像领域的对抗样本生成技术综述。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="Data Augmentation" scheme="https://superlova.github.io/tags/Data-Augmentation/"/>
    
      <category term="Robustness" scheme="https://superlova.github.io/tags/Robustness/"/>
    
      <category term="Deep Neural Networks" scheme="https://superlova.github.io/tags/Deep-Neural-Networks/"/>
    
      <category term="survey" scheme="https://superlova.github.io/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>Datawhale——SVHN——Task05：模型集成</title>
    <link href="https://superlova.github.io/2020/06/02/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task05%EF%BC%9A%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90/"/>
    <id>https://superlova.github.io/2020/06/02/Datawhale%E2%80%94%E2%80%94SVHN%E2%80%94%E2%80%94Task05%EF%BC%9A%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90/</id>
    <published>2020-06-02T02:18:31.000Z</published>
    <updated>2020-06-03T00:37:16.358Z</updated>
    
    <content type="html"><![CDATA[<p>三个臭皮匠，顶个诸葛亮。<br><a id="more"></a></p><h2 id="1-集成学习"><a href="#1-集成学习" class="headerlink" title="1. 集成学习"></a>1. 集成学习</h2><p>集成学习的一般结构，是首先产生一组“个体学习器”，再用<strong>某种策略</strong>将其结合起来。类似于“三个臭皮匠，顶个诸葛亮”的思想。</p><p><img src="/2020/06/02/Datawhale——SVHN——Task05：模型集成/2020-06-02-22-32-43.png" srcset="/img/loading.gif" alt></p><p>如果自己的<strong>个体学习器</strong>性能不是很令人满意，使用集成学习将能够提升一定的性能，集成学习器一般都能够获得比个体学习器要好的效果。</p><p>集成学习效果要提升，要尽可能满足两个条件：</p><ol><li>个体学习器性能不太差；</li><li>个体学习器之间不能太相似，结构、所用数据差异越大越好。</li></ol><p>可以证明，如果个体学习器之间的决策误差不存在关联，决策相互独立，那么随着个体学习器数量的增多，集成学习器的错误率将指数下降。</p><p>根据个体学习器的生成方式，目前的集成学习方法分成两大类：</p><ol><li>个体学习器之间存在强依赖关系、必须串行生成的序列化方法，代表为Boosting；</li><li>学习器之间不存在强依赖关系、可以并行的方法，代表为Bagging和随机森林。</li></ol><p>集成学习只能在一定程度上提高精度，并需要耗费较大的训练时间。具体的集成学习方法需要与验证集划分方法结合。</p><h3 id="1-1-Boosting"><a href="#1-1-Boosting" class="headerlink" title="1.1 Boosting"></a>1.1 Boosting</h3><p>Boosting算法是一类能将弱学习器提升为强学习器的算法。基本思想是：先利用初始训练集训练一个基本学习器，再基于基本学习器的表现，对训练样本做出调整，改变样本分布，使得先前被分类错误的训练样本在随后受到更多关注。如此重复训练，直到基学习器的数目达到指定的数值。最终将这几个基学习器进行加权结合。</p><h3 id="1-2-Bagging"><a href="#1-2-Bagging" class="headerlink" title="1.2 Bagging"></a>1.2 Bagging</h3><p>欲得到泛化性能强的集成学习模型，个体学习器之间应当相互独立。但是完全独立是做不到的，即便模型架构完全不同、训练数据完全不一样，这些个体学习器也是为了解决同一个任务而训练的，训练数据之间肯定存在关系，从而导致模型的决策存在相关性。因此Bagging算法就是想要尽可能提升个体学习器之间的差异性。</p><p>一种可能的做法是对训练样本进行采样，产生若干个不同的子集，每个子集都训练一个个体学习器。但是这样学习得到的个体学习器都没能获得足够的训练样本，因此我们可以进行折中，采用互相存在交集的分割方法分割数据集，然后训练模型。</p><p>随机森林本质上是许多决策树的集合，其中每棵树都和其他树略有不同。随机森林背后的思想是，每棵树的预测可能都相对较好，但可能对部分数据过拟合。如果构造很多树，并且每棵树的预测都很好，但都以不同的方式过拟合，那么我们可以对这些树的结果取平均值来降低过拟合。既能减少过拟合又能保持树的预测能力，这可以在数学上严格证明。</p><h2 id="2-深度学习中的集成方法"><a href="#2-深度学习中的集成方法" class="headerlink" title="2. 深度学习中的集成方法"></a>2. 深度学习中的集成方法</h2><h3 id="2-1-Dropout"><a href="#2-1-Dropout" class="headerlink" title="2.1 Dropout"></a>2.1 Dropout</h3><p>每个训练批次中，在更新权重之前，随机让一部分的节点停止工作，增加模型训练时的精度提升难度。</p><p><img src="/2020/06/02/Datawhale——SVHN——Task05：模型集成/2020-06-02-23-33-21.png" srcset="/img/loading.gif" alt></p><p>需要注意的是，训练的时候加dropout，测试的时候以及实际使用时，是不需要dropout的。这就像平时训练的时候腿上绑上沙袋，战时就能够获得更卓越的效果。有效的缓解模型过拟合</p><p><img src="/2020/06/02/Datawhale——SVHN——Task05：模型集成/2020-06-02-23-36-15.png" srcset="/img/loading.gif" alt></p><p>直观来讲，Dropout法使得每个节点都无法单纯依赖其他节点而滥竽充数，因为随时随地自己的同伴就可能被dropout。这样训练时，每个节点都会学到更多的知识。从而提升整体学习器的性能。因此这也算是集成学习。</p><h3 id="2-2-测试集数据扩增"><a href="#2-2-测试集数据扩增" class="headerlink" title="2.2 测试集数据扩增"></a>2.2 测试集数据扩增</h3><p>测试集数据扩增（Test Time Augmentation，简称TTA）也是常用的集成学习技巧，数据扩增不仅可以在训练时候用，而且可以同样在预测时候进行数据扩增，对同一个样本预测三次，然后对三次结果进行平均。</p><h2 id="3-结果后处理"><a href="#3-结果后处理" class="headerlink" title="3. 结果后处理"></a>3. 结果后处理</h2><ul><li>统计图片中每个位置字符出现的频率，使用规则修正结果；</li><li>单独训练一个字符长度预测模型，用来预测图片中字符个数，并修正结果。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;三个臭皮匠，顶个诸葛亮。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="datawhale" scheme="https://superlova.github.io/tags/datawhale/"/>
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="Ensemble" scheme="https://superlova.github.io/tags/Ensemble/"/>
    
      <category term="Boosting" scheme="https://superlova.github.io/tags/Boosting/"/>
    
      <category term="Bagging" scheme="https://superlova.github.io/tags/Bagging/"/>
    
  </entry>
  
  <entry>
    <title>numpy拼合数组方法大全</title>
    <link href="https://superlova.github.io/2020/06/01/numpy%E6%8B%BC%E5%90%88%E6%95%B0%E7%BB%84/"/>
    <id>https://superlova.github.io/2020/06/01/numpy%E6%8B%BC%E5%90%88%E6%95%B0%E7%BB%84/</id>
    <published>2020-06-01T08:39:58.000Z</published>
    <updated>2020-06-02T04:23:43.383Z</updated>
    
    <content type="html"><![CDATA[<p>numpy的一大特色就是其内部的矩阵向量运算。矩阵之间的拼接方法，你掌握多少？<br><a id="more"></a></p><h2 id="1-append拼接"><a href="#1-append拼接" class="headerlink" title="1. append拼接"></a>1. append拼接</h2><p>我们都知道对于Python原生列表list来说，append是最方便的添加元素的方法，一句list.append(elem)就能在列表最后添加一个元素。</p><p>在numpy中，append也是一个直观且好用的方法，np.append(A,B)能够直接拼合两个ndarray数组。</p><p>首先我们新建两个三维数组，一个全为零，一个全为一。</p><pre><code class="lang-python">C = np.zeros((2,2,2))D = np.ones((2,2,2))print(&quot;C: &quot;, C, C.shape)print(&quot;D: &quot;, D, D.shape)C:  [[[0. 0.]  [0. 0.]] [[0. 0.]  [0. 0.]]] shape=(2, 2, 2)D:  [[[1. 1.]  [1. 1.]] [[1. 1.]  [1. 1.]]] shape=(2, 2, 2)</code></pre><p>然后我们采用不同的方法将其拼合在一起。</p><p>首先是append(C,D)这种直观的方法，可以看到C和D都被展开成了一维。</p><pre><code class="lang-python">np.append(C,D)array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])</code></pre><p>在很多时候我们希望数组拼接时能够保持原有的维度，按照行拼接/列拼接/其他维度拼接。此时只需要改动append的参数axis即可。</p><pre><code class="lang-python">np.append(C,D,axis=0)array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.append(C,D,axis=1)array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])np.append(C,D,axis=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><p>对于三维数组，axis=0为层，axis=1为行，axis=2为列。这不难理解，因为确定单位数组中元素位置的坐标就是(层，行，列)</p><h2 id="2-concatenate拼接"><a href="#2-concatenate拼接" class="headerlink" title="2. concatenate拼接"></a>2. concatenate拼接</h2><p>concatenate从字面意义上就让人明白这个函数专门负责数组拼接。不仅仅是两个，还可以负责多个数组一起拼接。理论上来说concatenate的速度和内存消耗都比append要小，但我并没有实际做实验验证。</p><pre><code class="lang-python">np.concatenate((C,D)) # default axis=0array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.concatenate((C,D), axis=1) # =np.append(C,D,axis=1)array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])</code></pre><h2 id="3-stack系列"><a href="#3-stack系列" class="headerlink" title="3. stack系列"></a>3. stack系列</h2><p>stack系列函数包括np.stack/hstack/vstack/dstack/column_stack/row_stack，顾名思义，hstack是按照横向拼接，vstack竖着拼接，dstack则是层叠数组。其实我最烦这种抽象描述了，因为二维数组和三维数组/高维数组的抽象描述根本不一致，还是axis好。不明白axis的同学可以看<a href="https://superlova.github.io/2020/05/19/numpy%E4%B8%ADaxis%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/">这篇文章</a>。</p><pre><code class="lang-python">np.hstack((C,D)) # = np.append(C,D,axis=1) = np.column_stack()array([[[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]],       [[0., 0.],        [0., 0.],        [1., 1.],        [1., 1.]]])np.vstack((C,D)) # =np.append(C,D,axis=0) = np.row_stack()array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.dstack((C,D)) # =np.append(C,D,aixs=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><h2 id="4-np-r"><a href="#4-np-r" class="headerlink" title="4. np.r_[]"></a>4. np.r_[]</h2><p>神奇的numpy总能给出神奇的解法。np.r_是构建数组/拼合数组的最简便写法，但不一定是好理解的。这种写法和之前写的append没什么不同，但是更加简洁。你也可以使用np.r_做出更加复杂的功能。</p><p>一言以蔽之，np.r_[]表达式能够快速使得多个在中括号里面的array/array切片，按照axis=0拼接起来。</p><p>np.r_[]存在两种使用情况：</p><ol><li>如果中括号内部是由若干逗号(comma,)分隔的array，就将他们按照axis=0拼接起来。</li><li>如果中括号内部包括矩阵切片(slices)或者标量(scalars)，就将他们全部变成一维数组首尾相接。</li></ol><p><strong>注意：</strong></p><ul><li>中括号<code>[3:6:1]</code>内部代表的切片，其含义相当于<code>np.arange(3,6,1)</code>，即在<code>[3,6)</code>范围内，从3开始走一步取一个元素，也就是<code>[3,4,5]</code>。</li><li>中括号<code>[0:5:3j]</code>在最后加了字母<code>j</code>，相当于<code>np.linspace(0,5,3,endpoint=True)</code>，在<code>[0,5]</code>范围内，均匀地取三个元素。</li></ul><pre><code class="lang-python">np.r_[C,D] # =np.append(C,D,axis=0)array([[[0., 0.],        [0., 0.]],       [[0., 0.],        [0., 0.]],       [[1., 1.],        [1., 1.]],       [[1., 1.],        [1., 1.]]])np.r_[0:10:3, 0:5:4j]array([0.        , 3.        , 6.        , 9.        , 0.        ,       1.66666667, 3.33333333, 5.        ])</code></pre><p>在中括号内，如果最开始是一个<strong>特定的字符串</strong>，np.r_会试图根据字符串的含义，改变其输出格式。</p><ul><li><code>np.r_[&#39;r&#39;, index_expression]</code>和<code>np.r_[&#39;c&#39;, index_expression]</code>将输出从array类型转变成matrix类型。<code>np.r_[&#39;c&#39;, index_expression]</code>会把一维index_expression组装成N*1的列向量。</li></ul><pre><code class="lang-python">np.r_[&quot;r&quot;, 0:10:3, 0:5:4j]matrix([[0.        , 3.        , 6.        , 9.        , 0.        ,         1.66666667, 3.33333333, 5.        ]])np.r_[&quot;c&quot;, 0:10:3, 0:5:4j]matrix([[0.        ],        [3.        ],        [6.        ],        [9.        ],        [0.        ],        [1.66666667],        [3.33333333],        [5.        ]])</code></pre><ul><li><code>np.r_[&quot;n&quot;, index_expression]</code>前面字符串是整数，则拼接时将会按照axis=n进行拼接。</li></ul><pre><code class="lang-python">np.r_[&quot;-1&quot;,C,D]array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])</code></pre><h2 id="5-np-c"><a href="#5-np-c" class="headerlink" title="5. np.c_"></a>5. np.c_</h2><p>在日常使用时，我们经常需要按照最后一个维度拼合两个数组，也就是np.r_[‘-1’,index_expression]。此时我们可以直接使用<code>np.c_[]</code></p><pre><code class="lang-python">np.c_[C,D] # =np.append(C,D,axis=2)array([[[0., 0., 1., 1.],        [0., 0., 1., 1.]],       [[0., 0., 1., 1.],        [0., 0., 1., 1.]]])np.c_[0:10:3, 0:5:4j]array([[0.        , 0.        ],       [3.        , 1.66666667],       [6.        , 3.33333333],       [9.        , 5.        ]])</code></pre><p>关于numpy中的<code>np.c_</code>和<code>np.r_</code>相关知识，可以参考<a href="https://numpy.org/devdocs/reference/generated/numpy.r_.html#numpy.r_" target="_blank" rel="noopener">官方文档</a>，里面有关于中括号前参数的详细解释。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;numpy的一大特色就是其内部的矩阵向量运算。矩阵之间的拼接方法，你掌握多少？&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="numpy" scheme="https://superlova.github.io/tags/numpy/"/>
    
      <category term="array" scheme="https://superlova.github.io/tags/array/"/>
    
      <category term="concatenate" scheme="https://superlova.github.io/tags/concatenate/"/>
    
  </entry>
  
  <entry>
    <title>移动硬盘文件或目录损坏且无法读取解决方法</title>
    <link href="https://superlova.github.io/2020/05/31/%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%E6%8D%9F%E5%9D%8F%E4%B8%94%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/05/31/%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%E6%8D%9F%E5%9D%8F%E4%B8%94%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</id>
    <published>2020-05-31T07:33:24.000Z</published>
    <updated>2020-05-31T09:06:18.674Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h2><p>家里的移动硬盘寿命已有4年之久，里面存储了200多G的学习资料（字面意思）。今天我将其插在系统为win10的电脑上，却出现了以下情况：</p><ul><li>硬盘通电指示灯亮；</li><li>右下角托盘区域出现usb插入提示，并可以点击“安全删除硬件”；</li><li>在“我的电脑”界面，显示“本地磁盘 D:”，但是双击之后出现错误“文件或目录损坏且无法读取”。</li></ul><p>重启电脑、重新插拔、更换另一台win7系统的电脑，都是该状况。至此基本确定是移动硬盘本身的问题。</p><h2 id="硬盘参数："><a href="#硬盘参数：" class="headerlink" title="硬盘参数："></a>硬盘参数：</h2><ul><li>黑甲虫 640G 移动机械硬盘</li><li>磁盘格式为NTFS</li><li>使用4年有余</li><li>之前出现过数据丢失的状况，转移敏感数据之后，在该盘中只留有非敏感的学习资料，约280G</li></ul><p>查阅资料可知，我这种错误大概率是由于某次未断电插拔硬盘导致的文件目录错误。好消息是，这种错误可以通过一句简单的指令解决。</p><h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><ol><li>打开cmd</li><li>输入 chkdsk D: /f 请注意，我的移动硬盘盘符为D:</li></ol><p>参考：<a href="https://cloud.tencent.com/developer/article/1487000" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1487000</a></p><p>chkdsk 参数说明：</p><p>volume 指定驱动器(后面跟一个冒号)、装入点或卷名。<br>filename 仅用于 FAT/FAT32: 指定要检查是否有碎片的文件<br>/F 修复磁盘上的错误。<br>/V　 在 FAT/FAT32 上: 显示磁盘上每个文件的完整路径和名称。在 NTFS 上: 如果有清除消息，将其显示。<br>/R 查找不正确的扇区并恢复可读信息(隐含 /F)。<br>/L:size 仅用于 NTFS:? 将日志文件大小改成指定的 KB 数。如果没有指定大小，则显示当前的大小。<br>/X 如果必要，强制卷先卸下。卷的所有打开的句柄就会无效(隐含 /F)<br>/I 仅用于 NTFS: 对索引项进行强度较小的检查<br>/C 仅用于 NTFS: 跳过文件夹结构的循环检查。<br>/I 和 /C 命令行开关跳过卷的某些检查，减少运行 Chkdsk 所需的时间</p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>这种错误一般产生于外置移动硬盘上面，或者外置U盘等等。之所以产生这些问题，一般有以下几个原因：</p><ol><li>没有点击“安全删除硬件”直接拔USB接口导致系统没有完成读写操作。这会使得文件目录不完整，损坏文件目录系统。</li><li>劣质产品，或者劣质硬盘盒。硬盘盒内部的电源、电路供电不稳定，也会产生文件系统错误的状况。</li><li>停电了</li></ol><h2 id="恢复效果质量"><a href="#恢复效果质量" class="headerlink" title="恢复效果质量"></a>恢复效果质量</h2><p>如果是大移动硬盘并且是NTFS分区格式的，恢复质量十分理想，基本都能成功恢复文件和目录结构。</p><p>如果是FAT或FAT32格式，根据损坏程度不同，恢复质量效果比NTFS格式结构的分区稍差一些，所以日常使用建议使用NTFS格式分区，其数据安全性更高一些。</p><p>一般情况下，CHKDSK可以成功修复出错的分区。但仍有可能没有反应。此时建议不要拔出设备，重启电脑，再观察是否仍然错误。 如果故障依然存在，可以尝试用EasyRecovery、R-STUDIO等软件恢复分区数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题描述：&quot;&gt;&lt;a href=&quot;#问题描述：&quot; class=&quot;headerlink&quot; title=&quot;问题描述：&quot;&gt;&lt;/a&gt;问题描述：&lt;/h2&gt;&lt;p&gt;家里的移动硬盘寿命已有4年之久，里面存储了200多G的学习资料（字面意思）。今天我将其插在系统为win10的电脑上，
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="hardware" scheme="https://superlova.github.io/tags/hardware/"/>
    
      <category term="移动硬盘" scheme="https://superlova.github.io/tags/%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98/"/>
    
  </entry>
  
  <entry>
    <title>numpy中delete的使用方法</title>
    <link href="https://superlova.github.io/2020/05/31/np-delete%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/05/31/np-delete%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2020-05-31T05:10:08.000Z</published>
    <updated>2020-05-31T09:03:47.140Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍np.delete中的参数及使用方法<br><a id="more"></a></p><h2 id="Python中列表元素删除"><a href="#Python中列表元素删除" class="headerlink" title="Python中列表元素删除"></a>Python中列表元素删除</h2><p>在列表中删除元素，我们可以：</p><pre><code class="lang-python">list_a = [1,2,3,4,5]list_a.pop(-1)print(list_a) # [1,2,3,4]del list_a[0]print(list_a) # [2,3,4]del list[1:]print(list_a) # [2]</code></pre><h2 id="在numpy的ndarray中删除元素"><a href="#在numpy的ndarray中删除元素" class="headerlink" title="在numpy的ndarray中删除元素"></a>在numpy的ndarray中删除元素</h2><p>numpy中的数组ndarray是定长数组，对ndarray的处理不像对python中列表的处理那么方便。想要删除ndarray中的元素，我们往往只能退而求其次，返回一个没有对应元素的副本。在numpy中我们一般使用delete函数。此外，numpy的delete是可以删除数组的整行和整列的。</p><p>简单介绍一下<code>np.delete</code>：</p><pre><code class="lang-python">numpy.delete(arr, obj, axis=None)</code></pre><ul><li>arr：输入数组</li><li>obj：切片，整数，表示哪个子数组要被移除</li><li>axis：删除子数组的轴</li><li>返回：一个新的子数组</li></ul><p>下面是使用举例：</p><pre><code class="lang-python">A = np.arange(15).reshape((3,5))print(A)[[ 0  1  2  3  4] [ 5  6  7  8  9] [10 11 12 13 14]]B = np.delete(A, 1) # 先把A给ravel成一维数组，再删除第1个元素。C = np.delete(A, 1, axis=0) # axis=0代表按行操作D = np.delete(A, 1, axis=1) # axis=1代表按列操作print(A) # 并没有改变，delete不会操作原数组。[[ 0  1  2  3  4] [ 5  6  7  8  9] [10 11 12 13 14]]print(B) # 先把A给ravel成一维数组，再删除第1个元素。[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14]print(C) # axis=0代表按行操作[[ 0  1  2  3  4] [10 11 12 13 14]]print(D) # axis=1代表按列操作[[ 0  2  3  4] [ 5  7  8  9] [10 12 13 14]]</code></pre><p>不了解axis的读者可以看我写的<a href="https://superlova.github.io/2020/05/19/numpy%E4%B8%ADaxis%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/">这篇文章</a>。</p><h2 id="在np-delete的index参数中应用切片操作"><a href="#在np-delete的index参数中应用切片操作" class="headerlink" title="在np.delete的index参数中应用切片操作"></a>在np.delete的index参数中应用切片操作</h2><p>index参数必须是个由整数元素组成的列表，内部存放着的整数代表着目标array的下标。</p><p>当我想实现删除从第5个到第100个之间的所有元素时，不能使用slice，这就比较尴尬了。</p><pre><code class="lang-python">In [5]: np.delete(x, [3:6])  File &quot;&lt;ipython-input-215-0a5bf5cc05ba&gt;&quot;, line 1    np.delete(x, [3:6])                   ^SyntaxError: invalid syntax</code></pre><p>我们没办法在函数参数部分让其接受slice。怎么解决呢？我们可以把参数从<code>[start:end]</code>换成<code>A[start:end]</code>吗？</p><pre><code class="lang-python">A = np.arange(10)*2print(A)[ 0  2  4  6  8 10 12 14 16 18]B = np.delete(A, A[1:4]) # 搞错了吧！预期结果：0 8 10 12 14 16 18print(B)[ 0  2  6 10 14 16 18]</code></pre><p>我们这段代码能够执行，但是不是我们想要的结果。什么原因呢？是因为np.delete的index参数接受的是下标数组，而A[1:4]=[2,4,6]，那么np.delete就忠实地执行了删除第2、4、6个元素的任务。但我们的本意只是想删除下标从1到4的元素而已。</p><pre><code class="lang-python">D = np.delete(A, [1,2,3])print(D) # [ 0  8 10 12 14 16 18]</code></pre><p>要想使用slice，可以采用下列方式：1. <code>slice</code>函数或者<code>range</code>函数；2. <code>np.s_</code></p><pre><code class="lang-python">C = np.delete(A, slice(1,4))print(C) # [ 0  8 10 12 14 16 18]E = np.delete(A, np.s_[1:4])print(E) # [ 0  8 10 12 14 16 18]</code></pre><p>其实<code>np.s_[1:4]</code>只不过是很方便产生slice(1,4)的一种方式而已。</p><h2 id="其他实用的方法"><a href="#其他实用的方法" class="headerlink" title="其他实用的方法"></a>其他实用的方法</h2><p>除此之外，我们还可以采用mask的方式选择原数组中的元素组成新数组</p><pre><code class="lang-python">mask = np.ones((len(A),), dtype=bool)mask[[1,2,3]] = Falseprint(A[mask]) # [ 0  8 10 12 14 16 18]</code></pre><p>或者干脆采用数组拼合的方式</p><pre><code class="lang-python">G = np.empty(len(A)-len(A[1:4]), dtype=int)G[0:1] = A[0:1]G[1:len(G)] = A[4:]print(G) # [ 0  8 10 12 14 16 18]</code></pre><p>后两种方法不像我们想象的那么没用，反而很常见，尤其是mask方法。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将介绍np.delete中的参数及使用方法&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="Python" scheme="https://superlova.github.io/tags/Python/"/>
    
      <category term="numpy" scheme="https://superlova.github.io/tags/numpy/"/>
    
      <category term="slice" scheme="https://superlova.github.io/tags/slice/"/>
    
  </entry>
  
</feed>
