<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Superlova</title>
  
  <subtitle>Be a better man...</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://superlova.github.io/"/>
  <updated>2020-05-11T04:13:43.198Z</updated>
  <id>https://superlova.github.io/</id>
  
  <author>
    <name>Superlova</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深度学习工作站调研--结合政府采购网信息</title>
    <link href="https://superlova.github.io/2020/05/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E7%AB%99%E8%B0%83%E7%A0%94-%E7%BB%93%E5%90%88%E6%94%BF%E5%BA%9C%E9%87%87%E8%B4%AD%E7%BD%91%E4%BF%A1%E6%81%AF/"/>
    <id>https://superlova.github.io/2020/05/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E7%AB%99%E8%B0%83%E7%A0%94-%E7%BB%93%E5%90%88%E6%94%BF%E5%BA%9C%E9%87%87%E8%B4%AD%E7%BD%91%E4%BF%A1%E6%81%AF/</id>
    <published>2020-05-11T03:59:50.000Z</published>
    <updated>2020-05-11T04:13:43.198Z</updated>
    
    <content type="html"><![CDATA[<h1 id="服务器调研-2020年5月10日"><a href="#服务器调研-2020年5月10日" class="headerlink" title="服务器调研 2020年5月10日"></a>服务器调研 2020年5月10日</h1><p><strong>调研目标：</strong></p><ul><li>目前典型的计算机，包括商用台式机、工作站、服务器</li><li>搭配目前典型的GPU卡</li><li>GPU适配计算机，需要厂家网站公开的列表，特别是对于服务器。如果厂家没有，需要致电厂商（非销售商）的技术支持。</li></ul><h2 id="1-制约性能的典型项目"><a href="#1-制约性能的典型项目" class="headerlink" title="1. 制约性能的典型项目"></a>1. 制约性能的典型项目</h2><h3 id="1-1-主板"><a href="#1-1-主板" class="headerlink" title="1.1 主板"></a>1.1 主板</h3><p>Intel部分芯片组不支持PCIe 3.0接口，无法发挥显卡的最佳速度。</p><h4 id="名词解释："><a href="#名词解释：" class="headerlink" title="名词解释："></a>名词解释：</h4><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-21-33-30.png" srcset="/img/loading.gif" alt><br><strong>PCI Express / PCI-e</strong><br>PCI-E的全名叫PCI Express，简称PCI-E，官方简称PCIe，他是计算机内部的一种高速总线。PCI-E既是通道，也是接口，当他以接口形式存在的时候，就是我们主板上那长长的槽。PCI-E接口目前最大的作用就是插显卡<br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-21-32-30.png" srcset="/img/loading.gif" alt></p><p><strong>PCI Express 修订版 / PCIe版本</strong><br>PCIe所能承受的带宽一般以版本和长度来区分，目前最流行的PCIe版本是3.0，最新的版本是4.0，目前只有高端主板支持4.0，只有比2080ti还要高端的显卡才需要4.0。</p><p><strong>PCI Express 配置</strong><br>通俗的说就是插槽长度。X1长度是最短的，所能承受的带宽大约是986MB/S。X2长度就是2GB/S，X4长度就是4GB/S，那X16长度就是16GB/S。当前主流显卡，均采用PCIE×16插槽结构。只要具有PCIE×16插槽的主板，都是可以安装独立显卡的。<br>英特尔官网的意义没大看懂，真正有意义的是“支持的处理器 PCI Express 端口配置”这一项。</p><p><strong>支持的处理器 PCI Express 端口配置</strong><br>以Z390主板为例，该主板1x16 or 2x8 or 1x8+2x4，意思就是可以插1个长度为16X的显卡，也可以插两个长度为8X的固态硬盘之类的，但是如果同时插上显卡和固态硬盘，就会出现抢通道的现象：显卡占用16个通道，两个固态占用16个通道，然而<strong>PCI Express 通道数的最大值</strong>就只有24个，通道不够用就会导致限速，甚至无法正常运转。</p><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-13-34.png" srcset="/img/loading.gif" alt><br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-13-57.png" srcset="/img/loading.gif" alt><br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-14-07.png" srcset="/img/loading.gif" alt><br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-14-15.png" srcset="/img/loading.gif" alt></p><p>以上是当前在售处理器搭配主板（芯片组）的特性支持情况，仅供参考，并不是说某块主板用了上述某个芯片组芯片就会具备这么多的扩展接口及能力，具体还要看主板厂商针对这个版型作出什么样的“阉割”调整。</p><h3 id="1-2-电源"><a href="#1-2-电源" class="headerlink" title="1.2 电源"></a>1.2 电源</h3><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-11-24.png" srcset="/img/loading.gif" alt="顶级游戏显卡及需要的电源功率大小"></p><h2 id="2-目前典型计算机"><a href="#2-目前典型计算机" class="headerlink" title="2. 目前典型计算机"></a>2. 目前典型计算机</h2><p>服务器对显卡的支持不如工作站，台式机的性能过低，因此本调查汇聚于工作站查询。</p><h3 id="2-1-服务器"><a href="#2-1-服务器" class="headerlink" title="2.1 服务器"></a>2.1 服务器</h3><p>服务器按外形划分可以划分为：塔式服务器、机架式服务器、刀片式服务器。<br>服务器除了一些低端的塔式机能用显卡以外，其他的都不支持显度卡，当然机架式服务器很薄根本就没有显卡的空间。<br>如果购买服务器，官方售后将不会主动为你安装个人家用系列显卡，转而推销商业计算卡。<br><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-15-26-49.png" srcset="/img/loading.gif" alt></p><p>截至2020年5月，服务器热销品牌Top-10（取自<a href="http://top.zol.com.cn/compositor/server.html" target="_blank" rel="noopener">ZOL网</a>）：<br>Dell、华为、浪潮、联想、惠普、H3C、ThinkServer、中科曙光、宝德、IBM。</p><h3 id="2-2-工作站"><a href="#2-2-工作站" class="headerlink" title="2.2 工作站"></a>2.2 工作站</h3><p>工作站的机箱主要以塔式为主，和一般家用主机机箱差距不大。<br>工作站对显卡的支持比服务器强很多，具体来说，工作站的主板对PCI-E的接口支持更好。</p><p>以下价格和资料全部取自于北京市政府采购网。</p><p><strong>神舟</strong><br>HFMPB2O8型号支持双路2080ti或TITAN<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=1r6e15444412038777n5&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HFMPB2O8</a>    78,016.00 自带2080ti<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=2g0v15681729710791z0&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HFMPB99K</a>  55,691.28   自带2080ti<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=6u7m15621197126648s6&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HFMPB3IR</a>  32,870.00   C422可更换更高级显卡<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=8n5x15444417182251i6&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HFMPB3J9</a>  29,980.00   自带2080</p><p><strong>联想</strong><br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=6h7y15571256822209c5&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">Think Station P520</a>   46,920.00    C422可更换更高级显卡<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=1s8z15571265520623u2&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">ThinkStation P720</a> 35,000.00   C622可更换更高级 </p><p><strong>宏碁</strong><br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=7w0g15281019011939v9&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">AP150 F4</a> 38,500.00    C622可更换更高级 </p><p><strong>浪潮</strong><br>浪潮是自研主板，不过其主板支持PCIe 16x，理论上只要供电足够即可安装包括2080Ti在内的显卡<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=3f4m15287143876139q2&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">P8000</a>    37,260.00</p><p><strong>惠普</strong><br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=4g2q15281081290990x3&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HP Z4 G4</a>  15,900.00   C622可更换更高级<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=4v9p15281082398434h6&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HP Z6 G4</a>  23,500.00   C622可更换更高级<br><a href="http://114.255.53.119:81/bgpc_office_manage/produce/parmsInfo.htm?topPk=0z0m15314586871347z2&amp;tiitPk=BG_002X&amp;tioPk=" target="_blank" rel="noopener">HP Z8 G4</a>  35,800.00   C622可更换更高级 </p><p><strong>苹果</strong><br>苹果的主板仅支持AMD的显卡，A卡不能用作深度学习。</p><h3 id="2-3-商用台式机"><a href="#2-3-商用台式机" class="headerlink" title="2.3 商用台式机"></a>2.3 商用台式机</h3><p>即普通台式机。普通台式机难以支撑深度学习任务。</p><h2 id="3-显卡介绍"><a href="#3-显卡介绍" class="headerlink" title="3. 显卡介绍"></a>3. 显卡介绍</h2><p>显卡分为Nvidia显卡和AMD显卡，其中Nvidia显卡可以用来深度学习训练和推理。</p><p>比较显卡性能，可以去<a href="https://versus.com/cn" target="_blank" rel="noopener">这个网站</a></p><h3 id="3-1-Nvidia显卡简介"><a href="#3-1-Nvidia显卡简介" class="headerlink" title="3.1 Nvidia显卡简介"></a>3.1 Nvidia显卡简介</h3><p><a href="https://www.bybusa.com/gpu-rank" target="_blank" rel="noopener">2020年显卡天梯图</a></p><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-23-18.png" srcset="/img/loading.gif" alt="2020年显卡天梯图"></p><p>目前最强的显卡是2080ti。预计在2020年底的3080ti发布之前，2080ti还会持续称霸显卡江湖。</p><h3 id="3-2-游戏显卡"><a href="#3-2-游戏显卡" class="headerlink" title="3.2 游戏显卡"></a>3.2 游戏显卡</h3><p>对游戏显卡的调研，参考<a href="https://post.smzdm.com/p/a6lrwk3e/" target="_blank" rel="noopener">“什么值得买”上的调研</a>以及<a href="https://www.cnblogs.com/xiaozhi_5638/p/10923351.html" target="_blank" rel="noopener">这个网址</a>。</p><p><img src="/2020/05/11/深度学习工作站调研-结合政府采购网信息/2020-05-10-22-09-38.png" srcset="/img/loading.gif" alt="游戏显卡一览"></p><p><strong>Geforce系列</strong></p><p>这个系列是销量最多、大众最为熟悉的显卡，一般用来打游戏。价格便宜，最新出来的旗舰卡RTX 2080Ti京东售价大概1w左右，根据不同的品牌，价格有所波动。低配置的便宜的一千就能买到。官方定位是消费级，但是它在深度学习上的表现也非常不错，很多人用来做推理、训练，单张卡的性能跟深度学习专业卡Tesla系列比起来其实差不太多，但是性价比却高很多。比如已经停产的GTX 1080显卡的参数基本和深度学习入门级显卡Tesla P4一样，用来做训练和推理的效果比Tesla P4还要好，可是GTX 1080一张卡才卖5000~6000左右，而Tesla P4要卖到1.4w。</p><p>究其原因，很大程度上在于英伟达官方禁止使用GTX、RTX系列显卡用于深度学习等用途，一经使用，自动过保。除了商业考虑外，还包括：Tesla多块显卡合起来的性能不会受很大影响，且Tesla系列显卡功耗优化非常明显，基本都是被动散热，不提供风扇，更适合数据中心机房工作环境等。</p><h3 id="3-3-计算显卡"><a href="#3-3-计算显卡" class="headerlink" title="3.3 计算显卡"></a>3.3 计算显卡</h3><p>专业级显卡的介绍参考<a href="https://product.pconline.com.cn/itbk/diy/graphics/1802/10846244.html" target="_blank" rel="noopener">“什么值得买”上的调研</a>以及<a href="https://www.cnblogs.com/xiaozhi_5638/p/10923351.html" target="_blank" rel="noopener">这个网址</a>。</p><p><strong>Quadro系列</strong><br>Quadro系列显卡一般用于特定行业，比如设计、建筑等，图像处理专业显卡，比如CAD、Maya等软件，一般人很少用到，价格相对来讲也稍微贵一些，最新的包括RTX 3000/4000/6000/8000型号。</p><p><strong>Tesla系列</strong><br>Tesla系列显卡定位并行计算，一般用于数据中心，具体点，比如用于深度学习，做训练、推理等。阿里云、Amazon云有非常多的GPU服务器，基本都采用Tesla系列显卡。这个系列显卡有个特别明显的特征，那就是贵。Tesla系列入门级显卡 Tesla P4，前面提到过，用来做深度学习的效果比GTX 1080还差，但是价格是后者的3倍多。像其他更高级别的Tesla V100、Tesla P100 价格高达8w、4w，这种价位的显卡虽然性能强劲，但是一般人是买不起的，只有企业数据中心才会部署这种显卡。</p><h3 id="3-4-显卡性能指标"><a href="#3-4-显卡性能指标" class="headerlink" title="3.4 显卡性能指标"></a>3.4 显卡性能指标</h3><p>本部分请参考<a href="https://www.cnblogs.com/xiaozhi_5638/p/10923351.html" target="_blank" rel="noopener">这里</a>。</p><h3 id="3-4-显卡罗列"><a href="#3-4-显卡罗列" class="headerlink" title="3.4 显卡罗列"></a>3.4 显卡罗列</h3><p>政府采购网上，值得采购的显卡如下</p><div class="table-container"><table><thead><tr><th>型号</th><th>价格</th></tr></thead><tbody><tr><td>p5000</td><td>27000</td></tr><tr><td>p6000</td><td>43500</td></tr><tr><td>2080</td><td>13500</td></tr><tr><td>k4000</td><td>42450</td></tr><tr><td>p4000</td><td>6800</td></tr><tr><td>2070s</td><td>8000</td></tr><tr><td>8000</td><td>93350</td></tr><tr><td>2080ti</td><td>16000</td></tr><tr><td>1080ti</td><td>8620</td></tr><tr><td>p4</td><td>28000</td></tr><tr><td>2080</td><td>10290</td></tr><tr><td>2060</td><td>5000</td></tr><tr><td>titan rtx</td><td>30000</td></tr><tr><td>p1000</td><td>3500</td></tr><tr><td>2070</td><td>7500</td></tr><tr><td>m2000</td><td>2982</td></tr><tr><td>titan v</td><td>37500</td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;服务器调研-2020年5月10日&quot;&gt;&lt;a href=&quot;#服务器调研-2020年5月10日&quot; class=&quot;headerlink&quot; title=&quot;服务器调研 2020年5月10日&quot;&gt;&lt;/a&gt;服务器调研 2020年5月10日&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;调研目标：&lt;
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="PCIe" scheme="https://superlova.github.io/tags/PCIe/"/>
    
      <category term="显卡" scheme="https://superlova.github.io/tags/%E6%98%BE%E5%8D%A1/"/>
    
      <category term="工作站" scheme="https://superlova.github.io/tags/%E5%B7%A5%E4%BD%9C%E7%AB%99/"/>
    
  </entry>
  
  <entry>
    <title>chrome升级版本失败解决办法</title>
    <link href="https://superlova.github.io/2020/05/11/chrome%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"/>
    <id>https://superlova.github.io/2020/05/11/chrome%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</id>
    <published>2020-05-11T03:46:55.000Z</published>
    <updated>2020-05-11T04:22:34.367Z</updated>
    
    <content type="html"><![CDATA[<h2 id="错误描述："><a href="#错误描述：" class="headerlink" title="错误描述："></a>错误描述：</h2><p>在Win7电脑上试图将Chrome从32位的72版本升级到64位的80版本时发生问题，升级进度到62%报错：<br>Chrome安装 未知错误导致安装失败  “0x80040902”</p><p>从chrome官网下载“chromesetup.exe”，打开梯子之后下载成功，在安装过程中也出现未知错误。<br>从Chrome官网下载“Chromestandalonesetup64.exe”，即离线安装包，最后也出现同样的错误。<br>重新启动、进入安全模式、试图结束所有有关google的进程的方法对我都没用。</p><h2 id="最后有效的方法："><a href="#最后有效的方法：" class="headerlink" title="最后有效的方法："></a>最后有效的方法：</h2><p>把原来的Chrome从控制面板的“添加删除程序”中卸载；</p><p>按住windows+R，在“开始”运行中输入“regedit”，打开注册表编辑器，依次进入HKEY_CURRENT_USER\Software\Google\Chrome；</p><p>把Chrome这一项删除，然后重启。再安装就不会存在问题了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;错误描述：&quot;&gt;&lt;a href=&quot;#错误描述：&quot; class=&quot;headerlink&quot; title=&quot;错误描述：&quot;&gt;&lt;/a&gt;错误描述：&lt;/h2&gt;&lt;p&gt;在Win7电脑上试图将Chrome从32位的72版本升级到64位的80版本时发生问题，升级进度到62%报错：&lt;br&gt;
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="chrome" scheme="https://superlova.github.io/tags/chrome/"/>
    
  </entry>
  
  <entry>
    <title>testRNN--Coverage-guided Testing on Recurrent Neural Networks 论文阅读笔记</title>
    <link href="https://superlova.github.io/2020/03/25/testRNN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>https://superlova.github.io/2020/03/25/testRNN%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2020-03-25T02:37:35.000Z</published>
    <updated>2020-03-25T02:46:22.679Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;

      
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="RNN" scheme="https://superlova.github.io/tags/RNN/"/>
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
      <category term="testRNN" scheme="https://superlova.github.io/tags/testRNN/"/>
    
  </entry>
  
  <entry>
    <title>RNN-Test--Adversarial Testing Framework for Recurrent Neural Network Systems 论文阅读笔记</title>
    <link href="https://superlova.github.io/2020/03/25/RNN-Test%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>https://superlova.github.io/2020/03/25/RNN-Test%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2020-03-25T02:37:16.000Z</published>
    <updated>2020-03-25T02:46:51.436Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;

      
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="RNN" scheme="https://superlova.github.io/tags/RNN/"/>
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
      <category term="RNN-Test" scheme="https://superlova.github.io/tags/RNN-Test/"/>
    
  </entry>
  
  <entry>
    <title>lintcode-138 子数组求和问题</title>
    <link href="https://superlova.github.io/2020/03/24/lintcode-138-%E5%AD%90%E6%95%B0%E7%BB%84%E4%B9%8B%E5%92%8C/"/>
    <id>https://superlova.github.io/2020/03/24/lintcode-138-%E5%AD%90%E6%95%B0%E7%BB%84%E4%B9%8B%E5%92%8C/</id>
    <published>2020-03-24T09:30:31.000Z</published>
    <updated>2020-03-24T12:04:57.628Z</updated>
    
    <content type="html"><![CDATA[<ul><li>给定一个整数数组，找到和为零的子数组。</li><li>你的代码应该返回满足要求的子数组的起始位置和结束位置<a id="more"></a><h1 id="lintcode-138：子数组之和"><a href="#lintcode-138：子数组之和" class="headerlink" title="lintcode 138：子数组之和"></a>lintcode 138：子数组之和</h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2></li></ul><p>给定一个整数数组，找到和为零的子数组。你的代码应该返回满足要求的子数组的起始位置和结束位置<br><strong>样例 1:</strong><br>输入: [-3, 1, 2, -3, 4]<br>输出: [0,2] 或 [1,3]<br>样例解释： 返回任意一段和为0的区间即可。<br><strong>样例 2:</strong><br>输入: [-3, 1, -4, 2, -3, 4]<br>输出: [1,5]<br><strong>注意事项</strong><br>至少有一个子数组的和为 0</p><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><p>子数组之和问题。看看哪个区间段，段内所有元素加起来刚好等于0（或者某个值）。类似这种求区间段，段内元素满足什么条件的问题。</p><p>关键是下面这个结论：</p><p>准备一个数组array，其中第i个元素保存num[0]~num[i]之和。那么index_value中一旦出现两个元素其值相同，就说明这两个下标之间所有元素加起来等于0。</p><script type="math/tex; mode=display">\begin{aligned}& if & \sum_{i=0}^{\operatorname{index_1}}nums(i) = \sum_{i=0}^{\operatorname{index_2}}nums(i) \\ & then\quad & return \left[ \operatorname{index_1}+1, \operatorname{index_2} \right] \end{aligned}</script><p>举个例子：对于数组<code>num = [-3, 1, 2, -3, 4]</code>，我们可以构建array数组如下：</p><div class="table-container"><table><thead><tr><th>index</th><th>nums[index]</th><th>$\sum_{i=0}^{index}nums(i)$</th></tr></thead><tbody><tr><td>0</td><td>-3</td><td>-3</td></tr><tr><td>1</td><td>1</td><td>-2</td></tr><tr><td>2</td><td>2</td><td>0</td></tr><tr><td>3</td><td>-3</td><td>-3</td></tr><tr><td>4</td><td>4</td><td>1</td></tr></tbody></table></div><p>返回 [0, 2] 或 [1, 3]</p><p>在代码实现中，当我们采用数组实现array时，会受限于查询array内元素的线型时间复杂度，为了找某个值对应的下标，遍历array数组的过程，可能耗费线性复杂度的时间，导致代码TLE超时。</p><p>因此我们采用散列，将散列的key设置为前i个元素的和值，value为该值对应的下标位置。</p><p>在Python中查找元素，用<strong>字典</strong>可以大大加快查找速度。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre><code class="lang-python">class Solution:    &quot;&quot;&quot;    @param nums: A list of integers    @return: A list of integers includes the index of the first number and the index of the last number    &quot;&quot;&quot;    def subarraySum(self, nums):        index_value = {}        accumulator = 0        for i in range(len(nums)):            accumulator += nums[i]            if accumulator in index_value:                return [index_value[accumulator] + 1, i]            else:                index_value[accumulator] = i        else:            if accumulator == 0:                return [0, i]        return [0, 0]</code></pre><h2 id="变种：子数组元素之和等于k"><a href="#变种：子数组元素之和等于k" class="headerlink" title="变种：子数组元素之和等于k"></a>变种：子数组元素之和等于k</h2><script type="math/tex; mode=display">\begin{aligned}& if & \sum_{i=0}^{\operatorname{index_1}}nums(i) - \bold{k} = \sum_{i=0}^{\operatorname{index_2}}nums(i) \\ & then\quad & return \left[ \operatorname{index_1}+1, \operatorname{index_2} \right] \end{aligned}</script><pre><code class="lang-python">class Solution:    &quot;&quot;&quot;    @param nums: A list of integers    @return: A list of integers includes the index of the first number and the index of the last number    &quot;&quot;&quot;    def subarraySum(self, nums, obj_num):        index_value = {}        accumulator = 0        for i in range(len(nums)):            accumulator += nums[i]            if accumulator - obj_num in index_value:                return [index_value[accumulator - obj_num] + 1, i]            else:                index_value[accumulator] = i        else:            if accumulator == 0:                return [0, i]        return [0, 0]</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;给定一个整数数组，找到和为零的子数组。&lt;/li&gt;
&lt;li&gt;你的代码应该返回满足要求的子数组的起始位置和结束位置&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="code_exercises" scheme="https://superlova.github.io/categories/code-exercises/"/>
    
    
      <category term="algorithm" scheme="https://superlova.github.io/tags/algorithm/"/>
    
      <category term="lintcode" scheme="https://superlova.github.io/tags/lintcode/"/>
    
      <category term="array" scheme="https://superlova.github.io/tags/array/"/>
    
  </entry>
  
  <entry>
    <title>C++字符串高级操作总结</title>
    <link href="https://superlova.github.io/2020/03/23/C-%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    <id>https://superlova.github.io/2020/03/23/C-%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%80%BB%E7%BB%93/</id>
    <published>2020-03-23T15:50:02.000Z</published>
    <updated>2020-03-25T02:32:11.470Z</updated>
    
    <content type="html"><![CDATA[<p>C++的字符串操作非常多，功能也非常多样化，熟练使用标准库提供的字符串操作函数能够高效提升我们编写代码的效率和可读性。除了常用的<string>库中包含的几项基本操作之外，本文总结了几项特别好用而又不为人所知的高级操作。<br><a id="more"></a></string></p><h2 id="常见的基本操作回顾"><a href="#常见的基本操作回顾" class="headerlink" title="常见的基本操作回顾"></a>常见的基本操作回顾</h2><p>必须指明，<string>中字符串方法可以按照输入参数的类型不同调用不同的重载方法，这些函数名相同，但是参数类型和顺序完全不同，返回值也略有差别。</string></p><p>部分函数，包括insert和erase等函数可分为两类，如果输入的位置参数<code>pos</code>为整数<code>int</code>，此时返回值为<strong>被插入字符串</strong>的引用；而输入的位置参数类型为迭代器<code>iterator</code>，则会调用返回迭代器的函数，该迭代器<strong>指向被插入部分的头部</strong>。</p><p>而且<string>部分函数为了兼容C原生字符串，提供了一批适用于C String构造接口，这又产生了一大批只有参数顺序不同的同名函数。比如对于string构造方法上，输入原生string和输入C String的参数含义完全不同。</string></p><p>这些同名、功能相似但不同参数的函数使得C++新人学习标准库时容易产生极大的困扰。</p><h3 id="1-构造string"><a href="#1-构造string" class="headerlink" title="1. 构造string"></a>1. 构造string</h3><pre><code class="lang-cpp">const char * cp = &quot;Hello World!!!&quot;;char noNull[] = {&#39;H&#39;, &#39;i&#39;};</code></pre><p>输入一个char类型的指针，以及偏移量。转换从指针开始的偏移量个字符。<br>如果未指定偏移量，则默认转化到碰到’\0’为止。<br>没有’\0’结尾则该行为未定义。  </p><pre><code class="lang-cpp">string s1(cp); // 从C风格字符串转化string s2(noNull, 2); // 指定转化的字符个数string s3(noNull); // 未定义，因为noNull不是以空字符结尾string s4(cp + 6, 5);</code></pre><p>拷贝构造函数，从其他string拷贝<br>指定拷贝位置和拷贝字符个数<br>不指定pos则默认从头拷贝<br>不指定len则默认从pos开始全拷贝<br>pos越界则抛出异常<br>len越界没问题，只到’\0’  </p><pre><code class="lang-cpp">string s5(s1, 6, 5);string s6(s1, 6);string s7(s1, 6, 20);string s8(s1, 16);</code></pre><p>substr函数，输入pos和len<br>返回由该字符串的第pos位置拷贝len个字符组成的新子串  </p><pre><code class="lang-cpp">string s9 = s1.substr(0, 5);</code></pre><h3 id="2-改变string"><a href="#2-改变string" class="headerlink" title="2. 改变string"></a>2. 改变string</h3><p>以insert为例，简单介绍不同参数重载的不同insert。</p><p>insert除了接受迭代器的版本之外，还有直接接受下标的版本。返回值为被插入字符串的引用。<br>s.insert(pos, count, char)<br>s.insert(pos, char_ptr, len)<br>s.insert(pos, string, pos, len)</p><p>第一个位置总会是pos，表示被插入位置；</p><p>第二个参数如果是个数，那么你调用的是第一个insert函数，其含义为重复插入第三个参数char所制定的内容；</p><p>第二个参数如果是C风格字符串，那么第三个参数可以指出插入长度，不指名就默认把该C风格字符串全插到pos的位置；</p><p>第二个参数如果是string，那么你还需在string参数后指定从哪个pos开始插，并且指定len表示插入多少个。相对于插入C风格字符串的insert来说，插入string更灵活。</p><p>其他函数及其说明见下表。</p><p><img src="/2020/03/23/C-字符串高级操作总结/2020-03-24-20-38-14.png" srcset="/img/loading.gif" alt><br><img src="/2020/03/23/C-字符串高级操作总结/2020-03-25-08-58-36.png" srcset="/img/loading.gif" alt></p><h2 id="搜索字符串"><a href="#搜索字符串" class="headerlink" title="搜索字符串"></a>搜索字符串</h2><p><string>定义了六种不同的搜索方法，每种方法拥有四个重载版本。</string></p><p><img src="/2020/03/23/C-字符串高级操作总结/2020-03-25-09-00-50.png" srcset="/img/loading.gif" alt><br><img src="/2020/03/23/C-字符串高级操作总结/2020-03-25-09-02-09.png" srcset="/img/loading.gif" alt></p><p>需要注意的有两点：</p><ol><li>搜索函数返回类型为string::size_type，为无符号整数类型。</li><li>搜索失败时，返回string::npos，该值为-1，也就是无符号整数最大的值。</li></ol><h2 id="正则表达式库"><a href="#正则表达式库" class="headerlink" title="正则表达式库"></a>正则表达式库</h2><p>正则表达式是字符串匹配的有力工具。C++11加入了对正则表达式的支持，具体定义位于<regex>头文件中。</regex></p><p>在C++中，正则表达式可以做的工作有：</p><ul><li>Match 将整个输入拿来比对（匹配）某个正则表达式</li><li>Search 查找与正则表达式吻合的子串</li><li>Tokenize 根据正则表达式切分字符串</li><li>Replace 根据正则表达式替换字符串</li></ul><h3 id="第一种应用：Match和Search"><a href="#第一种应用：Match和Search" class="headerlink" title="第一种应用：Match和Search"></a>第一种应用：Match和Search</h3><p>具体流程可概括为：定义、匹配、判断</p><pre><code class="lang-cpp">regex reg(&quot;&lt;.*&gt;.*&lt;/.*&gt;&quot;); // 定义bool isExist = regex_match(string, reg); // 匹配整体//orbool isExist = regex_search(string, reg); // 匹配部分cout &lt;&lt; boolalpha &lt;&lt; isExist &lt;&lt; endl; // 判断</code></pre><p>你可能已经注意到了，regex_match和regex_search返回的仅仅是一个bool值，表明是否匹配。我们还需要匹配的位置。此时我们需要一个<code>match</code>对象来保存结果。<code>match</code>对象的方法如下所示。</p><pre><code class="lang-cpp">smatch m;bool isExist = regex_search(string, m, reg); // 结果保存在m中m.empty()m.size() // 返回匹配个数m.str(i) // 类似于python中group，返回第i个匹配位置的字符串。i=0则返回全部m.length(i) // 同上，返回第i个匹配字符串的长度m.position(i) // 同上，返回第i个匹配字符串的位置m.prefix().str() // 已匹配位置之前的字符串，字符串前缀m.suffix().str() // 已匹配位置之后的字符串，字符串后缀for (auto pos = m.begin(); pos != m.end(); ++pos) {    cout &lt;&lt; *pos &lt;&lt; endl;}代码中的参数i，代表了正则表达式中存在分组，i为提取分组i的被匹配内容。类似python中的group。分组操作是正则表达式的语法，本文不再赘述。</code></pre><p><code>match</code>对象根据保存内容类型不同分成</p><ul><li><code>smatch</code> 匹配string</li><li><code>cmatch</code> 匹配C风格字符串</li><li><code>wsmatch</code> 匹配wstring</li><li><code>wcmatch</code> 匹配const wchar_t*</li></ul><h3 id="第二种应用：Regex-Iterator"><a href="#第二种应用：Regex-Iterator" class="headerlink" title="第二种应用：Regex Iterator"></a>第二种应用：Regex Iterator</h3><p>data可能很长，reg可能会多次匹配。为了迭代所有的匹配成果，我们可以使用regex_iterator。根据类型不同，分别是<br><code>sregex_iterator</code><br><code>cregex_iterator</code><br><code>wsregex_iterator</code><br><code>wcregex_iterator</code></p><pre><code class="lang-cpp">regex reg(&quot;...&quot;);sregex_iterator pos(data.cbegin(), data.cend(), reg);sregex_iterator end;for (; pos != end; ++pos) {    cout &lt;&lt; pos-&gt;str() &lt;&lt; endl;}</code></pre><h3 id="第三种应用：Regex-Token-Iterator"><a href="#第三种应用：Regex-Token-Iterator" class="headerlink" title="第三种应用：Regex Token Iterator"></a>第三种应用：Regex Token Iterator</h3><p>你可能关注的不是被匹配的字符串，而是其余的字符串。此时正则表达式串就像是切割刀一样，将data分割成不含被匹配串的几部分。我们可以利用此功能实现C++中一直没能实现的字符串分割函数split。</p><pre><code class="lang-cpp">string data = &quot;qqq www    eee rrr&quot;;regex r(&quot;\\s+&quot;);sregex_token_iterator pos(data.cbegin(), data.cend(), r, -1); // -1代表你对正则表达式匹配的内容不感兴趣sregex_token_iterator end;for (; pos != end; ++pos) {    cout &lt;&lt; *pos &lt;&lt; endl;}</code></pre><h3 id="第四种应用：替换"><a href="#第四种应用：替换" class="headerlink" title="第四种应用：替换"></a>第四种应用：替换</h3><p>下面的代码将</p><pre><code class="lang-html">&lt;person&gt;&lt;first&gt;Nico&lt;/first&gt;&lt;/person&gt;</code></pre><p>替换成</p><pre><code class="lang-html">&lt;person&gt;&lt;first value=&quot;Nico&quot;/&gt;&lt;/person&gt;</code></pre><pre><code class="lang-cpp">string data = &quot;&lt;person&gt;&lt;first&gt;Nico&lt;/first&gt;&lt;/person&gt;&quot;regex reg(&quot;&lt;(.*)&gt;(.*)&lt;/(\\1)&gt;&quot;);string replace_pattern = &quot;&lt;$1 value=\&quot;$2\&quot;/&gt;&quot;;cout &lt;&lt; regex_replace(data, reg, replace_pattern) &lt;&lt; endl;</code></pre><p>模式替换串用$n指定第几个匹配部分group(n)<br>$1 value=$2 含义即为原来是group(1)的部分替换成group(2)的内容。</p><p><img src="/2020/03/23/C-字符串高级操作总结/2020-03-25-10-21-38.png" srcset="/img/loading.gif" alt></p><h2 id="string-view"><a href="#string-view" class="headerlink" title="string_view"></a>string_view</h2><p>C++17加入了string_view对象，能够避免string类型的复制临时对象操作。</p><ul><li>string_view对象由两部分组成，分别是<strong>数据的起始指针</strong>和<strong>数据的长度</strong>。有点类似于带其他语言表示字符串的方法，不依赖<code>&#39;\0&#39;</code>在结尾，而是通过一个变量记忆长度。</li><li>string_view只读，不能修改。可以很好地作为函数的参数和返回值</li></ul><pre><code class="lang-cpp">//使用string的拷贝操作string s(1000, &#39;0&#39;);string sub_s = s.substr(100, 200); // O(n)//使用view则不需要拷贝string_view sv(s); // no copystring_view sv2 = sv.substr(100, 200); // O(1)</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++的字符串操作非常多，功能也非常多样化，熟练使用标准库提供的字符串操作函数能够高效提升我们编写代码的效率和可读性。除了常用的&lt;string&gt;库中包含的几项基本操作之外，本文总结了几项特别好用而又不为人所知的高级操作。&lt;br&gt;&lt;/string&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="C++" scheme="https://superlova.github.io/tags/C/"/>
    
      <category term="string" scheme="https://superlova.github.io/tags/string/"/>
    
      <category term="regex" scheme="https://superlova.github.io/tags/regex/"/>
    
      <category term="STL" scheme="https://superlova.github.io/tags/STL/"/>
    
  </entry>
  
  <entry>
    <title>C++关联容器学习笔记</title>
    <link href="https://superlova.github.io/2020/03/20/C-%E5%85%B3%E8%81%94%E5%AE%B9%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://superlova.github.io/2020/03/20/C-%E5%85%B3%E8%81%94%E5%AE%B9%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2020-03-19T16:10:13.000Z</published>
    <updated>2020-03-20T11:21:43.587Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-关联容器特点简介"><a href="#1-关联容器特点简介" class="headerlink" title="1. 关联容器特点简介"></a>1. 关联容器特点简介</h2><p>关联容器和顺序容器是两种适用范围不同的容器。许多C++程序员只用过顺序容器诸如vector和string，但他们从未使用过set和map等关联数据结构。</p><p><img src="/2020/03/20/C-关联容器学习笔记/2020-03-20-09-47-21.png" srcset="/img/loading.gif" alt></p><p><code>set</code>是元素的简单集合，用来保存类型相同的一组元素。当你只是想知道一个值<strong>是否存在</strong>时，<code>set</code>是最有用的。</p><ul><li><code>set</code><strong>不会出现重复元素</strong></li><li>内部元素永远<strong>有序</strong></li><li><code>set</code>中的元素一经添加就<strong>不能修改</strong>。</li></ul><p><code>map</code>可以看做特殊的<code>vector</code>，其特殊之处在于此<code>map</code>中的每个元素都由两部分 <code>(key, value)</code> 构成，C++将每个这样的 <code>(key, value)</code> 封装成一个对象，其类别为<code>pair</code>。<code>map</code>内部元素都为<code>pair</code>类型。</p><ul><li><code>map</code><strong>不会出现重复<code>key</code></strong></li><li>内部元素永远有序，按照<code>pair</code>类型元素的key字段排序（key字段必须能够被排序）。</li><li><code>map</code>中的key一经添加就<strong>不能修改</strong>。</li></ul><h2 id="2-有序容器基本操作"><a href="#2-有序容器基本操作" class="headerlink" title="2. 有序容器基本操作"></a>2. 有序容器基本操作</h2><p>以下所有操作需要添加头文件：</p><pre><code class="lang-cpp">#include &lt;map&gt;#include &lt;set&gt;</code></pre><h3 id="2-1-初始化"><a href="#2-1-初始化" class="headerlink" title="2.1 初始化"></a>2.1 初始化</h3><h4 id="2-1-1-map"><a href="#2-1-1-map" class="headerlink" title="2.1.1 map"></a>2.1.1 map</h4><pre><code class="lang-cpp">map&lt;int, int&gt; m; // 默认初始化map&lt;int, int&gt; m{{1, 2}, {2, 4}}; // 初始化列表map&lt;int, int&gt; m2(m); // 拷贝构造函数map&lt;int, int&gt; m = {{1, 2}, {2, 4}}; // 初始化列表 + 拷贝构造函数// pair和make_pair()在#include&lt;utility&gt;中map&lt;int, int&gt; m3 = {    std::pair&lt;int, int&gt;(1, 2), std::pair&lt;int, int&gt;(2, 4)}; // 初始化列表的方法展开来说就是这样map&lt;int, int&gt; m4{    std::make_pair(1, 2), std::make_pair(2, 4)}; // 或者使用make_pair函数，免得输入参数类型，效果等价。// std::begin()和end()在#include &lt;iterator&gt; 中map&lt;int, int&gt; m5 = {std::begin(m), std::end(m)}; // 迭代器，前提是被迭代的对象内部元素类型是pair</code></pre><h4 id="2-1-2-set"><a href="#2-1-2-set" class="headerlink" title="2.1.2 set"></a>2.1.2 set</h4><pre><code class="lang-cpp">set&lt;int&gt; s; // 默认初始化set&lt;int&gt; s{1, 2, 3, 6, 9, 10}; // 初始化列表set&lt;int&gt; s2(s); // 拷贝构造函数set&lt;int&gt; s = {1, 2, 3, 6, 9, 10}; // 初始化列表 + 拷贝构造函数// std::begin()和end()在#include &lt;iterator&gt; 中int arr[] = {1, 2, 5, 8, 9};set&lt;int&gt; s2{std::begin(arr), std::end(arr)}; // 迭代器</code></pre><h4 id="2-1-3-定义排序方法"><a href="#2-1-3-定义排序方法" class="headerlink" title="2.1.3 定义排序方法"></a>2.1.3 定义排序方法</h4><p>可以给map或set初始化时输入一个比较器，用以替代原有的比较key大小的方法（原来一般是小于号）。这个比较器可以是一个函数，也可以是一个当做函数用的函数对象。下面是一个示例。</p><pre><code class="lang-cpp">struct comp {    template&lt;typename T&gt;    bool operator() (const T&amp; l, const T&amp; r) const {        return l &gt; r;    }};int main() {    map&lt;int, int, comp&gt; m = {        {1, 5}, {2, 3}, {7, 6}    };    for (auto&amp;&amp; [key, val] : m) {        cout &lt;&lt; key &lt;&lt; &quot; &quot; &lt;&lt; val &lt;&lt; endl;    }}output&gt;&gt; 7 6&gt;&gt; 2 3&gt;&gt; 1 5</code></pre><p>实现自己写的比较器，简单来说就是实现一个自定义的“&lt;”小于号。<br>原有的比较器<code>bool compare(object&amp; left, object&amp; right)</code>作用如下：</p><ol><li>compare输出true，map 认为 left 小于 right ，把left放在right前面。</li><li>compare输出false，map 认为 left 大于等于 right。</li><li>如果compare(left, right)为false，compare(right, left)也为false，就认为left==right。否则left放在right后面。</li></ol><blockquote><p>自己实现的比较器，必须让关键字集合满足以下性质：</p><ul><li>关键字自己不能小于自己</li><li>两个关键字不能互相小于对方</li><li>如果按照比较器，key1小于key2，key2小于key3，则key1小于key3</li></ul><p>学过离散数学的同学应该知道，上面描述的这种二元关系满足反自反性、反对称性和传递性。满足这三个性质的关系称之为“严格偏序关系”。我们日常生活中见到的数字比较的小于号、集合中“真包含于”都是这种关系。</p></blockquote><h3 id="2-2-添加元素"><a href="#2-2-添加元素" class="headerlink" title="2.2 添加元素"></a>2.2 添加元素</h3><h4 id="2-2-1-insert"><a href="#2-2-1-insert" class="headerlink" title="2.2.1 insert"></a>2.2.1 insert</h4><p>对于map</p><pre><code class="lang-cpp">map&lt;string, int&gt; m;m.insert({&quot;str&quot;, 1});m.insert(make_pair(&quot;ser&quot;, 1));m.insert(pair&lt;string, int&gt;(&quot;ssr&quot;, 1));m.insert(map&lt;string, int&gt;::value_type(&quot;sdr&quot;, 1));</code></pre><p>对于set</p><pre><code class="lang-cpp">vector&lt;int&gt; ivec = {2, 4, 6, 8};set&lt;int&gt; set2;set2.insert(1);set2.insert({2, 4, 6, 8});set2.insert(ivec.cbegin(), ivec.cend());</code></pre><p>insert函数和emplace函数返回pair对象，pair.first为迭代器，指向刚插入的元素，pair.second为bool，表示插入是否成功。如果由于存在重复导致插入失败，则除了second为false之外，first指向那个重复元素。</p><pre><code class="lang-cpp">set&lt;int&gt; s;const auto [iter, success] = s.insert(x); // 返回值拆成两个</code></pre><h4 id="2-2-2-对map使用下标-操作"><a href="#2-2-2-对map使用下标-操作" class="headerlink" title="2.2.2 对map使用下标[]操作"></a>2.2.2 对map使用下标[]操作</h4><p>map使用下标操作首先会查找该key的元素，找不到就新建一个key的pair，将其初始化。最后执行赋值操作。</p><pre><code class="lang-cpp">map&lt;char, int&gt; mp;mp[&#39;a&#39;] = 5;mp[&#39;b&#39;] = 4;mp[&#39;c&#39;] = 3;</code></pre><h3 id="2-3-访问和查找元素"><a href="#2-3-访问和查找元素" class="headerlink" title="2.3 访问和查找元素"></a>2.3 访问和查找元素</h3><p>map除了使用下标操作访问元素之外，还可以用<code>at()</code>函数。</p><pre><code class="lang-cpp">map&lt;char, int&gt; mp;mp.at(k) // 查找关键字为k的元素，找不到就抛出异常</code></pre><p>关联容器内置的<code>find</code>函数和<code>count</code>函数可以执行查找操作</p><pre><code class="lang-cpp">//c为一个map容器c.find(k) // 返回一个迭代器，指向关键字为k的元素。若k不在容器中，则返回尾后迭代器c.count(k) // 返回关键字等于k的元素数量。对于map和set而言，返回值永远是0或1。</code></pre><p>当我们要在map容器中查找一个元素时，我们可以使用find函数查找。</p><pre><code class="lang-cpp">auto it = word_count.find(&quot;foobar&quot;);if(it==word_count.end())   cout&lt;&lt;&quot;foobar is not in the map&quot;&lt;&lt;endl;else   cout&lt;&lt;it-&gt;first&lt;&lt;&quot; &quot;&lt;&lt;it-&gt;second&lt;&lt;endl;</code></pre><p>在有序容器中，我们还可以找到关键字k附近的元素。</p><pre><code class="lang-cpp">s.lower_bound(k); // 返回迭代器，指向第一个关键字**不小于**k的元素s.upper_bound(k); // 返回迭代器，指向第一个关键字**大于**k的元素s.equal_range(k); // 返回pair&lt;iter, iter&gt;，表示关键字为k的元素范围。适用于multiset/multimap。若是没有k，则返回两个end()</code></pre><p>在对于允许重复关键字的容器来说，查找元素的过程稍微复杂些，因为一个关键字可能对应多个值，我们需要把这么对应的值都找出来。<br>如果multimap中有多个元素具有相同的关键字，则这些关键字在容器中会相邻存储。我们可以通过这一特性，将一个关键字对应的多个值全部找出来。</p><pre><code class="lang-cpp">//《C++ Primer》示例，查找某作者对应的所有书籍//authors是一个multimap容器string search_item(&quot;Alain&quot;);int numbers=authors.count(search_item);auto it=authors.find(search_item);while(numbers){   cout&lt;&lt;iter-&gt;second&lt;&lt;endl;   ++it;   numbers--;}// 或者采用一种其他方式for (auto beg = authors.lower_bound(search_item),          end = authors.upper_bound(search_item);     beg != end; ++beg) {    cout &lt;&lt; beg-&gt;second &lt;&lt; endl; }// 或者采用一种更加直接的方式for (auto pos = authors.equal_range(search_item);     pos.first != pos.second; ++pos.first){    cout &lt;&lt; pos.first-&gt;second &lt;&lt; endl; // 打印每本书}</code></pre><h3 id="2-4-删除元素"><a href="#2-4-删除元素" class="headerlink" title="2.4 删除元素"></a>2.4 删除元素</h3><p>使用erase</p><pre><code class="lang-cpp">// s为关联容器，可能为set/map/multiset/multimaps.erase(k); // 删除指定关键字的元素，返回删除的个数。s.erase(iter); // iter必须指向s中的一个真实元素，返回指向删除元素之后的元素的迭代器。s.erase(iter1, iter2); // 删除迭代器[iter1, iter2)，其中必须是真是的元素。iter2指向的元素不删除。返回iter2</code></pre><h2 id="3-无序容器特有操作"><a href="#3-无序容器特有操作" class="headerlink" title="3. 无序容器特有操作"></a>3. 无序容器特有操作</h2><h3 id="3-1-无序容器特点"><a href="#3-1-无序容器特点" class="headerlink" title="3.1 无序容器特点"></a>3.1 无序容器特点</h3><p>如果我们不关心容器中元素的次序，那么我们就可以使用无序容器。在无序容器中，元素没有明确的排列次序，当你迭代容器内的所有元素时，会发现他们的次序个有可能。我们唯一关心的是某个元素特定元素是否位于容器内。</p><p>无需容器，常常以Hash table实现出来，内部结构是一个类似于<code>vector&lt;list&gt;</code>的列表，列表的元素是链表<code>linked list</code>。通过某个hash函数的运算，确定元素落于这个列表的位置。</p><p>Hash函数的运算目标是让每个元素的落点（位置）有助于用户快速访问任何一个元素（前提则是哈希函数本身也必须够快）。</p><p>由于这样一个快速而完美的哈希函数不一定存在。抑或由于造成array耗费巨额内存而显得不切实际，因此退而求其次的哈希函数有可能让多个元素落于同一位置上，所以设计上就让vector的元素再被放进一个linked list中。如此一来，vector的每个位置就得以存放一个以上的元素。</p><p><img src="/2020/03/20/C-关联容器学习笔记/2020-03-20-18-01-59.png" srcset="/img/loading.gif" alt></p><p>无序容器的主要优点是，当你打算查找一个特定值的元素，其速度甚至可能快过有序关联式容器（时间复杂度O(1)）。前提是你有一个良好的哈希函数。然而这样的哈希函数可能需要许多内存。</p><p>以下所有操作需要添加头文件：</p><pre><code class="lang-cpp">#include &lt;unordered_map&gt;#include &lt;unordered_set&gt;</code></pre><p><code>unordered_map</code>/<code>unordered_multimap</code>/<code>unordered_set</code>/<code>unordered_multiset</code>的初始化、插入、查找和删除的方法与普通的<code>map</code>/<code>multimap</code>/<code>set</code>/<code>multiset</code>没有大的区别。注意以下主要区别要点：</p><ol><li>无序容器内部不含比较器，因此你也不能提供自定义比较器。</li><li>每次对无序容器的添加操作可能会引起无序容器次序的改变。即便是相同元素，在不同的电脑上也可能得到不同的次序。</li><li>删除元素虽然不会引起无序容器次序改变，但是删除之后的第一次插入必然会引发次序改变。</li></ol><p>次序究竟会不会变化、怎样变化取决于使用的rehashing策略，该策略可由程序员自定义，就像在有序关联容器里定义排序函数那样。</p><h3 id="3-2-管理桶"><a href="#3-2-管理桶" class="headerlink" title="3.2 管理桶"></a>3.2 管理桶</h3><p>1.桶接口</p><pre><code class="lang-cpp">m.bucket_count()        正在使用的桶的数目m.max_bucket_count()    容器能容纳的最多的桶的数量m.bucket_size(n)        第n个桶中有多少个元素m.bucket(k)             关键字为k的元素在哪个桶</code></pre><p>2.桶迭代</p><pre><code class="lang-cpp">local_iterator            可以用来访问桶中元素的迭代器类型const_local_iterator      桶迭代器的const版本m.begin(n)、m.end(n)      桶n的首元素迭代器和尾后迭代器（n是什么类型？）m.cbegin(n)、m.cend(n)    与前两个函数类似，但返回const_local_iterator</code></pre><p>3.哈希策略</p><pre><code class="lang-cpp">//每个桶的平均元素数量，返回float值m.load_factor() //m试图维护的平均桶大小，返回float值，要求创建的新桶的load_factor&lt;=max_load_factor         m.max_load_factor() //重新存储，使得bucket_count&gt;=n，且bucket_count&gt;size/max_load_factor         m.rehash(n)  //重新存储，使得m可以保存n个元素且不必rehash m.reserve(n)</code></pre><h3 id="3-3-自定义哈希函数和比较函数"><a href="#3-3-自定义哈希函数和比较函数" class="headerlink" title="3.3 自定义哈希函数和比较函数"></a>3.3 自定义哈希函数和比较函数</h3><p>默认情况下，无序容器使用<code>==</code>来判断两key是否相等，并使用系统内置的哈希函数生成哈希值。不同类型的key会应用到不同的哈希函数，如下都是STL内置的哈希函数对象：</p><pre><code class="lang-cpp">struct hash&lt;char*&gt;struct hash&lt;const char*&gt;struct hash&lt;char&gt; struct hash&lt;unsigned char&gt; struct hash&lt;signed char&gt;struct hash&lt;short&gt;struct hash&lt;unsigned short&gt; struct hash&lt;int&gt; struct hash&lt;unsigned int&gt;struct hash&lt;long&gt; struct hash&lt;unsigned long&gt;</code></pre><p>如果key使用的是以上类型中的一种，可以使用缺省的hash函数。当然你程序员可以定义自己的hash函数。对于自定义对象，只能自定义hash函数。</p><p>下面是《C++ Primer》的一个自定义哈希函数的一个例子：</p><pre><code class="lang-cpp">/* 定义哈希函数和判等器 */size_t hasher(const Sales_data &amp;sd){    // 对书籍对象的哈希    return hash&lt;string&gt;() (sd.isbn()); // 返回其isbn编号的哈希，调用内置的string哈希函数}bool eqOp(const Sales_data &amp;lhs, const Sales_data &amp;rhs){    // 如何判断两本书是否相等？    return lhs.isbn() == rhs.isbn(); // 判断两书的isbn编号是否相等}/* 使用哈希函数和判等器 */using SD_multiset = unordered_multiset&lt;Sales_data, decltype(hasher)*, decltype(eqOp)*&gt;; // 类型名太长了，将类型名保存成别的变量名SD_multiset bookstore(42, hasher, eqOp);</code></pre><h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a>4. 小结</h2><p>对C++ 关联容器的总结到此告一段落。本篇文章从开始着手写作到完成，不间断地工作了八个小时，期间不断重温已经遗忘的知识，查阅资料，其中很多还是自己曾经收藏过的资料。</p><p>写作时，我多次问自己：写一篇不会有人看的文章值得吗？我也多次想要像我以前很多文章、像CSDN大多数的文章那样，随便水水，记录一下，反正只有自己看。</p><p>但是这次我觉得，我要为自己负责，要为已经付出的精力和时间负责。我相信大家都会有这种迷茫的时候，怀疑自己手头上的工作有没有意义，甚至想放弃。</p><p>不要轻言放弃，尤其是当你怀疑它的意义的时候。因为这个时候你可能是在为自己的懒惰找借口。将一件事情的意义贬低，这种想法出现的太容易，又太能让自己解脱了。这是一种让人没有负罪感的放弃方式。但是回头看，很多好想法，明明只要坚持一下就可以实现。因为对意义的评价，近乎于预测未来，我们大多数平凡人是没有这种本事的。</p><p>Be a better man, 每天进步一点点。大家共勉！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-关联容器特点简介&quot;&gt;&lt;a href=&quot;#1-关联容器特点简介&quot; class=&quot;headerlink&quot; title=&quot;1. 关联容器特点简介&quot;&gt;&lt;/a&gt;1. 关联容器特点简介&lt;/h2&gt;&lt;p&gt;关联容器和顺序容器是两种适用范围不同的容器。许多C++程序员只用过顺序容
      
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="C++" scheme="https://superlova.github.io/tags/C/"/>
    
      <category term="STL" scheme="https://superlova.github.io/tags/STL/"/>
    
      <category term="map" scheme="https://superlova.github.io/tags/map/"/>
    
      <category term="set" scheme="https://superlova.github.io/tags/set/"/>
    
  </entry>
  
  <entry>
    <title>DeepStellar--Model-Based Quantitative Analysis of Stateful Deep Learning Systems 论文阅读笔记</title>
    <link href="https://superlova.github.io/2020/03/19/DeepStellar%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>https://superlova.github.io/2020/03/19/DeepStellar%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2020-03-19T07:38:00.000Z</published>
    <updated>2020-03-25T02:37:49.035Z</updated>
    
    <content type="html"><![CDATA[<p>DeepStellar 是少有的针对RNN进行测试的工具，它提出了RNN测试的新思路。<br>封面上的大神就是谢肖飞博士，他是DeepStellar一问的作者。<br><a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DeepStellar 是少有的针对RNN进行测试的工具，它提出了RNN测试的新思路。&lt;br&gt;封面上的大神就是谢肖飞博士，他是DeepStellar一问的作者。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="RNN" scheme="https://superlova.github.io/tags/RNN/"/>
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
      <category term="DeepStellar" scheme="https://superlova.github.io/tags/DeepStellar/"/>
    
  </entry>
  
  <entry>
    <title>循环神经网络模型的覆盖率调研</title>
    <link href="https://superlova.github.io/2020/03/19/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A6%86%E7%9B%96%E7%8E%87%E8%B0%83%E7%A0%94/"/>
    <id>https://superlova.github.io/2020/03/19/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A6%86%E7%9B%96%E7%8E%87%E8%B0%83%E7%A0%94/</id>
    <published>2020-03-19T01:07:47.000Z</published>
    <updated>2020-03-20T01:12:40.514Z</updated>
    
    <content type="html"><![CDATA[<h1 id="循环神经网络模型的覆盖率调研"><a href="#循环神经网络模型的覆盖率调研" class="headerlink" title="循环神经网络模型的覆盖率调研"></a>循环神经网络模型的覆盖率调研</h1><h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><h3 id="1-1-循环神经网络"><a href="#1-1-循环神经网络" class="headerlink" title="1.1 循环神经网络"></a>1.1 循环神经网络</h3><p>循环神经网络（Recurrent neural network：RNN）是神经网络的一种。</p><p>单纯的RNN因为无法处理随着递归，权重指数级爆炸或梯度消失问题，难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题。循环神经网络可以描述动态时间行为。和前馈神经网络（feedforward neural network）接受较特定结构的输入不同，RNN将状态在自身网络中循环传递，因此可以接受更广泛的时间序列结构输入。手写识别是最早成功利用RNN的研究结果。</p><p>为了更好地理解循环神经网络，首先需要介绍前馈神经网络。</p><h4 id="1-前馈神经网络"><a href="#1-前馈神经网络" class="headerlink" title="1) 前馈神经网络"></a>1) 前馈神经网络</h4><p>前馈网络通过在网络的每个节点上做出的一系列操作传递信息。前馈网络每次通过每个层直接向后传递信息。这与循环神经网络不同。一般而言，前馈网络接受一个输入并据此产生输出，这也是大多数监督学习的步骤，输出结果可能是一个分类结果。输出可以是以猫狗等作为标签的类别。我们常见的卷积神经网络（CNN）就是一类经典的前馈网络。</p><p>前馈网络是基于一系列预先标注过的数据训练的。训练阶段的目的是减少前馈网络猜类别时的误差。一旦训练完成，我们就可以用训练后的权重对新批次的数据进行分类。</p><p><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-18-22-02-26.png" srcset="/img/loading.gif" alt="img1"></p><p>在前馈网络中，在<strong>测试阶段</strong>无论展示给分类器的图像是什么，都不会改变权重，所以也不会影响第二个决策。这是前馈网络和循环网络之间一个非常大的不同。也就是说，前馈网络<strong>在测试时</strong>不会记得之前的输入数据。它们只会<strong>在训练阶段</strong>记得历史输入数据。</p><p>与前馈神经网络不同，循环网络不仅将当前的输入样例作为网络输入，还将它们之前感知到的一并作为输入。</p><h4 id="2-前馈网络到循环网络的转变"><a href="#2-前馈网络到循环网络的转变" class="headerlink" title="2) 前馈网络到循环网络的转变"></a>2) 前馈网络到循环网络的转变</h4><p>下图是一个多层感知机示意图，该图所示的模型只拥有一个隐藏层（Hidden Layer），其接受来自输入层经过ReLU处理后的信号，输出的信号再经过Softmax层，从而产生一个分类结果。</p><p><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-18-22-06-04.png" srcset="/img/loading.gif" alt="img2"></p><p>如果在上述示例中的层数增加了，并且我们令隐藏层也接收输入，那么第一个隐藏层将激活传递到第二个隐藏层上，以此类推，最后到达输出层，每一层都有自己的权重（W）、偏置项（B）和激活函数（F）。</p><p><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-18-22-09-56.png" srcset="/img/loading.gif" alt="img3"></p><p>我们令所有隐藏层的权重和偏置项替换成相同的值，从而能使得隐藏层在某种意义上“合并”，如下图所示（注意图中方框内部隐藏层的参数）：</p><p><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-18-22-12-56.png" srcset="/img/loading.gif" alt="img4"></p><p>现在我们就可以将所有层合并在一起了。所有的隐藏层都可以结合在一个循环层中，如下图：</p><p><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-18-22-13-27.png" srcset="/img/loading.gif" alt="img5"></p><p>我们在每一步都会向隐藏层提供输入。现在一个循环神经元存储了所有之前步的输入，并将这些信息和当前步的输入合并。因此，它还捕获到一些当前数据步和之前步的相关性信息。t-1 步的决策影响到第 t 步做的决策。</p><p>如果我们在向网络输入 7 个字母后试着找出第 8 个字母，隐藏层会经历 8 次迭代。如果展开网络的话就是一个 8 层的网络，每一层对应一个字母。所以一个普通的神经网络被重复了多次。展开的次数与它记得多久之前的数据是直接相关的。</p><h4 id="3-循环神经网络基本结构"><a href="#3-循环神经网络基本结构" class="headerlink" title="3) 循环神经网络基本结构"></a>3) 循环神经网络基本结构</h4><p>下图是一个简单的循环神经网络如，它由输入层、一个隐藏层和一个输出层组成：<br><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-18-23-31-00.png" srcset="/img/loading.gif" alt></p><ul><li>x是一个向量，它表示输入层的值；<br>s是一个向量，它表示隐藏层的值（你也可以想象这一层其实是多个节点，节点数与向量s的维度相同）；<br>U是输入层到隐藏层的权重矩阵；<br>o也是一个向量，它表示输出层的值；<br>V是隐藏层到输出层的权重矩阵；<br>W是隐藏层上一次的值作为这一次的输入的权重。</li></ul><p>把上面的图展开，循环神经网络也可以画成下面这个样子：<br><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-18-23-33-05.png" srcset="/img/loading.gif" alt></p><p>网络在t时刻接收到输入$x_t$之后，隐藏层的值是$s_t$，输出值是$o_t$。关键一点是，$s_t$的值不仅仅取决于$x_t$，还取决于$s_{t-1}$。</p><p>我们可以用下面的公式来表示循环神经网络的计算方法：</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{o}_{t} &=g\left(V \mathbf{s}_{t}\right) \tag{1}\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}\mathbf{s}_{t} &=f\left(U \mathbf{x}_{t}+W \mathbf{s}_{t-1}\right) \tag{2}\end{aligned}</script><p>(1)是输出层的计算公式，输出层是一个全连接层，它的每个节点都和隐藏层的各个节点相连。V是输出层的权重矩阵，g是激活函数。(2)是隐藏层的计算公式，它是循环层。U是输入x的权重矩阵，W是上一次的值作为这一次的输入的权重矩阵，f是激活函数。</p><p>从上面的公式我们可以看出，循环层和全连接层的区别就是循环层多了一个权重矩阵 W。</p><h4 id="4-长短期记忆网络"><a href="#4-长短期记忆网络" class="headerlink" title="4) 长短期记忆网络"></a>4) 长短期记忆网络</h4><p>长短期记忆（英语：Long Short-Term Memory，LSTM）是一种时间循环神经网络（RNN），论文首次发表于1997年。由于独特的设计结构，LSTM适合于处理和预测时间序列中间隔和延迟非常长的重要事件。</p><p>LSTM是一种含有LSTM区块（blocks）或其他的一种类神经网络，文献或其他资料中LSTM区块可能被描述成智能网络单元，因为它可以记忆不定时间长度的数值，区块中有一个gate能够决定input是否重要到能被记住及能不能被输出output。</p><p>下图中，底下是四个S函数单元，最左边的单元为input，右边三个gate决定input是否能传入下个；左边第二个为input gate，如果这里gate近似于零，将把这里的值挡住，不会进到下一层。左数第三个是forget gate，当这产生值近似于零，将把过去记住的值忘掉。第四个也就是最右边的input为output gate，他可以决定在区块记忆中的input是否能输出 。</p><p><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-18-23-51-41.png" srcset="/img/loading.gif" alt></p><p>LSTM有很多个版本，其中一个重要的版本是GRU（Gated Recurrent Unit），根据谷歌的测试表明，LSTM中最重要的是Forget gate，其次是Input gate，最次是Output gate。</p><h3 id="1-2-循环神经网络测试的机遇和挑战"><a href="#1-2-循环神经网络测试的机遇和挑战" class="headerlink" title="1.2 循环神经网络测试的机遇和挑战"></a>1.2 循环神经网络测试的机遇和挑战</h3><p>当前研究大多集中于针对前馈神经网络的测试，诸如DeepXplore、DeepGauge针对CNN的测试等，而对RNN鲜有研究。由于RNN的循环特性，适用于CNN的分析方法不能简单地迁移到RNN上。目前学者大多采用模糊测试的方法，通过随机干扰数据集产生对抗性样本，而后分析RNN内部状态信息，引导数据集的扰动方向的方法，快速生成能使得RNN模型判断错误的对抗测试用例集合，达到模型测试的目的。</p><p>根据此思路，一方面可以针对数据集添加干扰的方式进行优化，采用启发式搜索改善对测试样本的Mutation过程；另一方面则是针对RNN内部状态信息的分析，引导算法快速找到有效的、难以察觉变化的对抗样本，这个思路类似于模型攻击。</p><p>目前RNN的对抗性测试主要面临三方面的挑战：</p><ol><li>对于非分类模型而言，没有较好的标准识别对抗样本能不能让模型发生错误。</li></ol><blockquote><p>For the sequential outputs not then applied to classification, there is no standard to decide the outputs as wrong outputs with respect to the changing degree.</p></blockquote><ol><li>对于序列输入的Mutation来说，很难保证添加的扰动是最小的</li></ol><blockquote><p>Applying the perturbations to words in a discrete space always cannot obtain a legal input and the explicit modification is distinguishable for humans.</p></blockquote><ol><li>现有应用于CNN等的覆盖率指标没有考虑到RNN内部结构特性，因此不能直接应用到RNN上。</li></ol><h2 id="2-覆盖指标调研"><a href="#2-覆盖指标调研" class="headerlink" title="2. 覆盖指标调研"></a>2. 覆盖指标调研</h2><p>目前针对循环神经网络的测试 (testing) 和验证 (verification) 等工作的研究还十分有限，根据目前调研取得的结果，现有学者的研究思路大体分成两类：抽象替代模型法和门覆盖率法。下文分别对这两个模型进行简述。</p><h3 id="2-1-抽象替代模型法"><a href="#2-1-抽象替代模型法" class="headerlink" title="2.1 抽象替代模型法"></a>2.1 抽象替代模型法</h3><h4 id="2-1-1-代表论文："><a href="#2-1-1-代表论文：" class="headerlink" title="2.1.1 代表论文："></a>2.1.1 代表论文：</h4><blockquote><p>Du, X., Xie, X., Li, Y., Ma, L., Liu, Y., &amp; Zhao, J. (2019, August). <strong>Deepstellar: model-based quantitative analysis of stateful deep learning systems.</strong> In Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (pp. 477-487).</p><p>Du, X., Xie, X., Li, Y., Ma, L., Liu, Y., &amp; Zhao, J. (2019, November). <strong>A Quantitative Analysis Framework for Recurrent Neural Network.</strong> In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE) (pp. 1062-1065). IEEE.</p></blockquote><h4 id="2-1-2-关键方法"><a href="#2-1-2-关键方法" class="headerlink" title="2.1.2 关键方法"></a>2.1.2 关键方法</h4><p>由于直接分析RNN内部结构具有状态转移的特性，因此DeepStellar一文提出<strong>将RNN建模成马尔科夫链</strong>，来模拟其内部状态和动态行为特性。基于马尔科夫链的抽象，该文设计了两个相似度指标和五个覆盖率标准，来衡量输入测试用例差异和测试用例的测试充分性。</p><p><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-19-02-00-02.png" srcset="/img/loading.gif" alt></p><ul><li><p>抽象模型结构模块：输入训练好的RNN，通过Profiling，分析其内部行为。一系列的RNN状态向量叫做trace。每个输入序列会通过Profiling分析得到一个trace。profiling结束之后就可以得到一系列的trace，记载着RNN训练过程访问过的和经过的状态。</p></li><li><p>分析内部状态空间和被训练集激活的trace的过程计算量很大，因此进一步抽象模型来简化状态和trace。首先对状态向量采用主成分分析，以保留其前k个主成分，并将这k个主成分等分成m部分。在状态转换方面，根据抽象状态将具体的转换概括成为抽象的转换。并且根据每个状态向不同方向转换的频率，导出了训练RNN的离散时间Markov链（DTMC）模型。</p></li><li><p>设计了两个相似度指标，用于衡量不同输入下激活的两个trace的相似度。分别是state-based trace similarity和transition-based trace similarity，简写为SBTSIM和TBTSIM。</p></li><li><p>五个覆盖率包括basic state coverage/n-step state boundary coverage, weighted state coverage/ basic transition coverage/weighted transition coverage，简写为BSCov/n-SBCov/WSCov/BTCov/WTCov。</p></li><li><p>将两个指标和五个标准应用于对抗样本检测和覆盖引导的测试上，来缓解来自对抗样本的威胁。运用两个相似度，即可在运行时检测对抗样本（<strong>Monitor</strong>）；运用五个覆盖率，我们将其用于指导测试用例生成上，生成的测试用例以提升覆盖率和找到更多的未被发现的defects为目标。这两个应用互相补充。</p></li></ul><h4 id="2-1-3-实验效果及评价"><a href="#2-1-3-实验效果及评价" class="headerlink" title="2.1.3 实验效果及评价"></a>2.1.3 实验效果及评价</h4><p>DeepStellar在精心的调参下，通过trace相似度检测算法能够很好地检测出当前输入样本是否为对抗样本（音频），准确度达到了89%。</p><p>DeepStellar提出的测试方法本质上是对一个等价模型进行分析的方法，抽象掉了RNN模型的很多细节，只保留了主干部分。思路值得借鉴。</p><p>DeepStellar的缺点也很明显，其高识别率的背后是精心的调参，并且作者也提到，面对更复杂的模型，结果未必会这么好。</p><blockquote><p>With finer-grained model, the result is not necessarily better.</p></blockquote><h3 id="2-2-门覆盖率法"><a href="#2-2-门覆盖率法" class="headerlink" title="2.2 门覆盖率法"></a>2.2 门覆盖率法</h3><h4 id="2-2-1-代表论文："><a href="#2-2-1-代表论文：" class="headerlink" title="2.2.1 代表论文："></a>2.2.1 代表论文：</h4><blockquote><p>Huang, W., Sun, Y., Huang, X., &amp; Sharp, J. (2019). <strong>testRNN: Coverage-guided Testing on Recurrent Neural Networks.</strong> arXiv preprint arXiv:1906.08557.</p></blockquote><h4 id="2-2-2-关键方法"><a href="#2-2-2-关键方法" class="headerlink" title="2.2.2 关键方法"></a>2.2.2 关键方法</h4><p>testRNN关注LSTM和其鲁棒性，鲁棒性指对输入添加小的扰动并不影响LSTM的判断结果的特性。注意，该工具只针对LSTM及相似的网络结构进行分析，原因在于其算法依赖于内部门结构的实现，而这种门结构只存在于LSTM类型的网络中。</p><p>testRNN的特色在于，其直接分析RNN内部结构并加以分析的思路非常类似于其前辈DeepXplore分析前馈神经网络的思路。但由于RNN网络内部关于“层”和“节点”的概念不同于CNN，因此对如何实现CNN中覆盖率迁移到RNN的应用中，testRNN提出了自己的方法。</p><ul><li><p>Cell覆盖率。Cell（后文称之为<strong>单元</strong>）覆盖旨在覆盖每个时间步的隐藏状态发生的显著变化$\Delta\xi_t$。当单元值$\Delta\xi_t$大于用户定义的阈值参数$\alpha_h$时，该单元将被激活并被测试用例覆盖。然后使用覆盖率来衡量由生成的测试用例激活至少一次的单元的百分比。（单元的隐藏状态变化大了，超过了用户定义的某个阈值，就算激活，测试用例激活的单元个数占总个数的比例就是该测试用例的覆盖率）</p></li><li><p>Gate覆盖率。门的覆盖率类似于单元覆盖率，但是信息是从LSTM单元的门中筛选的。上文提到，Google的研究团队发现，LSTM的四种门中最重要的门是忘记门（forget gate），因此testRNN专注于统计忘记门的覆盖率。忘记门的值$Rt(f，x)$表示可以从最后一个单元继承多少信息。由于LSTM以其长期的存储能力而闻名，因此检查一个单元格是否丢弃了从先前输入中学习到的适当数量的信息非常有意义。（忘记们忘记的信息量用Rt函数表示，则Rt太大了就激活？）</p></li></ul><p>下图是testRNN的具体处理流程。</p><p><img src="/2020/03/19/循环神经网络模型的覆盖率调研/2020-03-19-02-43-32.png" srcset="/img/loading.gif" alt></p><h4 id="2-2-3-实验效果"><a href="#2-2-3-实验效果" class="headerlink" title="2.2.3 实验效果"></a>2.2.3 实验效果</h4><p>testRNN着眼于门覆盖率，成功将分析CNN的那一套迁移了过来。但是testRNN的实验结果仅限于小数据集训练下的小网络，诸如MNIST分类数据集训练的双层LSTM网络等。因此能否将此方法推广到更加复杂的大型网络中，还有待探究。</p><h3 id="2-3-优化引导法"><a href="#2-3-优化引导法" class="headerlink" title="2.3 优化引导法"></a>2.3 优化引导法</h3><h4 id="2-3-1-代表论文："><a href="#2-3-1-代表论文：" class="headerlink" title="2.3.1 代表论文："></a>2.3.1 代表论文：</h4><blockquote><p>Guo, J., Zhao, Y., Han, X., Jiang, Y., &amp; Sun, J. (2019). <strong>RNN-Test: Adversarial Testing Framework for Recurrent Neural Network Systems.</strong> arXiv preprint arXiv:1911.06155.</p></blockquote><h4 id="2-3-2-关键方法"><a href="#2-3-2-关键方法" class="headerlink" title="2.3.2 关键方法"></a>2.3.2 关键方法</h4><p>RNN-Test一方面采用了和testRNN类似的“门覆盖率”方法来引导测试用例生成，另一方面采用了一种全新的优化函数思想，计算能同时使得扰动添加最小并且最有可能令模型发生判断错误的扰动方向。RNN-Test将二者结合起来，但正是因为该文仅仅是将这两种方法求得的偏移方向简单的加和，让人不禁怀疑其工作是否没有进行完全。</p><ul><li><p>状态不连续方向（State inconsistency orientation）：</p><script type="math/tex; mode=display">obj_{orient} = h_{t-1}^l + c_t^l - h_t^l</script><p>该优化函数的设计思想是，若一个样本能使得从隐状态t-1时刻输入的信息尽量大，而输出尽量小，那么这种样本更容易出现问题。这是因为t时刻$h_t^l$的值完全取决于$h_{t-1}^l $和$ c_t^l$，让这两部分产生大小差异更容易引发不确定行为。</p></li><li><p>损失函数优化方向（Cost orientation）:</p><script type="math/tex; mode=display">obj_{orient} = L_{seq}(y, \hat{y})</script><p>这一部分引用自FGSM的优化算法，该论文是对抗样本生成领域的开山之作。讲的是如何通过梯度上升算法求得添加扰动的方向，从而使得扰动最小的同时模型的变化最大。</p></li><li><p>决策边界方向（Decision boundary orientation）：</p><script type="math/tex; mode=display">obj_{orient} = (\sum_{i=0}^{k}\hat{y_{t_i}}) - \hat{y_t}</script><p>这一部分的灵感来自于RNN内部结构，由于每个时间步的隐状态事实上都会产生中间输出$y=o_t^l$，但一般我们认为只有最后阶段的输出向量才是有意义的。该优化函数将除了原来预测的最大值y之外前k个最大的y加起来，并减去原来的y。</p></li></ul><h4 id="2-3-3-实验效果"><a href="#2-3-3-实验效果" class="headerlink" title="2.3.3 实验效果"></a>2.3.3 实验效果</h4><p>该文章使用自己生成的对抗样本集合，对模型进行重新训练，模型的复杂度（Perplexity）有大约1.159%的降低。这说明模型更稳定了。</p><p>然而提升不大，运行效率却很低，计算代价较大。并且原文为了提升算法运行性能，Mutation过程采用了一遍Mutation，若不成功直接放弃的做法，原来的测试用例利用率较低、为了达到较高的突变利用率，算法不得不放宽添加干扰力度，这就导致生成太多无用的假测试用例。算法本身可以被优化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;循环神经网络模型的覆盖率调研&quot;&gt;&lt;a href=&quot;#循环神经网络模型的覆盖率调研&quot; class=&quot;headerlink&quot; title=&quot;循环神经网络模型的覆盖率调研&quot;&gt;&lt;/a&gt;循环神经网络模型的覆盖率调研&lt;/h1&gt;&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1
      
    
    </summary>
    
    
      <category term="paper" scheme="https://superlova.github.io/categories/paper/"/>
    
    
      <category term="RNN" scheme="https://superlova.github.io/tags/RNN/"/>
    
      <category term="testing" scheme="https://superlova.github.io/tags/testing/"/>
    
  </entry>
  
  <entry>
    <title>如何使用VS Code编写github pages博客</title>
    <link href="https://superlova.github.io/2020/01/11/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8VS-Code%E7%BC%96%E5%86%99github-pages%E5%8D%9A%E5%AE%A2/"/>
    <id>https://superlova.github.io/2020/01/11/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8VS-Code%E7%BC%96%E5%86%99github-pages%E5%8D%9A%E5%AE%A2/</id>
    <published>2020-01-11T13:55:17.000Z</published>
    <updated>2020-03-19T01:42:00.352Z</updated>
    
    <content type="html"><![CDATA[<p>使用VS Code写博客，需要你按照我之前写的两篇博客，将github pages平台搭建起来。</p><p><a href="https://superlova.github.io/2019/04/14/%E9%85%8D%E7%BD%AEhexo+GitHub%20Pages%E7%BA%AA%E5%AE%9E/">配置hexo+GitHub Pages纪实</a><br><a href="https://superlova.github.io/2019/04/25/hexo%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/">hexo图片加载失败解决方案</a></p><p>之后我们安装VSCode。接下来介绍我一直使用的几个插件，和它们的配置小技巧。</p><p>第一个是<strong>Markdown Preview Enhanced</strong>，有了该插件，就可以提前预览markdown文件的渲染效果。方法是使用VSCode打开以md后缀名结尾的文件，右键点击<strong>Markdown Preview Enhanced： Open Preview To The Side</strong>，即可在侧边栏生成即时渲染的md效果文件。</p><p>第二个是<strong>Markdown PDF</strong>，该插件可以令写好的md文件打印成pdf格式。该插件需要安装chromium内核。</p><p>第三个是<strong><strong>Paste Image</strong></strong>插件，可以很方便地在md文章中粘贴位于剪切板的图片。</p><p>粘贴的快捷键是Ctrl+Alt+V。</p><p>在Paste Image插件的Path设置部分，改成如下所示：<br><img src="/2020/01/11/如何使用VS-Code编写github-pages博客/2020-01-11-23-28-36.png" srcset="/img/loading.gif" alt><br>这样图片粘贴的位置就变成了<strong>当前文章目录下，与该文章同名的文件夹内</strong>，方便我们进行进一步整理。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用VS Code写博客，需要你按照我之前写的两篇博客，将github pages平台搭建起来。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://superlova.github.io/2019/04/14/%E9%85%8D%E7%BD%AEhexo+GitHub%20P
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="github pages" scheme="https://superlova.github.io/tags/github-pages/"/>
    
      <category term="hexo" scheme="https://superlova.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>总结论文中常用的Matplotlib和Seaborn绘图技术</title>
    <link href="https://superlova.github.io/2020/01/11/%E6%80%BB%E7%BB%93%E8%AE%BA%E6%96%87%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84Matplotlib%E7%BB%98%E5%9B%BE%E6%8A%80%E6%9C%AF/"/>
    <id>https://superlova.github.io/2020/01/11/%E6%80%BB%E7%BB%93%E8%AE%BA%E6%96%87%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84Matplotlib%E7%BB%98%E5%9B%BE%E6%8A%80%E6%9C%AF/</id>
    <published>2020-01-11T13:47:26.000Z</published>
    <updated>2020-03-19T01:45:18.572Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、使用matplotlib绘制图像"><a href="#一、使用matplotlib绘制图像" class="headerlink" title="一、使用matplotlib绘制图像"></a>一、使用matplotlib绘制图像</h1><p>matplotlib是一个Python的数据可视化2D图形库。matplotlib的特点是可以采用面向对象的方法，模仿MATLAB中的图形命令。matplotlib经常与numpy、pandas等库结合起来使用。<br>matplotlib可以采用MATLAB的命令风格使用，也可以采用面向对象的风格使用。</p><h2 id="matplotlib的图像中各组件名称"><a href="#matplotlib的图像中各组件名称" class="headerlink" title="matplotlib的图像中各组件名称"></a>matplotlib的图像中各组件名称</h2><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-11-23-42-39.png" srcset="/img/loading.gif" alt></p><h2 id="新建图像"><a href="#新建图像" class="headerlink" title="新建图像"></a>新建图像</h2><pre><code class="lang-python">fig, axes = plt.subplots(2,1,figsize=(5,10)) #两行一列组成一张图，图像大小宽5高10</code></pre><p>上面的语句创建了一个figure，由两个ax组成。把它想象成一张画布上面的两个贴画，会比较容易理解。</p><p>plt.figure()函数的前两个参数是设置figure是由几行几列的ax组成。figure(2,1)说明figure是由两行一列的ax一共两个ax组成。</p><p>后面的figsize参数设置画布的宽和高，单位为英寸。</p><h1 id="二、使用Seaborn绘制图像"><a href="#二、使用Seaborn绘制图像" class="headerlink" title="二、使用Seaborn绘制图像"></a>二、使用Seaborn绘制图像</h1><p>首先确定我们需要可视化的数据的结构。以iris鸢尾花数据集为例，</p><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-07-35.png" srcset="/img/loading.gif" alt></p><p>每一行代表一个数据对象，每一列代表数据对象的一个属性。但是现实生活的数据很多不长这样，只不过组织成一个表格的形式，内容大相径庭。因此在进行数据可视化时一定要保证你的数据也是<strong>用行代表数据对象，用列表示数据的属性</strong>。</p><h2 id="2-1-关联图"><a href="#2-1-关联图" class="headerlink" title="2.1 关联图"></a>2.1 关联图</h2><p>我们是用 <code>relplot</code>函数进行进一步绘制。实际上，<code>relplot</code> 可以看作是 <code>scatterplot</code> 和 <code>lineplot</code> 的结合版本。但是relplot包装层级更加高，这意味着它更适合快速应用，不适合自定义。如果你对它的效果不满意，恐怕还是得诉诸<code>scatterplot</code> 和 <code>lineplot</code>等与matplotlib结合更紧密的api，或者直接使用matplotlib。</p><pre><code class="lang-python">sns.relplot(x=&quot;sepal_length&quot;, y=&quot;sepal_width&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-10-26.png" srcset="/img/loading.gif" alt></p><p>x为花萼长度，y为花萼宽度。这样分x，y其实有一定道理，我们的目的是能够把不同类型的数据对象在图上区分开。因为同类花朵一般个头差不多，花萼的长度和宽度聚集在图的一部分区域。但是在上图我们是看不出来的。我们希望给不同类别添加不同颜色。</p><pre><code class="lang-python">sns.relplot(x=&quot;sepal_length&quot;, y=&quot;sepal_width&quot;, hue=&quot;species&quot;, data=iris)</code></pre><p>可以看到我们添加了<code>hue</code>字段，并要求按照<code>species</code>进行进一步分类。<code>hue</code>字段就是进行二次分类的参数。</p><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-15-48.png" srcset="/img/loading.gif" alt></p><p>如果是论文，则我们要使得读者在黑白打印的条件下也能发现区别。添加<code>stype</code>参数为<code>species</code>或许会有帮助。</p><pre><code class="lang-python">sns.relplot(x=&quot;sepal_length&quot;, y=&quot;sepal_width&quot;,            hue=&quot;species&quot;, style=&quot;species&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-18-31.png" srcset="/img/loading.gif" alt></p><p>不只是散点图，该方法还支持线形图，只需要指定 <code>kind=&quot;line&quot;</code> 参数即可。</p><pre><code class="lang-python">sns.relplot(x=&quot;sepal_length&quot;, y=&quot;sepal_width&quot;,            hue=&quot;species&quot;, style=&quot;species&quot;, kind=&quot;line&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-20-55.png" srcset="/img/loading.gif" alt></p><p>上图其实就是折线图，我们使用一个与matplotlib结合更紧密的api来探究花萼长度和花瓣长度之间的关系。</p><pre><code class="lang-python">sns.lineplot(x=&quot;sepal_length&quot;, y=&quot;petal_length&quot;,             hue=&quot;species&quot;, style=&quot;species&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-26-06.png" srcset="/img/loading.gif" alt></p><h2 id="2-2-类别图"><a href="#2-2-类别图" class="headerlink" title="2.2 类别图"></a>2.2 类别图</h2><p>懒人函数是<code>catplot</code>，<code>catplot</code>是下面几个底层函数的封装：</p><ul><li><p>分类散点图:</p><ul><li><a href="https://seaborn.pydata.org/generated/seaborn.stripplot.html" target="_blank" rel="noopener"><code>stripplot()</code></a> (<code>kind=&quot;strip&quot;</code>)</li><li><a href="https://seaborn.pydata.org/generated/seaborn.swarmplot.html" target="_blank" rel="noopener"><code>swarmplot()</code></a> (<code>kind=&quot;swarm&quot;</code>)</li></ul></li><li><p>分类分布图:</p><ul><li><a href="https://seaborn.pydata.org/generated/seaborn.boxplot.html" target="_blank" rel="noopener"><code>boxplot()</code></a> (<code>kind=&quot;box&quot;</code>)</li><li><a href="https://seaborn.pydata.org/generated/seaborn.violinplot.html" target="_blank" rel="noopener"><code>violinplot()</code></a> (<code>kind=&quot;violin&quot;</code>)</li><li><a href="https://seaborn.pydata.org/generated/seaborn.boxenplot.html" target="_blank" rel="noopener"><code>boxenplot()</code></a> (<code>kind=&quot;boxen&quot;</code>)</li></ul></li><li><p>分类估计图:</p><ul><li><a href="https://seaborn.pydata.org/generated/seaborn.pointplot.html" target="_blank" rel="noopener"><code>pointplot()</code></a> (<code>kind=&quot;point&quot;</code>)</li><li><a href="https://seaborn.pydata.org/generated/seaborn.barplot.html" target="_blank" rel="noopener"><code>barplot()</code></a> (<code>kind=&quot;bar&quot;</code>)</li><li><a href="https://seaborn.pydata.org/generated/seaborn.countplot.html" target="_blank" rel="noopener"><code>countplot()</code></a> (<code>kind=&quot;count&quot;</code>)</li></ul></li></ul><p>我们想知道不同类别下花萼长度的散点图。</p><pre><code class="lang-python">sns.catplot(x=&quot;sepal_length&quot;, y=&quot;species&quot;, kind=&#39;strip&#39;,data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-36-33.png" srcset="/img/loading.gif" alt></p><p><code>kind=&quot;swarm&quot;</code> 可以让散点按照 beeswarm 的方式防止重叠，可以更好地观测数据分布。</p><pre><code class="lang-python">sns.catplot(x=&quot;sepal_length&quot;, y=&quot;species&quot;, kind=&quot;swarm&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-38-46.png" srcset="/img/loading.gif" alt></p><p>箱线图</p><pre><code class="lang-python">sns.catplot(x=&quot;sepal_length&quot;, y=&quot;species&quot;, kind=&quot;box&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-41-06.png" srcset="/img/loading.gif" alt><br>变种箱线图</p><pre><code class="lang-python">sns.catplot(x=&quot;species&quot;, y=&quot;sepal_length&quot;, kind=&quot;boxen&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-41-24.png" srcset="/img/loading.gif" alt><br>提琴图</p><pre><code class="lang-python">sns.catplot(x=&quot;sepal_length&quot;, y=&quot;species&quot;, kind=&quot;violin&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-41-16.png" srcset="/img/loading.gif" alt><br>点线图</p><pre><code class="lang-python">sns.catplot(x=&quot;sepal_length&quot;, y=&quot;species&quot;, kind=&quot;point&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-41-36.png" srcset="/img/loading.gif" alt><br>柱状图</p><pre><code class="lang-python">sns.catplot(x=&quot;sepal_length&quot;, y=&quot;species&quot;, kind=&quot;bar&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-41-48.png" srcset="/img/loading.gif" alt></p><h2 id="2-3-分布图"><a href="#2-3-分布图" class="headerlink" title="2.3 分布图"></a>2.3 分布图</h2><p>如果想看一个变量到底是正态分布、卡方分布还是指数分布，此时就要使用分布图进行可视化了。一维分布图比较常见，二维以上分布图不太直观。绘制分布图的函数有这几个：<code>jointplot</code> <code>pairplot</code> <code>distplot</code> <code>kdeplot</code>。</p><p><code>distplot</code>可以方便的查看单变量的分布图。</p><pre><code class="lang-python">sns.distplot(iris[&quot;sepal_length&quot;])</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-48-17.png" srcset="/img/loading.gif" alt><br>图上那条曲线是根据数据拟合出来的核密度估计kde曲线（原理有待学习）。如果不想要这条线，可以在参数中设置<code>kde=False</code>。更可以只要kde曲线，设置<code>hist=False</code>即可。</p><p><code>jointplot</code>绘制二元变量的分布图，比如花瓣长度和宽度的关系。</p><pre><code class="lang-python">sns.jointplot(x=&quot;petal_length&quot;, y=&quot;petal_width&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-55-40.png" srcset="/img/loading.gif" alt></p><p>kde估计图也可以在二元变量分布图中出现。还有蜂巢图<code>kind=&quot;hex&quot;</code>、回归图<code>kind=&quot;reg&quot;</code>等。</p><pre><code class="lang-python">sns.jointplot(x=&quot;petal_length&quot;, y=&quot;petal_width&quot;, data=iris, kind=&quot;kde&quot;)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-57-09.png" srcset="/img/loading.gif" alt></p><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-16-58-51.png" srcset="/img/loading.gif" alt></p><p>最后注意到我们的鸢尾花数据集含有四组属性。我们想探究这四组属性两两之间的关系，就需要用到<code>pairplot</code></p><pre><code class="lang-python">sns.pairplot(iris, hue=&quot;species&quot;)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-17-01-04.png" srcset="/img/loading.gif" alt></p><h2 id="2-4-回归图"><a href="#2-4-回归图" class="headerlink" title="2.4 回归图"></a>2.4 回归图</h2><p><code>regplot</code> 绘制回归图，只会绘制一组回归曲线。</p><pre><code class="lang-python">sns.regplot(x=&quot;sepal_length&quot;, y=&quot;sepal_width&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-17-02-28.png" srcset="/img/loading.gif" alt></p><p><code>lmplot</code> 可以引入<code>hue</code>变量，绘制不同类别数据的回归图</p><pre><code class="lang-python">sns.lmplot(x=&quot;sepal_length&quot;, y=&quot;sepal_width&quot;, hue=&quot;species&quot;, data=iris)</code></pre><p><img src="/2020/01/11/总结论文中常用的Matplotlib绘图技术/2020-01-12-17-03-57.png" srcset="/img/loading.gif" alt></p><h2 id="2-5-矩阵图"><a href="#2-5-矩阵图" class="headerlink" title="2.5 矩阵图"></a>2.5 矩阵图</h2><p><code>heatmap</code>用来画热图，数据值大的格子颜色比较深。热力图在某些场景下非常实用，例如绘制出变量相关性系数热力图。<br><code>clustermap</code>用来画层次聚类结构图。对于iris数据集来说，这两类图没有用武之地。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、使用matplotlib绘制图像&quot;&gt;&lt;a href=&quot;#一、使用matplotlib绘制图像&quot; class=&quot;headerlink&quot; title=&quot;一、使用matplotlib绘制图像&quot;&gt;&lt;/a&gt;一、使用matplotlib绘制图像&lt;/h1&gt;&lt;p&gt;matplo
      
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="matplotlib" scheme="https://superlova.github.io/tags/matplotlib/"/>
    
      <category term="seaborn" scheme="https://superlova.github.io/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>用于科学计算的GPU选购参考</title>
    <link href="https://superlova.github.io/2019/07/01/%E7%94%A8%E4%BA%8E%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E7%9A%84GPU%E9%80%89%E8%B4%AD%E5%8F%82%E8%80%83/"/>
    <id>https://superlova.github.io/2019/07/01/%E7%94%A8%E4%BA%8E%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E7%9A%84GPU%E9%80%89%E8%B4%AD%E5%8F%82%E8%80%83/</id>
    <published>2019-07-01T10:11:15.000Z</published>
    <updated>2020-03-19T01:44:37.971Z</updated>
    
    <content type="html"><![CDATA[<p>实验室最近要采购一批显卡，需要调研显卡的型号和价格。</p><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><p>首先说一下需求：</p><ul><li>首先显卡的用途是科学计算，更具体一点是深度学习，有人做图像，有人做NLP；</li><li>其次预算有限，得买性价比最好的；</li><li>然后可能会有很多人要用服务器训练模型。</li></ul><p>然后这是戴尔服务器的售后人员发来的建议采购清单：<br><img src="/2019/07/01/用于科学计算的GPU选购参考/2019-07-01-18-19-43.png" srcset="/img/loading.gif" alt></p><p>其中M10：19999￥ P100： 49999￥ V100：59999￥ P40：49999￥</p><p>值得一提的是，谷歌的Colab上面用的是这款：<br><img src="/2019/07/01/用于科学计算的GPU选购参考/2019-07-01-18-21-48.png" srcset="/img/loading.gif" alt><br><img src="/2019/07/01/用于科学计算的GPU选购参考/2019-07-01-18-21-58.png" srcset="/img/loading.gif" alt></p><p>但是一个从事深度学习研究的学长建议我买1080Ti。他好像提都没提过Tesla啊？难道显卡水这么深？</p><h2 id="GPU参数"><a href="#GPU参数" class="headerlink" title="GPU参数"></a>GPU参数</h2><p>GPU的性能主要由下面三个主要参数构成：</p><p><strong>计算能力</strong>。通常我们关心的是32位浮点计算能力。当然，对于高玩来说也可以考虑16位浮点用来训练，8位整数来预测。</p><p><strong>内存大小</strong>。神经网络越深，或者训练时批量大小越大，所需要的GPU内存就越多。</p><p><strong>内存带宽</strong>。内存带宽要足够才能发挥出所有计算能力。</p><p>此外，针对不同深度学习架构，GPU参数的选择优先级是不一样的，总体来说分两条路线：</p><p><strong>卷积网络和Transformer</strong>：张量核心&gt;FLOPs（每秒浮点运算次数）&gt;显存带宽&gt;16位浮点计算能力</p><p><strong>循环神经网络</strong>：显存带宽&gt;16位浮点计算能力&gt;张量核心&gt;FLOPs</p><p>这个排序背后有一套逻辑，下面将详细解释一下。</p><p>在说清楚哪个GPU参数对速度尤为重要之前，先看看两个最重要的张量运算：矩阵乘法和卷积。</p><p>举个栗子，以运算矩阵乘法A×B=C为例，将A、B复制到显存上比直接计算A×B更耗费资源。也就是说，如果你想用LSTM等处理大量小型矩阵乘法的循环神经网络，显存带宽是GPU最重要的属性。</p><p>矩阵乘法越小，内存带宽就越重要。</p><p>相反，卷积运算受计算速度的约束比较大。因此，要衡量GPU运行ResNets等卷积架构的性能，最佳指标就是FLOPs。张量核心可以明显增加FLOPs。</p><p>Transformer中用到的大型矩阵乘法介于卷积运算和RNN的小型矩阵乘法之间，16位存储、张量核心和TFLOPs都对大型矩阵乘法有好处，但它仍需要较大的显存带宽。</p><h2 id="性价比分析"><a href="#性价比分析" class="headerlink" title="性价比分析"></a>性价比分析</h2><p>下面总结了一张GPU和TPU的标准性能数据，值越高代表性能越好。RTX系列假定用了16位计算，Word RNN数值是指长度&lt;100的段序列的biLSTM性能。</p><p>这项基准测试是用PyTorch 1.0.1和CUDA 10完成的。</p><p><img src="/2019/07/01/用于科学计算的GPU选购参考/2019-07-01-19-09-53.png" srcset="/img/loading.gif" alt="GPU和TPU的性能数据"></p><p>性价比可能是选择一张GPU最重要的考虑指标。</p><p>性价比可能是选择一张GPU最重要的考虑指标。在攻略中，小哥进行了如下运算测试各显卡的性能：</p><ul><li>用语言模型Transformer-XL和BERT进行Transformer性能的基准测试。</li><li>用最先进的biLSTM进行了单词和字符级RNN的基准测试。</li><li>上述两种测试是针对Titan Xp、Titan RTX和RTX 2080 Ti进行的，对于其他GPU则线性缩放了性能差异。</li><li>借用了现有的CNN基准测试。</li><li>用了亚马逊和eBay上显卡的平均售价作为GPU的参考成本。<br>最后，可以得出CNN、RNN和Transformer的归一化性能/成本比值，如下所示：</li></ul><p><img src="/2019/07/01/用于科学计算的GPU选购参考/2019-07-01-19-11-20.png" srcset="/img/loading.gif" alt="CNN、RNN和Transformer的每美元性能"></p><p>在上面这张图中，数字越大代表每一美元能买到的性能越强。可以看出， RTX 2060比RTX 2070，RTX 2080或RTX 2080 Ti更具成本效益，<strong>甚至是Tesla V100性价比的5倍以上</strong>。</p><p>所以此轮的性价比之王已经确定，是RTX 2060无疑了。</p><p>下图是李沐老师画了900和1000系列里各个卡的32位浮点计算能力和价格的对比（价格是wikipedia的推荐价格，真实价格通常会有浮动）。</p><p><img src="/2019/07/01/用于科学计算的GPU选购参考/2019-07-01-19-06-00.png" srcset="/img/loading.gif" alt></p><p>由于GPU的功耗，散热和体积，需要一些额外考虑。</p><ul><li>机箱体积<br>GPU尺寸较大，通常不考虑太小的机箱。而且机箱自带的风扇要好。</li><li>电源<br>购买GPU时需要查下GPU的功耗，50w到300w不等。因此买电源时需要功率足够的。</li><li>主板的PCIe卡槽<br>推荐使用PCIe 3.0 16x来保证足够的GPU到主内存带宽。如果是多卡的话，要仔细看主板说明，保证多卡一起使用时仍然是16x带宽。（有些主板插4卡时会降到8x甚至4x）</li></ul><h2 id="Tesla为什么那么贵？"><a href="#Tesla为什么那么贵？" class="headerlink" title="Tesla为什么那么贵？"></a>Tesla为什么那么贵？</h2><p>英伟达现在有一项非常坑爹的政策，如果在数据中心使用CUDA，那么只允许使用Tesla GPU而不能用GTX或RTX GPU。</p><p>由于担心法律问题，研究机构和大学经常被迫购买低性价比的Tesla GPU。<strong>然而，Tesla与GTX和RTX相比并没有真正的优势，价格却高出10倍。</strong></p><p>Nvidia卡有面向个人用户（例如GTX系列）和企业用户（例如Tesla系列）两种。企业用户卡通常使用被动散热和增加了内存校验从而更加适合数据中心。但计算能力上两者相当。<strong>企业卡通常要贵上10倍</strong>。</p><p>Tesla显卡那么贵，其实是贵在双精度浮点数运算能力上了，外加一个鸡肋的ECC校验功能，实在不值。</p><h2 id="总结建议："><a href="#总结建议：" class="headerlink" title="总结建议："></a>总结建议：</h2><p><strong>最佳GPU</strong>：RTX 2070</p><p><strong>避免的坑</strong>：所有Tesla、Quadro、创始人版（Founders Edition）的显卡，还有Titan RTX、Titan V、Titan XP</p><p><strong>高性价比</strong>：RTX 2070（高端），RTX 2060或GTX 1060 (6GB)（中低端）</p><p><strong>计算机视觉或机器翻译研究人员</strong>：采用鼓风设计的GTX 2080 Ti，如果训练非常大的网络，请选择RTX Titans</p><p><strong>NLP研究人员</strong>：RTX 2080 Ti</p><p><strong>已经开始研究深度学习</strong>：RTX 2070起步，以后按需添置更多RTX 2070</p><h2 id="其他配件要求："><a href="#其他配件要求：" class="headerlink" title="其他配件要求："></a>其他配件要求：</h2><p><img src="/2019/07/01/用于科学计算的GPU选购参考/2019-07-01-19-19-14.png" srcset="/img/loading.gif" alt="各硬件性能要求"></p><ul><li><p>CPU:<br>因为主要使用显卡进行cuda计算，因此对CPU的要求并不是很高，频率越高、线程数越多越好，一般最低要求cpu核心数大于显卡个数。其中一个制约因素：cpu的最大PCI-E 通道数。每张显卡占用16条pcie通道才能达到最大性能，而单cpu最大支持40条pcie，也就是即使有4个pcie x16接口，只能最多达到2路x16加一路x8，插上的显卡不能发挥全部性能。不过，主板芯片组其实也可以扩充一部分pcie通道。（x99主板可以扩宽2.0的8lanes，z170可以扩充3.0的20lanes）</p></li><li><p>主板:<br>前面提到了cpu提供的pcie通道数的限制，如果要使用多块显卡，就需要主板提供额外的pcie通道，一般只有服务器级别的主板才会提供扩展pcie通道如x99、x299等主板，但是使用此类主板必须搭配具有该接口的服务器级cpu（xeon系列、i7 7900x以上、i9系列等），如果不需要三块以上的显卡，使用cpu提供的40lane pcie即可。</p></li><li><p>内存：<br>深度学习需要大量数据，中间计算过程也会临时储存大量数据，一般要求具有显存2~3倍的内存，32G或64G乃至更高。内存频率越高越好。<br>最低建议32G DDR4 3200MHz内存(16G*2)约2000元，预算宽裕可升级到64G（约4000元）</p></li><li><p>硬盘：<br>深度学习需要大量数据，和较快的访问速度，一般使用一个较大的固态硬盘作为系统盘和训练数据仓储盘，另外使用hdd机械硬盘作为仓储盘。<br>建议使用512G以上nVME固态硬盘（800元）搭配几TB(2TB约300元）Hdd作为储存空间</p></li><li><p>电源、机箱：电源其实还是要买个比较稳定的，因为要保证长期稳定运行会有“无休止”的training。一般使用大品牌的经过80PLUS金牌或铂金认证的电源。只搭配一张显卡700w即可，每多一张增加400w。4*titan V大概使用1600w电源。</p></li></ul><p>深度学习实验室共享服务器，7x24小时运行  2080ti或者4titan V ，预算充裕可以专门购置一台高性能多显卡深度学习服务器，24*7小时运行，其他用户可以在自己的笔记本电脑和台式机上编写和初步调试卷积神经网络，本地验证无误后，上传至服务器进行训练任务。这样做可以极大的节省设备开支，最大限度的利用计算资源，也避免了每个用户单独配置复杂的软件环境。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;实验室最近要采购一批显卡，需要调研显卡的型号和价格。&lt;/p&gt;
&lt;h2 id=&quot;需求分析&quot;&gt;&lt;a href=&quot;#需求分析&quot; class=&quot;headerlink&quot; title=&quot;需求分析&quot;&gt;&lt;/a&gt;需求分析&lt;/h2&gt;&lt;p&gt;首先说一下需求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先显卡的用
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="deep learning" scheme="https://superlova.github.io/tags/deep-learning/"/>
    
      <category term="GPU" scheme="https://superlova.github.io/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>NLP学习笔记4</title>
    <link href="https://superlova.github.io/2019/06/30/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04/"/>
    <id>https://superlova.github.io/2019/06/30/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04/</id>
    <published>2019-06-30T12:59:29.000Z</published>
    <updated>2020-03-19T01:30:44.788Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-利用朴素贝叶斯模型进行文本分类"><a href="#1-利用朴素贝叶斯模型进行文本分类" class="headerlink" title="1. 利用朴素贝叶斯模型进行文本分类"></a>1. 利用朴素贝叶斯模型进行文本分类</h2><p>朴素贝叶斯是一种构建分类器的简单方法。该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。它不是训练这种分类器的单一算法，而是一系列基于相同原理的算法：<strong>所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关</strong>。</p><p>举个例子，如果一种水果其具有红，圆，直径大概3英寸等特征，该水果可以被判定为是苹果。尽管这些特征相互依赖或者有些特征由其他特征决定，然而朴素贝叶斯分类器认为这些属性在判定该水果是否为苹果的概率分布上独立的。</p><p>尽管是带着这些朴素思想和过于简单化的假设，但朴素贝叶斯分类器在很多复杂的现实情形中仍能够获取相当好的效果。2004年，一篇分析贝叶斯分类器问题的文章揭示了朴素贝叶斯分类器获取看上去不可思议的分类效果的若干理论上的原因。尽管如此，2006年有一篇文章详细比较了各种分类方法，发现更新的方法（如决策树和随机森林）的性能超过了贝叶斯分类器。</p><p>对于某些类型的概率模型，在监督式学习的样本集中能获取得非常好的分类效果。在许多实际应用中，朴素贝叶斯模型参数估计使用<strong>最大似然估计方法</strong>；换而言之，在不用到贝叶斯概率或者任何贝叶斯模型的情况下，朴素贝叶斯模型也能奏效。</p><p>朴素贝叶斯分类器的一个优势在于只需要根据少量的训练数据估计出必要的参数（变量的均值和方差）。由于变量独立假设，只需要估计各个变量的方法，而不需要确定整个协方差矩阵。</p><p>朴素贝叶斯分类器是与线性模型非常相似的一种分类器，但它的训练速度往往更快。这种高效率所付出的代价是，朴素贝叶斯模型的泛化能力要比线性分类器（如LogisticRegression 和LinearSVC）稍差。</p><p>朴素贝叶斯模型如此高效的原因在于，它通过单独查看每个特征来学习参数，并从每个特征中收集简单的类别统计数据。scikit-learn 中实现了三种朴素贝叶斯分类器：GaussianNB、BernoulliNB 和MultinomialNB。GaussianNB 可应用于任意连续数据， 而BernoulliNB 假定输入数据为二分类数据，MultinomialNB 假定输入数据为计数数据（即每个特征代表某个对象的整数计数，比如一个单词在句子里出现的次数）。BernoulliNB 和MultinomialNB 主要用于文本数据分类。</p><pre><code class="lang-python"># 从sklearn.datasets里导入20类新闻文本数据抓取器。from sklearn.datasets import fetch_20newsgroups# 从互联网上即时下载新闻样本,subset=&#39;all&#39;参数代表下载全部近2万条文本存储在变量news中。news = fetch_20newsgroups(subset=&#39;all&#39;)# 从sklearn.cross_validation导入train_test_split模块用于分割数据集。from sklearn.cross_validation import train_test_split# 对news中的数据data进行分割，25%的文本用作测试集；75%作为训练集。X_train, X_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=33)# 从sklearn.feature_extraction.text里导入CountVectorizerfrom sklearn.feature_extraction.text import CountVectorizer# 采用默认的配置对CountVectorizer进行初始化（默认配置不去除英文停用词），并且赋值给变量count_vec。count_vec = CountVectorizer()# 只使用词频统计的方式将原始训练和测试文本转化为特征向量。#学习词汇的词典并返回文档矩阵。X_count_train = count_vec.fit_transform(X_train)#不进行学习直接转换文档document-term矩阵X_count_test = count_vec.transform(X_test)# 从sklearn.naive_bayes里导入朴素贝叶斯分类器。from sklearn.naive_bayes import MultinomialNB# 使用默认的配置对分类器进行初始化。mnb_count = MultinomialNB()# 使用朴素贝叶斯分类器，对CountVectorizer（不去除停用词）后的训练样本进行参数学习。mnb_count.fit(X_count_train, y_train)# 输出模型准确性结果。print (&#39;The accuracy of classifying 20newsgroups using Naive Bayes (CountVectorizer without filtering stopwords):&#39;, mnb_count.score(X_count_test, y_test))# 将分类预测的结果存储在变量y_count_predict中。y_count_predict = mnb_count.predict(X_count_test)# 从sklearn.metrics 导入 classification_report。from sklearn.metrics import classification_report# 输出更加详细的其他评价分类性能的指标。print (classification_report(y_test, y_count_predict, target_names = news.target_names))</code></pre><p><img src="/2019/06/30/NLP学习笔记4/2019-06-30-20-42-49.png" srcset="/img/loading.gif" alt></p><h2 id="2-利用SVM模型进行文本分类"><a href="#2-利用SVM模型进行文本分类" class="headerlink" title="2. 利用SVM模型进行文本分类"></a>2. 利用SVM模型进行文本分类</h2><h2 id="3-pLSA、共轭先验分布、LDA"><a href="#3-pLSA、共轭先验分布、LDA" class="headerlink" title="3. pLSA、共轭先验分布、LDA"></a>3. pLSA、共轭先验分布、LDA</h2><p>常用于文本数据的一种特殊技术是主题建模（topic modeling），这是描述将每个文档分配给一个或多个主题的任务（通常是无监督的）的概括性术语。这方面一个很好的例子是新闻数据，它们可以被分为“政治”“体育”“金融”等主题。如果为每个文档分配一个主题，那么这是一个文档聚类任务。如果每个文档可以有多个主题，那么这个任务与第3 章中的分解方法有关。我们学到的每个成分对应于一个主题，文档表示中的成分系数告诉我们这个文档与该主题的相关性强弱。通常来说，人们在谈论主题建模时，他们指的是一种叫作隐含狄利克雷分布（Latent Dirichlet Allocation，LDA）的特定分解方法</p><h3 id="隐含狄利克雷分布"><a href="#隐含狄利克雷分布" class="headerlink" title="隐含狄利克雷分布"></a>隐含狄利克雷分布</h3><p>从直观上来看，LDA 模型试图找出频繁共同出现的单词群组（即主题）。LDA 还要求，每个文档可以被理解为主题子集的“混合”。重要的是要理解，机器学习模型所谓的“主题”可能不是我们通常在日常对话中所说的主题，而是更类似于 PCA 或 NMF所提取的成分，它可能具有语义，也可能没有。即使 LDA“主题”具有语义，它可能也不是我们通常所说的主题。</p><p>举个自然语言处理的例子，我们可能有许多关于体育、政治和金融的文章，由两位作者所写。在一篇政治文章中，我们预计可能会看 到“州长”“投票”“党派”等词语，而在一篇体育文章中，我们预计可能会看到类似“队 伍”“得分”和“赛季”之类的词语。这两组词语可能会同时出现，而例如“队伍”和 “州长”就不太可能同时出现。但是，这并不是我们预计可能同时出现的唯一的单词群组。这两位记者可能偏爱不同的短语或者选择不同的单词。可能其中一人喜欢使用“划界”（demarcate）这个词，而另一人喜欢使用“两极分化”（polarize）这个词。其他“主题”可 能是“记者 A 常用的词语”和“记者 B 常用的词语”，虽然这并不是通常意义上的主题。</p><h2 id="4-使用LDA生成主题特征，在之前特征的基础上加入主题特征进行文本分类"><a href="#4-使用LDA生成主题特征，在之前特征的基础上加入主题特征进行文本分类" class="headerlink" title="4. 使用LDA生成主题特征，在之前特征的基础上加入主题特征进行文本分类"></a>4. 使用LDA生成主题特征，在之前特征的基础上加入主题特征进行文本分类</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-利用朴素贝叶斯模型进行文本分类&quot;&gt;&lt;a href=&quot;#1-利用朴素贝叶斯模型进行文本分类&quot; class=&quot;headerlink&quot; title=&quot;1. 利用朴素贝叶斯模型进行文本分类&quot;&gt;&lt;/a&gt;1. 利用朴素贝叶斯模型进行文本分类&lt;/h2&gt;&lt;p&gt;朴素贝叶斯是一种
      
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="deep learning" scheme="https://superlova.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>NLP学习笔记3</title>
    <link href="https://superlova.github.io/2019/06/27/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03/"/>
    <id>https://superlova.github.io/2019/06/27/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03/</id>
    <published>2019-06-27T12:51:24.000Z</published>
    <updated>2020-03-19T01:30:30.272Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-TF-IDF原理。"><a href="#1-TF-IDF原理。" class="headerlink" title="1. TF-IDF原理。"></a>1. TF-IDF原理。</h2><p>tf-idf（英语：term frequency–inverse document frequency）是一种用于信息检索与文本挖掘的常用加权技术。tf-idf是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。tf-idf加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了tf-idf以外，互联网上的搜索引擎还会使用基于链接分析的评级方法，以确定文件在搜索结果中出现的顺序。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>在一份给定的文件里，词频（term frequency，tf）指的是某一个给定的词语在该文件中出现的频率。这个数字是对词数（term count）的归一化，以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词数，而不管该词语重要与否。）对于在某一特定文件里的词语 ${\displaystyle t_{i}!}$来说，它的重要性可表示为：</p><script type="math/tex; mode=display">{\displaystyle \mathrm {tf_{i,j}\!} ={\frac {n_{i,j}\!}{\sum _{k}n_{k,j}\!}\!}\!}</script><p>以上式子中 ${\displaystyle n_{i,j}!} n_{i,j}$是该词在文件 ${\displaystyle d_{j}!} d_{j}$中的出现次数，而分母则是在文件 ${\displaystyle d_{j}!} d_{j}$中所有字词的出现次数之和。</p><p>逆向文件频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的idf，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到：</p><script type="math/tex; mode=display">{\displaystyle \mathrm {idf_{i}\!} =\lg {\frac {|D|}{|\{j:t_{i}\in d_{j}\}|}\!}\!}</script><p>其中</p><p>$|D|$：语料库中的文件总数</p><script type="math/tex; mode=display">{\displaystyle |\{j:t_{i}\in d_{j}\}|} $$：包含词语 ${\displaystyle t_{i}\!} t_{i}$的文件数目（即 ${\displaystyle n_{i,j}\neq 0} n_{i,j}\neq 0$的文件数目）如果词语不在数据中，就导致分母为零，因此一般情况下使用 $${\displaystyle 1+|\{j:t_{i}\in d_{j}\}|}</script><p>然后</p><script type="math/tex; mode=display">{\displaystyle \mathrm {tf{}idf_{i,j}\!} =\mathrm {tf_{i,j}\!} \times \mathrm {idf_{i}\!} }</script><p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的tf-idf。因此，tf-idf倾向于过滤掉常见的词语，保留重要的词语。</p><h3 id="1-2-例子"><a href="#1-2-例子" class="headerlink" title="1.2 例子"></a>1.2 例子</h3><p>有很多不同的数学公式可以用来计算tf-idf。这边的例子以上述的数学公式来计算。词频（tf）是一词语出现的次数除以该文件的总词语数。假如一篇文件的总词语数是100个，而词语“母牛”出现了3次，那么“母牛”一词在该文件中的词频就是3/100=0.03。而计算文件频率（IDF）的方法是以文件集的文件总数，除以出现“母牛”一词的文件数。所以，如果“母牛”一词在1,000份文件出现过，而文件总数是10,000,000份的话，其逆向文件频率就是lg（10,000,000 / 1,000）=4。最后的tf-idf的分数为0.03 * 4=0.12。</p><h3 id="1-3-tf-idf的理论依据及不足"><a href="#1-3-tf-idf的理论依据及不足" class="headerlink" title="1.3 tf-idf的理论依据及不足"></a>1.3 tf-idf的理论依据及不足</h3><p>tf-idf算法是创建在这样一个假设之上的：对区别文档最有意义的词语应该是那些在文档中出现频率高，而在整个文档集合的其他文档中出现频率少的词语，所以如果特征空间坐标系取tf词频作为测度，就可以体现同类文本的特点。另外考虑到单词区别不同类别的能力，tf-idf法认为一个单词出现的文本频数越小，它区别不同类别文本的能力就越大。因此引入了逆文本频度idf的概念，以tf和idf的乘积作为特征空间坐标系的取值测度，并用它完成对权值tf的调整，调整权值的目的在于突出重要单词，抑制次要单词。但是在本质上idf是一种试图抑制噪声的加权，并且单纯地认为文本频率小的单词就越重要，文本频率大的单词就越无用，显然这并不是完全正确的。idf的简单结构并不能有效地反映单词的重要程度和特征词的分布情况，使其无法很好地完成对权值调整的功能，所以tf-idf法的精度并不是很高。</p><p>此外，在tf-idf算法中并没有体现出单词的位置信息，对于Web文档而言，权重的计算方法应该体现出HTML的结构特征。特征词在不同的标记符中对文章内容的反映程度不同，其权重的计算方法也应不同。因此应该对于处于网页不同位置的特征词分别赋予不同的系数，然后乘以特征词的词频，以提高文本表示的效果。</p><h2 id="2-文本矩阵化，使用词袋模型，以TF-IDF特征值为权重。"><a href="#2-文本矩阵化，使用词袋模型，以TF-IDF特征值为权重。" class="headerlink" title="2. 文本矩阵化，使用词袋模型，以TF-IDF特征值为权重。"></a>2. 文本矩阵化，使用词袋模型，以TF-IDF特征值为权重。</h2><p>TfidfVectorizer可以把原始文本转化为tf-idf的特征矩阵，从而为后续的文本相似度计算，主题模型(如LSI)，文本搜索排序等一系列应用奠定基础。基本应用如：</p><h3 id="第一步：分词"><a href="#第一步：分词" class="headerlink" title="第一步：分词"></a>第一步：分词</h3><p>采用著名的中文分词库jieba进行分词：</p><pre><code class="lang-python">import jiebatext = &quot;&quot;&quot;我是一条天狗呀！我把月来吞了，我把日来吞了，我把一切的星球来吞了，我把全宇宙来吞了。我便是我了！&quot;&quot;&quot;sentences = text.split()sent_words = [list(jieba.cut(sent0)) for sent0 in sentences]document = [&quot; &quot;.join(sent0) for sent0 in sent_words]print(document)</code></pre><h3 id="第二步：建模"><a href="#第二步：建模" class="headerlink" title="第二步：建模"></a>第二步：建模</h3><pre><code>理论上，现在得到的document的格式已经可以直接拿来训练了。让我们跑一下模型试试。</code></pre><pre><code class="lang-python">tfidf_model = TfidfVectorizer().fit(document)print(tfidf_model.vocabulary_)# {&#39;一条&#39;: 1, &#39;天狗&#39;: 4, &#39;日来&#39;: 5, &#39;一切&#39;: 0, &#39;星球&#39;: 6, &#39;全宇宙&#39;: 3, &#39;便是&#39;: 2}sparse_result = tfidf_model.transform(document)print(sparse_result)# (0, 4)    0.707106781187# (0, 1)    0.707106781187# (2, 5)    1.0# (3, 6)    0.707106781187# (3, 0)    0.707106781187# (4, 3)    1.0# (5, 2)    1.0</code></pre><h3 id="第三步：参数"><a href="#第三步：参数" class="headerlink" title="第三步：参数"></a>第三步：参数</h3><pre><code>查了一些资料以后，发现单字的问题是token_pattern这个参数搞的鬼。它的默认值只匹配长度≥2的单词，就像其实开头的例子中的&#39;I&#39;也被忽略了一样，一般来说，长度为1的单词在英文中一般是无足轻重的，但在中文里，就可能有一些很重要的单字词，所以修改如下：</code></pre><pre><code class="lang-python">tfidf_model2 = TfidfVectorizer(token_pattern=r&quot;(?u)\b\w+\b&quot;).fit(document)print(tfidf_model2.vocabulary_)# {&#39;我&#39;: 8, &#39;是&#39;: 12, &#39;一条&#39;: 1, &#39;天狗&#39;: 7, &#39;呀&#39;: 6, &#39;把&#39;: 9, &#39;月&#39;: 13, &#39;来&#39;: 14, &#39;吞&#39;: 5, &#39;了&#39;: 2, &#39;日来&#39;: 10, &#39;一切&#39;: 0, &#39;的&#39;: 15, &#39;星球&#39;: 11, &#39;全宇宙&#39;: 4, &#39;便是&#39;: 3}</code></pre><p>token_pattern这个参数使用正则表达式来分词，其默认参数为r”(?u)\b\w\w+\b”，其中的两个\w决定了其匹配长度至少为2的单词，所以这边减到1个。对这个参数进行更多修改，可以满足其他要求，比如这里依然没有得到标点符号，在此不详解了。</p><h2 id="3-互信息"><a href="#3-互信息" class="headerlink" title="3. 互信息"></a>3. 互信息</h2><p>在概率论和信息论中，两个随机变量的互信息（Mutual Information，简称MI）或转移信息（transinformation）是变量间相互依赖性的量度。不同于相关系数，互信息并不局限于实值随机变量，它更加一般且决定着联合分布$ p(X,Y) $和分解的边缘分布的乘积$ p(X)p(Y) $的相似程度。互信息是点间互信息（PMI）的期望值。互信息最常用的单位是bit。</p><p>一般地，两个离散随机变量$ X $和$ Y $的互信息可以定义为：</p><script type="math/tex; mode=display">{\displaystyle I(X;Y)=\sum _{y\in Y}\sum _{x\in X}p(x,y)\log {\left({\frac {p(x,y)}{p(x)\,p(y)}\!}\right)},\,\!}</script><p>其中$ p(x,y) $是 $X $和 $Y $的联合概率分布函数，而 ${\displaystyle p(x)} $和$ {\displaystyle p(y)}  $分别是 X 和 Y 的边缘概率分布函数。</p><p>在连续随机变量的情形下，求和被替换成了二重定积分：</p><script type="math/tex; mode=display">{\displaystyle I(X;Y)=\int _{Y}\int _{X}p(x,y)\log {\left({\frac {p(x,y)}{p(x)\,p(y)}\!}\right)}\;dx\,dy,} $$,其中 $p(x,y)$ 当前是 X 和 Y 的联合概率密度函数，而 ${\displaystyle p(x)} $和$ {\displaystyle p(y)}$分别是$ X $和$ Y $的边缘概率密度函数。如果对数以 2 为基底，互信息的单位是bit。直观上，互信息度量 X 和 Y 共享的信息：它度量知道这两个变量其中一个，对另一个不确定度减少的程度。例如，如果 X 和 Y 相互独立，则知道 X 不对 Y 提供任何信息，反之亦然，所以它们的互信息为零。在另一个极端，如果 X 是 Y 的一个确定性函数，且 Y 也是 X 的一个确定性函数，那么传递的所有信息被 X 和 Y 共享：知道 X 决定 Y 的值，反之亦然。因此，在此情形互信息与 Y（或 X）单独包含的不确定度相同，称作 Y（或 X）的熵。而且，这个互信息与 X 的熵和 Y 的熵相同。（这种情形的一个非常特殊的情况是当 X 和 Y 为相同随机变量时。）互信息是 X 和 Y 的联合分布相对于假定 X 和 Y 独立情况下的联合分布之间的内在依赖性。 于是互信息以下面方式度量依赖性：$I(X; Y) = 0$ 当且仅当 X 和 Y 为独立随机变量。从一个方向很容易看出：当 X 和 Y 独立时，$p(x,y) = p(x) p(y)$，因此：$${\displaystyle \log {\left({\frac {p(x,y)}{p(x)\,p(y)} \!}\right)}=\log 1=0.\,\!}</script><p>此外，互信息是非负的（即 $I(X;Y) ≥ 0$; 见下文），而且是对称的（即 $I(X;Y) = I(Y;X)$）。</p><p>互信息又可以等价地表示成</p><script type="math/tex; mode=display">{\displaystyle {\begin{aligned}I(X;Y)&{}=H(X)-H(X|Y)\\&{}=H(Y)-H(Y|X)\\&{}=H(X)+H(Y)-H(X,Y)\\&{}=H(X,Y)-H(X|Y)-H(Y|X)\end{aligned}\!}\!}</script><p>其中$ {\displaystyle \ H(X)} $ 和$ {\displaystyle \ H(Y)}  $是边缘熵，$H(X|Y) $和$ H(Y|X) $是条件熵，而 $H(X,Y) $是 X 和 Y 的联合熵。</p><p><strong>互信息越小，两个来自不同事件空间的随机变量彼此之间的关系性越低; 互信息越高，关系性则越高。</strong></p><h2 id="4-对特征矩阵使用互信息进行特征筛选"><a href="#4-对特征矩阵使用互信息进行特征筛选" class="headerlink" title="4. 对特征矩阵使用互信息进行特征筛选"></a>4. 对特征矩阵使用互信息进行特征筛选</h2><p><code>sklearn.metrics.mutual_info_score</code></p><pre><code class="lang-python">from sklearn import datasetsfrom sklearn import metrics as mriris = datasets.load_iris()x = iris.datalabel = iris.targetx0 = x[:, 0]x1 = x[:, 1]x2 = x[:, 2]x3 = x[:, 3]# 计算各特征与label的互信息print(mr.mutual_info_score(x0, label))print(mr.mutual_info_score(x1, label))print(mr.mutual_info_score(x2, label))print(mr.mutual_info_score(x3, label))</code></pre><p><img src="/2019/06/27/NLP学习笔记3/2019-06-27-20-45-13.png" srcset="/img/loading.gif" alt><br><code>sklearn.feature_selection.mutual_info_classif</code></p><pre><code class="lang-python">from sklearn import datasetsfrom sklearn.feature_selection import mutual_info_classifiris = datasets.load_iris()x = iris.datalabel = iris.targetmutual_info = mutual_info_classif(x, label, discrete_features= False)print(mutual_info)</code></pre><p><img src="/2019/06/27/NLP学习笔记3/2019-06-27-20-45-28.png" srcset="/img/loading.gif" alt></p><blockquote><p>参考文献<br><a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Tf-idf</a><br><a href="https://zh.wikipedia.org/wiki/%E4%BA%92%E4%BF%A1%E6%81%AF" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E4%BA%92%E4%BF%A1%E6%81%AF</a><br><a href="https://blog.csdn.net/yyy430/article/details/88249709" target="_blank" rel="noopener">https://blog.csdn.net/yyy430/article/details/88249709</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-TF-IDF原理。&quot;&gt;&lt;a href=&quot;#1-TF-IDF原理。&quot; class=&quot;headerlink&quot; title=&quot;1. TF-IDF原理。&quot;&gt;&lt;/a&gt;1. TF-IDF原理。&lt;/h2&gt;&lt;p&gt;tf-idf（英语：term frequency–inverse
      
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="deep learning" scheme="https://superlova.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习——集成方法</title>
    <link href="https://superlova.github.io/2019/06/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95/"/>
    <id>https://superlova.github.io/2019/06/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95/</id>
    <published>2019-06-27T08:04:10.000Z</published>
    <updated>2020-03-19T01:38:46.937Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-投票分类器"><a href="#1-投票分类器" class="headerlink" title="1. 投票分类器"></a>1. 投票分类器</h2><p>三个臭皮匠顶一个诸葛亮。即便是很多预测准确率仅强于随机的个体学习器的组合，经过一定的安排，也可以发挥令人惊讶的效果。在机器学习中，这种看起来没什么含金量的学习策略称之为<strong>集成学习</strong>。</p><p>集成学习首先需要一系列的个体学习器。之后采用某些策略结合它们的判断。</p><p>集成学习的要求：</p><ul><li>构成集成学习器的个体学习器，其性能不能太差，至少要为强于随机的<strong>弱学习器</strong>。</li></ul><p>当然强学习器更好。在最后的结果汇总阶段，也会更多听取强学习器的意见。</p><ul><li>个体学习器要具有一定的多样性。</li></ul><p>广泛吸收各种不同学习器的意见，做出的决策才有代表性。在机器学习中，体现出的要求就是模型之间的差别要尽可能的大。一方面可以通过划分不同的数据集，独立训练来得到差异性；另一方面我们也可以选取不同的训练模型，比如SVM、决策树、逻辑回归。</p><p>集成学习法的准确率比集成学习中表现最好的分类器准确率还高，这究竟是为什么？难道那一些不入流的臭鱼烂虾机器学习法，它们存在的意义就是提升集成学习中的准确率的吗？</p><p>我们来打个比方。假设我有一枚硬币，这枚硬币经过加工处理，正面朝上的可能性比背面要高那么一点点，51%的可能性是正面。问，如果我投掷1000次硬币，正面朝上次数大于背面朝上次数的可能性占比多少？一万次呢？</p><p>事实上，1000次投掷，最后正面次数比背面多的概率就达到了0.72，如果投掷10000次，那么就是0.94，几乎是必然事件。</p><p>将其类比到集成学习中来，如果相互独立的个体学习器足够多，那么我们得到正确结论的概率将大大提升。不过这里有一个最关键的点：<strong>模型之间相互独立</strong>。这个要求其实是蛮难达到的，因为即便是不同的机器学习模型，如果采用相同或者相似的数据集进行训练，那么他们之间必然存在某种相关性。更不用说连模型都是一模一样的情况了。</p><h2 id="2-Boosting算法"><a href="#2-Boosting算法" class="headerlink" title="2. Boosting算法"></a>2. Boosting算法</h2><p>Boosting算法的核心思想是分割训练集，用同一种机器学习算法得到差异化的一系列模型。</p><p>先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本的分布进行调整，是的先前基学习器做错的训练样本在后续收到更多地关注。然后基于调整后的样本分布来训练下一个基学习器。如此反复进行，训练T个基学习器，最终加权投票。</p><p><img src="/2019/06/27/机器学习——集成方法/2019-06-27-21-57-03.png" srcset="/img/loading.gif" alt></p><p><img src="/2019/06/27/机器学习——集成方法/2019-06-27-21-57-17.png" srcset="/img/loading.gif" alt></p><h2 id="3-Bagging算法"><a href="#3-Bagging算法" class="headerlink" title="3. Bagging算法"></a>3. Bagging算法</h2><p>有放回采样被称为Bagging。采用Bagging的方法我们可以得到很多的可能有重复样本的数据子集。我们在之前的文章中已经提到，对于每个选取的子集，平均下来只有63%的训练实例被采样，剩下的37%正好当做测试集。</p><p>随机森林就采用了Bagging采样方法来训练很多的决策树。如果你观察单一的决策树，重要的特征会出现在更靠近根部的位置，不重要的特征会经常出现在靠近叶子的位置。因此我们可以通过计算一个特征在森林的全部树中出现的平均深度来预测特征的重要性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-投票分类器&quot;&gt;&lt;a href=&quot;#1-投票分类器&quot; class=&quot;headerlink&quot; title=&quot;1. 投票分类器&quot;&gt;&lt;/a&gt;1. 投票分类器&lt;/h2&gt;&lt;p&gt;三个臭皮匠顶一个诸葛亮。即便是很多预测准确率仅强于随机的个体学习器的组合，经过一定的安排，也可以
      
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="machine learning" scheme="https://superlova.github.io/tags/machine-learning/"/>
    
      <category term="boosting" scheme="https://superlova.github.io/tags/boosting/"/>
    
  </entry>
  
  <entry>
    <title>NLP学习笔记2</title>
    <link href="https://superlova.github.io/2019/06/24/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/"/>
    <id>https://superlova.github.io/2019/06/24/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/</id>
    <published>2019-06-24T12:19:24.000Z</published>
    <updated>2020-03-19T01:30:10.989Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-分词的概念和实现细节"><a href="#1-分词的概念和实现细节" class="headerlink" title="1. 分词的概念和实现细节"></a>1. 分词的概念和实现细节</h2><p>NLP的底层任务可分为词法分析、句法分析和语义分析，分词是词法分析中最基本的任务。中文分词是在一个中文序列的词与此之间加上空格或者其他边界标志进行分割，从而方便接下来步骤的处理。</p><p>分词算法可分为两种，一种是基于词典的分词算法，另一种是基于字的分词算法。</p><h3 id="1-1-基于词典的分词算法："><a href="#1-1-基于词典的分词算法：" class="headerlink" title="1.1 基于词典的分词算法："></a>1.1 基于词典的分词算法：</h3><p><strong>最大匹配分词算法</strong>，有正向和反向两种。主要思路是将词典构造成一颗Trie树，也成为词典树。以“他说的确实在理”这句话为例，构造Trie树如图所示：</p><p><img src="/2019/06/24/NLP学习笔记2/2019-06-24-20-42-46.png" srcset="/img/loading.gif" alt></p><p>Trie树由词的公共前缀构成节点，降低了存储空间的同时提升查找效率。最大（正向）匹配分词将句子与Trie树进行匹配，在匹配到根结点时由下一个字重新开始进行查找。比如正向（从左至右）匹配“他说的确实在理”，得出的结果为“他／说／的确／实在／理”。如果进行反向最大匹配，则为“他／说／的／确实／在理”。</p><p>单独依仗这种方法达不到很好的分词效果，而且分词时间复杂度为O(N)，即随着字符串长度线性上升。</p><p><strong>最短路径分词算法</strong>，讲一句话中所有的词匹配出来构成<strong>词图</strong>，词图是一个有向无环图。之后分词问题转化为求开始节点和结束节点之间的最短路径的问题。有迪杰斯特拉算法以及其他算法。不一定只保存最短的路径，有可能保存前N短的路径。图的边上也有可能按照不同词汇出现的概率大小不同安排不同的权值。</p><p><img src="/2019/06/24/NLP学习笔记2/2019-06-24-20-47-26.png" srcset="/img/loading.gif" alt></p><p>如何构建不同权值的词图？有基于n-gram的分词算法。最后我们可以得到词的概率图。</p><p><img src="/2019/06/24/NLP学习笔记2/2019-06-24-20-49-14.png" srcset="/img/loading.gif" alt></p><h3 id="1-2-基于字的分词算法"><a href="#1-2-基于字的分词算法" class="headerlink" title="1.2 基于字的分词算法"></a>1.2 基于字的分词算法</h3><p>与基于词典的分词不同的是，基于字的分词事先不对句子进行词的匹配，而是将分词看成序列标注问题，把一个字标记成B(Begin), I(Inside), O(Outside), E(End), S(Single)。因此也可以看成是每个字的分类问题，输入为每个字及其前后字所构成的特征，输出为分类标记。对于分类问题，可以用统计机器学习或神经网络的方法求解。</p><p>在NLP中，最常用的神经网络为循环神经网络（RNN，Recurrent Neural Network），它在处理变长输入和序列输入问题中有着巨大的优势。LSTM为RNN变种的一种，在一定程度上解决了RNN在训练过程中梯度消失和梯度爆炸的问题。双向（Bidirectional）循环神经网络分别从句子的开头和结尾开始对输入进行处理，将上下文信息进行编码，提升预测效果。</p><h2 id="2-词、字符频率统计"><a href="#2-词、字符频率统计" class="headerlink" title="2. 词、字符频率统计"></a>2. 词、字符频率统计</h2><p>统计一篇文章中单词出现的次数，首先应该知道该文章中，有多少个单词（去重后），然后再统计单词在文章中的出现频率。这里使用最简单的方式来实现该功能。</p><pre><code class="lang-python">def statistics():    path = ...    with open(path, &#39;r&#39;, encoding=&#39;UTF-8&#39;) as text:        print(string.punctuation)        words = [raw_word.strip(string.punctuation).lower() for raw_word in text.read().split()]        words_index = set(words)        counts_dict = {index: words.count(index) for index in words_index}    for word in sorted(counts_dict, key=lambda x: counts_dict[x], reverse=True):        print(&#39;{}--{} times&#39;.format(word, counts_dict[word]))</code></pre><h2 id="3-语言模型中unigram、bigram、trigram的概念"><a href="#3-语言模型中unigram、bigram、trigram的概念" class="headerlink" title="3. 语言模型中unigram、bigram、trigram的概念"></a>3. 语言模型中unigram、bigram、trigram的概念</h2><p>简单地说，语言模型就是用来计算一个句子的概率的模型。为了解决參数空间过大的问题。引入了马尔科夫假设：随意一个词出现的概率只与它前面出现的有限的一个或者几个词有关。</p><p>如果一个词的出现与它周围的词是独立的，那么我们就称之为unigram也就是一元语言模型：</p><p><img src="/2019/06/24/NLP学习笔记2/2019-06-24-20-55-14.png" srcset="/img/loading.gif" alt></p><p>如果一个词的出现仅依赖于它前面出现的一个词，那么我们就称之为bigram：</p><p><img src="/2019/06/24/NLP学习笔记2/2019-06-24-20-54-56.png" srcset="/img/loading.gif" alt></p><p>同理，trigram：</p><p><img src="/2019/06/24/NLP学习笔记2/2019-06-24-20-55-41.png" srcset="/img/loading.gif" alt></p><p>一般来说，N元模型就是假设当前词的出现概率只与它前面的N-1个词有关。在实践中用的最多的就是bigram和trigram了。</p><h2 id="4-文本矩阵化"><a href="#4-文本矩阵化" class="headerlink" title="4. 文本矩阵化"></a>4. 文本矩阵化</h2><pre><code class="lang-python">a =&quot;自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。自然语言处理是一门融语言学、计算机科学、数学于一体的科学&quot;b = &quot;因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，所以它与语言学的研究有着密切的联系，但又有重要的区别。自然语言处理并不是一般地研究自然语言，而在于研制能有效地实现自然语言通信的计算机系统，特别是其中的软件系统。&quot;c =&quot;因而它是计算机科学的一部分。自然语言处理（NLP）是计算机科学，人工智能，语言学关注计算机和人类（自然）语言之间的相互作用的领域。&quot;import jiebaall_list= [&#39;  &#39;.join(jieba.cut(s,cut_all = False)) for s in [a,b,c]]print(all_list)</code></pre><pre><code class="lang-python">#从文件导入停用词表stpwrdpath =&quot;C:\\Users\\Administrator\Desktop\lect09_codes\lect09_proj\stop_words\\中文停用词库.txt&quot;with open(stpwrdpath, &#39;rb&#39;) as fp:    stopword = fp.read().decode(&#39;utf-8&#39;)  # 提用词提取#将停用词表转换为list  stpwrdlst = stopword.splitlines()# 从sklearn.feature_extraction.text里导入CountVectorizerfrom sklearn.feature_extraction.text import CountVectorizer# 对CountVectorizer进行初始化（去除中文停用词）count_vec=CountVectorizer(stop_words=stpwrdlst) #创建词袋数据结构X_count_train = count_vec.fit_transform(all_list[:2])  #&lt;class &#39;scipy.sparse.csr.csr_matrix&#39;&gt;# 将原始训练和测试文本转化为特征向量X_count_train= X_count_train.toarray()X_count_test = count_vec.transform(all_list[2]).toarray()print(X_count_train)#词汇表print(&#39;\nvocabulary list:\n\n&#39;,count_vec.get_feature_names())print( &#39;\nvocabulary dic :\n\n&#39;,count_vec.vocabulary_)print (&#39;vocabulary:\n\n&#39;)for key,value in count_vec.vocabulary_.items():    print(key,value)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-分词的概念和实现细节&quot;&gt;&lt;a href=&quot;#1-分词的概念和实现细节&quot; class=&quot;headerlink&quot; title=&quot;1. 分词的概念和实现细节&quot;&gt;&lt;/a&gt;1. 分词的概念和实现细节&lt;/h2&gt;&lt;p&gt;NLP的底层任务可分为词法分析、句法分析和语义分析，分词
      
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="deep learning" scheme="https://superlova.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>NLP学习笔记1</title>
    <link href="https://superlova.github.io/2019/06/21/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"/>
    <id>https://superlova.github.io/2019/06/21/NLP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/</id>
    <published>2019-06-21T13:02:07.000Z</published>
    <updated>2020-03-19T01:31:01.669Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IMDB数据集探索"><a href="#IMDB数据集探索" class="headerlink" title="IMDB数据集探索"></a>IMDB数据集探索</h1><p>实验是在Google Colab上面做的，机器也是用的谷歌云。</p><pre><code class="lang-python"># keras.datasets.imdb is broken in 1.13 and 1.14, by np 1.16.3!pip install tf_nightly</code></pre><p>安装tensorflow</p><pre><code class="lang-python">from __future__ import absolute_import, division, print_function, unicode_literalsimport tensorflow as tffrom tensorflow import kerasimport numpy as npprint(tf.__version__)</code></pre><p>导入相关的包</p><pre><code class="lang-python">imdb = keras.datasets.imdb(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)</code></pre><p>导入IMDB数据集，将其分成四部分，分别是训练集、训练集答案、测试集、测试集答案。</p><pre><code class="lang-python">print(&quot;Training entries: {}, labels: {}&quot;.format(len(train_data), len(train_labels)))print(train_data[0])len(train_data[0]), len(train_data[1])</code></pre><p>探索数据集。可以发现，训练集的每一个训练样本是一个由数字组成的列表。我还纳闷呢，这不应该是文本序列吗？</p><p>后来我发现，每个数字对应着不同的单词。比如1对应的是The，4对应的是film。之后只要根据字典mapping一下就好。</p><pre><code class="lang-python"># A dictionary mapping words to an integer indexword_index = imdb.get_word_index()# The first indices are reservedword_index = {k:(v+3) for k,v in word_index.items()}word_index[&quot;&lt;PAD&gt;&quot;] = 0word_index[&quot;&lt;START&gt;&quot;] = 1word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknownword_index[&quot;&lt;UNUSED&gt;&quot;] = 3reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])def decode_review(text):    return &#39; &#39;.join([reverse_word_index.get(i, &#39;?&#39;) for i in text])decode_review(train_data[0])</code></pre><p>提取字典。并尝试利用字典还原一个样本的本来面貌。</p><pre><code class="lang-python">train_data = keras.preprocessing.sequence.pad_sequences(train_data,                                                        value=word_index[&quot;&lt;PAD&gt;&quot;],                                                        padding=&#39;post&#39;,                                                        maxlen=256)test_data = keras.preprocessing.sequence.pad_sequences(test_data,                                                       value=word_index[&quot;&lt;PAD&gt;&quot;],                                                       padding=&#39;post&#39;,                                                       maxlen=256)len(train_data[0]), len(train_data[1])print(train_data[0])</code></pre><p>简化训练集和测试集，每个样本之提取最多256个单次，不够的就以0来凑。</p><pre><code class="lang-python"># input shape is the vocabulary count used for the movie reviews (10,000 words)vocab_size = 10000model = keras.Sequential()model.add(keras.layers.Embedding(vocab_size, 16))model.add(keras.layers.GlobalAveragePooling1D())model.add(keras.layers.Dense(16, activation=tf.nn.relu))model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))model.summary()</code></pre><p>安排网络，输入层、池化层、全连接、softmax层。</p><pre><code class="lang-python">model.compile(optimizer=&#39;adam&#39;,              loss=&#39;binary_crossentropy&#39;,              metrics=[&#39;acc&#39;])</code></pre><pre><code class="lang-python">x_val = train_data[:10000]partial_x_train = train_data[10000:]y_val = train_labels[:10000]partial_y_train = train_labels[10000:]history = model.fit(partial_x_train,                    partial_y_train,                    epochs=40,                    batch_size=512,                    validation_data=(x_val, y_val),                    verbose=1)</code></pre><p>训练！</p><pre><code class="lang-python">results = model.evaluate(test_data, test_labels)print(results)</code></pre><p>测试结果是准确率87%。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;IMDB数据集探索&quot;&gt;&lt;a href=&quot;#IMDB数据集探索&quot; class=&quot;headerlink&quot; title=&quot;IMDB数据集探索&quot;&gt;&lt;/a&gt;IMDB数据集探索&lt;/h1&gt;&lt;p&gt;实验是在Google Colab上面做的，机器也是用的谷歌云。&lt;/p&gt;
&lt;pre&gt;&lt;
      
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="NLP" scheme="https://superlova.github.io/tags/NLP/"/>
    
      <category term="deep learning" scheme="https://superlova.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>模型评估与选择——周志华《机器学习》CH2</title>
    <link href="https://superlova.github.io/2019/06/21/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9%E2%80%94%E2%80%94%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8BCH2/"/>
    <id>https://superlova.github.io/2019/06/21/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9%E2%80%94%E2%80%94%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8BCH2/</id>
    <published>2019-06-21T03:26:15.000Z</published>
    <updated>2020-03-19T01:36:52.124Z</updated>
    
    <content type="html"><![CDATA[<p>模型如何评估，选择标准是什么？<br>先让我们了解一下常见的衡量标准</p><p>错误率+精度=1</p><h3 id="误差："><a href="#误差：" class="headerlink" title="误差："></a>误差：</h3><p><strong>训练误差/经验误差</strong> training/empirical error<br><strong>泛化误差</strong> generalization error</p><p>训练误差低，泛化误差不一定低。这其中牵扯到过拟合和欠拟合的问题。</p><p><strong>过拟合</strong>：过分学习，将训练样本中不属于规律的的噪声也一并学习的现象。<br>防止过拟合，一般采用将数据集分成训练集和测试集，利用训练集训练模型，利用测试集拟合泛化误差的办法。</p><p><strong>测试误差</strong> testing error</p><h3 id="划分数据集的方法"><a href="#划分数据集的方法" class="headerlink" title="划分数据集的方法"></a>划分数据集的方法</h3><h4 id="样本划分之留出法-hold-out"><a href="#样本划分之留出法-hold-out" class="headerlink" title="样本划分之留出法 hold-out"></a>样本划分之留出法 hold-out</h4><p>将样本分成互斥的两部分S,T<br>用S训练，用T测试。分割比例自己确定。<br>需要注意的是，必须保证S、T同分布，建议采用<strong>分层采样</strong>stratified sampling，即数据集中的每个类别雨露均沾。<br>另外可以随机划分若干次，防止单次划分出现极端采样结果。随机次数越高，结果的<strong>保真性</strong>fidelity越高。</p><h4 id="样本划分之交叉验证-cross-validation"><a href="#样本划分之交叉验证-cross-validation" class="headerlink" title="样本划分之交叉验证 cross validation"></a>样本划分之交叉验证 cross validation</h4><p>将数据集采用分层划分，分成若干个互斥的小数据集。每个小数据集都当一次测试集，其他数据集组成新训练集。如果分割成k个小数据集，则这种验证方法会做k个不同的划分。因此又称为k-fold 交叉验证。</p><p>极端情况是留一法 leave one out，即k=|D|。</p><h4 id="样本划分之自助法-bootstrapping"><a href="#样本划分之自助法-bootstrapping" class="headerlink" title="样本划分之自助法 bootstrapping"></a>样本划分之自助法 bootstrapping</h4><p>从D中进行m次<strong>放回抽样</strong>，形成新的小数据集D’,理所应当地，新数据集内可能有重复元素，即<script type="math/tex">|unique(D')|\leq m</script></p><p>大数据集中的一个元素x不被选中的概率是<script type="math/tex">\mathbb{P}\{x\in \mathit{D}\cap x\notin \mathit{D}'\}=(1-\frac{1}{m})^m</script>，此时如果m取得越多，概率就越趋近于<script type="math/tex">\lim_{m\rightarrow\infty}(1-\frac{1}{m})^m=\frac{1}{e}</script>。</p><p>最后可以利用D’训练，用D/D’测试。此种抽样方法又称为<strong>包外估计</strong> out of bag estimate，适用于|D|很小的情况。</p><h3 id="如何判断模型的好坏？"><a href="#如何判断模型的好坏？" class="headerlink" title="如何判断模型的好坏？"></a>如何判断模型的好坏？</h3><p>为防止专有名词混淆，此处主要采用英文术语。<br>对于二分类模型，有以下评价模型的标准：</p><p>accuracy：模型结果与真实值相同的比率。中文称之为<strong>精度</strong>。</p><p>precision：模型所得结果中正例比率。中文称之为<strong>准确率</strong>。若想准确率提升，直观的方法是只挑选自己十分确定的样本。所谓不打无准备之仗。不过这样肯定会放过很多原本是正例的样本。</p><p>recall：正例中模型结果占比。中文称为<strong>查全率</strong>、<strong>召回率</strong>。想提高查全率，就要把所有疑似样本全都收集进来，所谓宁杀一千不放一个。这样显然也会提高误杀率。</p><p><strong>PR曲线</strong>：即准确率-查全率曲线。对于预测模型来说，对未知样本的预测，准确率和查全率往往不可兼得。呈现一个这种曲线：</p><p><img src="/2019/06/21/模型评估与选择——周志华《机器学习》CH2/2019-06-21-11-58-57.png" srcset="/img/loading.gif" alt></p><p>模型对每个样本会给出自己的判断，并且还会有自己的置信度。我们可以按照置信度排序，就可以做出PR曲线。</p><p>只有PR曲线，我们可以说模型C最差，因为这条曲线完全被A或B模型的曲线所包围。但是不好判断A红线与B黑线的性能，因为二者有交叉。这种情况有三种度量：</p><p>求<strong>曲线下面积</strong>是一种思路，不过有比较高的计算成本，更喜欢采用的是<strong>平衡点</strong>Break-Even point，可以看到我们挑了三个小红点。靠外的模型好。另外可以采用F1度量。计算公式是<script type="math/tex">F_1=\frac{2PR}{P+R}</script>这个公式就是准确率和查全率的调和平均<script type="math/tex">\frac{1}{F_1}=\frac{1}{2}(\frac{1}{P}+\frac{1}{R})</script>。之所以取调和平均，是因为调和平均在四种平均中最小，因此更重视较小值。</p><p><img src="/2019/06/21/模型评估与选择——周志华《机器学习》CH2/2019-06-21-12-46-48.png" srcset="/img/loading.gif" alt="四大基本不等式"></p><p>对于实际问题，准确率和查全率的意义不一样。超市小偷识别系统更害怕冤枉好人，因此可能更注重准确率；而地铁检查系统可能抱着“宁查一千不放一个”的态度，更追求查全率。因此对F1评价稍作修改，我们就得到了F_beta度量指标：<script type="math/tex">F_{\beta}=\frac{(1+\beta^2)PR}{\beta^2P+R}</script>，其实这个公式就是加了权重后的调和平均<script type="math/tex">\frac{1}{F_{\beta}}=\frac{1}{1+\beta^2}(\frac{1}{P}+\frac{\beta^2}{R})</script>。$\beta&gt;1$则更注重查全率R，$\beta&lt;1$则更注重查准率P。</p><p><strong>ROC曲线</strong>是另外一个思路的评价标准，横坐标是假正例，纵坐标是真正例。其绘制方法也是将样本按照置信度排序，如果样本是真正例，则垂直向y轴正方向绘制一个单位；如果样本是假正例，则水平向x轴正方向绘制一个单位。</p><p>理想状态下，模型将所有正例排在反例前面，因此曲线应该一直往上升，升到m个正例穷尽之后，再水平到|D|-m个反例。但是往往模型会判断失误，于是就出现了这种图像：</p><p><img src="/2019/06/21/模型评估与选择——周志华《机器学习》CH2/2019-06-21-12-59-40.png" srcset="/img/loading.gif" alt></p><p>左图是无限样例下，才可能达到的光滑ROC曲线。右图是实际可能的ROC曲线。ROC曲线围成的面积称之为<strong>AUC</strong>。ROC越丰满，AUC越大，模型的判别效果越好。</p><p><strong>AUC</strong>同样也可判断模型的好坏。而且AUC实际上可以通过数值方法来近似求解，有如下公式：<script type="math/tex">AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)(y_i+y_{i+1})</script></p><p>若预测正误代价不同，可参考西瓜书“<strong>代价曲线</strong>”，此处不再赘述。</p><p><strong>假设检验</strong>模块，数学味道太浓，写成博客实用度不高。而且西瓜书上讲的也不甚明了，真正想了解假设检验的朋友，可参考《统计推断》一书或其他的数理统计教材。</p><h3 id="偏差方差分解-bias-variance-decomposition"><a href="#偏差方差分解-bias-variance-decomposition" class="headerlink" title="偏差方差分解 bias variance decomposition"></a>偏差方差分解 bias variance decomposition</h3><p>这种分解可以解释泛化性能为什么会下降到一定程度后上升，越训练越差。</p><p>偏差 bias<br>方差 var</p><p><script type="math/tex">E(f) = bias^2(x)+var(x)+\epsilon^2</script>，我们想令Ef最小。事实上训练越充分，偏差bias越小，但是方差var会提高。所以并不是训练越多越好。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;模型如何评估，选择标准是什么？&lt;br&gt;先让我们了解一下常见的衡量标准&lt;/p&gt;
&lt;p&gt;错误率+精度=1&lt;/p&gt;
&lt;h3 id=&quot;误差：&quot;&gt;&lt;a href=&quot;#误差：&quot; class=&quot;headerlink&quot; title=&quot;误差：&quot;&gt;&lt;/a&gt;误差：&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;
      
    
    </summary>
    
    
      <category term="notes" scheme="https://superlova.github.io/categories/notes/"/>
    
    
      <category term="machine learning" scheme="https://superlova.github.io/tags/machine-learning/"/>
    
      <category term="model evaluation" scheme="https://superlova.github.io/tags/model-evaluation/"/>
    
  </entry>
  
  <entry>
    <title>三星笔记本升级硬盘实录</title>
    <link href="https://superlova.github.io/2019/06/16/%E4%B8%89%E6%98%9F%E7%AC%94%E8%AE%B0%E6%9C%AC%E5%8D%87%E7%BA%A7%E7%A1%AC%E7%9B%98%E5%AE%9E%E5%BD%95/"/>
    <id>https://superlova.github.io/2019/06/16/%E4%B8%89%E6%98%9F%E7%AC%94%E8%AE%B0%E6%9C%AC%E5%8D%87%E7%BA%A7%E7%A1%AC%E7%9B%98%E5%AE%9E%E5%BD%95/</id>
    <published>2019-06-16T08:21:15.000Z</published>
    <updated>2020-03-19T01:42:38.449Z</updated>
    
    <content type="html"><![CDATA[<p>这是一篇装机实录，主要内容有：</p><ul><li>给老式（2014年左右）无光驱笔记本电脑安装固态硬盘、拆卸机械硬盘；</li><li>重装系统的坑</li><li>固态硬盘体验</li></ul><h1 id="旧本盼望新生"><a href="#旧本盼望新生" class="headerlink" title="旧本盼望新生"></a>旧本盼望新生</h1><p>很早之前就想为自己的古董笔记本提升一下性能了。我的笔记本型号是NP370R5V-S02CN，属于2014年那会儿产的机型。i5的CPU、8G的内存（其中我额外购置了4G内存条），再加上5年的使用习惯，让我对这台机器还比较满意。限制笔记本电脑性能的主要瓶颈就是硬盘了。</p><p>我是一个等等党，平时也不会在自己的电脑上运行特别复杂的程序，大部分都在服务器或者公有云上跑了。所以对笔记本电脑的需求不是那么急切。固态2块钱1G的时候我没有心动，1块钱1G的时候我还是没有心动，但是我看到西数蓝盘500G的固态只卖379元，而且5年质保时，我真的憋不住了。</p><p>之前我一直用的是windows 7的操作系统，一直没敢上windows 10，因为听说windows 10挺吃性能的。现在我打算把原来笔记本电脑上的数据备份一下之后，直接上windows 10。因此我不需要进行系统迁移，直接重装系统。</p><h1 id="部件难堪重负"><a href="#部件难堪重负" class="headerlink" title="部件难堪重负"></a>部件难堪重负</h1><h2 id="1-制作启动U盘"><a href="#1-制作启动U盘" class="headerlink" title="1) 制作启动U盘"></a>1) 制作启动U盘</h2><p>的过程，我完全按照网上说的，先到校园网下载win10专业版镜像，利用我手头上的16G空U盘和Rufus 3.5软件，将ISO镜像拷入U盘，格式化为启动盘。</p><p>此处U盘的大小一般8G以上为宜。现在是2019年，市面上8G的U盘算容量不大的了。不知道以后会不会淘汰掉。Rufus是免费软件，相同功能的软件还有UltraISO等。</p><p>需要注意的是，不要使用老毛桃等PE，虽然傻瓜式安装，但是系统不纯净。而且装系统的过程并不复杂，多踩踩坑就熟悉了。</p><h2 id="2-拆卸更换硬盘"><a href="#2-拆卸更换硬盘" class="headerlink" title="2) 拆卸更换硬盘"></a>2) 拆卸更换硬盘</h2><p>我的笔记本似乎在设计的时候就料到了用户会添加内存条和更换硬盘，因此包裹硬盘和内存区域的外壳与主板是分开的，只需拆卸一颗螺丝，即可将硬盘位和内存位暴露出来。这给我的拆卸过程减少了很多麻烦。</p><p>关机，拆后盖，连电池都不用拆卸，直接把硬盘固定位的四颗螺丝拧下来，换上固态，美滋滋。</p><p>将拆卸下来的机械硬盘放在我买的硬盘盒里面（25元），大小刚刚合适（2.5寸）。沉甸甸的，里面存了不少数据【doge】。</p><p>开始重装系统。现在的固态硬盘是空的，里面没有系统。插入U盘，按下电源键后按F2进入BIOS模式。这里开始就有坑了。</p><h2 id="3-更新操作系统"><a href="#3-更新操作系统" class="headerlink" title="3) 更新操作系统"></a>3) 更新操作系统</h2><p>首先我准备安装的是win10，原来安装的是win7。win7的磁盘引导是MBR方式，而最新的引导方式是UEFI，这两种磁盘格式化方式是不一样的，也只有当磁盘里没有任何数据的一开始，我敢将磁盘的引导方式修改一下，换作原来我真的害怕稍微操作数据就没了。所以我进行了如下设置：</p><ul><li>将Security Boot关闭</li><li>将AHCI引导换成UEFI启动</li><li>Boot Mode换成UEFI only<br>一顿操作，win10安装完成了，哈哈哈。令我没想到的事情来了！</li></ul><h2 id="4-电脑受不了Windows-10"><a href="#4-电脑受不了Windows-10" class="headerlink" title="4) 电脑受不了Windows 10"></a>4) 电脑受不了Windows 10</h2><p>安装win10后，固态硬盘的好处显现出来了，任何东西都是秒开，延迟大大的降低了。就在我享受各种操作的时候，突然电脑卡住了。</p><p>就是卡死在一瞬间，鼠标都不能动了。等了好久也没用，我长按电源键强制关机后再启动，没用，过一会儿还是死机。</p><p>我怀疑是不是我的电脑其他部件太过古老了？当时的风扇吹出来的风都烫手。但是当我放凉之后再次开机，还是会毫无征兆地死机。</p><p>我怀疑是不是我安装的软件里面有不兼容的驱动？有可能是显卡驱动之类的。因为三星官网关于我这个机型的驱动，最多支持到win7。</p><p>各种原因都查了个遍，一下午过去了，一晚上过去了，我还是没能解决这个问题。总不能是固态的问题吧？</p><p>我认真的思考了一下，西部数据蓝盘，打折出售，也有可能是卖给我了劣质盘。但是我现在没办法安装磁盘检测软件，一开电脑就死机。</p><h2 id="5-悲伤地换回windows-7"><a href="#5-悲伤地换回windows-7" class="headerlink" title="5) 悲伤地换回windows 7"></a>5) 悲伤地换回windows 7</h2><p>于是我决定，重新安装回win7，如果能用就不折腾了。</p><p>下载win7镜像，使用rufus制作启动盘，此时的分区格式就选择mbr好了。我妥协了！不折腾了。</p><p>一如既往地修改BIOS，BootMode改成Legacy。win7一会儿就安装好了。没有其他的问题。</p><p>真是邪了门了，而且用win7发热的现象也缓解了很多！</p><p>看来真的是，给老电脑更换一个新固态，好比是给老年人更换年轻人的心脏，心有余而力不足啊！</p><h1 id="体验固态硬盘"><a href="#体验固态硬盘" class="headerlink" title="体验固态硬盘"></a>体验固态硬盘</h1><p>上次有这种性能大幅度稳定提升一个档次的感觉的时候，是这台电脑安装新的内存条之后。读写速度真的是限制目前性能的一大瓶颈。</p><p>由于我的内部接口是SATA 2，所以无法发挥SATA 3接口的西数蓝盘的全部威力。不过这也在我的计算之中了，因为相对于HDD，SSD带来的提升实在是天壤之别。</p><p><img src="/2019/06/16/三星笔记本升级硬盘实录/2019-06-19-19-01-03.png" srcset="/img/loading.gif" alt></p><p>等到老娘今后有钱了，这个硬盘还能拆下来重复利用，岂不是美滋滋。</p><p>本来寻思给这篇文章加点图，算啦，反正也不是什么成功经验。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这是一篇装机实录，主要内容有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给老式（2014年左右）无光驱笔记本电脑安装固态硬盘、拆卸机械硬盘；&lt;/li&gt;
&lt;li&gt;重装系统的坑&lt;/li&gt;
&lt;li&gt;固态硬盘体验&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;旧本盼望新生&quot;&gt;&lt;a href=&quot;#旧本盼望
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="hardware" scheme="https://superlova.github.io/tags/hardware/"/>
    
      <category term="SSD" scheme="https://superlova.github.io/tags/SSD/"/>
    
  </entry>
  
  <entry>
    <title>高级操作系统——分布式系统——课程设计与实现</title>
    <link href="https://superlova.github.io/2019/06/15/%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>https://superlova.github.io/2019/06/15/%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/</id>
    <published>2019-06-15T12:15:05.000Z</published>
    <updated>2020-03-19T01:32:43.832Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h1><h2 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h2><p>尝试实现一个无连接的数据报Socket进程间通信（UDP）</p><h2 id="二、实验内容"><a href="#二、实验内容" class="headerlink" title="二、实验内容"></a>二、实验内容</h2><ol><li>创建两个进程，使用无链接的数据报Socket实现交换一个字符串。一个叫做Sender.java ，用于向一个名为Receiver.java的进程发送一个字符串。</li><li>Sender.java需要一个命令行参数，用于表示传递消息的端口号.</li><li>Receiver.java 需要一个命令行参数用于表示接受消息的端口号。</li><li>接受方需要阻塞直到从发送方收到一个消息。如果发送放在接受运行之前发送出消息，消息会丢失。这种情况在此实验中是允许的。</li><li>消息缓冲可以是定长的。如果发送的消息比消息缓冲长，接受方就看不到完整的消息。这种情况在此实验中是允许的。例如，消息缓冲的长度是5，而发送方发送一个消息 “123456789”，则接受方只能看到“12345”。</li></ol><h2 id="三、实验设计"><a href="#三、实验设计" class="headerlink" title="三、实验设计"></a>三、实验设计</h2><h3 id="实验背景："><a href="#实验背景：" class="headerlink" title="实验背景："></a>实验背景：</h3><p><strong>UDP简介</strong></p><p><a href="https://blog.csdn.net/qq_23473123/article/details/51464272" target="_blank" rel="noopener">JAVA Socket 实现 UDP 编程</a></p><p>UDP协议全称是用户数据报协议，在网络中它与TCP协议一样用于处理数据包，是一种无连接的协议。在OSI模型中，在第四层——传输层，处于IP协议的上一层。UDP有不提供数据包分组、组装和不能对数据包进行排序的缺点，也就是说，当报文发送之后，是无法得知其是否安全完整到达的。UDP用来支持那些需要在计算机之间传输数据的网络应用。包括网络视频会议系统在内的众多的客户/服务器模式的网络应用都需要使用UDP协议。</p><p>UDP协议的主要作用是将网络数据流量压缩成数据包的形式。一个典型的数据包就是一个二进制数据的传输单位。每一个数据包的前8个字节用来包含报头信息，剩余字节则用来包含具体的传输数据。</p><p><strong>什么时候应该使用UDP：</strong><br>当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 </p><p>比如，日常生活中，常见使用UDP协议的应用如下：</p><p>QQ语音、QQ视频……</p><p><strong>Java中的UDP</strong></p><p>在Java中，实现UDP连接和数据传输的类主要是DatagramPacket和DatagramSocket。</p><p>DatagramSocket类表示用来发送和接收数据报包的套接字。</p><p>数据报套接字是包投递服务的发送或接收点。每个在数据报套接字上发送或接收的包都是单独编址和路由的。从一台机器发送到另一台机器的多个包可能选择不同的路由，也可能按不同的顺序到达。</p><p>在 DatagramSocket 上总是启用 UDP 广播发送。在接收端（Receiver），DatagramSocket只需输入空闲端口即可初始化对象。在消息发送端（Sender），DatagramSocket不需要任何参数初始化，直接新建对象。</p><p>DatagramSocket对象拥有send()和receive()方法，参数是DatagramPacket对象，即发送和接收数据包。</p><p>DatagramPacket类表示数据报包。</p><p>数据报包用来实现无连接包投递服务。每条报文仅根据该包中包含的信息从一台机器路由到另一台机器。从一台机器发送到另一台机器的多个包可能选择不同的路由，也可能按不同的顺序到达。不对包投递做出保证。</p><p>发送方（sender）要负责在数据报包上面贴好标签，注明收信人（地址和端口），这样才能够准确地被收信人（receiver）收到。</p><p>在DatagramPacket包中的函数 int getLength()返回实际接受的字节数，<br>byte[] getData()返回接受到的数据。</p><p>要想接受端给发送端回信息，就需要知道发送端的IP地址InetAddress getAddress()和发送端进程所绑定的端口号int getPort()。</p><p>数据报套接字发送成功之后，就相当于建立了一个虚连接，双方可以发送数据。</p><h3 id="实验环境："><a href="#实验环境：" class="headerlink" title="实验环境："></a>实验环境：</h3><p>Intellij IDEA, JDK 1.8, Windows 10</p><h3 id="实验思路："><a href="#实验思路：" class="headerlink" title="实验思路："></a>实验思路：</h3><ol><li>新建两个类，Sender和Receiver。由于逻辑简单，具体代码可直接在main中实现；</li><li>Sender和Receiver类需要接收命令行参数，可利用Intellij IDEA的类运行设置来输入参数，利用main函数的args参数来传递命令行参数，避免了操作命令行界面的不便；<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-16-36-58.png" srcset="/img/loading.gif" alt><br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-16-37-07.png" srcset="/img/loading.gif" alt></li><li>Sender：定义地址、端口号、数据；创建数据报包，包含发送的数据信息；创建DatagramSocket对象；向服务器发送数据报包。</li><li>Receiver：创建服务器端DatagramSocket，指定端口；创建数据报，用于接收客户端发送的数据；接收客户端发送的数据；读取数据。</li></ol><h3 id="相关代码："><a href="#相关代码：" class="headerlink" title="相关代码："></a>相关代码：</h3><p><code>Sender.java</code></p><pre><code class="lang-java">public class Sender {    public static void main(String[] args) throws IOException {        /*         * 向Receiver发送数据         * java Sender 192.168.1.101 12 hello         */        // 1.定义服务器的地址、端口号、数据        if (args.length != 3) {            System.out.println(&quot;参数个数不正确！&quot; + args.length);            return;        }        System.out.println(args[0]);        System.out.println(args[1]);        System.out.println(args[2]);        InetAddress address = InetAddress.getByName(args[0]);        //InetAddress address = InetAddress.getByName(&quot;localhost&quot;);        int port = Integer.parseInt(args[1]);        byte[] data = args[2].getBytes();        // 2.创建数据报，包含发送的数据信息        DatagramPacket packet = new DatagramPacket(data, data.length, address, port);        // 3.创建DatagramSocket对象        DatagramSocket socket = new DatagramSocket();        // 4.向服务器端发送数据报        socket.send(packet);    }}</code></pre><p><code>Receiver.java</code></p><pre><code class="lang-java">public class Receiver {    /*     * 接收Sender发送的数据     * java Receiver 12     */    public static void main(String[] args) throws IOException {        // 设置缓冲区大小        int bufferLength = 5;        // 设置参数格式        if (args.length != 1) {            System.out.println(&quot;参数个数不正确！&quot; + args.length);            return;        }        // 1.创建服务器端DatagramSocket，指定端口        DatagramSocket socket = new DatagramSocket(Integer.parseInt(args[0]));        // 2.创建数据报，用于接收客户端发送的数据        byte[] data = new byte[bufferLength];        DatagramPacket packet = new DatagramPacket(data, data.length);        // 3.接收客户端发送的数据        System.out.println(&quot;****服务器端已经启动，等待客户端发送数据&quot;);        socket.receive(packet);// 此方法在接收到数据报之前会一直阻塞        // 4.读取数据        String info = new String(data, 0, packet.getLength());        System.out.println(&quot;我是服务器，客户端说：&quot; + info);    }}</code></pre><h2 id="四、实验结果与分析"><a href="#四、实验结果与分析" class="headerlink" title="四、实验结果与分析"></a>四、实验结果与分析</h2><p>编译过程略去。</p><ol><li>运行Reciever<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-16-53-22.png" srcset="/img/loading.gif" alt></li><li>运行Sender<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-16-54-43.png" srcset="/img/loading.gif" alt></li><li>此时的Receiver<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-16-55-10.png" srcset="/img/loading.gif" alt></li></ol><h3 id="实验分析："><a href="#实验分析：" class="headerlink" title="实验分析："></a>实验分析：</h3><p>缓冲区大小可以修改。修改后的缓冲区大小为5，可以看到，Sender中的消息<code>Hello!</code>发送给Receiver后，尾部的感叹号被削去。</p><p>通过本次实验，我了解了UDP连接的原理与优缺点，掌握了在Java中建立UDP连接的方法。</p><hr><h1 id="实验三"><a href="#实验三" class="headerlink" title="实验三"></a>实验三</h1><h2 id="一、实验目的-1"><a href="#一、实验目的-1" class="headerlink" title="一、实验目的"></a>一、实验目的</h2><p>尝试通过面向流模式的socket实现通信。</p><h2 id="二、实验内容-1"><a href="#二、实验内容-1" class="headerlink" title="二、实验内容"></a>二、实验内容</h2><ol><li>创建一个名为Acceptor.java的程序。此程序可以接受一个连接并用流模式socket接受一个消息。创建一个名为 Requestor.java 的程序。此程序可以请求一个连接，并使用流模式socket。</li><li>Acceptor.java 有2个命令行参数，分别用于表示本进程使用的服务器socket的端口号，以及要发送的消息。</li><li>Requestor.java 有2个命令行参数，分别表示连接acceptor的主机名和连接acceptor的端口号。</li></ol><h2 id="三、实验设计-1"><a href="#三、实验设计-1" class="headerlink" title="三、实验设计"></a>三、实验设计</h2><h3 id="实验背景：-1"><a href="#实验背景：-1" class="headerlink" title="实验背景："></a>实验背景：</h3><p><a href="https://blog.csdn.net/qq_23473123/article/details/51461894" target="_blank" rel="noopener">Java 通过 Socket 实现 TCP 编程</a></p><p><strong>TCP简介</strong></p><p>TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。</p><p><strong>Java Socket简介</strong></p><p>所谓socket 通常也称作”套接字“，用于描述IP地址和端口，是一个通信链的句柄。应用程序通常通过”套接字”向网络发出请求或者应答网络请求。</p><p>ServerSocket用于服务器端，Socket是建立网络连接时使用的。在连接成功时，应用程序两端都会产生一个Socket实例，操作这个实例，完成所需的会话。对于一个网络连接来说，套接字是平等的，并没有差别，不因为在服务器端或在客户端而产生不同级别。不管是Socket还是ServerSocket它们的工作都是通过SocketImpl类及其子类完成的。</p><p><strong>Java Socket常用方法</strong></p><p>. Accept方法用于产生”阻塞”，直到接受到一个连接，并且返回一个客户端的Socket对象实例。”阻塞”是一个术语，它使程序运行暂时”停留”在这个地方，直到一个会话产生，然后程序继续；通常”阻塞”是由循环产生的。</p><p>. getInputStream方法获得网络连接输入，同时返回一个InputStream对象实例。<br>. getOutputStream方法连接的另一端将得到输入，同时返回一个OutputStream对象实例。</p><p>注意：其中getInputStream和getOutputStream方法均会产生一个IOException，它必须被捕获，因为它们返回的流对象，通常都会被另一个流对象使用。</p><p><strong>Java 操作流对象</strong></p><p>建立Socket连接后，两台机器之间便以流模式进行通信。在Java API中，可以从其中读入一个字节序列的对象称做输入流，而可以向其中写入一个字节序列的对象称做输出流。这些字节序列的来源地和目的地可以是文件，而且通常都是文件，但是也可以是网络连接，甚至是内存块。抽象类InputStream和OutputStream构成了输入/输出（I/O)类层次结构的基础。</p><p>本次实验我选择利用Scanner作为读取流的手段，用PrintWriter作为写入流的手段。</p><h3 id="实验环境：-1"><a href="#实验环境：-1" class="headerlink" title="实验环境："></a>实验环境：</h3><p>Intellij IDEA, JDK 1.8, Windows 10</p><h3 id="实验思路：-1"><a href="#实验思路：-1" class="headerlink" title="实验思路："></a>实验思路：</h3><ol><li>新建两个类，ConnectionAcceptor和ConnectionRequestor。由于逻辑简单，具体代码可直接在main中实现；</li><li>ConnectionAcceptor和ConnectionRequestor类需要接收命令行参数，可利用Intellij IDEA的类运行设置来输入参数，利用main函数的args参数来传递命令行参数，避免了操作命令行界面的不便；</li><li>ConnectionRequestor：建立连接；接收数据；发送数据；关闭连接。</li><li>ConnectionAcceptor：接收请求；发送数据；接收数据；断开连接。</li></ol><h3 id="相关代码：-1"><a href="#相关代码：-1" class="headerlink" title="相关代码："></a>相关代码：</h3><p><code>ConnectionRequestor.java</code></p><pre><code class="lang-java">public class ConnectionRequestor {    /*     * java ConnectionRequestor 192.168.1.101 12     */    public static void main(String[] args) throws IOException {        // 检查参数个数        if (args.length != 2) {            System.out.println(&quot;Wrong parameters!&quot;);            return;        }        // 1. 建立连接        String host = args[0];        int port = Integer.parseInt(args[1]);        Socket socket = new Socket(host, port);        // 2. 接收数据        InputStream inputStream = socket.getInputStream();        Scanner scanner = new Scanner(inputStream);        String line = scanner.nextLine();        System.out.println(&quot;收到来自发送方的消息：&quot; + line);        // 3. 发送数据        OutputStream outputStream = socket.getOutputStream();        PrintWriter printWriter = new PrintWriter(outputStream, true);        printWriter.println(&quot;我已收到消息，内容是&quot; + line);        // 4. 关闭连接        socket.close();    }}</code></pre><p><code>ConnectionAcceptor.java</code></p><pre><code class="lang-java">public class ConnectionAcceptor {    /*     * java ConnectionAcceptor 12 Hello     */    public static void main(String[] args) throws IOException {        // 检查参数个数        if (args.length != 2) {            System.out.println(&quot;Wrong parameters!&quot;);            return;        }        // 1. 接受请求        int port = Integer.parseInt(args[0]);        ServerSocket serverSocket = new ServerSocket(port);        Socket socket = serverSocket.accept();        // 2. 发送数据        OutputStream outputStream = socket.getOutputStream();        PrintWriter printWriter = new PrintWriter(outputStream, true);        printWriter.println(args[1]);        // 3. 接收数据        InputStream inputStream = socket.getInputStream();        Scanner scanner = new Scanner(inputStream);        String line = scanner.nextLine();        System.out.println(&quot;服务器应答：&quot; + line);        // 4. 断开连接        socket.close();    }}</code></pre><h2 id="四、实验结果与分析-1"><a href="#四、实验结果与分析-1" class="headerlink" title="四、实验结果与分析"></a>四、实验结果与分析</h2><p>编译过程略去。</p><ol><li>运行ConnectionAcceptor<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-17-27-34.png" srcset="/img/loading.gif" alt></li><li>运行ConnectionRequestor<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-17-28-48.png" srcset="/img/loading.gif" alt></li><li>此时的ConnectionAcceptor<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-17-29-13.png" srcset="/img/loading.gif" alt></li></ol><h3 id="实验分析：-1"><a href="#实验分析：-1" class="headerlink" title="实验分析："></a>实验分析：</h3><p>通过本次实验，我了解了TCP连接的原理与优缺点，掌握了TCP和UDP的主要不同之处，掌握了在Java中建立TCP Socket连接的方法，掌握了流处理的基本方法。</p><hr><h1 id="实验四"><a href="#实验四" class="headerlink" title="实验四"></a>实验四</h1><h2 id="一、实验目的-2"><a href="#一、实验目的-2" class="headerlink" title="一、实验目的"></a>一、实验目的</h2><p>创建进程之间的多播。</p><h2 id="二、实验内容-2"><a href="#二、实验内容-2" class="headerlink" title="二、实验内容"></a>二、实验内容</h2><ol><li>MulticastSender.java用于发送多播消息给多播接收程序。多播IP地址是239.1.2.3 端口号为1234。</li><li>MulticastReceiver.java 用于接收多播消息并显示消息。</li><li>实验最终效果要求：至少开启两个以上的MulticastReceiver进程，MulticastSender发送的消息，均可被MulticastReceiver收到。</li></ol><h2 id="三、实验设计-2"><a href="#三、实验设计-2" class="headerlink" title="三、实验设计"></a>三、实验设计</h2><h3 id="实验背景：-2"><a href="#实验背景：-2" class="headerlink" title="实验背景："></a>实验背景：</h3><p><a href="https://blog.csdn.net/zhouzixin053/article/details/22823521" target="_blank" rel="noopener">java————多播编程——-MulticastSocket</a></p><p><strong>单播：</strong></p><p>一个单个的发送者和一个接受者之间通过网络进行的通信。</p><p>1、服务器及时响应客户机的请求</p><p>2、服务器针对每个客户不同的请求发送不同的数据，容易实现个性化服务。</p><p><strong>多播：</strong></p><p>一个发送者和多个接受者之间的通信。</p><p>广播特点：主机之间“一对所有”的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管你是否需要）。</p><p>1、网络设备简单，维护简单，布网成本低廉。</p><p>2、由于服务器不用向每个客户机单独发送数据，所以服务器流量负载极低。</p><p>多播的地址是特定的，D类地址用于多播。D类IP地址就是多播IP地址，即224.0.0.0至239.255.255.255之间的IP地址。</p><p><strong>多播程序设计的框架</strong></p><p>要进行多播的编程，需要遵从一定的编程框架。多播程序框架主要包含套接字初始化、设置多播超时时间、加入多播组、发送数据、接收数据以及从多播组中离开几个方面。其步骤如下：</p><p>（1）建立一个socket。</p><p>（2）然后设置多播的参数，例如超时时间TTL、本地回环许可LOOP等。</p><p>（3）加入多播组。</p><p>（4）发送和接收数据。</p><p>（5）从多播组离开。</p><p><strong>Java MulticastSocket</strong></p><p>多播通过多播数据报套接MulticastSocket类来实现</p><p>重要的构造方法：</p><pre><code class="lang-java">MulticastSocket()//创建多播套接字MulticastSocket(int port)//创建多播套接字并将其绑定到特定端口MulticastSocket(SocketAddress bindaddr)//创建绑定到指定套接字地址的MulticastSocket</code></pre><p>常用的方法：</p><pre><code class="lang-java">void joinGroup(InetAddress meastaddr)//加入多播组void leaveGroup(InetAddress meastaddr)//离开多播组void send(DatagramPacket p)//从此套接字发送数据包public void receive(DatagramPacket p)//从此套接字接收数据包</code></pre><h3 id="实验环境：-2"><a href="#实验环境：-2" class="headerlink" title="实验环境："></a>实验环境：</h3><p>Intellij IDEA, JDK 1.8, Windows 10</p><h3 id="实验思路：-2"><a href="#实验思路：-2" class="headerlink" title="实验思路："></a>实验思路：</h3><ol><li>新建两个类，MulticastSender和MulticastReciever。由于逻辑简单，具体代码可直接在main中实现；</li><li>为了体现多播的广播特性，MulticastReciever的进程要多几个，随着MulticastSender的启动，全部收到信息才行。</li><li>MulticastSender：新建多播连接；构造数据包；广播数据；关闭连接。</li><li>MulticastReciever：新建多播连接；构造数据包；接收数据；关闭连接。</li></ol><h3 id="相关代码：-2"><a href="#相关代码：-2" class="headerlink" title="相关代码："></a>相关代码：</h3><p><code>MulticastSender.java</code></p><pre><code class="lang-java">public class MulticastSender {    public static void main(String[] args) throws IOException {        // 新建多播连接        int port = 1234;        String address = &quot;239.1.2.3&quot;;        MulticastSocket multicastSocket = new MulticastSocket(port);        InetAddress groupAddress = InetAddress.getByName(address);        multicastSocket.joinGroup(groupAddress);        // 构造数据包        byte[] message = &quot;Hello!&quot;.getBytes();        DatagramPacket datagramPacket = new DatagramPacket(message, message.length, InetAddress.getByName(address), port);        // 广播数据        multicastSocket.send(datagramPacket);        // 关闭连接        multicastSocket.close();    }}</code></pre><p><code>MulticastReciever.java</code></p><pre><code class="lang-java">public class MulticastReciever {    public static void main(String[] args) throws IOException {        // 新建多播连接        int port = 1234;        String address = &quot;239.1.2.3&quot;;        MulticastSocket multicastSocket = new MulticastSocket(port);        InetAddress groupAddress = InetAddress.getByName(address);        multicastSocket.joinGroup(groupAddress);        // 构造数据包        byte[] message = new byte[1024];        DatagramPacket datagramPacket = new DatagramPacket(message, message.length, InetAddress.getByName(address), port);        // 接收数据        multicastSocket.receive(datagramPacket);        System.out.println(&quot;接收到了广播消息：&quot; + new String(message));        // 关闭连接        multicastSocket.close();    }}</code></pre><h2 id="四、实验结果与分析-2"><a href="#四、实验结果与分析-2" class="headerlink" title="四、实验结果与分析"></a>四、实验结果与分析</h2><p>编译过程略去。</p><ol><li>运行MulticastReciever（6个）<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-17-45-12.png" srcset="/img/loading.gif" alt></li><li>运行MulticastSender<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-17-46-17.png" srcset="/img/loading.gif" alt></li><li>此时的MulticastReciever<br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-17-46-34.png" srcset="/img/loading.gif" alt><br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-17-46-48.png" srcset="/img/loading.gif" alt><br><img src="/2019/06/15/高级操作系统——分布式系统——课程设计与实现/2019-06-15-17-47-02.png" srcset="/img/loading.gif" alt><br>剩下三个略去不表，结果相同。</li></ol><h3 id="实验分析：-2"><a href="#实验分析：-2" class="headerlink" title="实验分析："></a>实验分析：</h3><p>通过本次实验，我了解了多播的原理和相对于单播的优点，掌握了在Java中建立多播MulticastSocket连接的方法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;实验二&quot;&gt;&lt;a href=&quot;#实验二&quot; class=&quot;headerlink&quot; title=&quot;实验二&quot;&gt;&lt;/a&gt;实验二&lt;/h1&gt;&lt;h2 id=&quot;一、实验目的&quot;&gt;&lt;a href=&quot;#一、实验目的&quot; class=&quot;headerlink&quot; title=&quot;一、实验目的&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="record" scheme="https://superlova.github.io/categories/record/"/>
    
    
      <category term="distribute system" scheme="https://superlova.github.io/tags/distribute-system/"/>
    
      <category term="OS" scheme="https://superlova.github.io/tags/OS/"/>
    
      <category term="java" scheme="https://superlova.github.io/tags/java/"/>
    
  </entry>
  
</feed>
